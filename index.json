[{"categories":["自媒體經營"],"content":"哈囉，我是古古，這封信是每月一次的自媒體月報，主要分享我經營《古古的後端筆記》個人品牌的幕後秘辛。\n正如標題所提到的，這週開始準備要暫時休刊了🥹，詳情我會在下面說明，上面一樣是先記錄成長人數 \u0026amp; 這兩個月發過的文章。\n2025.5～6 月粉絲追蹤數、電子報訂閱人數 # 這兩個月的粉絲成長人數如下：\n這兩個月撰寫的電子報主題、文章 # 這邊記錄了我這兩個月撰寫了哪些電子報和文章，大家如果對於其中的內容有興趣的話，也可以前往查看：\nDocker 常用指令介紹 + 第一個 Docker 程式 為 Spring Boot 生成 Docker image（Multi-stage build） 終身免費的 VM 服務！Google Cloud 免費方案分享 近況更新 # 正如標題所提到的，我最近下了一個艱難的決定，就是要暫時休刊《古古的後端筆記》電子報了🥹，目前預計會暫時休刊一年（嗚嗚QQ），後續如果有機會復刊的話，也會再發信通知大家我回來了～。\n那麼，也來聊一下為什麼想要暫時休刊吧！\n之所以會做這個決定，主要原因還是因為我最近又換了新工作，而因為新工作有部分會涵蓋到 Frontend 的開發，因此同時要「上手新工作的內容」+「產出後端學習筆記」這兩件事，感覺有點負荷不過來了😭。\n所以最終左思右想，想說既然當初決定回來工作了，那就還是把工作擺第一優先吧！先把自己的本職做好，有多餘的時間再投入到自媒體上和大家分享內容。這也是為什麼休刊時間暫時會定一年的關係，希望在上手工作內容之後，還能夠有機會回來和大家一起每週學習後端新知。\n不過我真的要吐嘈一下，我覺得自媒體和工作這兩件事真的是死循環欸\u0026hellip;.，要工作後才能有更多自媒體內容可以分享，但是開始工作後又會壓縮到自媒體寫稿的時間，能夠長期兼顧這兩項的真的是神人，請接受我的 respect 🙏。\n總之，很感謝大家這段時間的陪伴🥹🥹🥹，如果之後有機會復刊的話（或是不定期發刊），也都會直接發送到大家的信箱的～另外私訊的部分還是可以歡迎隨時私訊我！Threads 上和 Facebook 上我也偶爾會出沒的，如果有捕捉到我歡迎隨時跟我閒聊XD。\n另外這次電子報的暫停不是自媒體的終點！！我把它當成一個蓄積更多能量的機會，等到在工作中有更多的體悟、有更多實戰的經驗，說不定到時候寫出來的文章也可以更有深度。\n我還是很期待新工作的挑戰的💪，一起變強！\n","date":"2025-07-07","objectID":"07a50fad6e457f40c5b65f71a02f1d31","title":"軟體工程師的自媒體之路 - 2025.5～6 月報（暫時休刊）","url":"https://kucw.io/blog/as-a-content-creator/monthly-report-202505-06/"},{"categories":["其他技術分享"],"content":"在技術分享的過程中，我發現很多人想要入門練習 VM、或是想要找一個免費的雲端主機來部署程式，但是卻不知道要去哪裡找這種資源。\n而剛好我已經用 Google Cloud 的免費服務很久了，使用體感還滿不錯的！！所以這篇文章就來跟大家分享一下，要如何免費使用 Google Cloud 所提供的 VM 服務，免費部署你所寫的程式。\n目錄 什麼是 Google Cloud 的終身免費方案？ 如何創建免費的 Compute Engine？ 如何登入進 Compute Engine 的 VM 裡？ 如何將程式上傳到此 VM 中？ Google Cloud 的終身免費方案總結 結語 什麼是 Google Cloud 的終身免費方案？ # 其實各大雲端服務廠商如 GCP（Google Cloud Platform）、AWS（Amazon Web Service）、阿里雲\u0026hellip;等等，通常都會提供 12 個月的免費方案，目的是讓你在這一年期間試玩雲端上的服務，進一步轉化成他們的付費用戶。\n不過我們今天要用的不是這個！而是真・永久免費方案，即是 Google Cloud 提供的 Free Tier 方案，其中就有一項是針對 Compute Engine 的規範，提供我們每個月可以使用：\n一個 e2-micro 的 VM（地點必須選擇 us-west1、us-central1、us-east1） 30 GB 的標準硬碟 HDD 對外網路量 1GB 所以簡單來說，只要我們在創建 VM 時，選擇最小的 e2-micro 來創建，並且乖乖的將 VM 創建在美國內部、而且不使用高速的 SSD 硬碟，這樣就可以永久免費享用那台 VM 的服務。\n以我個人的使用經驗來說，我曾經用這台 VM 開發過 LINE Bot、Discord Bot 的程式，除了要連線進去 VM 會有一點卡頓感之外，在程式運作期間的 response time 其實都滿快的！！\n所以如果是要做為 VM 的開發練習、部署 side project 的雲端主機、部署個人網站\u0026hellip;等等，e2-micro 應該都還滿夠用，但如果要做更大型的開發可能就不太適合這樣（但想想也是啦，畢竟是很初階的 VM，能夠使用就要感謝了XD，如果要做大型的開發還是得乖乖付費）。\n如何創建免費的 Compute Engine？ # 補充：經實測，現在要綁定信用卡才能使用 Compute Engine 的服務，如果大家要繼續往下操作的話，會需要先準備好一張信用卡 \u0026amp; 個人資訊，如果暫時不想提供的話，那就先看看這篇文章，了解一下流程就好～。\n了解了 Google Cloud 所提供的免費資源額度之後，接下來我們就實際到 Google Cloud 中，來創建一個免費的 Compute Engine（即是 VM 服務）出來吧！\n首先要先打開 https://console.cloud.google.com/ 進到 Google Cloud 的控制台，接著點擊左上角的「選取專案」，然後選擇「新增專案」。\n接著專案名稱可以隨意填，好了之後就按下「建立」，這樣子就可以在 Google Cloud 中建立一個專案，後續就可以在裡面使用 Compute Engine 的服務創建 VM。\n創建好專案之後，接著要再點擊一次上面的「選取專案」，然後選擇剛剛所創建出來的 Project。\n接著展開左邊的側邊欄，然後選擇「Compute Engine」裡面的「VM 執行個體」。\n此時會打開 Compute Engine API 的啟用畫面，就點擊「啟用」，然後等他跑一下。\n補充：如果你是第一次使用 Google Cloud 的服務的話，這裡就會顯示「必須啟用計費功能」，然後會把你導去綁定信用卡 \u0026amp; 強制啟用 300 美元的試用\u0026hellip;.，我自己是已經有綁過信用卡 + 用過 300 美元的試用，所以現在不會再問我了，但第一次使用可能會需要填滿多資料 + 滿多步驟，這裡大家可以自由斟酌是否要填寫相關的資訊給 Google（不過如果不填寫的話後面也沒辦法做就是了😂）。\n等他跑完之後，理論上大家就會被跳轉到下面這個「VM 執行個體」的頁面，如果沒有被跳轉過來的話，也可以跟前面的步驟一樣，先展開左邊的側邊欄，然後選擇「Compute Engine」裡面的「VM 執行個體」，就一樣可以進到這個畫面。\n接著點擊上方的「建立執行個體」，就可以開始創建一個 VM。\n然後重點來了！！！接下來的每個步驟都要小心選擇，如果沒有好好選的話，可能就會不小心選用到高價的服務，月底帳單就要哭了🥹。\n首先 instance 的名稱可以隨意填，這就是到時候被創建出來的 VM 的名稱，區域只能選擇「us-west1、us-central1、us-east1」其中一個，建議選擇 us-west1 的地區，這在美國西岸，離台灣比較近，網路延遲會小一點。\n接著往下拉一點，然後將「機型」調整為 e2-micro，這一步非常重要！！！VM 的機型可以說是影響價格最大的關鍵因素，所以一定要選 e2-micro（微型）才對！！\n接著點擊左側的「OS 和儲存空間」，然後選擇「變更」，將我們要使用的硬碟類型變更一下。\n這裡一定要把「開機硬碟類型」改成「標準永久磁碟」（其實就是俗稱的 HDD 傳統硬碟），另外大小雖然 Google Cloud 上限是提供到 30 GB，不過經個人實測其實填 20 GB 就很夠用了。\n所以調整完硬碟之後的最終狀態會是下面這樣，\n接著再點擊左側的「網路」，然後勾選「允許 HTTP 流量」和「允許 HTTPS 流量」，他會自動在下面的網路標記添加標籤，這部分不用特別動他，讓他自動添加即可。\n接著往下拉一點，然後點擊「網路介面」中的「default」。\n並且在「網路服務級別」的地方改成勾選「標準級（us-west1）」，改好之後記得按完成。\n2025.7.15 更新：大家抱歉\u0026hellip;我沒發現到 Google Cloud 的 UI 有改版過，所以漏加了下面的設定，因此可能會導致大家莫名其妙被收了 6 元台幣😭。建議大家將之前的 VM 砍掉，重新創建一個新的，避免後續再次被 Google Cloud 收費🙏。\n改好上述的設定之後，還需要點擊左側的「資料保護」，然後選擇「無備份」，這樣子才不會啟動 Google Cloud 的備份流程（之前被多收的 6 元台幣就是這個備份快照所導致的）。\n接著再點擊左側的「觀測能力」，然後取消勾選「Ops Agent」，取消 Google Cloud 的監測系統，避免被收取額外費用。\n這樣到這邊就全部設定完畢了！因此接下來就可以按下建立，創建出這個 VM 出來了。\n此時在右邊的預估每月費用中，費用會顯示 6.91 美元左右，這個不用怕，他到時在月底帳單會自己折抵，所以月底帳單收到的費用會是 0 元，如果後續有發現被超收的情況的話，一定要趕快找 Google 申訴！\n建議也可以比對一下紅框處是否只有「2vCPU + 1GB memory」和「20GB 標準永久硬碟」這兩行，如果有其他多出來的設定都是錯誤的，之前我就是犯了這個錯\u0026hellip;。\n如何登入進 Compute Engine 的 VM 裡？ # 等他跑一段時間創建好 VM 之後，這時候就可以看到該 VM 的內部 IP、外部 IP，以及其他的相關資訊。\n如果想要登入進那台 VM 玩耍的話，只要點擊右邊的 SSH，這時 Google Cloud 就會開啟一個新的視窗，創建一個新的 SSH 連線給我們。\n因此只要在新視窗中點擊「Authorize」：\n就可以直接透過此視窗開啟 SSH 連線，登入到 V","date":"2025-06-03","objectID":"79e74e49cb7f0c5690d9604038fc2553","title":"終身免費的 VM 服務！Google Cloud 免費方案分享","url":"https://kucw.io/blog/gcp-free-tier/"},{"categories":["Spring Boot"],"content":"本文介紹要如何使用 Dockerfile 的 Multi-stage build 寫法，為 Spring Boot 生成更精簡的 Docker image。\n目錄 什麼是 Multi-stage build？ 在 Spring Boot 中使用 Multi-stage build 來生成 image 如何知道要把 src 複製到 /root/src 底下？ 結語 什麼是 Multi-stage build？ # 在生成 docker image 時，通常會透過撰寫 Dockerfile 來生成，而 Dockerfile 有兩種寫法可以用，一種就是用基本的 Dockerfile 寫法，另一種則是更進階的 Multi-stage build 寫法。\n針對這種需要編譯的程式語言（ex: Java、C++），用 Multi-stage build 會更好，因為 Multi-stage build 的概念是「依序 build 多個 image，但是只取最終的 image 來生成」。\n所以就可以先在前面的 Build stage 中先編譯 Spring Boot 檔案，此時在這個 image 裡面會有許多跟「執行」無關的檔案，像是 src、pom.xml、target 資料夾中的一堆編譯檔\u0026hellip;等等，這些檔案其實跟執行無關，跟執行真正有關的就只有 .jar 檔而已。\n而在 Build stage 執行完之後，就可以馬上把這個 .jar 檔拉到 Package stage 裡面，並且最終只生成 Package stage 的 image 出來，這樣子中間那些編譯檔就不用也被包進 image 裡面，徒增 image 大小了，讚！！\n另外補充一下，其實 Build、Package 這些名稱完全就是自己想叫什麼就叫什麼，沒有任何規範，只是一個概念而已，實際上可以有多個 stage，並且每個 stage 的名字可以自由取名。\n在 Spring Boot 中使用 Multi-stage build 來生成 image # 要在 Spring Boot 使用 Dockerfile 來 build image 的話，首先要先在 Spring Boot 的資料夾底下創建一個 Dockerfile （注意是要放在和 src 平行的層級，不是放在 src 裡面）。\n然後就可以在 Dockerfile 中撰寫 Multi-stage build 的程式：\n# -- build stage -- # 在 build 階段可以挑選 maven:3.9.0-eclipse-temurin-17 當作基底 image，他裡面已經預裝好 Maven 和 Java 17，讚！（所以挑 image 真的也是一門藝術，挑到對的 image 就可以省去很多自己安裝的步驟） # 記得最後面一定要加 AS xxx，這樣才能使用 Multi-stage build 的功能 FROM maven:3.9.0-eclipse-temurin-17 AS build # 拉取必要的 source code 和 pom.xml 進到 image 裡面（即是把 src 底下的所有程式複製到 image 的 /root/src 中，把 pom.xml 複製到 image 的 /root 裡） # 至於如何知道要放在 /root 下而不是放在 /usr 下，下面會講 COPY src /root/src COPY pom.xml /root # cd 到 /root 資料夾裡面，並且執行 mvn build Spring Boot WORKDIR /root RUN mvn clean package -Dmaven.test.skip=true # -- package stage -- # 因為在執行階段其實只需要 jre 就好，不需要整個 jdk 都拉進來，所以這裡採用的是 eclipse-temurin:17-jre，可以讓 image size 變得更小，選 image 的藝術 again FROM eclipse-temurin:17-jre # 偷 build 階段生成好的 .jar 檔進到此 image 裡面，所以就是複製 build 階段的 /root/target/*.jar 過來，並且將他改名成 app.jar COPY --from=build /root/target/*.jar app.jar # 聲明要開啟 8080 port EXPOSE 8080 # 指定運行此 package image 的指令 CMD [\u0026#34;java\u0026#34;, \u0026#34;-jar\u0026#34;, \u0026#34;app.jar\u0026#34;] 寫好之後就可以在 Spring Boot 中開啟 terminal，然後執行 docker build -t my/springboot:1.0.0 .，表示要運行當前的 Dockerfile，生成此 Spring Boot 程式的 image 出來（注意此處只會生成最終的 package image 出來，前面的 build image 就會被丟掉了）。\n此時就會在本機中生成一個 my/springboot:1.0.0 的 image 出來，接著只要執行 docker run -p 8080:8080 my/springboot:1.0.0，就可以用 docker 執行 Spring Boot 程式了，讚！\n如何知道要把 src 複製到 /root/src 底下？ # 在撰寫 Dockefile image 時，最常見的困擾就是「不知道要把檔案複製到哪裡去」。\n舉例來說，像是在上面的 build 階段時，就必須要把 Spring Boot 的 src 複製到 build image 中的 /root/src 底下，然後要把 pom.xml 複製到 /root 底下：\n# 使用 maven:3.9.0-eclipse-temurin-17 當做基底 image FROM maven:3.9.0-eclipse-temurin-17 # 複製 src 底下的程式到 image 的 /root/src 中，複製 pom.xml 複製到 image 的 /root 中 COPY src /root/src COPY pom.xml /root 之所以會知道要複製到這些位置，除了靠經驗傳承之外，其實也可以透過爬 Docker Hub 上的 image 介紹得知。\n以 maven:eclipse-temurin 為例，在 maven image 中的第 27、28 行就有定義 ARG USER_HOME_DIR=/root 和 ENV MAVEN_CONFIG=/root/.m2，所以其實這個 image 預設的 user home 就是 /root，而不是 /usr，因此才會把 src 程式複製到 /root 底下。\n所以如果想要客製化自己的 settings.xml 的話，那就要把 setting.xml 複製到 /root/.m2/setting.xml 的位置，這樣才會真的生效！\n因此在用任何 image 時，建議也可以來 Docker Hub 中查看 image 的介紹，可以更透徹的了解這個 image 中的系統結構。\n結語 # 這篇文章我們介紹了如何使用 Dockerfile 去生成 Spring Boot 的 image，並且採用了 Multi-image build 的技術，減少最終生成的 image 大小。\n如果你對後端技術有興趣的話，也歡迎免費訂閱《古古的後端筆記》電子報，每週二為你送上一篇後端","date":"2025-05-22","objectID":"afdc317a4bd1909d84c3d0eefa7e58b4","title":"為 Spring Boot 生成 Docker image（Multi-stage build）","url":"https://kucw.io/blog/springboot-docker-image/"},{"categories":["其他技術分享"],"content":"初入門 Docker 時，可能會對 Docker 中有哪些指令感到眼花撩亂，這篇文章會介紹如何運行你的第一個 Docker 程式，並且介紹 Docker 的常用指令有哪些。\n如果只想查看 Docker 常用指令的介紹，可以直接點擊 Docker 常用指令 跳轉到下方。\n目錄 Docker 中的 Image、Container、Registry 的用途 運行第一個 Docker Container 安裝 Docker Desktop 下載 Docker Image Docker 常用指令介紹 pull 指令（下載 image） run 指令（創建並運行 container） start/stop 指令（運行/結束 container） ps -a 指令（查看所有 container 的運行狀態） exec 指令（對正在運行的 container 下達指令） logs 指令（查看該 container 輸出的 log） inspect 指令（查看該 container 的詳細資訊） rm 指令、rmi 指令、images 指令 Docker 常用指令總結 結語 Docker 中的 Image、Container、Registry 的用途 # 在 Docker 中，Image、Container、Registry 是很常出現的三個名詞：\n1. Image（映像檔）\n大家可以把 image 想像成是任何一段程式（或是一個 .jar 檔），所以當我們作為 Developer 寫完程式之後，就可以將這段程式封存成一個 image，並且打上一個 tag 的編號 x.x.x（這個效果就等同於 Maven 的版號）。\n2. Container（容器）\nContainer 的概念類似於「買一台新電腦，然後在裡面運行 image 裡的程式」，在 Docker 中可以運行許多個 Container，每一個 Container 都是一個獨立的環境。\n3. Registry（倉庫）\n可以把 Registry 想像成一個雲端倉庫，裡面會存放所有 image 們（概念等同於 Maven 需要有一個地方存放 .jar 檔），所以不管是要 push image 上去、還是要 pull image 下來，都是在跟 Registry 倉庫溝通。\nDocker 官方的 Registry 叫做 Docker Hub，預設就是會從這個地方下載 image 下來，或是公司內部也很常見會建置私人的 Registry，存放公司內部的 image 們。\n運行第一個 Docker Container # 安裝 Docker Desktop # 要在電腦上運行 Docker 的話，首先要先安裝 Docker Desktop 這個軟體，因此大家可以先進到 Docker 官網，然後根據自己的電腦系統下載對應的 Docker Desktop（建議大家也可以順便辦一下 Docker 的帳號，等一下可以登入進 Docker Desktop 中）。\n下載好 Docker Desktop 之後，接著就可以在 terminal 中輸入指令，從 Registry（倉庫）中拉取想要的 image 下來，並且使用該 image 生成 container 來運行。\n補充：安裝好 Docker Desktop 之後，記得要執行他才可以，他一定要在背景運行著，這樣等等我們輸入的指令才會生效。\n所以如果等等在執行下面的 docker 指令時看到 Cannot connect to the Docker daemon at unix:///Users/kujudy/.docker/run/docker.sock. Is the docker daemon running? 的錯誤，就表示你忘記執行 Docker Desktop 軟體了。\n下載 Docker Image # 在 Docker 官方的 Registry Docker Hub 中，裡面提供了各式各樣的 image 供大家下載。\n舉例來說，在 Docker Hub 中有一個 image 叫做 hello-world（沒錯就叫這個名字），此時點擊他右邊的 Copy 就可以複製拉取這個 image 的指令。\n只要在 terminal 中貼上這段指令（或是自己手動輸入 docker pull hello-world），就可以下載 hello-world 這個 image 下來。\n此時如果回到剛剛安裝的 Docker Desktop 查看一下的話，就可以看到在 Images 中出現了 hello-world 這個 image 了，這就表示我們下載了 hello-world 這個 image 映像檔到我們的電腦中。\n而要運行這個 image 的話，只需要在 terminal 中再輸入 docker run hello-world，就可以用 hello-world image 去生成一個 container 出來，並且 Docker 就會去執行這個 container 中的程式，因此最終就會輸出如下的資訊在 console 上。\n這個 image 比較簡單，就只是輸出文字在 console 上而已，其他的 image 有各式各樣的功能可以使用，基本上熱門的服務如 nginx、redis…等，都有 image 可以用。\n順便一提，此時如果回到 Docker Desktop 上查看的話，就可以看到在 Containers 區中多了一個容器出來，他上面就會寫這個 container 的 id 是多少（即是 f10ff7cdfb54）、以及這個 container 是從哪個 image 生成出來的（即是 hello-world image）。\n所以其實安裝了 Docker Desktop 之後，我們就能透過 Docker Desktop 的好用介面，一目瞭然現在到底下載了哪些 image、以及有哪些 container 是正在運行著的，算是方便我們管理這樣（不過這些功能也完全可以用 terminal 指令來查看，就看大家喜歡哪一種）。\nDocker 常用指令介紹 # 成功運行起第一個 Docker 程式之後，接下來也來介紹一下 Docker 中常用的指令有哪些。\npull 指令（下載 image） # docker pull [image name]:[image tag]：從 Registry 中下載 image 到本機電腦。\n如果想要從遠端倉庫中下載某個 image 時，就要用 docker pull 來下載，像是 docker pull nginx 就可以下載 nginx 這個 image 下來。\n另外在下載 image 時，也可以特別指定要下載的 image 是哪個版本（版本在 docker 中稱為 tag）。\n舉例來說，在下載 nginx 時就可以輸入 docker pull nginx:1.28，表示要下載 tag 為 1.28 的 nginx image 下來，這裡的 1.28 就等同於是版本號。\n如果沒有指定版本的話，預設就是下載 latest 這個 tag 下來（表示當前的最新版），所以 docker pull nginx 和 docker pull nginx:latest 是完全一樣的。\n# 這兩個下載的 image 一模一樣 docker pull nginx docker pull nginx:latest 不過在實務上，建議大家在下載和使用 image 時，一定要特別指定要使用的是哪個 tag，不要用無腦用 latest 最新版，這樣很容易會遇到版本升級導致的問題…這是特別要注意的地方！！\nrun 指","date":"2025-05-20","objectID":"4e6342b9b8802362f355ae31117b400c","title":"Docker 常用指令介紹 + 第一個 Docker 程式","url":"https://kucw.io/blog/docker-command/"},{"categories":["自媒體經營"],"content":"哈囉，我是古古，這篇文章是每月一次的自媒體月報，主要分享我經營《古古的後端筆記》個人品牌的幕後秘辛，如果你也對於「自媒體創業」有興趣的話，歡迎繼續閱讀本文～\n補充：如果想了解《古古的後端筆記》電子報的起源，也可以先查看創刊號的文章。\n2025.3～4 月粉絲追蹤數、電子報訂閱人數 # 這兩個月的粉絲成長人數如下：\n2025/2/25 人數 2025/4/29 人數 3 月份總成長人數 4 月份總成長人數 Facebook 粉專追蹤數 4607 4674 +37 +30 電子報訂閱人數 3079 3348 +155 +114 Threads 粉絲追蹤數 8135 8732 +391 +206 IG 粉絲追蹤數 688 747 +34 +25 本月撰寫的電子報主題、文章 # 這邊記錄了我這兩個月撰寫了哪些電子報和文章，大家如果對於其中的內容有興趣的話，也可以前往查看：\nCron 是什麼？定時任務的語法怎麼寫？ CDN 是什麼？一次搞懂 CDN 的用途和三大好處 Elasticsearch 是什麼？認識地表最強的全文搜尋工具！ Elasticsearch 進階用法，如何透過 function_score 自定義排序結果？ 近況更新 # 雖然自媒體月報已經有點快被我拿來當成個人生活的抒發😂，但是還是有一個消息想跟大家更新一下，就是我已經找到工作啦～\n其實更準確的說是我已經入職一陣子了，只是想說剛好趁著月報的機會和大家更新一下近況這樣，很感謝大家一路以來的關心，不管是 FB 私訊還是電子報的回信我都有收到，也特別感謝中間有幫忙牽線分享面試機會的古粉們🥹（揪甘心），一路上遇到很多貴人相助，心中只有萬分感謝😭（但拜偷別私訊我問我在哪上班，暫時不方便透露🥹）。\n是說我本來有打算和大家分享這次找工作被問到的問題有哪些，但是考慮到各種因素最後還是作罷（怕牽扯到法律問題的話會有點麻煩，所以只能跟大家說聲抱歉了\u0026hellip;.）。\n然後也跟大家分享一下這份新工作吸引我的地方在哪吧！這份新工作的內容其實會有點偏 DevOps（還沒看 CI/CD 那篇電子報的快去看🤣），有很多機會可以碰 Docker + Kubernetes 的場合，覺得很有挑戰性，是以前完全沒有機會碰到的領域！而且 DevOps 的角色定義也很吸引我，可以當 Developer 和 Operations 的橋樑感覺很酷XD。\n另外我同時也在想，如果我多懂一點 Operations 的東西，將來是不是就可以將一些簡單常用的技巧分享給電子報的大家（也就是 Developer），看能不能提供一些「站在 Developer 角度必學的 Operations 知識」，讓 Developer 和 Operations 之間的隔閡不要再那麼大之類的？不知道XD，可能還需要更多時間來思考一下這個方向。\n總之，這份後端電子報仍舊會持續下去的！！未來的內容主要還是會圍繞在後端的主題上，頂多偶爾會講一點點 Operations 的東西而已，不會真的寫很硬的 Operations 知識，我還是希望能藉由這份電子報，和大家一起精進系統設計的相關技術💪。\n新的一年挑戰新的事物，Sharing is Learning，無限進步🚀！！\n2025.3～4 月報總結 # 以上就是這兩個月的自媒體月報了！如果有什麼想了解的也歡迎隨時回信給我，每一封信我都會看的，那我們就下個月再見啦！\n","date":"2025-05-06","objectID":"04e535d2763e740cac552d4e667169dc","title":"軟體工程師的自媒體之路 - 2025.3～4 月報","url":"https://kucw.io/blog/as-a-content-creator/monthly-report-202503-04/"},{"categories":["其他技術分享"],"content":"大家在工作上可能常常會聽到 CI/CD、持續集成、持續部署\u0026hellip;等等的名詞，但是卻不清楚這些名詞背後所代表的意義是什麼，因此這篇文章我們就來介紹一下，到底什麼是 CI/CD，以及他們之間的區別吧！\n目錄 什麼是 CI/CD？ CI（持續集成） CD（持續交付） 補充：Continuous Delivery 和 Continuous Deployment 的差別 CI/CD 總結 補充：什麼是 DevOps？ 結語 什麼是 CI/CD？ # 所謂的 CI/CD，他其實要拆分成兩個名詞來看，分別是 CI 和 CD：\nCI（Continuous Integration，持續集成） CD（Continuous Delivery，持續交付） 所以雖然 CI 和 CD 長得很像，但是他們實際上所負責的是完全不同的流程！所以接下來我們就分別來看一下，CI 到底是負責什麼部分、而 CD 又是負責哪些部分。\nCI（持續集成） # 所謂的 CI，就是指「計畫需求、實作程式、建置程式、測試程式」這四個步驟的統稱，而 CI 的終極目標，就是要讓這四件事可以被「自動化」執行，重點在「自動化」。\n舉例來說，不管你是前端工程師、後端工程師、還是 Android/iOS 工程師，只要你的工作內容是「寫程式完成客戶的需求」（客戶可以是企業用戶，也可以是一般使用者），那麼你就是屬於開發者（Developer），而 Developer 的日常任務，其實就是大家常常在做的釐清需求、寫程式、測試程式而已。\n所以 CI 並不是一個什麼新的流程，他只是希望可以把 Developer 日常的工作整合在一起，讓大家在「釐清需求 → 寫程式 → build code → 測試程式」這段路可以做得更順暢一點而已。\n因此在 CI 的流程中：\n首先會先從 plan（計畫）開始，也就是先釐清需求為何 釐清好需求之後，接著就進到 code 的環節，開始去實作程式 等到程式實作完之後，這時候就可以進到 build 環節來 build code（建置程式），通常前端會用 webpack 來 build code、後端則是用 Maven 和或是 Gradle 來 build build 完程式之後就會進到 test 環節，此時就可以運行單元測試、或是運行自動化測試，確保我們所 build 出來的 code 是能正常運行的 因此大家也可以觀察一下，當你 push code 到你們公司的 GitHub、GitLab、BitBucket 等…雲端時，常常就會觸發一些 job 去 build code、去執行單元測試，而這些自動化執行的 job，其實都是 CI 的一環！！\n也因為有了這些自動化 build code、自動化執行單元測試的 job，所以我們作為 Developer 不僅可以省去反覆手動操作的時間，也可以確保我們所撰寫的程式是已經被驗證過的，不會 merge 一份有問題的程式回 master branch。\n所以到這裡，CI 的任務就完成了，因此簡單來說，CI 只要好好守護 Developer 們能夠把程式 build 完、把測試程式 run 完，CI 就功成身退了，接下來就是要進到 CD 的戰場了！\nCD（持續交付） # 在我們進入 CD 的介紹前，大家可以先回想一下，你作為 Developer（前後端均可），是否還記得當你的 Pull Request 被 merge 之後，到底發生了什麼事嗎？如果你沒辦法很明確的說出後續每一個步驟在幹嘛，其實是非常正常的，因為「部署程式」這件事情，在職責上確實不歸 Developer 管。\n一般在分工比較細的大公司來說，會將工程師區分成兩種人：Developer（開發工程師）和 Operations（維運工程師），其中 Developer 就是負責寫程式，達成 PM 的需求，而 Operations 則是負責部署程式，將 Developer 寫的程式部署到 server 上，讓使用者可以真的用到這個程式。\n所以所謂的 CD，就是指 Operations 中的「發佈程式、部署程式、維運程式、監控程式運行狀態」這四個步驟的統稱，而 CD 的終極目標，一樣是要讓這四件事可以被「自動化」運行（這裡的自動化有一點微妙的差別，等等會介紹）。\n因此在 CD 的流程中：\n首先會從 release 開始，也就是當 Developer 的程式被 merge 之後，維運工程師就可以開始來處理發版的部分 發佈完成之後，接著就會進到 deploy 的環節，將這份程式部署到 server 上 deploy 完成之後會進到 operate 環節，管理程式是否有正常運行 最終則是 monitor 環節，持續監控程式的運行狀態，時時刻刻確保服務在線，不會中斷 所以在 CD 的流程中，可以看到幾乎全部都是在做部署程式、維護 server 的相關操作，而這裡擴展下去就可以講非常非常廣了。\n舉例來說，如果今天 server 選擇部署在 AWS 上，那麼如何更好的管理和運用 AWS 上的服務，就是 CD 要處理的部分，如果今天換成使用另一個雲端服務 GCP，那麼 CD 又會需要跟著改。\n又或是說，假設今天是使用 Docker + Kubernetes 來部署程式，那麼如何打包 image、如何設定環境變數、如何使用 Kubernetes 調度 pod…等等，這些也是 CD 要處理的部分。\n因此 CD 在玩法上可以說是更加的多樣化，追求的已經不僅僅是「把程式弄到 server 上去 run」這麼簡單而已，而是要追求「又快、又好擴展、又安全、又省錢」這種巔峰造極的境界了。\n也因為如此，近幾年的部署流程其實也是各種飛速發展，其中最熱門的大概就是 Docker + Kubernetes 這類的容器化部署了，大家如果對這方面有興趣的話，可以參考我之前寫的 Docker 介紹，或是搜尋網路上各位大大們的 Docker 教學。\n反正總而言之，CD 的任務就是要守護 Operations（維運工程師），讓維運工程師可以用最有效率的方式去部署和管理 server，同時也努力幫老闆省下最多的成本就對了！\n補充：Continuous Delivery 和 Continuous Deployment 的差別 # 了解了 CD 的概念之後，這裡也補充一下前面提到的「有點微妙的自動化」的部分。\n在 CD 中，又可以細分成 Continuous Delivery（持續交付）和 Continuous Deployment（持續部署），他們兩個之間的差別就在於「部署到 production 正式環境這一步，是否需要人工手動操作」。\nContinuous Delivery（持續交付）：部署到 production 環境需要人工手動操作 Continuous Deployment（持續部署）：全自動化，不需人工介入 像是在前面的 CI 和 CD 的介紹中，一直有提到 CI 和 CD 的終極目標是「自動化」執行，但是會不會自動化過了頭，反而導致我們所交付的程式有問題呢？\n舉例來說，假設當你所寫的程式被 merge 回 master branch 之後，假設就這樣自動化一路部署到 production 環境，中間完全沒有任何人再對他進行壓力測試、或是沒有進行服務的整合測試，可能就會出現意料之外的問題。\n還有一個問題是，有時候功能的發佈是會需要搭配商業策略的，譬如說 iOS 的新功能常常會在 iPhone 發表會上宣布，這就是一種為了商業策略而延遲發版的行為。\n因此一般在實務上，Continuous Delivery（持續交付）會是比較常見的做法（即是部署到 production","date":"2025-05-05","objectID":"6dbbf7f0cd01c961638d03e145905fc2","title":"CI/CD 是什麼？他們之間的差別在哪裡？","url":"https://kucw.io/blog/cicd-intro/"},{"categories":["Elastic Search"],"content":"Elasticsearch 除了可以用來實作一般的全文搜尋之外，如果想要實作「推薦排序」，針對多個維度綜合比較，Elasticsearch 也是支援這類的用法的！\n因此這篇文章我們就來介紹一下，要如何透過 Elasticsearch 中的 function_score，來實作自定義排序的結果吧！\n補充：如果對 Elasticsearch 不太熟悉，也可以先回頭參考 Elasticsearch 的基本介紹 Elasticsearch 是什麼？認識地表最強的全文搜尋工具！。\n目錄 回顧：什麼是 Elasticsearch？ 例子：美食地圖實作 Elasticsearch 中的推薦排序實作（使用 function_score） Elasticsearch 中的 function_score 總結 結語 回顧：什麼是 Elasticsearch？ # 所謂的 Elasticsearch，他是一個強大的「全文搜尋」（Full-Text Search）工具，讓我們可以從大量的數據中，快速找到想要的資料在哪裡。\n也因為 Elasticsearch 的專長是「全文搜尋」，所以一般通常會將他用來「架設搜尋引擎」，因此像是旅遊攻略、評論、社群貼文、電商產品….等等諸如此類的查詢，背後都很適合使用 Elasticsearch 來實作！\n不過，當大家將 Elasticsearch 應用在旅遊攻略、評論、社群貼文…等等的功能實作時，這時候就會遇到一個非常重要的問題，那就是「什麼樣內容的文章應該排在最前面？」，因此「如何調整文章的排序結果」，這就是這週我們要來探討的主題了！\n例子：美食地圖實作 # 想像一下，假設現在你要實作一個美食地圖的查詢功能，在這個美食地圖中，要提供使用者「距離搜尋」、「關鍵字搜尋」、「依照評價排序」…等相關功能，具體大家可以想像成 Google Map 中的搜尋餐廳或是 Uber Eats 中的尋找餐廳的類似功能。\n假設現在使用者查詢了「小籠包」這個關鍵字，並且想要根據「評價由大到小」來排序的話，那這個在 Elasticsearch 中很好實作，就是直接使用 order 來排序就好（邏輯類似於 SQL 中的 ORDER BY）。\n又或是使用者查詢了「小籠包」這個關鍵字，並且想要查詢他「方圓 2 公里以內」的所有小籠包餐廳，那這個在 Elasticsearch 中也很好實作，即是使用 geo_point 格式來查詢即可（詳細用法可以參考 Elasticsearch 官網，這裡先不詳細展開介紹）。\n但是！！問題來了！！！假設今天使用者選擇了「推薦排序」，那麼作為後端的我們，到底應該是把「評價較優」的店家放在前面，還是要把「距離較近」的店家放在前面呢？這真的是個好問題對吧，畢竟誰都想要排在比較前面的位置，這樣子曝光度會比較高，生意也會比其他店家更好。\n所以這時 Elasticsearch 就開始思考，有沒有辦法提供一個「多維度的評分機制」，讓我們可以根據多個維度，來決定這個店家的總分為何呢？ 答案是有的！我們可以透過 Elasticsearch 中的 function_score，對多個維度的值進行權重加總，最終計算出每一個店家的總分，因此就可以實作出「推薦排序」的功能了！\nElasticsearch 中的推薦排序實作（使用 function_score） # 補充：以下內容較為複雜，建議大家對 function_score 有個概念即可，等到後續真正用到時再回來查相關實作細節。\n在 Elasticsearch 中，有一個特別的地方，就是他會針對「每一個文件給出一個 _score 的分數」，這個 _score 就是指「該文件的匹配程度」，因此簡單來說，_score 的值越高的文件，他在搜尋的結果就會被排在越前面，這個就是 Elasticsearch 的運作機制。\n所以如果我們想要實作一個「多維度的評分機制」，根據店家距離、評價數、價格…等等的多個維度去決定一個店家的總分，那麼就是要透過 function_score 的用法，手動的去改變 Elasticsearch 的 _score 的計算方式，這樣子最終的排序結果，才會是我們期望的「推薦排序」。\n舉例來說，一個基本的 function_score 模板如下圖所示：\nGET /_search { \u0026#34;query\u0026#34;: { \u0026#34;function_score\u0026#34;: { // 主查詢，查詢完後這裡自己會有一個評分，就是 old_score \u0026#34;query\u0026#34;: {.....}, // 這裡可以寫上多個加強函數 // 每一個加強函數會產生一個 boost_score（加強 score），因此有多個 functions 就會有多個 boost_score \u0026#34;functions\u0026#34;: [ { \u0026#34;field_value_factor\u0026#34;: ... }, { \u0026#34;gauss\u0026#34;: ... }, { \u0026#34;filter\u0026#34;: {...}, \u0026#34;weight\u0026#34;: ... } ], // 決定多個 boost_score 們要怎麼合併成一個 total_boost_score \u0026#34;score_mode\u0026#34;: \u0026#34;sum\u0026#34;, // 決定 total_boost_score 怎麼和原始的 old_score 合併 \u0026#34;boost_mode\u0026#34;: \u0026#34;sum\u0026#34; } } } 如果拆解一下這個模板的話，基本上就是在 functions 的地方，可以去添加各種不同維度的評分，最終再透過 score_mode 和 boost_mode，將這些不同維度的評分給加總（或是相乘）起來，最終得到每一個店家的總分。\n所以以上面的美食地圖的功能為例，我們就可以在主 query 中寫上「小籠包」的查詢，並且在 functions 裡面，寫上我們想要根據「評價數」和「距離」分別去評分，最終再透過 score_mode 和 boost_mode，將這些分數全部加總起來，就是這個店家的最終得分 _score 了。\n因此透過 function_score 的用法，我們就可以成功的在 Elasticsearch 中實作出「推薦排序」的功能，進而去針對多個維度，去進行綜合性的比較了！\n補充：如果大家想了解更多 function_score 的具體實作，也可以參考我之前寫的 function_score 系列文章。\nElasticsearch 中的 function_score 總結 # 所以總結上述的介紹的話，如果將來我們想要在 Elasticsearch 中實作「推薦排序」這類較為複雜的排序，需要同時針對多個維度的方向來排序時，那麼就可以透過 function_score 的用法，手動的改變 Elasticsearch 中的 _score 的評分機制，最終得到我們想要的排序結果。\n並且因為 Elasticsearch 的 function_score 是可以一直往上加的，所以不管是要一個維度、還是要 N 個維度，都可以根據當下的需求來擴展，因此擴展性可以說是非常的高！\n不過，也因為 function_score 改變的是「排序的結果」，所以這個其實沒有絕對的對錯，畢竟青菜蘿蔔各有所好，你認為好吃的店家，其他人可能不覺得好吃，所以要如何調出一個「完美的 function_score 參數」，反而才是最困難的部分。\n另外也隨著 AI 的興起，使得「推薦排序」的實作不一定要透過 Elasticsearch 來實作，而是可以考慮改成 AI 的演算法來實時運算","date":"2025-04-22","objectID":"25bf5783d168cf20c0d27ae570169ead","title":"Elasticsearch 進階用法，如何透過 function_score 自定義排序結果？","url":"https://kucw.io/blog/elasticsearch-function-score-intro/"},{"categories":["Elastic Search"],"content":"Elasticsearch 可以說是長年霸佔「全文搜尋」排行榜的第一名，不管是在使用者的產品開發上、還是在內部的 log 系統中，也都常常能看見 Elasticsearch 的身影，因此這篇文章我們就來介紹一下，Elasticsearch 到底是什麼吧！\n目錄 什麼是 Elasticsearch？ 在以前的 SQL 資料庫時代 使用 Elasticsearch 之後 什麼是反向索引（Inverted Index）？ Elasticsearch 介紹 Elasticsearch 總結 補充：反向索引的實戰經驗分享 結語 什麼是 Elasticsearch？ # 首先 Elasticsearch 其實是由兩個單字 Elastic 和 Search 所組成，因此念法上就會唸成 Elastic Search，只不過官方的產品名稱是全部縮寫在一起而已。\n而 Elasticsearch 本身是一個強大的「全文搜尋」（Full-Text Search）工具，也就是一個「能夠讓你自己架設搜尋引擎」的工具。所以簡單的說，Elasticsearch 的目標就是「讓使用者能夠快速的從一堆數據中，找到他想要的資料在哪裡」，也就是搜尋引擎最重要的作用了。\n不過在我們開始介紹 Elasticsearch 到底是強在哪裡之前，我們可以先回頭來看一下，在 Elasticsearch 還沒有誕生之前，我們是如何使用 SQL 資料庫來實作「查詢」的功能的。\n在以前的 SQL 資料庫時代 # 想像一下，假設現在你要開發一個「評論」的網站，因此在你的資料庫中，就會有一張 review 的 table，裡面記錄了每一筆評論的詳細內容：\nreview_id review_text（評論內容） 1 I jumped out the brown fox 2 hello how are you 那麼問題來了，假設現在使用者輸入了 brown，要你查詢出帶有 brown 的評論，這時候你要怎麼實作？\n最直覺的做法，就是使用「SQL 的模糊搜尋 LIKE %」，從這些評論中找出到底哪些評論中包含 brown 這個單字，因此通常就會寫出類似於下方的 SQL 語法，去資料庫中查詢所有評論。\nSELECT * FROM review WHERE review_text LIKE \u0026#34;%brown%\u0026#34; 雖然上述的作法能夠查詢出帶有 brown 單字的評論，但是這個查詢的效率實在是太差了！因為模糊搜尋沒辦法使用 index 來加速查詢效率，只能呆呆的一筆一筆數據去比對，因此縱使這個方法勉勉強強能夠解決查詢的問題，但是卻解的不夠漂亮。\n所以為了更好的解決這個問題，Elasticsearch 就被發明出來了！\n使用 Elasticsearch 之後 # 在 Elasticsearch 中，一樣是會先對每一筆 review 評論建立一筆數據（在 Elasticsearch 中稱為「文件」），並且因為 Elasticsearch 是屬於 NoSQL 資料庫，所以會使用 JSON 格式來儲存該文件。\n[ { \u0026#34;review_id\u0026#34;: 1, \u0026#34;review_text\u0026#34;: \u0026#34;I jumped out the brown fox\u0026#34; }, { \u0026#34;review_id\u0026#34;: 2, \u0026#34;review_text\u0026#34;: \u0026#34;hello how are you\u0026#34; } ] 其實到這邊其實都跟上面的 SQL 資料庫一模一樣，只是 Elasticsearch 換個方式用 JSON 儲存而已，到目前為止沒有任何的差別。\n不過！！重點來了！！Elasticsearch 之所以能夠快速的查詢出「帶有 brown」的評論，就是因為 Elasticsearch 在插入一筆文件時，會預先對該文件建立「反向索引」（Inverted Index），因此之後就可以借助「反向索引」的力量，快速的找出相關評論。\n什麼是反向索引（Inverted Index）？ # 舉例來說，當 Elasticsearch 插入一筆數據 hello how are you 時，他除了正常的插入一筆文件之外，他同時也會將 hello how are you 拆分成許多不同的小單字，譬如說會拆分成 hello、how、are、you 這四個字，並且 Elasticsearch 會將這些單字「對應」到該筆評論數據上。\n因此後續當使用者查詢 hello 或是查詢 are 時，Elasticsearch 就可以去檢查反向索引，如果有任何一個命中的話（譬如說命中 hello 這個反向索引），那麼就可以根據反向索引，去找出該索引指向的真實的數據（也就是 hello how are you 這個評論），這樣子就可以快速的在大量的資料中，去找到我們想要的數據了！\n也因為在整個 Elasticsearch 的世界中，他不僅要儲存每一筆真實的評論數據之外，Elasticsearch 同時也需要為每一筆評論數據生成對應的反向索引，因此佔用的數據空間會比一般的 SQL 資料庫還要多，不過這其實也是演算法中典型的「用空間換取時間」的概念，即是先對數據進行預處理，將數據處理成好查詢的方式，等到未來需要時就可以馬上查詢，就可以達到「降低查詢時間」的終極目標了！\nElasticsearch 介紹 # 了解了 Elasticsearch 中最最最核心的「反向索引」的概念之後，我們再回頭來看 Elasticsearch 的介紹時，就可以比較看得懂了。\n所謂的 Elasticsearch，他是一個強大的「全文搜尋」（Full-Text Search）工具，目標是讓我們可以從大量的數據中，快速找到想要的資料在哪裡。而 Elasticsearch 之所以可以做到這件事，就是因為他使用了「反向索引」（Inverted Index）的設計，先對數據進行預處理，因此才能夠在查詢時達到比傳統 SQL 資料庫更高的效率。\n也因為 Elasticsearch 的專長是「全文搜尋」，所以一般通常會將他用來「架設搜尋引擎」，因此像是旅遊攻略、評論、社群貼文、電商產品\u0026hellip;等等諸如此類的查詢，背後都很適合使用 Elasticsearch 來實作！\n圖片來源： Elasticsearch 官網 而除了一般的功能開發之外，Elasticsearch 也很常拿來用在內部系統中，最常見的就是用來「收集所有系統的 log」，這樣子 DevOps 或是後端工程師就可以搭配 Kibana、Grafana 之類的 UI 介面，從 Elasticsearch 中直接查詢 log 的資料，就不用再登入每一台 server 中去找 log 了！\nElasticsearch 總結 # 所以總結來說，只要牽扯到「全文搜尋」，基本上就是 Elasticsearch 的天下（當然 FAANG 大廠自行研發的搜尋引擎除外，他們的數據量真的太大，應該不是用 ES），並且內部的 log 系統通常也都是用 ELK 三兄弟來建置，所以了解一下 Elasticsearch 的用法絕對是很吃香的！\n大家如果對 Elasticsearch 有興趣的話，後續也可以參考 Elastic 官網的文件教學，或是我很久很久以前也有寫過一些 Elasticsearch 的文章，大家有興趣的話也可以參考看看～（不過這些文章年代有點久遠，可能很多東西已經不適用了，後續有時間我再來把這部分重寫一下）。\n補充：反向索引的實戰經驗分享 # 最後再跟大家補充一個我經歷過的 Elasticsearch 反向索引的真實故事…\n前面有提到，「","date":"2025-04-08","objectID":"9ceef27dc5c29f4f1673c70906e2e1a0","title":"Elasticsearch 是什麼？認識地表最強的全文搜尋工具！","url":"https://kucw.io/blog/elasticsearch-intro/"},{"categories":["其他技術分享"],"content":"在網路全球化的趨勢下，CDN 現今已經是一個很重要的技術了，但是 CDN 的用途到底是什麼？以及使用 CDN 的好處有哪些？這篇文章我們就來詳細了解一下吧！\n目錄 什麼是 CDN（內容傳遞網路）？ 海底電纜的故事 海底電纜的限制 CDN 如何解決網路傳輸的限制？ 補充：使用 CDN 的注意事項 使用 CDN 的三大好處 1. 降低網路延遲、降低頻寬成本 2. 提升網站可靠性、平衡流量 3. 防禦資安 DDoS 攻擊 CDN 總結 結語 什麼是 CDN（內容傳遞網路）？ # 所謂的 CDN，他的全稱是 Content Delivery Network，中文翻譯為「內容傳遞網路」，而 CDN 的用途，就是 「將靜態資源（ex: 圖片、影片、JavaScript 套件）部署到全球化的節點上，讓當地的居民可以更快速的取得到這些內容」。\n不過，在了解 CDN 所帶來的好處之前，大家要先對「海底電纜」有一點基本的認識，因此下面我們就先來介紹一下什麼是海底電纜，再回頭來說明 CDN 所帶來的好處有哪些。\n海底電纜的故事 # 大家有沒有曾經好奇過，為什麼我們人明明站在台灣，但是卻能夠看到美國網友所上傳的影片或梗圖呢？這確實是透過「網路」來傳遞沒錯，但是這個「網路」，他到底是如何從美國發送到台灣的？是透過衛星嗎？還是透過高壓電？還是說是透過微波通訊來傳遞？？\n特別像是台灣這種海島來說，我們四周都是海，感覺要拉高壓電也不太可能，全部透過衛星來傳遞成本也太高了，因此所謂的「海底電纜」，就是台灣主要的對外網路連線方式。\n大家可以把「海底電纜」想像成是中華電信在台灣四周海域中所鋪設的光纖，每一條光纖會長得像是下面這樣，也就是因為有鋪設這些海底電纜，因此我們的網路訊號才可以傳遞出去，外部的網路訊號也才可以傳遞進來。\n圖片來源： Inside the Extreme Life of Divers Repairing Billion $ Underwater Cables 而其實不光是中華電信，很多大型企業如 Google、Amazon\u0026hellip;等，也都會鋪設自己的海底電纜！像是 Google 一直以來都有海底電纜的鋪設計畫，下圖就是 Google 目前為止所鋪設的海底電纜。\n圖片來源： Google Cloud 據點 而 Google 自己鋪電纜的好處是可以拉一條專線給 Google 自己的服務使用，確保未來不會因為各種因素（ex: 地緣政治）導致全球化的網路失效。\n所以在現今的網路時代下，我們人處在台灣卻可以刷著 YouTube、Instagram，觀看其他國家的人所上傳的影片，背後就是因為有海底電纜在進行網路數據的傳輸。\n海底電纜的限制 # 而說到這裡，就不得不提一下海底電纜的一些物理限制了。\n因為海底電纜畢竟還是屬於光纖網路，因此 「兩者距離越長，傳輸的時間就要越久」，這個完全是物理上的限制，現今沒有更好的方式可以解決。\n所以換句話說，即使台灣和美國之間有一條海底電纜，能夠把彼此的網路串接在一起，但是彼此傳輸的時間仍舊需要很久，可能你人在台北，傳一張圖片給高雄的朋友只要 1 秒，但是傳給海的另一邊的美國朋友卻需要 20 秒，這個就是海底電纜的網路傳輸限制，專業術語稱為 「latency（延遲）」。\n因此簡單的說的話，物理距離越遠，你們之間的網路 latency 就會越高，因此就算全球化的海底電纜能夠將你我連接在一起，但是這個使用者體驗其實是不太好的。\n所以為了解決這個問題，CDN 就出現了！！\nCDN 如何解決網路傳輸的限制？ # 基於上述的限制，現在我們知道 「物理距離越遠，傳輸的時間就要越久」，那麼，我們是不是只要把圖片放在離使用者近一點的地方，這樣子使用者就可以更快的拿到那張圖片了？沒錯！！這個就是 CDN 的核心邏輯，也就是 「將靜態資源（ex: 圖片、影片、JavaScript 套件）部署到 全球化 的節點上，讓 當地的居民 可以更快速的取得到這些內容」。\n舉例來說，當 Netflix 製作完一部新的影集之後，他除了把這個影集上傳到美國的主 server 之外（稱為 Origin Server），他還可以把這部影集也上傳到其他地區的 server（稱為 Edge Server），譬如說日本、台灣、新加坡、澳洲…等。\n因此到時候，使用者就可以「就近」挑選離他最近的 Edge Server，並且可以直接從該 Edge Server 中串流一模一樣的影集觀看，因此就可以達到「降低網路傳輸時間」的好處了！\n所以透過 CDN，Netflix 就可以在世界各地提供高品質、無延遲的影片觀看服務了！\n補充：使用 CDN 的注意事項 # 不過在這邊要再特別提醒一下，只有「靜態資源」（ex: 圖片、影片、JavaScript 套件\u0026hellip;等檔案）才能夠放在 CDN 上，借助 CDN 的力量擴散到全世界，因此像是後端程式的動態處理，這些是沒辦法放到 CDN 上面的，只能夠自己在雲端中部署。\n所以基本上在後端開發中，最常見的部署到 CDN 上的就是影片和圖片，其他像是前端的 JS 等相關檔案，因為後端不太會接觸到，所以比較少需要處理這部分。\n使用 CDN 的三大好處 # 了解了 CDN 的用途和限制之後，接下來我們也可以來看一下使用 CDN 的三大好處。\n使用 CDN 有三大好處，分別是：\n降低網路延遲、降低頻寬成本 提升網站可靠性、平衡流量 防禦資安 DDoS 攻擊 1. 降低網路延遲、降低頻寬成本 # 使用 CDN 的第一個好處，就是可以降低網路延遲和頻寬成本。\n降低網路延遲其實就是 CDN 當初被發明出來的目的，也就是上面所介紹的內容，透過將靜態資源部署在「全球化」的 Edge Server 上，就可以讓「當地的居民」就近取得到相關內容，降低網路傳輸的延遲，進而提升使用者體驗。\n而且也因為有了 CDN 之後，台灣人就可以就近取得影片，因此 Netflix 就不需要每次都把影片從美國傳到台灣，也就可以降低海底電纜的傳輸頻寬成本了。\n2. 提升網站可靠性、平衡流量 # 使用 CDN 的另一個好處，就是可以提升網站的可靠性、以及平衡相關的流量。\n舉例來說，假設 Netflix 在台灣的 CDN 節點掛掉了，那就可以趕快把台灣的流量轉移到附近地區（ex: 日本、香港、新加坡），確保台灣的 Netflix 用戶能夠繼續觀看劇集（雖然這不可避免地會多增加一些網路延遲，但是總比完全不能看好）。\n除此之外，即使台灣的 CDN 節點沒掛掉，Netflix 也可以根據台灣的尖峰流量，動態的調整香港的 CDN 來協助分攤，因為有的時候可能台灣某一陣子很瘋某個劇，流量就會大量上升，因此這時候就可以讓附近的 CDN 一起幫忙分擔流量，降低台灣 CDN 節點的負擔。\n3. 防禦資安 DDoS 攻擊 # 使用 CDN 的第三個好處，是可以防禦資安相關的 DDoS 攻擊。\n不過這部分我其實還不太熟，因此只能先貼相關的連結給大家參考（Cloudflare 官方的 CDN SSL/TLS | CDN security）。\n其實資安的部分算是使用 CDN 的附加好處啦，因為這跟 CDN 最一開始要解決的問題不太一樣，算是大家先因為「降低網路延遲」的原因用了 CDN 之後，才發現 CDN 在資安的表現上也很讚這樣，因此目前也常常會透過 CDN，來避免相關的資安攻擊。\n更新：以下是來自 Kuma 大大使用 CDN 防禦 DDoS 的實務經驗分享！大家有興趣也可以追蹤他的 YouTube 頻道：Kuma 老師的軟體工程教室。\nDDoS 我可以粗淺的補充一下，以前我前公司被打爆勒索過。\n如果你把 domain name 直接指到你的伺服器，當","date":"2025-03-18","objectID":"ff6caecc434989de506c53229349c979","title":"CDN 是什麼？一次搞懂 CDN 的用途和三大好處","url":"https://kucw.io/blog/cdn/"},{"categories":["其他技術分享"],"content":"只要是後端開發，多多少少都會有一些撰寫定時任務的需求，像是每天晚上 10 點固定處理報表、或是每 30 分鐘處理一批次的任務\u0026hellip;等等，因此這篇文章我們就來介紹一下，這個「定時任務」的語法到底要怎麼寫吧！\n目錄 什麼是 Cron？ Cron 表達式的寫法（5 個 *） 補充：Cron 表達式的進階用法 Cron 總結 補充：Spring Boot 的 Cron 表達式寫法（6 個 *） 結語 什麼是 Cron？ # 所謂的 Cron，其實是 Linux 系統下的一個定時任務管理服務，但是因為 Cron 的表達式實在是太萬用了，所以目前也很廣泛用在 GitHub Actions、Spring Boot 的 @Scheduled\u0026hellip;等框架上。\n舉例來說，只要大家有看過類似的表達式 - cron: \u0026quot;0 21 * * *\u0026quot; 或是 @Scheduled(cron = \u0026quot;0 0 21 * * *\u0026quot;) 的寫法，裡面的一堆莫名其妙的 *，其實就是 Cron 的「定時任務」的寫法！\n因此像是在上面這兩個例子中，\u0026quot;0 21 * * *\u0026quot; 指的其實就是「每天晚上 9 點整執行一次這個任務」的意思。\n不過也因為 Cron 的表達式實在是有點抽象，所以下面我們就來介紹一下 Cron 中的每一個 * 代表的意義，來徹底了解一下如何使用 Cron 寫出我們想要的時間吧！\nCron 表達式的寫法（5 個 *） # 在 Cron 中，最傳統且常見的表達式為「5 個 *」，不過因為 Spring Boot 本身的設計不太一樣，所以 Spring Boot 會採用「6 個 *」 的方式來撰寫（因此大家如果不是寫 Java/Spring Boot 的話，就只要看上半部分的 Cron 傳統寫法就好，但如果是寫 Java/Spring Boot 的話，建議也要把下面的補充部分看完）。\n而如果要寫出 Cron 的傳統表達式（5 個 * 的版本），首先必須要先寫出 5 個 *，並且每個 * 之間要用一個空白鍵隔開，所以最基本的 Cron 表達式就會像是下面這個樣子：\n* * * * * 而這 5 個 *，他們所站的每一個「位置」，就會代表不同的意思，譬如說左邊數過來第一個 * 是表示「分鐘」的意思，左邊數過來第二個 * 是表示「小時」的意思…以此類推，因此這 5 個 * 的實際意義，可以用下面這張圖來表示：\n所以舉例來說，假設 Cron 表達式為 0 16 * * *，那就是表示「我們指定在每天的 16:00」要執行一次這個任務（因為我們設定了第一個 * 為 0，第二個 * 為 16，所以就是表示我們指定要在分鐘數為 0、並且小時數為 16 的時候執行任務，因此 0 16 * * * 的結果才會是在每天的 16:00 執行任務）。\n再舉一個例子，假設 Cron 的表達式為 23 1 * * *，就是表示我們指定在「每天的凌晨 1 點 23 分」要執行這個任務。\n再再舉一個例子，假設 Cron 的表達式為 59 23 * * *，就是表示我們指定要在「每天的晚上 23:59 分」執行任務。\n所以對於 Cron 表達式而言，只要你將某一個 * 改為一個確切的數字，其實就是指定要在「那個時間點」執行任務，就只是這樣子而已！！Magic！！\n不過另外也補充一下，除了有被修改過的數字，其他維持原樣的 * 則是表示「所有」的意思，所以像是 23 1 * * *，就只有前面的 23 1 的「凌晨 1 點 23 分」是固定的，其他的 * * * 則是表示「所有」，也就是在「所有日期、所有月份、所有星期」底下的「凌晨 1 點 23 分」，都會執行當前這個任務，因此 23 1 * * * 才會被解讀成「每天的凌晨 1 點 23 分」。\n下面再舉更多的例子給大家參考：\nCron 表達式 實際意義 備註 0 21 * * * 在每天的晚上 21:00 執行一次任務 * * * * * 每分鐘都要執行一次任務 0 * * * * 在每個小時的 0 分執行一次任務（ex: 1 點 0 分、2 點 0 分…. 23 點 0 分） 0 0 * * 5 在每週五的 0 點 0 分執行任務 但一般會避免寫 0 點 0 分這種數字，因為 0 點 0 分是一天的開始，所以如果是要進行那種「當天晚上結算的任務」，改成 23:59 會比較好 59 23 * * 0 在每週日的 23 點 59 分執行任務 注意 0 是週日（Sunday），1-6 是週一到週六 30 10 1 * * 在每個月的 1 號的早上 10:30 分執行一次任務 所以透過上面的例子，我們就可以指定「現在是想要在哪一天、哪一個小時、哪一分」，去執行我們想要執行的任務了！\n補充：如果想要自己玩玩看 Cron 表達式，也可以到 Crontab.guru 這個網站玩一下，他不僅有基礎教學，還可以檢測你寫的 Cron 表達式是否正確，因此也很推薦大家在撰寫 Cron 表達式時先丟上來檢查一下，確認沒問題之後再寫進程式裡面。\n補充：Cron 表達式的進階用法 # 不過，Cron 除了有上述的常見用法之外，Cron 其實有更進階的用法，但以下這些用法其實我自己也用的不多，所以建議大家參考就好。\n舉例來說，在上面的 Cron 的基本用法中，當我們寫 30 10 * * * 時，就是要在「每天的 10:30」執行任務，很直覺對吧，但是如果我們寫成 */3 10 * * * 時，就是表示要在「每天的 10 點 0 分、10 點 3 分、10 點 6 分、10 點 9 分\u0026hellip;（不斷加三分鐘）\u0026hellip;、10 點 54 分、10 點 57 分」執行任務。\n除此之外，我們也可以改寫成是 30 10-15 * * *，則是表示要在「每天的 10:30、11:30、12:30、13:30、14:30、15:30」執行任務。\n再或者，我們也可以改寫成是 30 10,23 * * *，表示要在「每天的 10:30 和 23:30」執行任務（這個好用）。\n所以在 Cron 的進階用法中，已經進展到「不只是指定某個特定的時間點了」，而是變成「指定一段時間區間」或是「指定時間的變動方式」了，因此大家如果有比較特殊的需求，就可以研究一下 Cron 的進階用法，寫出最符合你想要的時間表達式。\n這邊也是舉更多的例子給大家參考，或是大家也可以直接到 Crontab.guru 上測試，他也有支援進階的用法。\nCron 表達式 實際意義 0 22 * * 1-5 在週一到週五的每天晚上 22:00 執行任務 23 12-20/2 * * * 在每天的 12:23、14:23、16:23、18:23、20:23 執行任務 30 10,11 * * 0 在每週日的 10:30 和 11:30 執行任務 59 23 1 */2 * 在每個奇數月（1、3、5、7、9、11）的 1 號的 23:59 執行任務 Cron 總結 # 所以總結上面的介紹的話，Cron 原本是 Linux 中的一個定時任務管理工具，但是因為他的表達式實在是太好用，所以現在很廣泛使用的定時任務的表達上面。\n而常見的 Cron 為 5 位數（預設是 5 個 *），每一個位數分別代表了「分鐘」、「小時」、「日期」、「月份」、「星期幾」的含義，因此大家就可以透過修改不同位數的值，用來表達你想要在哪個時間點執行任務了！\n補充：Spring Boot 的 Cron 表達式寫法（6 個 *） # 在 Spring Boot 中，如果我們想要使用 @Scheduled 創建一個定時任務的話，則是要","date":"2025-03-11","objectID":"72bcf4c692c3bab41f551aa8a50b87c3","title":"Cron 是什麼？定時任務的語法怎麼寫？","url":"https://kucw.io/blog/cron/"},{"categories":["自媒體經營"],"content":"哈囉，我是古古，這篇文章是每月一次的自媒體月報，主要分享我經營《古古的後端筆記》個人品牌的幕後秘辛，如果你也對於「自媒體創業」有興趣的話，歡迎繼續閱讀本文～\n補充：如果想了解《古古的後端筆記》電子報的起源，也可以先查看創刊號的文章。\n2025.2 月粉絲追蹤數、電子報訂閱人數 # 本月份（2025.2）的粉絲成長人數如下：\n2025/1/28 人數 2025/2/25 人數 2 月份（1 月份）總成長人數 Facebook 粉專追蹤數 4547 4607 +60（+72） 電子報訂閱人數 2872 3079 +207（+392） Threads 粉絲追蹤數 7354 8135 +781（+1358） IG 粉絲追蹤數 600 688 +88（+111） 這個月的數據也是順順成長，雖然數據可能相比上個月有稍微降低，但也是因為我這個月比較忙碌，比較沒辦法很好的兼顧社群的營運，所以才會這樣。\n等到之後比較穩定之後，應該就比較有時間可以跟大家在社群上互動惹！在此之前可能只有在電子報才看得到我😂，大家如果有什麼想跟我說的悄悄話可以直接私訊我 or 回信給我，我看到都會盡量回的🙏。\n本月的自媒體主題：電子報為什麼又開始紅了？ # 這個月剛好有一個自媒體主題很想跟大家分享，所以就借月報的篇幅來寫了，那就是：「電子報為什麼又開始紅了？」。\n最近看到台灣越來越多人開始寫電子報，覺得很讚！其實電子報作為上古時代的行銷產物，曾經有一度是被大家唾棄的，曾經我們對電子報的印象是「促銷信件」，就是那種直接會被你丟到垃圾信件的廣告信，但是現在我們對電子報的印象卻是「吸取知識的管道」，到底為什麼電子報有這麼大的轉變？今天就來討論一下這個話題吧！\n電子報和其他社群媒體有一個最最最不一樣的差別，在於 「曝光度」，也就是俗稱的 「流量」。\n其實在現今的社群媒體中（不管是 Facebook、Threads、YouTube、抖音），當創作者寫完一篇文章之後，其實這篇文章不一定會被我的讀者所看到。\n舉例來說，當我在 Facebook 上發一篇文時，可能只有三分之一的追蹤者能看到這篇文章，其他的追蹤者是「根本連看都沒看到，連想按讚的機會都沒有」，而為什麼會有這個差別？就是 Facebook 的演算法所導致的。\n目前的演算法是當你發一篇文之後，他會先小範圍的散播這篇文章給你的部分追蹤者，假設這些追蹤者的反應很好（譬如說按讚、留言、分享），那麼演算法就會覺得這篇文章是個好文，所以就會再把這篇文章擴散出去，讓更多人能看到這篇文章。\n但如果反過來呢？假設你寫的文章沒什麼人按讚分享，那麼演算法就會覺得這篇文章不好，因此後續就不會推送這篇文章給其他人，因此這篇文章的觀看人數就會非常少，原因就是因為被演算法給掐滅了。\n所以在大社群時代下，只有 Facebook 這種平台是贏家，我們這些小創作者都只是他的囊中之物而已，今天 Facebook 心情好，他就會將你的文章推送給更多人，假設今天他心情不好，你寫的任何寶藏文章都沒人看得到，這就是演算法的機制，也就是 「曝光度」 的概念。\n那麼，要打破這個機制，有沒有其他解決方案呢？有的，那就是電子報！！\n電子報有一個特性，就是 「創作者可以直接把他寫的文章交到你手上」，舉例來說，只要我有你的信箱，我寫的每一封電子報，都可以確保這封信一定會進到你的信箱裡面。\n所以對於電子報而言，再也沒有「曝光度」的問題了，只要我肯寫，只要你肯讀，創作者和讀者之間一定可以維持某種聯繫，再也不會發生「我寫了，但是你沒收到」的幽靈情況出現。\n並且電子報還有一個附加價值，就是 「隱私性」，舉例來說，假設我在 Facebook 上公開發一篇文，可能你對於電子報中的某個議題很感興趣，但是又不好意思在下面留言，私訊好像又有點麻煩，所以就作罷。\n但是電子報可以直接透過「回信」的方式，就可以直接讓讀者有一個窗口和創作者對話，並且這個過程是完全隱私的！！！只有讀者和創作者彼此知道信件內容而已，因此寫起來可以更隨心所欲一點，不用擔心會被第三者看到。\n所以基於上述的種種好處，電子報就從以往的促銷信件時代，轉換成了大知識時代，將來可能會有越來越多創作者同時經營「電子報 + 社群平台」（我現在就是這樣），除了持續在 Facebook 等社群平台打造影響力之外，同時也確保喜歡我的內容的讀者真的可以收到我創作的內容，不然寫了那麼久的文章，結果最終被 Facebook 吃掉，沒辦法傳遞給想閱讀的讀者手上，還是會有點難過的🥹。\n希望後續台灣也會有越來越多的創作者使用電子報進行創作，讓這些精彩的內容可以被看見，而不是埋沒在社群平台的底下。\n本月撰寫的電子報主題、文章 # 這邊記錄了我這個月撰寫了哪些電子報和文章，大家如果對於其中的內容有興趣的話，也可以前往查看：\nDNS 是什麼？在瀏覽器中輸入 URL 會發生什麼事？ Polling 和 Webhook 是什麼？如何更有效的串接第三方系統？ Http 中的 GET 和 POST 的差別在哪裡？ 2025.2 月報總結 # 呼～這個月大概是這樣吧！電子報的部分因為覺得很有共鳴所以打的有點長😂，希望你們會喜歡這類內容。\n那我們就下個月再見啦！\n","date":"2025-03-04","objectID":"8d992ff7f509cc6e08e392c0297aaa62","title":"軟體工程師的自媒體之路 - 2025.2 月報","url":"https://kucw.io/blog/as-a-content-creator/monthly-report-202502/"},{"categories":["其他技術分享"],"content":"在軟體開發中，Http 可以說是大家最常打交道的一個協議了，因此這篇文章就會來介紹一下 Http 中的 GET 和 POST 的差別。\n目錄 什麼是 Http Method？ GET 介紹 POST 介紹 GET 和 POST 總結 補充：GET 和 POST 的更多細節比較 結語 什麼是 Http Method？ # 所謂的 Http Method，就是在發送一個 API 時，所使用的請求方式。\n較常見的 Http Method 有以下四種：\nGET POST PUT DELETE 其中 GET 和 POST 是使用上最常見的兩種請求方法，所以接下來我們就來比較一下，GET 和 POST 之間的差別在哪裡吧！\nGET 介紹 # GET 是最常使用的 Http Method，大家可以把 GET 想像成是 「明信片」 的概念，也就是 「當你使用 GET 來請求時，你所傳遞的參數就會被別人看見」。\n舉例來說，在使用 GET 來請求時，我們就要將請求參數添加在 url 的最後面。因此在下面的例子中，我們就必須要將參數 id=123\u0026amp;name=Judy 添加在 url 的最後面（黃色區塊所示），這樣子才能夠成功傳遞參數給後端。\n所以在使用 GET 方法來請求時，所有的請求參數都是「公開的」，因此任何人都能查看參數的值，所以 GET 就像是「明信片」一樣，信中的內容可以被所有人查看。\n也因為使用 GET 來請求的所有參數都會被看見，因此如果你的請求參數是比較敏感的資訊（ex: 身分證字號、手機號碼），那就不建議使用 GET 方式來請求，因為這些數據會暴露在 url 中給其他人看到，可能就會導致數據的洩漏。\n甚至瀏覽器也會 cache GET 請求的 url，以記錄你曾經訪問過哪些網頁，因此使用 GET 來請求真的是走過路過都會留下痕跡，因此敏感數據絕對不可以使用 GET 來傳遞！！\n因此如果想要更隱私的傳遞參數，就可以使用下面的 POST 來實作。\nPOST 介紹 # 不同於 GET 是公開所有的請求參數，POST 就是相反過來，POST 會隱藏所有的請求參數，因此任何人都沒辦法取得其中的請求參數，所以 POST 也可以說是「信封」的概念，所有的內容都會好好的被封裝在信封內，不會隨意向外部展示。\n舉例來說，在使用 POST 來請求時，我們就要改成將請求參數添加在 request body 中，並且通常會使用 JSON 格式來添加數據。因此在下面的例子中，我們就會將 JSON 參數 {\u0026quot;id\u0026quot;: 123, \u0026quot;name\u0026quot;: \u0026quot;Judy\u0026quot;} 添加在 request body 中（藍色區塊所示），這樣子就能夠隱私的將參數傳遞給後端了。\n所以在使用 POST 方法來請求時，所有的請求參數都是「隱私的」，只有收件者（後端）都能查看，其他人是完全看不到的，因此就像是「信封」一樣，信中的內容會對其他人隱藏，只有收件者後端可以查看。\n也因為使用 POST 來請求時，所有的參數都會被隱藏起來，不被其他人所看見，因此像是比較敏感的資訊（ex: 身分證字號、手機號碼），就很適合使用 POST 來請求，確保敏感數據不會洩漏。\n補充：雖然 POST 是信封的概念，會將所有請求參數隱藏起來，但是駭客仍舊是可以透過其他招數來偷看裡面的內容，因此就算是 POST 來請求還是會有風險，所以仍舊需要做其他的資安加強（ex: Https），才能確保數據不會被駭客給偷走。\nGET 和 POST 總結 # 所以總結上面的介紹的話，就可以將 GET 和 POST 做一個比較：\nGET： 明信片的概念，將參數放在 url 中傳遞，並且所有參數都是「公開的」，任何人都能看見。 POST： 信封的概念，將參數放在 request body 中傳遞，並且會將所有參數「隱藏起來」，其他人都看不見。 所以大家以後就可以根據自己目前的 API 的需求，選擇最適合的請求方式了！\n補充：GET 和 POST 的更多細節比較 # 如果大家想了解更多關於 GET 和 POST 的技術細節，也可以參考下方的表格整理（資料來源：前后端数据交互(八)——请求方法 GET 和 POST 区别）。\nGET POST 上一頁、重新整理網頁 無影響 數據會重新被提交 收藏 可收藏至瀏覽器中的「我的最愛」 不可收藏 cache 能被瀏覽器、後端 cache 不能被 cache 歷史 參數會保存在瀏覽器的歷史中 參數不會保存在瀏覽器歷史中 安全性 較差，因為請求參數添加在 URL 中 較安全，因為參數不會被保存在瀏覽器的歷史中、也不會隨著 URL 被記錄在 log 裡 數據長度 有限制，因為 URL 的最大長度是有規範的（最大 2048 個字符） 無限制 使用情境 一般網頁讀取 表單提交、新增數據 結語 # 這篇文章我們先介紹了 GET 和 POST 的用法，並且也比較了他們之間的差別，其實就是一個是「明信片」、另一個是「信封」而已～\n如果還想了解更多關於 Http、API 設計的相關知識，也可以參考過往的文章：\n一文搞懂 Http Status Code，詳細解析 200、301、401、403、500、503 RESTful API 設計指南，3 個必備條件缺一不可！ 如果你對後端技術有興趣的話，也歡迎免費訂閱《古古的後端筆記》電子報，每週二為你送上一篇後端技術分享，那我們就下一篇文章見啦！\n補充：我開設的 Spring Boot 零基礎入門、Spring Security 零基礎入門、GitHub 免費架站術 已在 Hahow 平台上架啦！輸入折扣碼「HH202601KU」即可享 85 折優惠。\n","date":"2025-02-25","objectID":"9bb2e3f8f5517f0194864faf55a8e66a","title":"Http 中的 GET 和 POST 的差別在哪裡？","url":"https://kucw.io/blog/http-get-post/"},{"categories":["其他技術分享"],"content":"一般在實作後端系統時，如果想要去串接外部的第三方系統，這時候就會有兩種串接方式：Polling 和 Webhook，所以這篇文章我們就來了解一下 Polling 和 Webhook 之間的差別吧！\n目錄 什麼是 Polling？什麼是 Webhook？ 串接股票中心的故事 使用 Polling 來串接 使用 Webhook 來串接 Polling 和 Webhook 總結 補充：在 Webhook 的實作中，股票中心是如何通知我們的後端程式？ 結語 什麼是 Polling？什麼是 Webhook？ # 在串接第三方的系統時，我們可以使用兩種方式來串接，分別是 Polling 和 Webhook，而他們兩個在實作上其實是完全相反的兩種方式：\nPolling（輪詢）： 由「我們的後端程式」主動且瘋狂的去問「第三方系統」，詢問當前數據的值為何。 Webhook： 當數據有變動時，由「第三方系統」主動通知「我們的後端程式」，告訴我們數據已經變化了。 這個乍聽之下會覺得有點抽象，所以下面就透過一個例子，來介紹一下 Polling 和 Webhook 的差別。\n串接股票中心的故事 # 假設你現在想要實作一個後端的系統，當你偵測到某隻股票的價格低於某個點時（譬如說台積電股價跌破 1000 元），這時候你就要在後端系統中儲存當下的時間，如果是由你來實作這個後端程式，你會怎麼實作？\n使用 Polling 來串接 # 最直覺的做法，就是在你的後端程式裡面，每秒鐘都去 call 股票中心的 API，瘋狂的去問台積電現在的價格是多少，因此假設在 12:01 分時台積電的價格跌到 960 元，你就可以在你的系統中記錄當前的這筆時間。\n上面這種「不斷的去詢問股票中心 Server 當前的股價為何」的行為，就稱為是 Polling（輪詢）。\n但是上面這個做法有一個缺點，就是你 「每一秒」 都得要 call 一次股票中心的 API，才能知道當下的台積電股價，又因為一天有 86400 秒，所以你的後端程式一天就得要 call 股票中心的 API 86400 次，就會造成很大量的 API call，加重股票中心 server 的負擔。\n並且上面的做法除了會使得 API call 的數量飆升之外，其實在這些 API call 中，也不是每一次的 API 都很有用處。因為我們真正想要的功能，是「當台積電跌破 1000 元以下時，記錄當下的時間」，所以當台積電現在是 1100、1200、1300 元時，這些 API call 的返回值對我們都是沒有意義的，就只有跌破 1000 元的那個時間點，才是我們真正關注的部分。\n所以為了解決 Polling 的問題，Webhook 就出現了！\n使用 Webhook 來串接 # 在剛剛的 Polling 中，主動方是「我們實作的後端程式」，也就是由我們主動發起 API call，一直不斷地瘋狂去煩股票中心，問他現在台積電的股價是多少。\n而在 Webhook 中，則是會反過來，主動方變成是「股票中心」，也就是當台積電跌破 1000 元時，股票中心就會主動 call 我們的 API，通知我們台積電跌破 1000 元了！！\n所以在 Webhook 的設計中，主動方會變成是「股票中心」，只有當股票中心發現台積電跌破我們預期的值時，才發送通知給我們，在其他時間時，股票中心則是會什麼事都不做，完全不會 call 我們的 API，大大的減少了 API call 的次數。\n因此透過 Webhook 的設計，就可以將 API call 的次數降到最低，只有在台積電的股價跌破 1000 元時才會 call 一次我們的 API，比起前面的 Polling 的設計要 call 86400 次少多了！！因此在一般在實作上，通常會建議採用 Webhook 的設計，這樣子可以讓兩邊的 Server 負擔都不會那麼大，減少浪費的 API call 次數。\nPolling 和 Webhook 總結 # 所以總結上面的介紹的話，當我們在串接第三方的系統時，就可以使用兩種方式來串接，分別是：\nPolling（輪詢）： 由「我們的後端程式」主動且瘋狂的去問「第三方系統」，詢問當前數據的值為何。 Webhook： 當數據有變動時，由「第三方系統」主動通知「我們的後端程式」，告訴我們數據已經變化了。 因此下次大家在串接第三方系統時，就可以看一下他們的系統是否有支援 Webhook 的設計，如果有的話，就可以使用 Webhook 的方式來串接，這樣子就不用再瘋狂的一直去重複大量的 API call 了！\n補充：在 Webhook 的實作中，股票中心是如何通知我們的後端程式？ # 了解了 Polling 和 Webhook 的差異之後，這裡也順便補充一下 Webhook 的實作。\n因為 Webhook 的核心設計理念是「由股票中心變成主動方」，因此當台積電股價跌破 1000 元時，股票中心需要主動通知我們的後端程式，告訴我們台積電目前的股價。\n所以為了讓「股票中心有能力通知我們的後端程式」，需要實作兩個步驟：\n1. 我們需要先在我們自己的後端程式中，先新增一個新的 API\n首先我們需要在我們的後端程式裡面，先新增一個 API 出來（假設叫做 /myapi），至於這個 API 的請求參數有哪些、以及這個 API 的請求方法（ex: GET、POST）為何，通常第三方系統都會有詳細的定義，到時可以查詢一下第三方系統的相關文件。\n@RestController public class MyController { @RequestMapping(\u0026#34;/myapi\u0026#34;) public void myApi(@RequestParam String stockName, @RequestParam Integer price) { // 記錄當前股價和時間 } } 2. 到第三方系統中，在 Webhook 處填上你的 /myapi 的 API\n創建好 API 之後，接著可以登入到第三方系統，然後通常就會有一個填寫 Endpoint URL 的地方（如下圖所示），讓你將你剛剛所創建的 /myapi 的 API 給填上來（這邊因系統不同而有不同的介面，甚至有的第三方系統沒有 UI 介面，要自己去跟他們的工程師對接）。\n只要完成了上述的步驟之後，未來當你預期的事件發生時（ex: 台積電跌破 1000 元），這時候第三方系統就會 call 你所填上的 API（也就是 https://example.com/myapi）。\n所以換句話說的話，當你的 /myapi 被 call 時，就表示台積電跌破 1000 元了，因此你就可以在這個 /myapi 的程式中，去實作你想要實作的功能（如記錄當前的股價和時間…等等），這樣子就可以和第三方系統成功使用 Webhook 串接在一起了！\n結語 # 這篇文章我們先分別介紹了 Polling 和 Webhook 是什麼，並且也比較了他們之間的差別，Polling 和 Webhook 可以說是在串接第三方系統時很常見的兩種方式，雖然目前比較流行的是 Webhook 的作法，但是多了解一下 Polling 的設計理念也是很可以的～\n如果你對後端技術有興趣的話，也歡迎免費訂閱《古古的後端筆記》電子報，每週二為你送上一篇後端技術分享，那我們就下一篇文章見啦！\n補充：我開設的 Spring Boot 零基礎入門、Spring Security 零基礎入門、GitHub 免費架站術 已在 Hahow 平台上架啦！輸入折扣碼「HH202601KU」即可享 85 折優惠。\n","date":"2025-02-18","objectID":"1112e9d93e5f1efe24770390415a11a5","title":"Polling 和 Webhook 是什麼？如何更有效的串接第三方系統？","url":"https://kucw.io/blog/polling-webhook/"},{"categories":["其他技術分享"],"content":"相信大家在準備面試時，常常會遇到一題是「在瀏覽器中輸入 URL 會發生什麼事？」，而這背後其實就和 DNS 息息相關。\n因此這篇文章我們就來介紹一下，到底在瀏覽器中按下 URL 會發生什麼事，以及其背後的 DNS 原理吧！\n目錄 什麼是 DNS？ 在沒有 DNS 的年代 DNS 的雛形 現今 DNS 的全貌 DNS 總結 結語 什麼是 DNS？ # 所謂的 DNS，全稱是 Domain Name System（好像沒有中文翻譯），DNS 的用途在於「查詢某個域名的 IP 位置為何」，這個聽起來可能有點抽象，所以接下來我們就透過例子來了解一下 DNS 的用途到底是什麼。\n在沒有 DNS 的年代 # 首先回到最最最古老的年代，其實當我們運行一台 Server 起來時，這台 Server 擁有的只有 IP 位置而已，譬如說某一台 Server 就會運行在 142.250.196.206 這個 IP 上面，因此當前端想要 call 後端的 api 時，前端就是要 call http://142.250.196.206:80/api ，就可以訪問這台 Server 上所運行的後端程式了。\n所以到這裡要先掌握一個重點，就是 「前後端之間溝通，只需要知道對方的 IP 位置即可」，只要知道對方的 IP 位置，前端就可以直接去 call 該 IP 上所運行的 Server，去請求後端的數據了。\nDNS 的雛形 # 不過，雖然對於前後端來說，他們彼此之只要知道對方的 IP 就可以進行溝通，但是對於使用者而言，要記住這麼長一串的 IP 地址可是很累人的啊！！譬如上方所提到的 IP 例子 142.250.196.206，要記住這麼長一串 IP 位置是很痛苦的。\n但是如果我們能把這個 IP 位置，轉換成「一個簡單好記的英文單字」，這樣子是不是會更方便記憶？譬如說我們將 142.250.196.206 轉換為 google.com，google.com 總是比一串數字來的好記多了對吧！！也因為如此，DNS 就被發明出來了！！！\n大家可以把 DNS 想像成是一張很大很大的 table，他裡面會儲存 域名:IP位置 的一一對應，所以以上面的例子來說，就可以在 DNS 這張 table 中插入一筆 google.com 和 142.250.196.206 的對應關係。\n域名 IP google.com 142.250.196.206 \u0026hellip; \u0026hellip; 因此這時當使用者在瀏覽器中輸入 http://google.com/api 時，就會依序執行以下的步驟：\n使用者在瀏覽器中輸入 http://google.com/api 網址 瀏覽器詢問 DNS：「google.com 的 IP 位置是多少？」 DNS 查詢他的 table 中有沒有記錄 google.com 所對應的 IP 的值，因為 table 中有記錄（即是 142.250.196.206），所以 DNS 就會回覆瀏覽器：「google.com 的 IP 為 142.250.196.206」 瀏覽器知道 IP 位置之後，改成去請求 http://142.250.196.206/api，成功連線到後端 Server，因此就可以成功的去 call 後端的 api 了 後端返回 api 的數據 所以在其實在這整個前後端的溝通中，DNS 所負責的任務就只是「查詢一下 google.com 這個域名的 IP 位置為何」而已，比想像中單純對吧！DNS 至始至終都只是在記錄「域名和 IP 之間的對應關係」而已，只要掌握好這個核心邏輯就可以了！！\n補充：實際上 142.250.196.206 其實就是 Google 在台灣的一組 IP 地址，如果在瀏覽器中輸入 142.250.196.206 的話，就會跳轉到 https://www.google.com/ 上，大家有興趣也可以玩一下～。\n現今 DNS 的全貌 # 不過，雖然 DNS 所負責的任務就只是「查詢一下 google.com 這個域名的 IP 位置為何」而已，但是當這個域名數量變的很多很多很～～～多的時候，DNS 也逼不得已得進化一下，設計成更能符合當前量級需求的架構。\n因此在現今的 DNS 架構中，不會僅使用一張 table 來記錄所有的 域名:IP 的對應關係，而是會分成：\nRoot Name Server（根域名） TLD Name Server（頂級域名） Authoritative Name Server（權威域名） 這三層來依序將「域名」解析成「IP」。\n舉例來說，假設今天的域名是 www.googe.com，那 DNS 內部就會先拿著 www.google.com 去問 Root Server 這個該去找誰解析成 IP，Root Server 會先檢查這個域名的結尾（也就是 .com），因此就會叫 DNS 拿去找第二層的 .com TLD Name Server。\n而當 DNS 去問第二層的 .com TLD Name Server www.googe.com 的 IP 為何時，第二層的 .com TLD Name Server 就會去解析主域名（也就是 google.com），然後叫 DNS 拿著去找第三層的 google.com Name server。\n而當 DNS 終於抵達第三層的 google.com Name Server 時，DNS 就會一樣會問他 www.google.com 的 IP 為何，這時候第三層的 google.com Name Server 就會找出他的真實 IP 為何（也就是 142.250.196.206），然後將他回傳給 DNS。\n到這裡為止，DNS 內部才是真正的找出 www.google.com 所對應的 IP 地址為 142.250.196.206，因此就可以將這個 IP 地址回傳給瀏覽器，讓瀏覽器去請求這個 IP 地址了！\n不過即使 DNS 的內部架構變的稍微複雜一點，但是 DNS 實際上要做的事情仍舊是不變的！也就是「查詢一下 google.com 這個域名的 IP 位置為何」而已，因此如果覺得上面的 DNS 架構太複雜的話，暫時忘記他也是可以的，只要記得 DNS 的目的是「查詢域名的 IP 位置為何」就好，細節可以等真的要用到的時候再回來參考即可。\nDNS 總結 # 所以總結一下上面的介紹的話，所謂的 DNS，全稱是 Domain Name System，並且 DNS 的用途在於「查詢某個域名的 IP 位置為何」。\n而在 DNS 的內部架構中，為了提升查詢的效率以及提高能同時乘載的查詢量，所以 DNS 內部會分成三層（Root、TLD、Authoritative），根據域名的結尾不同，去分配到不同的 DNS Server 上，盡可能的分散每一台 DNS Server 所需要負責的查詢數量，讓這些 DNS Server 能夠承載目前世界上所有人的 IP 查詢。\n也因為 DNS 的用途在於「查詢某個域名的 IP 位置為何」，因此當使用者在瀏覽器中輸入某個 URL 時，實際上瀏覽器在背後就會偷偷先去詢問 DNS：「這個域名的 IP 為何？」，等到問到 IP 位置之後，瀏覽器才會實際去 call 該 IP 上所運行的後端服務，因此下次再有人問你「在瀏覽器中輸入 URL 會發生什麼事」時，你就可以大膽的回覆他「DNS 會先去\u0026hellip;」的答案了！\n補充：其實在瀏覽器拿到 Server 的 IP 位置之後，還會需要和 Server 建立 TCP/IP 的連線，等到建立完連線之後才能真正的 call API 取得數據，不過老實說 TCP/IP 的","date":"2025-02-04","objectID":"99557aa4e80c4dba2c632fb92fa863cb","title":"DNS 是什麼？在瀏覽器中輸入 URL 會發生什麼事？","url":"https://kucw.io/blog/dns/"},{"categories":["自媒體經營"],"content":"哈囉，我是古古，這篇文章是每月一次的自媒體月報，主要分享我經營《古古的後端筆記》個人品牌的幕後秘辛，如果你也對於「自媒體創業」有興趣的話，歡迎繼續閱讀本文～\n補充：如果想了解《古古的後端筆記》電子報的起源，也可以先查看創刊號的文章。\n2025.1 月粉絲追蹤數、電子報訂閱人數 # 本月份（2025.1）的粉絲成長人數如下：\n2024/12/31 人數 2025/1/28 人數 1 月份（去年 12 月份）總成長人數 Facebook 粉專追蹤數 4475 4547 +72（+86） 電子報訂閱人數 2480 2872 +392（+404） Threads 粉絲追蹤數 5996 7354 +1358（+1430） IG 粉絲追蹤數 489 600 +111（+136） 這個月一樣是各項指標持續成長中（感謝大家的支持🙏） ，不過我最近其實想要回頭找工程師的工作了，所以想說剛好藉著這個自媒體月報的篇幅，也想跟大家分享一下「為什麼我做了自媒體之後，仍舊想要回頭找工程師的工作」。\n為什麼我做了自媒體之後，仍舊想要回頭找工程師的工作？ # 會想要回頭找工程師的工作，主要原因應該還是因為我在 2024 年的自媒體一年中過的不是很好，覺得「全職自媒體」這個行業可能不太適合我，自媒體可以是我的一個事業，但是沒辦法完全是我的主業這樣。\n可能是因為剛好我走的這條路是「技術自媒體」，我自己也很喜歡分享知識、教課，如果我自己沒有真的在第一線的程式上打拼的話，感覺自己好像會離技術越來越遠，並且也不確定自己目前分享的東西業界到底還有沒有在用、是不是其實分享了沒用的知識…等等，諸如此類的焦慮會很常浮現在我心中🥹。\n我想要變強，不想要原地踏步，但是有很多經驗是必須在第一線實戰中累積的，不管是解決問題的能力、團隊合作的能力、甚至是通靈客戶的能力（懂的都懂），這些都是得真實的和別人相處之後，才有辦法累積的實力，相較來說，「自媒體」終究只有「自己」，一個人的能力還是有極限的。\n不過我不是要放棄自媒體了唷！！我覺得自媒體作為一個副業來說還是很讚的👍，至少有一個管道可以分享最近學到的知識、可以抒發心情、可以認識到很多不同的大大們、可以幫助到需要幫助的人，這份工作對我而言真的很有意義。\n我希望將來可以在工作中越變越強，並且在變強之後，也想帶著大家一起變強，2025 年給自己的期許是「Sharing is Learning!」，我會努力做到的！\n所以如果總結一下的話，我會想要從「自媒體」回去做「工程師」，有以下幾點：\n「自媒體」會離業界越來越遠，不確定自己所知是否仍是業界主流，容易感到焦慮 「自媒體」是很自由沒錯，但是長期的精神壓力會很重（壓力來自於不確定感和不安感），不確定未來方向要往哪裡走、下一個客戶在哪裡 當「工程師」的好處有：可以磨練自己的技術、團隊合作能力、客戶通靈能力，並且可以參與大型的專案開發，累積系統架構的設計能力 同時兼顧「自媒體 + 工程師」感覺是目前最棒的選擇，但是要兼顧兩者真的很累（曾經兼過，那陣子都沒睡飽過），不知道是否能找出更平衡的兼顧方式 （2025 來找找看吧！） 目前的想法大概是這樣，想把目前的心情記錄下來，不僅給自己做一個記錄，也一起分享給大家～\n但我覺得人的每一個階段都會喜歡不一樣的東西啦，所以我也是有可能工作個 3、5 年之後，就又辭職跑去全職做自媒體了🤣，未來的事情誰知道呢？人生在世一場，如果能夠在每一個時間點，都做出不愧於自己的決定，應該就能盡量不留下遺憾了吧。\n希望 2025 年，我們都可以做出自己最想要的那個決定！\n本月撰寫的電子報主題、文章 # 這邊記錄了我這個月撰寫了哪些電子報和文章，大家如果對於其中的內容有興趣的話，也可以前往查看：\n電腦中的 RAM（記憶體）的用途是什麼？他和硬碟的差別在哪裡？ 如何成為資深工程師？心態最重要 Event Sourcing 是什麼？他和 CRUD 的差別在哪裡？ GPU 是什麼？為什麼 GPU 對 AI 的發展很重要？ 2025.1 月報總結 # 最近這幾個月都在忙著學習技術，比較沒有多餘的心力看自媒體的書了🥹，近期的目標應該會優先擺在找工作上，後續如果有比較多求職心得時，也再來跟大家分享求職的過程～\n那我們就下個月的月報再見啦！\n","date":"2025-02-04","objectID":"31251f5946e36deaf38b9c13c348e00e","title":"軟體工程師的自媒體之路 - 2025.1 月報","url":"https://kucw.io/blog/as-a-content-creator/monthly-report-202501/"},{"categories":["其他技術分享"],"content":"在 AI 的浪潮下，GPU 可以說是一間公司的算力的體現，但是 GPU 到底是什麼？為什麼他對 AI 的發展這麼重要呢？所以這篇文章我們就來介紹一下，到底什麼是 GPU 吧！\n目錄 什麼是 GPU？ 影像處理簡介 GPU 和影像處理的關聯 為什麼 GPU 在 AI 時代這麼重要？ 補充：為什麼提升「訓練模型」的速度這麼重要？ GPU 總結 結語 什麼是 GPU？ # 所謂的 GPU，全稱是 Graphics Processing Unit，中文翻譯為「圖形處理器」，所以顧名思義，其實 GPU 最一開始的用途，就是拿來「處理影像圖形」用的。 只不過因為 GPU 的「平行處理」的特性實在太好用，所以後來才被拿來挖礦、甚至發展 AI。\n所以在了解 GPU 為什麼對 AI 很重要之前，首先一定要先了解 GPU 的用途為何，了解 GPU 是怎麼做到「平行處理」的概念的，才能夠了解為什麼 GPU 對於 AI 的發展這麼重要。\n影像處理簡介 # 其實 GPU 最一開始的用途就是拿來「處理圖形」的，而在了解 GPU 的用途之前，我們必須要先了解一下目前電腦螢幕裡面是如何構成的，才能知道 GPU 的用途為何。\n舉例來說，在每一台電腦螢幕中，其實都是由好幾個微小的像素（pixel）所組成，而每一個像素你可以想像成就是一個小格子。\n所以像是現在主打的 4K 螢幕（3840×2160），就是指這台螢幕的長度有 3840 個像素，而高度則是有 2160 個像素，因此在整台螢幕上面，就是有 3840 x 2160 = 829 萬個像素（pixel）存在。\n所以我們平常在使用螢幕時，不管是觀看 YouTube 影片、寫程式、打遊戲…等等，電腦就要分別計算「每一格 pixel 當前應該要呈現什麼顏色」，而當所有的 pixel 都計算好自己應該長什麼顏色之後，最終就會呈現一張完整的圖片了。\n如果大家有生成過點陣圖、或是有玩過 Minecraft 的話，其實就是背後用的就是「像素」的概念，像是下圖就是一個 pixel 實際呈現的結果，當每一格 pixel 都計算出他的顏色之後，最終呈現給我們人眼看的結果，就是最右邊的「寶劍」了！\n所以在影像處理的世界中，「每一格 pixel 都是獨立的，自己控制自己要呈現什麼顏色」，而當這些 pixel 們計算好自己要呈現什麼顏色之後，最終合成再整個合在一起看，就是對我們人類有意義的圖片了～\n所以其實對於 pixel 而言，他其實根本不知道現在是要呈現什麼圖片😂，他的任務就是乖乖計算自己要什麼顏色，剩下的怎麼解讀就交給人類自己去判定。\nGPU 和影像處理的關聯 # 所以透過上面的介紹，現在我們知道「一張圖片之所以能夠呈現出來，靠的就是 pixel 們自己在背後默默的運算」，而這其實就是 GPU 被發明出來的契機！\n在 GPU 還沒被發明出來之前，如果我們用傳統 CPU 的去計算 pixel 的值的話，那就是得寫個 for loop，然後每一次 loop 就去計算每一格 pixel 的值。\n圖片來源： 【OpenGL 篇】为什么游戏总要编译着色器？ 但是使用 CPU 這樣子 for loop 一格一格計算實在是太慢了，所以為了加快計算的過程，GPU 就被發明出來了！！\n在 GPU 裡面，有超超超超超級多個核心存在，每一個核心都可以執行一個簡單的計算，所以對於 GPU 而言，他就可以為每一個 pixel 都分配一個核心，然後 「在同一時間，所有核心都去計算他所分配到的 pixel 的值」，所以 GPU 就可以一口氣計算出所有 pixel 的顏色，因此就可以得到最終的結果了。\n圖片來源： 【OpenGL 篇】为什么游戏总要编译着色器？ 所以 GPU 之所以強大的地方，就在於「平行處理」，每一個 GPU 核心都有強大計算的能力，只要你告訴他要計算的是哪一格 pixel、以及要處理的數據有哪些，GPU 就可以為那一格 pixel 分配一個核心，專門去計算這個 pixel 的最終顏色，又因為 GPU 中的核心數量非常多，因此就可以達到「同時計算所有 pixel」的效果了～\n所以對於 GPU 來說，「平行處理」就是他的最強大的武器，而這也是 GPU 為什麼會在 AI 世界大放異彩的特質！\n為什麼 GPU 在 AI 時代這麼重要？ # 首先在 AI 時代中，所有的模型都是「訓練」出來的，而在訓練模型的過程中，使用 GPU 的「平行處理」就可以加快訓練的過程。\n「訓練」的概念有點像是在教導小孩子一樣，每一個模型一開始都是一個天真無邪的孩子，並且每個孩子的特長和天賦都不同，而我們工程師所做的，就是拿著「同樣的對話範例」去給這個孩子看，試試看這個孩子最終會長成什麼樣子。\n像是你可以拿下面這兩段對話，去訓練 X 模型，所以這時候 X 模型就會去「旁觀」這兩段對話，並且自己去理解這段對話（就像是小時候我們看著父母的言行一樣，就是從旁觀中去學習，所以身教大於言教啊！）。\nA：你好 B：哈囉你好，你吃飽了沒？ A：你好 B：心情不好，滾 而當你使用上面這兩段對話「訓練」完 X 模型之後，這時候當你跟 X 模型說「你好」時，他可能會回你：\n你：你好 X 模型：滾 或是 你：你好 X 模型：哈囉滾 因此在「訓練」模型的過程中，其實我們作為工程師，也是不知道 X 模型最終到底會回覆什麼的，一定得等到訓練完成之後，我們才能夠透過一問一答的測試的方式，去檢查 X 模型的回覆是否如我們預期。\n所以在 AI 的時代中，所有的模型其實都是通過「訓練」出來的，並且上面這種給 X 模型參考旁觀對話的過程，也稱為「訓練模型」。\n而 GPU 之所以在 AI 的發展中很重要，就是因為 「使用 GPU 的平行處理，就可以加快訓練的過程」。\n舉例來說，如果我們使用傳統 CPU 來訓練 X 模型的話，那就像是教育小孩一樣，一次只能夠教導一個科目，等到這個科目完成之後，才教導下一個科目。\n而如果我們使用 GPU 來訓練 X 模型的話，那就像是教育一個超級天才一樣，你可以一口氣教超級多科目，這個天才會用他的超級 GPU 腦袋，為每一個科目都分配一個核心，並且同時處理這些科目（就像前面的處理 pixel 一樣）。\n所以只要我們使用了 GPU，就可以「大幅提升訓練模型的速度」，因此就可以快速將 X 模型訓練完畢，進而檢查他的訓練成果了。\n補充：為什麼提升「訓練模型」的速度這麼重要？ # 這裡可能會有人有疑問，就是「為什麼提升訓練模型的速度這麼重要？」，就讓我緩緩道來我個人的訓練模型的經驗，跟大家分享一下我 train model 的血淚史\u0026hellip;.🥹（以下「訓練模型」會簡稱為 train model）。\n以前我在唸研究所的時候有稍微旁聽過 Machine Learning 的課（機器學習，算類 AI 吧），那時候有個作業要自己去 train 一個 model 出來，我當時就是調調調參數，然後按下 Enter 鍵放下去讓他跑，接著我就沒事幹了只能苦苦等著他跑完🥹。\n想當然第一次跑出來的結果一定是很爛，需要重 train，所以這時候我又只能重新調一下參數，然後再按下 Enter 鍵，重新用新參數去 train model，然後我就又只能再苦苦等一天\u0026hellip;.。\n所以 train model 真的是會花很多時間都在空等….，就像是你寫了一段程式，然後要等一天後你才能 debug 一樣，只有煎熬可言（而且進度也會進展的很慢），所以這也是為什麼 GPU 真的很重要。\n只要有一個好的 GPU，就可以讓 train model 的時間從 3 天降成 30 分鐘（是有點誇張的比喻，但大概是這個概念），同樣是 30 天的開發週期，有一個好 GPU 的工","date":"2025-01-21","objectID":"c93798d2b665f2b9cbbe43d0561e88bf","title":"GPU 是什麼？為什麼 GPU 對 AI 的發展很重要？","url":"https://kucw.io/blog/gpu-ai/"},{"categories":["其他技術分享"],"content":"Event Sourcing 的設計理念可以說是和一般常見的 CRUD 完全不同，我一開始聽到的時候也驚嘆「啊？？竟然還能這樣？？」，所以這篇文章我們就來了解一下，到底什麼是 Event Sourcing 吧！\n目錄 什麼是 Event Sourcing？ Event Sourcing 和傳統 CRUD 的差別在哪裡？ Event Sourcing 的優化 Event Sourcing 的優勢 Event Sourcing 總結 補充：Event Sourcing 和 DDD 補充 2：Event-Driven Design 是什麼？ 結語 什麼是 Event Sourcing？ # 所謂的 Event Sourcing，中文硬翻的話是「事件溯源」，重點在於「事件」這兩個字。\n而 Event Sourcing 的概念，其實就只是 「將每一筆發生的 Event（事件）都記錄下來」 而已，比想像中單純！\n舉例來說，如果大家去銀行存款/提款的話，銀行一定會記錄「你在某某時間存了多少錢」，因此當你後續去畫簿子（或是查看交易記錄時），就可以看到自己「每一筆存款/提款的時間、以及金額的大小」，而這種「把每一個 Event 都記錄下來」的設計方式，就稱為是 Event Sourcing。\n也因為在 Event Sourcing 中，我們所儲存的是「每一個 Event 的記錄」，而不是儲存「最終的餘額結果」，所以假設使用者想要知道他現在到底有多少存款的話，那我們就只能手動的一筆一筆 event 加總，也就是「把事件全部重頭執行一遍」，最終就可以得到他的最終餘額。\n所以像是在上面的例子中，我們就需要加總這 3 筆 event，也就是「存款 500」、「存款 1000」、「提款 200」，因此使用者最終的餘額就是 500 + 1000 - 200 = 1300。\n因此 Event Sourcing 說穿了，就只是將 「每一筆發生的 Event 忠實的記錄下來」 的架構模式而已！\nEvent Sourcing 和傳統 CRUD 的差別在哪裡？ # 大概了解了 Event Sourcing 的概念之後，我們也可以來比較一下 Event Sourcing 和傳統 CRUD 的差別在哪裡。\n由於 Event Sourcing 的特徵是「將每一個發生的 Event 都記錄下來」，因此在資料庫中我們所儲存的，是每一個 Event 發生的時間。優點是可以知道每一個 Event 的具體發生的時間，缺點則是沒辦法馬上知道最終的總額是多少，需要一筆一筆將 Event 全部加總之後，才能夠得到結果。\n而傳統 CRUD 則不一樣，傳統的 CRUD 是「直接將最終的結果儲存下來」，因此當使用者存錢時，CRUD 就是直接去修改使用者的當前餘額，將他修改成最終的數字。因此 CRUD 的優點是可以快速地知道當前餘額是多少，但是缺點是不知道使用者中間到底交易過幾次。\n也由於 Event Sourcing 和 CRUD 在本質上的不同，因此一般來說，通常是「對每一個 Event 都要詳細記錄的情境」才需要使用 Event Sourcing 來設計，像是金融業銀行、股票買賣、Audit Log\u0026hellip;等等，這種要細到每筆帳都要清算的情況，就很適合用 Event Sourcing 來實作。\n而如果沒有這種需求的話，其實用 CRUD 就真的很夠用了，因為一般來說大家在意的不是那個過程，而是最終的結果，所以這也是為什麼 CRUD 目前還是後端設計主流，就是因為 CRUD 可以應付大部分的真實場景。\n所以作為一個後端工程師，能夠熟練掌握最基本的 CRUD 能力還是非常重要的，基本功不能丟啊！\nEvent Sourcing 的優化 # 呈上面所說，因為 Event Sourcing 就是瘋狂的把每一筆發生過的 Event 給記錄下來，所以每次要得到最終結果的時候，都得要重新一筆一筆的把 Event 給加總，才能夠得到最終結果，但其實在實作上，是有一些手段可以加速的。\n像是我們可以在每天加總該天的 Event，最後生成一個當天的最終結果給使用者看，所以像是股票買賣記錄，就可以在當天晚上結算，先得到一個結果（術語稱為 snapshot），這樣後續就不用再重頭一筆一筆加總 Event 了，只要從今天的結果繼續往下加總明天的 Event 就好。\nEvent Sourcing 的優勢 # 補充：本段內容擷取自 高速大量業務的應用架構關鍵\n另外 Event Sourcing 也有一個超級強大的優勢，就是能夠 「提高後端系統的吞吐量」。\n因為 Event Sourcing 是瘋狂把每一筆 Event 記錄下來就好，所以他就不需要執行 SELECT SQL 語法，先查到要更新的是哪一筆數據，再進行更新，Event Sourcing 就只要直接無腦把 Event 數據 INSERT 到資料庫就好，因此資料庫就可以特意挑選那種擅長寫入的資料庫了！\nEvent Sourcing 總結 # 所以總結上面的介紹，所謂的 Event Sourcing，就是 「將每一筆發生的 Event 都記錄下來」，因此將來不管是要查詢使用者的哪一筆操作有問題、還是要回溯到當下的狀況，都可以用我們所儲存的 Event 數據來回溯。\n而 Event Sourcing 和 CRUD 最大的差別，就在於：\nEvent Sourcing 是「儲存每一筆 Event」。 CRUD 是「儲存數據的最終結果」。 因此大家就可以根據自己的情境，選擇最適合你的架構了～\n補充：Event Sourcing 和 DDD # 其實只要講到 Event Sourcing，就一定會提到跟他很有關係的 DDD。\n所謂的 DDD，全稱是 Domain-Driven Design（領域驅動設計），概念大概是將程式劃分成好幾個領域，每一個領域需要搭配一個領域專家，並且會有一個聚合根（Aggregate），負責該領域的所有事件和數據處理。\n上面這段文字看起來很難對不對？嗯其實我也覺得很難😂，感覺文字分開看我都懂，合在一起看就不太懂🥹。\n由於 DDD 我也只有略懂而已，所以大家如果有興趣的話，也可以再上網查詢「CQRS、Aggregate」\u0026hellip;等關鍵字，這邊就不班門弄斧了🙏。\n補充 2：Event-Driven Design 是什麼？ # 其實了解了 Event Sourcing 的目的是「儲存每一筆 Event 的記錄」之後，要了解另一個名詞 Event-Driven Design 就很容易了～\n所謂的 Event-Driven Design，中文翻譯為「事件驅動設計」，概念大概就是 「當某事件發生時，我們要執行什麼功能」。\n舉例來說，假設我們架設了一組 RabbitMQ，你就可以說「當某個 Queue 出現 message 時，我們就要更新資料庫」，而這其實就是一個 Event-Driven Design，也就是「當某個事件出現時，我們就執行什麼程式」這樣。\n另外如果大家有寫過前端的程式的話，其實整個前端的架構都是 Event-Driven Design，像是「當使用者點擊某個 Button，我就要執行某段程式」，或是「當使用者滑動視窗時，我要改變 Dom 的狀態」\u0026hellip;等等，整個前端其實就是超級大的 Event-Driven Design 架構。\n也因為 Event-Driven Design 的使用情境很廣泛（不僅前端廣泛使用，後端其實也會用到），所以建議大家要了解一下他的概念會比較好～。\n結語 # 這篇文章我們介紹了 Event Sourcing 是什麼，並且也比較了 Event Sour","date":"2025-01-14","objectID":"707e5baa57964af9f7bf09b59f5b0cdd","title":"Event Sourcing 是什麼？他和 CRUD 的差別在哪裡？","url":"https://kucw.io/blog/event-sourcing/"},{"categories":["職涯相關"],"content":"其實所謂的「資深工程師」，他並不是一個突然從天而降的改變，而是一個緩慢的、融入到你工作中的微小變化。\n可能是你今天多幫同事解決了一個 bug 可能是你今天又多學到了一些技術 可能是你以前每一個微小的功能所累積下來的穩定表現，讓主管願意相信你，將更重要的任務交給你 所以要成為資深工程師，並不是突然神蹟降臨，將你頭上的稱號從「初階工程師」升級成「資深工程師」這樣。\n而是會融入在每一天的工作生活中，你慢慢的變強，慢慢的累積周遭同事、主管對你的信任，慢慢的成為人們口中的英雄，這時候你突然回首一看，才發現自己其實已經變成資深工程師了。\n通常到這個時候主管就會約你 1-1，將你的職稱升到資深工程師，確保「你的職稱」和「你所具備的能力」是相符的，這時候就恭喜你～正式成為資深工程師啦🎉🎉\n所以不用急、不用太焦慮，只要慢慢的累積技術實力，不斷變強，每一次提交 commit 時都當成是出 bug 會嚴重到被電到飛高高的那種，戰戰兢兢的前進，慢慢的就會到達你想要的高度了～祝大家職場順遂！\nPS: 其實我覺得「成為資深工程師」和「談戀愛」很像😂，都是那種累積許多微小的改變，最終慢慢的喜歡上一個人這樣（可能我不是那種突然來個浪漫大餐、盛大告白就會心動的類型XD）。\n每一次的 commit 提交，就像是在觀察曖昧對象的每一個舉動一樣：\n可能是 coding style 不好（沒有整理儀容） 可能是架構設計的有問題（金錢觀、感情觀的落差） 可能是單元測試沒寫好出 bug（訂位餐廳但是沒有 double check 所以訂錯時間） 每一個小舉動，都影響著我是否對這個人有加分或扣分（當然對方也是用同樣的標準在審視我），最終當這個人的分數突破 100 分之後，就可以在一起了（就可以升遷了），大概是這種感覺吧XDD\n補充：我開設的 Spring Boot 零基礎入門、Spring Security 零基礎入門、GitHub 免費架站術 已在 Hahow 平台上架啦！輸入折扣碼「HH202601KU」即可享 85 折優惠。\n","date":"2025-01-08","objectID":"454c65d47d19ac3956676267cff8db83","title":"如何成為資深工程師？心態最重要","url":"https://kucw.io/blog/how-to-become-senior-developer/"},{"categories":["其他技術分享"],"content":"RAM 可以說是組裝電腦的必備元件，也是電腦運行程式的基礎，所以這篇文章我們就來介紹一下，電腦中的 RAM 到底是什麼吧！\n目錄 RAM（記憶體）簡介 RAM 的用途 RAM 和硬碟的差別 RAM 總結 補充：「重開機治百病」是什麼原理？ 結語 RAM（記憶體）簡介 # 所謂的 RAM，他的全稱是「Random Access Memory」，台灣通常翻譯為「記憶體」、大陸則是翻譯為「內存」，不過不管是記憶體還是內存，他們指的都是電腦中的 RAM。\n大家平常最接近 RAM 的情境，通常會是在買手機 or 買電腦的時候，像是在買電腦時，常常會聽到賣家宣傳：「這台電腦的記憶體有 16GB」或是「你要不要擴充記憶體到 16GB？」，這個記憶體所指的，實際上就是 RAM。\n像是下圖中就是一條常見的 RAM：（平常有在組桌機的人可能有摸過，但如果你是買筆電的話，就很少有機會能看到 RAM，因為廠商在生產筆電時，就已經把他嵌進筆電裡面了）\n那麼 RAM 到底可以幹嘛呢？RAM 真的是容量越大越好嗎？（當然越大也越貴），下面就介紹 RAM 實際的用途為何。\nRAM 的用途 # 不知道大家在寫程式時，有沒有曾經思考過：「這個程式到底是怎麼運行在電腦上的？」，譬如說，當我們在程式中使用一個變數時，這個變數的空間到底哪裡來的？實際上這些變數就是存放在 RAM 裡面。\n舉例來說，有一台電腦，他的 RAM 有 25 個空格：\n假設此時有一個 A 程式，他裡面宣告了 5 個變數（假設一個變數佔用一格），所以當這台電腦執行 A 程式時，A 程式就會去 RAM 中佔用 5 格（沒錯就是佔地為王），因此 RAM 就只會剩下 20 格可以給其他人用。\n假設這個時候，這台電腦又想去執行 B 程式，而剛好 B 程式裡面宣告了 15 個變數，因此 B 程式就會佔走 RAM 中的 15 格，因此 RAM 只剩下 5 格可以使用。\n而如果這個時候，這台電腦又想去運行 C 程式，但因為 C 程式裡面宣告了 20 個變數，因此 C 程式需要 RAM 中的 20 格才能成功運行起來。但是因為目前 RAM 中僅存的空格只剩 5 格（其他的被 A 程式和 B 程式佔走了），因此 RAM 就沒有足夠的空間能夠運行 C 程式，所以此時就沒辦法運行 C 程式。\n但如果這時候你還是很想運行 C 程式的話，那該怎麼辦呢？答案很簡單，你只要關掉 A 程式或是 B 程式，將 RAM 的空間釋放出來，就可以運行 C 程式了。\n舉例來說，因為 C 程式需要 20 格，所以在這個情境下，就需要關掉 B 程式，將 B 程式的 15 格釋放出來，這樣子才有足夠的空間運行 C 程式。\n所以這也是為什麼常常當我們 Google 分頁開太多時、或是 VS Code + IntelliJ + 其他 IDE 雙開時，電腦會開始有點卡卡的，這就是因為每一個分頁、每一個程式，他們實際上都在搶 RAM 的地盤啊！！！\n當 RAM 剩餘的空間不夠時，電腦就會開始卡卡的，所以這也是為什麼在買電腦的時候，一定會建議大家要把 RAM 從 8GB 升到 16GB，因為當你的 RAM 有 16GB 時，就表示你的 RAM 的空地比較大，因此就可以 「同時容納更多的程式」，重點在「同時」。\n所以換句話說，只要 RAM 越大，你就可以越瀟灑的運行更多的程式，再也不用擔心 RAM 的空間不夠用了，讚讚讚！！\nRAM 和硬碟的差別 # 了解了 RAM 的用途之後，接著我們可以看一下 RAM 的特性，以及 RAM 和硬碟的差別。\nRAM 有一個很重要的特性，就是「當電腦關機之後，RAM 中的所有數據就會全部被刪掉，無法救回」，所以像是我們在程式中所宣告的變數，因為變數是儲存在 RAM 裡面，所以如果沒有及時的把變數中的值儲存到資料庫的話，那麼當這台電腦關機時，該變數的值也就會跟著被刪掉了，因此即使你重新開機，也無法找回當初的變數的值。\n所以為了能夠有一個地方能「永久保存數據」，因此這時候就是「硬碟」派上用場的時候了！\n其實硬碟大家日常生活中應該用的滿多的了，像是我們可以在 Windows 的 C 槽中創建一個檔案、或是在 Macbook 中創建一個檔案，這些檔案所儲存的位置，其實都是儲存在硬碟上。\n而硬碟的特性，就是「即使電腦關機，裡面的數據仍舊會保存下來」，因此硬碟在電腦中所扮演的角色，就是一個永久的儲存空間，只要是關機後仍然想保留下來的數據，一定要儲存在硬碟中，這樣才不會隨著電腦關機而消失。\n因此電腦就是透過 RAM 和硬碟的搭配，來完成程式的執行和數據的儲存了！\nRAM 總結 # 所以總結上面的介紹，RAM 的全稱是「Random Access Memory」，中文翻譯為「記憶體」或是「內存」，並且 RAM 的用途是「用來儲存程式執行過程中的變數」，也就是提供足夠的空間讓程式能夠順利運行。\n而 RAM 和硬碟的差別就在於：\nRAM： 當電腦關機之後，RAM 中的所有數據就會全部被刪掉，無法救回。 硬碟： 即使電腦關機，裡面的數據仍舊會保存下來。 因此大家如果想要將程式中的計算結果永久儲存下來的話，記得一定要寫進硬碟裡面（不管是寫進檔案裡也好、還是寫進資料庫也好，就是要寫進硬碟就是了），不然的話那些數據就會隨著電腦關機，一起跟著消失了！\n補充：「重開機治百病」是什麼原理？ # 當大家了解 RAM 的概念之後，其實就可以理解「重開機治百病」的背後原理到底是什麼了🤣。\n不知道大家有沒有遇到過，不管遇到什麼問題，好像只要重新開機一下，就可以解決他，很有可能就是因為 RAM 出問題了。\n在前面有提到，RAM 的用途是「儲存程式執行過程中的變數」，而因為每個程式各自都會需要宣告一些變數，所以 RAM 需要提供足夠的空地給每一個程式。\n但是重點來了！！假設有某個程式在結束執行時，不好好的歸還他所租借的空地的話，那這樣 RAM 就會越租越少，到最後就會變成無地可租的情況。\n舉例來說，如果有一個 D 程式，他明明租借了 5 塊空格，但是在他程式執行完畢之後，他卻只歸還了 4 格，這樣子 RAM 的總額就會只剩下 24 格（原本是 25 格），進而降低了後續能租出去的空地，因此 RAM 就會越用越少，嚴重一點就會導致無空地可用，因此電腦就會整個卡住，沒辦法運行任何程式。\n如果沒有寫過較底層的程式語言（如 C、C++），可能會覺得「當程式結束了，變數仍舊會佔用空間」這件事情怎麼可能發生，但是事實上，這件事情是真的會發生的🥹。\n一般來說，較高階的程式語言（如 Java、Kotlin、Python、JavaScript、PHP…等），都會自動處理那些沒有用到變數，所以對於寫這些高階程式語言的工程師來說，當我們創建一個變數時，其實我們不需要思考「什麼時候要銷毀它」，我們只要創建它、然後用它來解決程式邏輯就好，根本不需要思考什麼時候要銷毀它，因為高階語言會自動幫我們去銷毀這些變數。\n但是對於 C 和 C++ 這類較底層的語言來說，當你創建一個變數時，你是得要記得去銷毀他的，如果你忘記銷毀的話….那麼你的 RAM 就會一直沒辦法被釋放，因此那格 RAM 就會永遠被佔用，即使你的程式已經停止運作了，那格 RAM 仍舊會一直被佔用。\n那假設那一格 RAM 一直被佔用該怎麼辦？目前只有一種手段可以解決，就是「重新開機」，因為重開機會強制刪除 RAM 中的所有數據，因此該格 RAM 就可以重新被釋放出來，讓其他人租借。\n所以這也是為什麼重開機可以解決許多問題的原因，根本原因就是因為有某個工程師程式沒寫好，老是寫出一些忘記銷毀的變數，使得 RAM 的可用空間越變越小，所以才會導致電腦越跑越慢🥹。\n所以下次當你的電腦又越跑越慢時，先","date":"2025-01-07","objectID":"499821c0d6bb84a8b28133623fbf96b2","title":"電腦中的 RAM（記憶體）的用途是什麼？他和硬碟的差別在哪裡？","url":"https://kucw.io/blog/ram/"},{"categories":["自媒體經營"],"content":"哈囉，我是古古，這篇文章是每月一次的自媒體月報，主要分享我經營《古古的後端筆記》個人品牌的幕後秘辛，如果你也對於「自媒體創業」有興趣的話，歡迎繼續閱讀本文～\n補充：如果想了解《古古的後端筆記》電子報的起源，也可以先查看創刊號的文章。\n2024.12 月粉絲追蹤數、電子報訂閱人數 # 本月份（2024.12）的粉絲成長人數如下：\n2024/11/26 人數 2024/12/31 人數 12 月份（11 月份）總成長人數 Facebook 粉專追蹤數 4389 4475 +86（+239） 電子報訂閱人數 2076 2480 +404（+444） Threads 粉絲追蹤數 4566 5996 +1430（+2009） IG 粉絲追蹤數 353 489 +136（+106） 各項指標仍舊成長中！可能目前還在流量成長期，所以我目前也會先朝著「盡量提高曝光度」努力，先讓大家「能看到我」、讓大家知道「我有在分享後端內容」，再由大家自由決定是否想要訂閱電子報。\n本月撰寫的電子報主題、文章 # 這邊記錄了我這個月撰寫了哪些電子報和文章（花了整個月在介紹 JWT😂），大家如果對於其中的內容有興趣的話，也可以前往查看：\nSession 和 JWT 的差別在哪裡？ 密碼學中的 Encode、Encrypt、Hash 的差別在哪裡？ JWT 是什麼？一次搞懂 JWT 的組成和運作原理 JWT 是如何實作「數位簽名」的？揭秘 signature 的面紗 2024 回顧 # 回顧 2024 年，這是我身為自由工作者的整整一年，在這個期間，我做了：\n錄製完成一門線上課程：Spring Security 零基礎入門 出版一本書：Spring Boot 零基礎入門 參加了幾場社群分享 還有就是，創立了這份電子報 老實說身為一個自媒體工作者，我其實是對我的 2024 年有點沮喪的😞，我深刻感受到一人工作在自律上的種種困難，以及很討厭自己的創作產能不是很穩定，心情很常會變得很低落\u0026hellip;（我想再次跟購買過課程的同學說聲抱歉😭，抱歉中間延期了那麼多次才完成所有課程影片\u0026hellip;）。\n有時候我會坐在電腦前面，明明已經想好要寫哪個主題，我也大概知道大綱要怎麼寫、素材要怎麼找，但是就提不起勁，最終就變成坐在電腦前發呆，然後那一天就這樣消失了\u0026hellip;。\n不過，即使 2024 年的我過得不是很好，但我仍舊想要試著改變，希望可以透過不同的形式，找回當初創作的快樂，而這個嘗試之一，就是創立了電子報！\n我也不知道為什麼，可能是寫電子報的負擔沒有錄製課程影片大，也可能是電子報的頻率比較低（一週寫一篇就好），目前電子報也已經寫了 20 期了，真的很感謝大家一路以來的訂閱和支持🙏。\n不過未來我還是會想錄製課程的！還有好多主題想要錄，而且我相信 「軟體的價值在於重複使用」，只要我好好的錄一次影片，這支影片就可以被許多人重複觀看，不斷的重複使用，超級讚！\n因此在 2025 年，我希望可以再錄製一堂線上課程出來，不過目前主題暫時還沒想好，等到確定了會再跟大家說～（只是有了前幾次錄製課程的教訓，這次我會盡力將進度安排得更合理一點的🥹）。\n2025 展望：Sharing is Learning! # 拍謝上面的 2024 年回顧好像有點沈重😂，只是想說既然是自媒體月報，就想要把自己真的經歷過的心情跟大家分享這樣，自由工作者其實真的沒有想像中輕鬆（壓力來自於不確定感和不安感），雖然是能每天睡到自然醒啦，不過長期下來的心情其實是沒辦法太放鬆的，大概就是「長期精神慢性病 + 睡到飽的健康身體」這樣。\n不過 2025 年展望，我們說點輕鬆的！！沒錯我要開始畫餅了🤣（展望就是拿來畫餅的對吧XD）\n在 2025 年，除了上面提到的「想要再錄製一堂線上課程」之外，2025 年我想用一句話來期許，就是 「Sharing is Learning!」（分享就是最好的學習！）。\n在新的 2025 年，我想學更多，也想分享更多！想要把學習到的知識分享給大家，也想要讓自己變得更強！！！\n老實說我不知道我還能寫多久（希望至少寫 3 年啦），但我相信我沒辦法寫一輩子（就算我能寫一輩子，我也沒辦法重現當下學習知識的快樂和成就感）。\n人的成長只有一次，我希望我能慢慢變強，我也希望能夠帶著大家一起變強，與其看著照片牆上一張張專業的攝影牆讚嘆不已，倒不如真的親身一步一步爬上山比較有趣對吧？\n希望 2025 年會是起飛的一年，大家坐穩繫好安全帶，我們一起變強💪！！！\n如果你喜歡這份電子報，歡迎分享給你的朋友、同事，揪他一起訂閱電子報，大家一起變強！\n電子報訂閱連結：https://kucw.io/bio/\n","date":"2025-01-07","objectID":"67b062c4eb6b086bb13b2a9d6e610e69","title":"軟體工程師的自媒體之路 - 2024.12 月報","url":"https://kucw.io/blog/as-a-content-creator/monthly-report-202412/"},{"categories":["其他技術分享"],"content":"因應 Medium 的付費牆、以及 SEO 的政策調整，我發現我在 Medium 上的文章越來越難被搜尋到了🥹。\n有的人可能不知道什麼是 SEO（Search Engine Optimization，搜尋引擎最佳化），簡單的說，你 SEO 做得越好，這篇文章就可以在 Google 搜尋中排名越前面，而在 Google 搜尋中排名越前面，自然點閱率就越高，曝光度就越大（因為大家在找資料的時候，一定都是先點前幾個連結嘛）。\n所以在寫文章時，除了提升自己文章的內容之外，要怎麼樣讓自己的文章可以 「被看見」，也是非常重要的一件事！\n是 Medium 還是 Google 把我文章吃了？ # 鑑於 SEO 實在是太重要了，所以這也是為什麼我會離開 Medium 的主因。\n回想 Medium 剛起家的時候，他憑藉著自身簡約的網站風格、再加上 SEO 的優化政策做得非常好，所以有非常多的作者轉移到 Medium 上寫文章。\n但是近幾年 Medium 對 SEO 優化做了非常多調整，我自己曾在 Medium 上和 GitHub 個人網站上，分別寫了兩篇一模一樣的文章，但是當我用同樣的關鍵字去查詢的時候，GitHub 個人網站的文章可以排在前三名，而 Medium 的文章我翻到第 10 頁了還找不到，差距非常大。\n上圖為我使用同樣的關鍵字「lombok」去查詢的結果，我在自架的 GitHub 個人網站上寫的文章可以進到第 1 頁，但是 Medium 的文章卻連前 10 頁都找不到\nMedium 的文章連結：https://medium.com/@kujudy/java-lombok-cc4a2947ab5a\nGitHub 個人網站的文章連結：https://kucw.io/blog/2020/3/java-lombok\n老實說，當時看到這種情況我真的是哭笑不得，我沒想到 Medium 對 SEO 的影響會大到這麼誇張，如果是差個幾頁就算了，但是在 10 頁之內都找不到自己寫的文章，知道的當下還是有點沮喪的😞。\n有寫過文章的人就知道，產出一篇文章的背後，要花很多時間去研究、安排架構、調整用字遣詞，自己都花很多時間和熱情去寫文章了，但是卻因為這個 Medium 的 SEO 政策的關係，導致自己寫的內容沒辦法被別人看見，只能默默地在網路的世界不斷下沉\u0026hellip;\n想到這裡，就更加讓我下定決心要離開 Medium 了。\n下一站在哪裡？ # 有鑒於曾經在 Medium 上投注了心血，卻沒辦法得到相對應成果的痛苦經驗，所以這次我決定，我不要再受限在任何一個平台上了，因為難保下一個平台不會發生和 Medium 同樣的事情，如果這一次轉換平台，又碰到和 Medium 一樣的問題，那到時候就又只能崩潰的尋找下一個替代方案。\n在花了很多時間在網路上查了各種方法之後，最後我發現了在國外很熱門的 Hugo 架站工具，Hugo 在 GitHub 上有 76.9K 的 Stars，算是非常活躍的社群！\n只要使用這套 Hugo 架站工具，再搭配上 GitHub 提供的免費個人網站域名 GitHub Pages，這樣就可以架設出自己的個人網站了！聽起來好像滿簡單的，所以當時我就花了一些時間去看官方文件，因此就開始了我的自架個人網站之路。\n如何使用 Hugo 在 GitHub 上架設個人網站？ # 如果你本身有工程師背景的話，其實照著 Hugo 官方的文件做，再花一些時間 debug，很快就能在 GitHub 上架出個人網站了。\n但如果你完全沒有寫過任何一行程式的話，那要直接上手 Hugo 的難度還是滿高的，因為在使用 Hugo 的過程中，會有一些必要的背景知識，而這些是官方文件不會教你的。\n在使用 Hugo 架站之前，你必須要知道的幾件事：\n如何使用 brew or choco 去安裝 Hugo？ 如何修改程式碼？（工程師通常都有自己用習慣的編輯器，像我是 VS Code + IntelliJ 雙棲） 如何使用 Git，將程式碼上傳到 GitHub 上？ 如何撰寫 Markdown 文章？ 如果以上這四點你都了解的話，那麼直接看 Hugo 官方文件來架個人網站完全沒問題，但如果你對上面提到的 Git、Markdown 這些專有名詞有障礙的話，建議會需要先上網查一下相關資料，或是參考下面的線上課程。\n工商時間 | 一起在 GitHub 上架設個人網站吧！ # Hahow 線上課程：Github 免費架站術！輕鬆打造個人品牌， 輸入折扣碼「HH202601KU」即可享 85 折優惠\n如果你沒有工程師背景，但也想擺脫各大文章平台的束縛，擁有一個自己的個人網站的話（並且還是免費的！），也許這門線上課程就是你在找的引路人。\n本課程會一步步的從零開始教學，介紹要如何使用 Hugo 以及 Github Pages，架設出屬於你的個人網站，因此當你上完這門課時，你的個人網站也已經完成了！\n架設好自己的個人網站，然後呢？ # 架設出自己的個人網站之後，我才發現可以玩的東西多太多了！\n1. 文章終於可以分類了 # 光這點我覺得就完勝 Medium，我真的很不解為什麼 Medium 不願意提供一個分類的機制給大家使用，難道 Medium 覺得我們寫的文章都很整齊不用分類整理嗎！！！\n2. 可以添加個人經歷頁面，讓網站更豐富 # 以前在 Medium 寫文章時，只能設定一些簡單的自我介紹，但是如果是自架個人網站的話，就可以自由發揮，用圖形化的方式去呈現一些個人經歷，同時也可以去整合自己的其他作品，讓別人進到這個網站，就可以了解你過去所有的經歷、作品集、以及所寫的所有文章。\n不過要達到這個效果，會需要具備一些前端的 Html、Css\u0026hellip;等知識，但是如果很熟悉前端的知識的話，做出來的網站豐富度真的不是 Medium 可以比的，完勝 Medium！\n3. 使用 Google Search Console 查看搜尋成效 # 這個是 Google 提供的很酷的功能，我也是架了個人網站才接觸到這個功能。\n當架設好個人網站之後，可以到 Google Search Console 裡，申請在 Google 搜尋引擎上註冊你的個人網站，只要申請成功之後，這樣其他人就可以透過 Google 搜尋找到你的個人網站了！\n並且申請了入住 Google 搜尋之後，後續你也可以透過 Google Search Console，去查看個人網站的搜尋成效，譬如說我可以查看某段時間內，網頁的 曝光量 / 點擊量 有多少，或是網頁的點擊率是多少。\n如果網頁點擊率低的話，就表示別人在 Google 搜尋結果中看到我的文章，但是卻沒有點進來看內容，那原因可能就是因為我的文章標題下得不夠吸引人，所以我就可以朝這個方向去修改我的文章標題。\n4. 使用 Google Analytics（GA）查看網站成效 # 這個也是 Google 提供的功能，不過 GA 的名氣就比 Google Search Console 大多了，一般前端工程師和行銷的職位都會碰到 GA。\n架設好個人網站之後，可以到 Google Analytics 申請使用 GA 的服務，接著就可以使用 GA 去查看個人網站的流量了。\n5. 使用 Google AdSense 收取廣告費 # Google 真的是佛心來著，不只提供了許多好用的功能給我們使用，現在竟然還可以讓我們靠寫文章來賺錢！！\n大家在瀏覽網站的時候，常常會看到有的網站下面有一個「Google 提供的廣告」對吧？這個就是 Google Adsense 的功能。\nGoogle AdSense 這個功能簡單的說，就是你將個人網站中的一塊地租給 Google，而 G","date":"2025-01-01","objectID":"aec97ec3769fafde70d3e2508c4c802b","title":"為了 SEO！我離開了 Medium，改在 GitHub 上自架個人網站","url":"https://kucw.io/blog/2021/1/from-medium-to-github/"},{"categories":["其他技術分享"],"content":"在上一篇的 JWT 是什麼？一次搞懂 JWT 的組成和運作原理 文章中，我們有介紹了 JWT 是由三個部分所組成，分別是：header、payload 以及 signature。\n而在 header、payload、signature 這三個部分中，他們各自負責的功能如下：\nheader： 用來設定這個 JWT 的簽名算法、以及此 Token 的類型 payload： 用來儲存使用者的數據，可以根據自己的需求進行客製化 signature： 用來儲存「簽名」的計算結果 因此這篇文章我們就會接著來探討，為什麼 JWT 透過 signature 的部分就可以實作出「數位簽名」的概念，並且也會介紹「數位簽名」到底是有多神奇，可以直接阻擋駭客的竄改。\n本文為 JWT 系列文的最終章，會使用到前面所提到的所有概念（包括 JWT 的組成、非對稱加密、Hash），因此如果你對這些概念還不太熟悉，建議可以先回頭參考前面文章的介紹（建議按照順序閱讀，才會有最佳的閱讀體驗）：\nSession 和 JWT 的差別在哪裡？ 密碼學中的 Encode、Encrypt、Hash 的差別在哪裡？ JWT 是什麼？一次搞懂 JWT 的組成和運作原理 JWT 是如何實作「數位簽名」的？揭秘 signature 的面紗（本文） 目錄 signature（數位簽名）的運作邏輯 前置作業 JWT 的生成 JWT 的驗證 JWT 的數位簽名總結 結語 signature（數位簽名）的運作邏輯 # 前置作業 # 如果要實作 JWT 的數位簽名的機制，最常見的做法是使用 「非對稱加密」 來實作，所以在實作前，後端需要先生成一組「公鑰」和「私鑰」出來，等等就會使用這兩組密鑰來搭配實作「數位簽名」的功能。\n而當後端生成好一對公鑰和私鑰之後，就可以開始來進行 JWT 的生成了！\n補充：在非對稱加密中，公鑰是公開的、可以廣發給所有人，私鑰則是私有的，要自己保管好，絕對不可以洩漏。並且使用公鑰來加密的數據，只能使用私鑰來解密；使用私鑰來加密的數據，只能使用公鑰來解密。\nJWT 的生成 # 在生成 JWT 時，首先後端要先根據自己的商業邏輯，填上 header 和 payload 中的值。\n所以像是在下方的 payload 中，我就填上了 {\u0026quot;sub\u0026quot;:\u0026quot;123\u0026quot;, \u0026quot;name\u0026quot;:\u0026quot;古古\u0026quot;...} 的資訊，用來表示這個 JWT 中所裝的使用者資訊，是名叫「古古」的使用者資訊。\n這裡大家可以根據自己的需求，在 payload 中填上你想要的值，不管你在 payload 中填上什麼值，對後續的 signature 生成都不會有任何影響（只不過在生成 signature 之前，一定要先確定好 payload 中的值要填什麼就是了，一旦 signature 生成之後，就不能改 payload 中的值了）。\n而當寫好 header 和 payload 中的值之後，此時後端需要對 header + payload 的值 Hash 一下（此處使用的是 SHA-256 Hash 演算法），所以此時就會計算出 header + payload 被 Hash 過後的結果，即是 srtp3k。\n接著後端要使用「私鑰」，將這個 hash value srtp3k 加密，因此就會得到一個加密過後的結果 ap9fPl...。\n而當後端產生出 ap9fPl... 這個加密過後的結果之後，後端必須將這個值放在 JWT 中的 signature 的欄位中，因此最後後端傳送出去的 JWT 結果，就會在 signature 的部分填上 ap9fPl... 的加密過後的值。\n所以到這裡，就完成了第一階段的「JWT 的生成」了，因此此時後端就可以將這個 JWT Token 傳送給前端，交由前端保存這個 JWT Token。\nJWT 的驗證 # 而當前端後續拿著這個 JWT 來請求 api 時，我們身為後端，就必須要驗證這個 JWT 的正確性（即是是否有被駭客竄改過），而要驗證 JWT 的正確性，就是去檢查其中的 signature 的值就可以了。\n舉例來說，當前端拿著剛剛的那一個 JWT 來請求 api 時，這時候我們身為後端，必須要先對當下的 header + payload 的區塊進行 Hash，先計算出 header + payload 的 Hash 值，因此此時就會得到一個 Hash 結果（即是下方區塊中的 srtp3k）。\n這時候 JWT 中最精華的地方來了！！！當後端計算出 header + payload 的 Hash value 之後，後端只要使用「公鑰」將 signature 解密，然後比較一下「當初所計算出來 Hash 的值」和「現在所計算出來的 Hash 值」是否一樣，就可以知道此 JWT Token 是否有被竄改過了！\n像是假設駭客偷偷修改 name 的值，將他從 古古 改為 我是駭客 的話，那麼當後端在收到這個 JWT 時，當下所計算出的 header + payload 的值就會是 Fy93HE，而這個值就會和「使用公鑰解密 signature 所得到的原始 Hash 值 srty3k」不一樣，因此 JWT 就會驗證失敗，所以後端就會認為這個 JWT 中的內容有被偷偷修改過，因此就不相信裡面的數據。\n所以總結來說的話，當後端收到 JWT 時，後端只要驗證一下 「當下 header + payload 所計算出來的 Hash 值」 和 「使用公鑰解密 signature 所得到的值」 是否一樣，就可以知道這個 JWT 有沒有被偷偷修改了，這就是「數位簽名」的核心運行邏輯啦！！\n所以大家以後就可以透過 JWT 的數位簽名的特性，將 JWT 直接儲存在前端中，後端就只要在收到 JWT 時驗證一下簽名就好，因此就不需要再儲存大量的數據在後端裡面了！讚！！\nJWT 的數位簽名總結 # 所以總結上面的介紹，JWT 之所以可以透過 signature 的「數位簽名」來避免駭客的竄改，就是因為他使用了「非對稱加密」來實作數位簽名的機制。\n而我們身為後端，在生成 JWT 時，需要使用「私鑰」來加密 header + payload 的數據，並將結果放在 signature 中。\n並且在驗證前端傳過來的 JWT 時，需要使用「公鑰」來解密 signature 得到原始值，並且比較他和「當下 header + payload 所計算出來的 Hash 值」是否一樣，如果一樣的話，才表示 JWT 驗證成功，裡面的數據沒有被駭客所竄改，因此可以相信裡面的數據。\n因此大家就可以透過這個步驟，在你的後端程式中實作 JWT 的相關程式了！\n補充：本文是擷取自我開設的線上課程「資安一把罩！Spring Security 零基礎入門」的內容，如果你想了解更多的資安內容、以及如何應用 Spring Security，歡迎參考課程簡介 （輸入折扣碼「HH202601KU」即可享 85 折優惠）。\n結語 # 這篇文章我們介紹了 JWT 的「數位簽名」的核心運作邏輯是什麼，數位簽名可以說是 JWT 中最重要的特性，就是因為有了數位簽名，才使得我們可以將 JWT 儲存在前端 Client 中，打破了以往只能將數據儲存在後端的設計方式，可以說是超級厲害的發明！！\n如果你對後端技術有興趣的話，也歡迎免費訂閱《古古的後端筆記》電子報，每週二為你送上一篇後端技術分享，那我們就下一篇文章見啦！\n本文為 JWT 系列文的最終章，如果你想回顧前面的介紹，也可以參考前面的文章：\nSession 和 JWT 的差別在哪裡？ 密碼學中的 ","date":"2024-12-24","objectID":"7eb1dd8c7bb1414a121ff19a83fe8216","title":"JWT 是如何實作「數位簽名」的？揭秘 signature 的面紗","url":"https://kucw.io/blog/jwt-signature/"},{"categories":["其他技術分享"],"content":"在現今的架構中，JWT 可以說是使用非常廣泛的一項技術，所以這篇文章我們就來介紹一下 JWT 是由哪些部分所組成，以及每個部分所負責的功能為何吧！\n本文為 JWT 系列文之一，建議在閱讀本文前，要先了解 Session 和 JWT 之間的差別、以及 Encode/Decode 的概念，才會比較好上手。如果你對這些概念還不太熟悉，也可以參考前面的文章介紹（建議按照順序閱讀，才會有最佳的閱讀體驗）：\nSession 和 JWT 的差別在哪裡？ 密碼學中的 Encode、Encrypt、Hash 的差別在哪裡？ JWT 是什麼？一次搞懂 JWT 的組成和運作原理（本文） JWT 是如何實作「數位簽名」的？揭秘 signature 的面紗 目錄 回顧：Session 和 JWT 的差別 什麼是 JWT？ JWT 中的 header 部分：存放通用資訊 補充：JWT 中的 Encode 和 Decode JWT 中的 payload 部分：存放使用者的數據 補充 1：payload 中的常用變數 補充 2：不要在 payload 中存放敏感數據 JWT 中的 signature 部分：實作數位簽名 JWT 總結 結語 回顧：Session 和 JWT 的差別 # 在 Session 和 JWT 的差別在哪裡？ 的文章中，我們有介紹到 Session 和 JWT 的差別分別是：\nSession 認證： 將登入的資訊儲存在「後端 Server」上 JWT 認證： 將登入的資訊儲存在「前端 Client」中 所以大家就可以根據自己的需求，選擇到底要使用 Session 來進行認證、還是使用 JWT 進行認證。\n不過在當時的那篇文章中，我們先跳過了「為什麼後端可以無條件相信 JWT 中的內容？」的相關細節，因此這篇文章就會回過頭來介紹這部分，了解 JWT 中的組成有哪些，以及 JWT 的運作原理是什麼，使得後端可以無條件相信 JWT 中所記錄的資訊。\n什麼是 JWT？ # 所謂的 JWT，他的全稱是 JSON Web Token，而他的用途，通常就是用來「傳遞身份認證的數據」。\n在 JWT 中，會由三個部分所組成，分別是：header、payload 以及 signature，並且在每一個部分之間，就會使用一個 . 作為分隔。\n像是在下面的例子中，左邊的 eyJhb.... 這段亂碼，他其實就是一個 JWT Token，所以他就可以根據其中的 . 區分成三個部分，也就是 header、payload 以及 signature。\n所以其實 JWT 格式，他就只是一段亂碼，只是我們可以使用 .，把內部的資訊區隔成三個部分而已。\n而如果我們把下面這段 JWT 的亂碼，貼到 JWT 的官方網站 https://jwt.io/ 中的話：\neyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjMiLCJuYW1lIjoi5Y-k5Y-kIiwiaWF0IjoxNzIxMDAxNjAwfQ.G41XQGNNJ5Tp88U48aXh4n0XtGkpPkQ3xK6j43_61gE309hzyTVyciG5v05aVIvvY9NrApYiQdvwlMMrjRPFVV8xunghtKKFMj3kPx93Ll8Pf6n-tDiL_NZYqcusrgwtb-EDza80hMG5PTu75ogTIfRKr4jC0_FZzLaMix07LaZReoUSionTWTxJlm8qJc0BAFXgsaGNs9oVhCXOg_jJmOfFZBP0tD3q4xaKp9MTtLRTtslAhoAjPczdnPqaWGcaS8OY11RUTvvxijA7W-mPRlmqt0Hd_XForETUFZRdCKsPQIiGjkavycPtdiViVihQKstHlT4afEzYvzWSeK1cnw 就可以看到這個網站就會將此 JWT 分成三個部分，也就是剛剛提到的 header、payload、signature。\n所以在了解 JWT 的運作原理之前，一定要先知道 「JWT 是由 header、payload 和 signature 這三個部分所組成」，每一個部分所負責的功能都不一樣，所以先了解 JWT 的結構是非常重要的！\n而在 JWT 中，每一個部分所負責的功能都不一樣，以下分別介紹他們各自所負責的功能：\nJWT 中的 header 部分：存放通用資訊 # 首先 header 的用途，就是用來存放一些通用的資訊，譬如說可以用來設定這個 JWT 的簽名算法、以及設定這個 JWT 的 Token 類型。\n舉例來說，像是在下方的 header 例子中，裡面的 alg 就是用來設定這個 JWT 的簽名算法，而 typ 則是表示這個 Token 是 JWT 類型。\n{ \u0026#34;alg\u0026#34;: \u0026#34;RS256\u0026#34;, \u0026#34;typ\u0026#34;: \u0026#34;JWT\u0026#34; } 所以在 header 中，主要就是用來設定這個 JWT 的通用資訊。\n補充：JWT 中的 Encode 和 Decode # 而大家如果觀察一下的話也可以發現，在 JWT 的官網中（https://jwt.io/），當我們在左側貼上 JWT 的亂碼之後，在右邊所呈現的會是 Decode（解碼）過後的結果。\n像是以 header 的亂碼 eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9 為例，將他 Decode 之後，就可以得到原始的 JSON 字串 {\u0026quot;alg\u0026quot;:\u0026quot;RS256\u0026quot;,\u0026quot;typ\u0026quot;:\u0026quot;JWT\u0026quot;}。\n所以在 JWT 中，header 的亂碼看似好像有加密，但他實際上是完全沒有加密的！！！JWT 只是使用 Base64 將 JSON 字串給編碼一下而已，完全沒有加密的成分在裡面，因此所有人都有能力 Decode 這段亂碼，取得原始的 JSON 字串。\n補充：不熟悉 Encode 和 Decode 的概念的話，可以回頭參考 密碼學中的 Encode、Encrypt、Hash 的差別在哪裡？ 中的介紹。\nJWT 中的 payload 部分：存放使用者的數據 # 了解了 header 的用途之後，接著我們可以來看一下 payload 的用途。\npayload 的用途，就是用來存放使用者的數據，所以在 payload 中，我們就可以根據自己的需求，自由決定我們想要放什麼資訊在裡面。\n所以像是在下面的 payload 例子中，裡面就存放了 \u0026quot;name\u0026quot;: \u0026quot;古古\u0026quot; 的數據，用來表示這個使用者的名字為「古古」，因此我們就可以根據自己的需求，在 payload 中存放客製化的使用者數據了！\n{ \u0026#34;sub\u0026#34;: \u0026#34;123\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;古古\u0026#34;, \u0026#34;iat\u0026#34;: 1721001600 } 補充 1：payload 中的常用變數 # 在客製化 payload 的數據時，我們也是可以使用 JWT 預先定義好的變數名稱來實作的。\n舉例來說，sub 所代表的就是「使用者的 id 的值」，至於 iat 所代表的就是「這個 JWT Token 的創建時間」，這些都是 JWT 預設的變數名稱，算是使用 JWT 的一個默契。\n所以大家在使用上，除了自己定義變數名稱之外，建議也可以多多利用 JWT 所定義的變數名稱，這樣就可以讓不同工程師所設計出來的 payload 長得差不多，就不用再每次都一個一個詢問「這個變數名稱的含義","date":"2024-12-17","objectID":"c1bdb26661440edca46b780306f991c3","title":"JWT 是什麼？一次搞懂 JWT 的組成和運作原理","url":"https://kucw.io/blog/jwt/"},{"categories":["其他技術分享"],"content":"在密碼學中，Encode、Encrypt、Hash 可以說是三大基礎概念，並且也是後端工程師必備的密碼學知識，因此這篇文章就會詳細來介紹什麼是 Encode、Encrypt、Hash，以及比較他們之間的區別。\n本文為 JWT 系列文之一，如果你對 JWT 的其他文章有興趣，也可以直接點擊下列連結跳轉到該文章（不過建議還是按照順序閱讀，才會有最佳的閱讀體驗）：\nSession 和 JWT 的差別在哪裡？ 密碼學中的 Encode、Encrypt、Hash 的差別在哪裡？（本文） JWT 是什麼？一次搞懂 JWT 的組成和運作原理 JWT 是如何實作「數位簽名」的？揭秘 signature 的面紗 目錄 Encode、Encrypt、Hash 簡介 什麼是 Encode（編碼）？ 什麼是 Encrypt（加密）？ 什麼是對稱加密？ 什麼是非對稱加密？ 什麼是 Hash（雜湊）？ 補充：Hash 真的沒辦法被破解嗎？ 補充 2：我還是很想用 MD5，真的沒辦法了嗎？ Encode、Encrypt、Hash 總結 結語 Encode、Encrypt、Hash 簡介 # 在密碼學中有三大概念，分別是：\nEncode（編碼） Encrypt（加密） Hash（雜湊） 以下分別介紹如何透過這三種不同的方法，去對數據做不同的處理。\n什麼是 Encode（編碼）？ # 所謂的 Encode（編碼），就是「數據可以直接被編碼」，並且中間「不需要」任何的密鑰參與。\n像是在下面的例子中，左邊的原始字串 123，就可以被 Encode（編碼）成右邊的 gg2oGVzdD，而右邊的 gg2oGVzdD，他也是可以直接被 Decode（解碼）回原始的字串 123 的。\n因此在 Encode 和 Decode 的過程中，是不需要任何的密鑰，「所有人」 都可以輕易的 Encode 和 Decode。\n而一般在實務上，最常見的 Encode 演算法為「Base64」，像是在這個 Base64 Encode 的網站中，只要在上面輸入 test123，下面就會出現 Encode 過後的結果 dGVzdDEyMw==。\n而這時如果大家複製一下下方的結果 dGVzdDEyMw==，然後點擊左邊的 Decode 連結（跳轉到 Decode 的頁面），然後將剛剛的結果 dGVzdDEyMw== 貼在上面的話，這時候就可以直接將這個結果 Decode 回原始的字串 test123。\n所以對於 Encode 和 Decode 來說，他們完全不需要密鑰的參與，也可以對數據進行「編碼和解碼」，因此所有人都可以針對某一筆數據進行 Encode 和 Decode。\n也因為如此，大家在使用 Base64 去 Encode 數據時，一定要注意這個數據是沒有被加密過的，所以所有人都有能力將他 Decode 回原始的字串！！一定要小心！！！\n所以下次當你看到有人在網路上隨意散播使用 Base64 Encode 的數據時，你完全可以大膽的將他 Decode，就可以得到原始的字串，因此千萬不要再誤解 Base64 很安全了🥹，他真的就只是一個編碼的工具而已，完全沒有任何加密的成分在裡面！\n補充：Encode 其實嚴格上來說不算加密，因為他只是改變數據的呈現方式，完全沒有加密可言，但口語上有時候還是會把 Encode 歸類成加密，因此才放在這裡一起介紹。\n什麼是 Encrypt（加密）？ # 了解了 Encode 之後，接下來我們可以來看一下 Encrypt 的相關介紹。\n所謂的 Encrypt（加密），就是「將數據加密成密文」，所以透過 Encrypt 加密過後的數據，他可以說是非常安全的。\n而在 Encrypt 的世界中，又可以再細分成兩種加密方式，分別是：\n對稱加密 非對稱加密 所以以下針對這兩種加密方式來介紹。\n什麼是對稱加密？ # 在對稱加密中，只會有「一把」密鑰存在，因此不論是加密還是解密，就統統是用這把密鑰來進行。\n舉例來說，左邊的原始的字串 123，他就可以透過這把密鑰（或是簡稱為這把 key），加密成右邊的 gg2oGVzdD，而右邊的 gg2oGVzdD，他也可以透過這把密鑰，解密回原始的字串 123。\n所以在對稱加密中，就只會存在「一把」密鑰，因此不管你是要加密還是解密，統統就是透過這把密鑰進行。\n也因為在對稱加密中只有一把密鑰存在，所以這把密鑰必須要好好的保護，絕對不可以洩漏，一但密鑰洩漏，駭客就可以透過這把密鑰解密出原始的字串，因此在對稱加密中，保護密鑰是非常重要的任務！\n什麼是非對稱加密？ # 而不同於對稱加密，在非對稱加密中，則是會有「兩把」密鑰存在。\n在這兩把密鑰中，其中一把會叫做「公鑰」（也就是 Public Key），另一把則叫做「私鑰」（也就是 Private Key），因此在非對稱加密中，就是由「公鑰」和「私鑰」共同配合，對數據進行加密和解密。\n所以這兩把密鑰，他們的特性如下：\n公鑰（Public Key）：公開的，可以複製好幾份，廣發給所有人 私鑰（Private Key）：私有的，必須要好好的保護，不可以洩漏 並且在非對稱加密中，有一個很神奇的運作邏輯，也就是：\n由 「公鑰」 所加密的數據，只能夠由 「私鑰」 解密 由 「私鑰」 所加密的數據，只能夠由 「公鑰」 解密 所以換句話說的話，就是 「由其中一把鑰匙所加密的數據，只能夠用另一把鑰匙來解密」，這就是「非對稱加密」的運作方式。\n也由於非對稱加密的神奇特性（其中一把加密的數據，只能用另一把解密），所以在 JWT 中的「數位簽名」，實際上就是用非對稱加密所實作的。甚至不止 JWT，像是區塊鏈中的數位簽名，他背後也是用非對稱加密實作的（不如說只要是扯到「數位簽名」或是「數位簽章」這個概念，底層都是同一套，都是用非對稱加密實作）。\n所以在了解 JWT 的「數位簽名」是如何實作的之前，建議大家一定要先了解「非對稱加密」的運作邏輯（也就是其中一把加密的數據，只能用另一把解密），這樣子後續在了解 JWT 的相關知識時，才能夠知道他底層的運作邏輯為何。\n什麼是 Hash（雜湊）？ # 在了解了 Encrypt 中的「對稱加密」和「非對稱加密」之後，最後我們也可以來看一下 Hash 的相關介紹。\n所謂的 Hash（雜湊），就是「單方面的將數據轉換成亂碼（或稱為 Hash Value，雜湊值）」，並且這個 Hash Value，他是「不能夠」轉換回原始的字串的。\n舉例來說，左邊的原始字串 123，他可以被 Hash 成右邊的亂碼 gg2o861kdn5（又稱為 Hash Value，雜湊值），但是我們卻沒辦法將右邊的亂碼 gg2o861kdn5，轉換回原始的字串 123。\n所以在 Hash 的世界中，所有的數據只要被 Hash 過，就再也沒辦法轉換回原始的數據，就算老天來也沒用，世界上沒有人（包含駭客和你自己）有能力將 Hash Value 轉換回原始的數據。\n補充：Hash 真的沒辦法被破解嗎？ # 從根本的邏輯上，只要一個數據被 Hash 過，那我們是真的沒有辦法將這個數據轉換回原始的字串，但是！！駭客就想到一招破解的方式：「既然我沒辦法將數據轉換回來，那我乾脆提前做一張很大很大的表格，提前記錄 什麼樣的數據 會轉換成 什麼樣的亂碼 不就好了？」\n舉例來說，駭客可以提前計算出 123 這個字串會被 Hash 成 gg2o861kdn5、456 這個字串會被 Hash 成 aaaa777k3nt\u0026hellip;等等的結果。因此當駭客發現某一筆被 Hash 過的值是 aaaa777k3nt 時，駭客就只要回來查詢這張表格，就可以馬上找出 aaaa777k3nt 的原始字串是","date":"2024-12-10","objectID":"a601351e37d769ac312a94d4d0166cef","title":"密碼學中的 Encode、Encrypt、Hash 的差別在哪裡？","url":"https://kucw.io/blog/encode-encrypt-hash-intro/"},{"categories":["其他技術分享"],"content":"在現今的架構中，JWT 可以說是使用非常廣泛的一項技術，但是 JWT 到底是什麼？以及他的用途為何？甚至 JWT 和 Session 的差別在哪裡？這些都是在了解 JWT 的過程中，需要具備的知識。\n因此在這個 JWT 系列文中，我會用 4 篇文章介紹 JWT 的前世今生，包含在 JWT 的用途是什麼、他要解決的是什麼問題、以及 JWT 的底層運作邏輯為何。\n所以首先這篇文章，我們就先來介紹 Session 和 JWT 的運作原理為何，以及並且比較他們之間的差別。\n目錄 什麼是 Session 認證？ 什麼是 JWT 認證？ 補充：後端為什麼能無條件相信 JWT？ 小結：Session 和 JWT 的運作邏輯 Session 和 JWT 的優缺點比較 使用 Session 的優點和缺點 使用 JWT 的優點和缺點 到底使用 Session 好，還是使用 JWT 好？ 結語 什麼是 Session 認證？ # Session 和 JWT 可以說是現今主流的兩種登入認證機制，不過在開始比較 Session 和 JWT 的差別之前，首先我們要先來介紹一下什麼是 Session 身份認證機制。\n所謂的 Session 認證，就是「將登入的資訊儲存在後端 Server 上」的一項技術，所以換句話說的話，就是後端 Server 會儲存這個使用者的登入資訊，並且回傳一個 Session id 給使用者。\n舉例來說，假設我是一個使用者，我的帳號密碼是 Judy / 123，這時候當我在網站上輸入帳號密碼，並且嘗試登入時，首先後端 Server 會先去驗證我的帳號密碼 Judy / 123 是否曾經註冊過（畢竟得先註冊過才能登入），假設這組帳號密碼存在的話，後端 Server 就會生成一個 Session id（也就是 66EE89C175E），並且將 Session id 存放在資料庫中，然後將 Session id 回傳給前端。\n所以當前端（此處以瀏覽器為例）收到 Session id 的值時，前端就可以將這個 Session id 的值存放在 Cookie 中，等待後續使用。因此到這裡就完成了登入的操作，所以使用者理論上就會被跳轉回首頁，並且已經是成功登入的狀態。\n而當使用者成功登入之後，假設使用者後續想要去 call 其他受保護的 api（ex：查看個人設定），這時候前端就可以在 call api 時，同時也帶上當初後端 Server 發放的 Session id，這樣後端在收到這一次的請求時，就可以去資料庫查詢一下這個 Session id 的值是否存在，如果存在的話，就表示這個使用者已經有成功登入過了，所以就可以允許這一次的 api 通過，進而返回實際的結果給前端。\n所以對於 Session 這種登入機制而言，所有的登入記錄都是儲存在「後端 Server」上，前端所拿到的 Session id 的值，其實就只是一組沒有意義的亂碼，只有後端 Server 才知道這組 Session id 實際上對應到的是哪個使用者的登入資訊。\n因此 Session 這種登入機制，他就是「將登入的資訊儲存在後端 Server 上」的一項技術。\n什麼是 JWT 認證？ # 了解了什麼是 Session 的登入機制之後，接著我們可以來介紹什麼是 JWT 的登入機制。\n所謂的 JWT 認證，就是「將登入的資訊儲存在前端 Client 中」的一項技術，所以換句話說的話，就是會將使用者的登入資訊，直接儲存在前端的 Client 中，因此在後端 Server 中是不會儲存任何一筆登入資訊的！\n這聽起來可能有點神奇，不過 JWT 的運作邏輯是這樣子的：\n和前面一樣的例子，假設我是一個使用者，我的帳號密碼是 Judy / 123，這時候當我在網站上輸入帳號密碼，並且嘗試登入時，首先後端 Server 一樣是會先去驗證我的帳號密碼 Judy / 123 是否曾經註冊過。\n但是這裡重點來了！！假設這組帳號密碼存在的話，後端 Server 就會生成一個 JWT 格式的 Token，並且會直接返回該 Token，而且「不需要」在後端 Server 中儲存這個 Token 的數據。\n所以在 JWT 認證的世界中，後端 Server 是不需要儲存任何一筆 JWT 的數據的！！！後端 Server 要做的事情，就是生成 JWT Token，然後直接回傳就好，就是這麼簡單暴力！！！\n這時候你可能會想：這樣到時候要怎麼驗證這個 JWT Token 是有效的？這時候就是展現 JWT 的神奇地方之處了！！\n當使用者成功登入之後，假設使用者後續要想去 call 其他受保護的 api，這時候前端就可以在 call api 時，同時也帶上當初後端 Server 發放的 JWT Token，而當後端收到這個 Token 時，只要這個 JWT 的簽名驗證成功，後端就會無條件相信 JWT Token 中的內容，也就是 JWT Token 聲稱這個使用者的名字叫做 Judy，那後端就無條件相信這一次來請求的人就叫 Judy；JWT Token 聲稱這個使用者的 id 是 111，後端就無條件相信這個使用者的 id 是 111。\n所以在 JWT 認證的世界中，後端就是這麼的天真可愛，只要 JWT 說什麼，後端就無條件相信他，完全不需要質疑 JWT 的安全性，因此在 JWT 的認證機制中，所有的登入記錄都是儲存在「前端 Client」上，前端所拿到的 JWT Token，就是一個包含所有使用者資訊的 Token，因此只要能夠正確解讀這個 JWT Token，就可以拿到使用者的所有資訊。\n所以 JWT 這種登入機制，他就是「將登入的資訊儲存在前端 Client 上」的一項技術。\n補充：後端為什麼能無條件相信 JWT？ # 第一次接觸 JWT 的人，一定會很疑惑覺得：「到底為什麼後端可以這麼無條件的相信 JWT？」，事實上後端之所以可以無條件相信 JWT 中的內容，是因為 JWT 本身是一個帶有數位簽名的 Token 格式。\n在 JWT 的組成結構中，可以分成 3 個部分，分別是：header、payload、signature。\n舉例來說，下面這一串亂碼：\neyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjMiLCJuYW1lIjoi5Y-k5Y-kIiwiaWF0IjoxNzIxMDAxNjAwfQ.G41XQGNNJ5Tp88U48aXh4n0XtGkpPkQ3xK6j43_61gE309hzyTVyciG5v05aVIvvY9NrApYiQdvwlMMrjRPFVV8xunghtKKFMj3kPx93Ll8Pf6n-tDiL_NZYqcusrgwtb-EDza80hMG5PTu75ogTIfRKr4jC0_FZzLaMix07LaZReoUSionTWTxJlm8qJc0BAFXgsaGNs9oVhCXOg_jJmOfFZBP0tD3q4xaKp9MTtLRTtslAhoAjPczdnPqaWGcaS8OY11RUTvvxijA7W-mPRlmqt0Hd_XForETUFZRdCKsPQIiGjkavycPtdiViVihQKstHlT4afEzYvzWSeK1cnw 就可以被解析成 header、payload、signature 這三個部分（每一個部分之間用一個點 . 隔開）。\nheader：\neyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9 payload：\neyJzdWIiOiIxMjMiLCJuYW1lIjoi5Y-k5Y-kIiwiaWF0IjoxNzIxMDAxNjA","date":"2024-12-03","objectID":"928d0098dad7feaefea15cfc9d537791","title":"Session 和 JWT 的差別在哪裡？","url":"https://kucw.io/blog/session-vs-jwt/"},{"categories":["自媒體經營"],"content":"哈囉，我是古古，這篇文章是每月一次的自媒體月報，主要分享我經營《古古的後端筆記》個人品牌的幕後秘辛，如果你也對於「自媒體創業」有興趣的話，歡迎繼續閱讀本文～\n補充：如果想了解《古古的後端筆記》電子報的起源，也可以先查看創刊號的文章。\n2024.11 月粉絲追蹤數、電子報訂閱人數 # 本月份（2024.11）的粉絲成長人數如下：\n2024/10/29 人數 2024/11/26 人數 11 月份總成長人數 Facebook 粉專追蹤數 4150 4389 +239 電子報訂閱人數 1632 2076 +444 Threads 粉絲追蹤數 2557 4566 +2009 IG 粉絲追蹤數 247 353 +106 這個月的各項指標就是順順的成長，沒有特別突出的爆文，比較意外的是 Threads 和 Facebook 竟然黃金交叉了😂。\n但不得不說我最近也都是滑 Threads 比較多，趁著現在 Threads 裡面沒有廣告，滑起來真的很愉快舒暢XDD，推推！（天曉得以前在 Facebook 要被多少篇商周雞湯文、或是各種廣告轟炸）\n本月自媒體活動：我出書了！！ # 這個月我出了人生的第一本書《Spring Boot 零基礎入門》！！！而且也感謝博碩出版社願意支援我「預購送簽名」的活動，完全是圓了我的簽書夢，謝謝博碩🥹。\n出書的寫作心法和幕後花絮，在之前的文章中已經有和大家分享：\niThome 鐵人賽 - 得《優選》獎項的寫作心法 iThome 鐵人賽 - 出書的幕後花絮 所以這邊就不多贅述，就以一張我簽名簽到很開心的照片作為收尾吧🤣！\n如果你也想要出自己的一本書，非常推薦大家可以參加每年 iThome 舉辦的 30 天鐵人賽活動，只要得獎就可以出書（冠軍、優選、佳作皆可出書）。\n老實說就連在我已經開過好幾堂線上課程的前提下，靠自己的力量還是很難出一本書（首先你要有人脈能聯繫上出版社編輯，然後你要說服他們願意讓你出書），所以藉由 iThome 所舉辦的盛事活動，先用得獎來證明自己的文章是值得出書的，後續再直接和出版社對接，真的是素人出書最簡單的方式了～\n本月撰寫的電子報主題、文章 # 這邊記錄了我這個月撰寫了哪些電子報和文章，大家如果對於其中的內容有興趣的話，也可以前往查看：\n資料庫的 ACID、Transaction（交易）介紹 免費仔萬歲！使用 GitHub Actions 實作 CI/CD、網路爬蟲 iThome 鐵人賽 - 出書的幕後花絮 給工程師的求職建議（年資 1-3 年） 雲端服務中的 IaaS、PaaS、FaaS、SaaS 的差別 2024.11 月報總結 # 呼～大概是這樣！這個月其實花了大半部分的精力在出書上，所以沒有太多時間學習自媒體的相關知識，最後也要真的感謝大家的支持🙏，希望你們會喜歡我的簽名🤣。\n下個月應該就比較有空學習自媒體的內容了！我已經囤積了好幾本書想看了🤣，等到有更多心得也會再和大家分享～那我們就下個月的月報再見啦！\n如果你對後端筆記有興趣，也歡迎免費訂閱《古古的後端筆記》電子報，每週二為你送上一篇後端技術分享，一起變強💪\n","date":"2024-12-03","objectID":"d5fb4323b2b9ca3138617f665f26889c","title":"軟體工程師的自媒體之路 - 2024.11 月報","url":"https://kucw.io/blog/as-a-content-creator/monthly-report-202411/"},{"categories":["其他技術分享"],"content":"IaaS、PaaS、FaaS、SaaS 這些名詞，是大家一開始在接觸雲端服務時，很容易搞混的名詞，所以這篇文章我們就來介紹一下他們的差別吧！\n目錄 1. 什麼是 IaaS？ IaaS 的優點 IaaS 的缺點 2. 什麼是 PaaS？ PaaS 的優點 PaaS 的缺點 小結：IaaS 和 PaaS 的區別 3. 什麼是 FaaS？ FaaS 的優點 FaaS 的缺點 補充：FaaS 也稱為 Serverless（無伺服器運算） 4. 什麼是 SaaS？ IaaS、PaaS、FaaS、SaaS 總結 結語 1. 什麼是 IaaS？ # IaaS 是 Infrastructure as a Service 的簡寫，中文翻譯為「基礎結構即服務」，IaaS 是指「你能夠使用這個服務來創建 VM」。\n所以假設有一個雲端服務是 IaaS，那就表示他可以讓我們在上面自由的創建 VM，並且我們可以在該 VM 中安裝喜歡的 Java 版本、或是安裝喜歡的 Python 版本，然後我們也可以在這個 VM 裡面自由的運行想運行的程式，完全不受到任何限制！\n所以只要是直接提供一台 VM 給你自由運用的服務，即是屬於 IaaS 的一種，也就是 Infrastructure as a Service。\n舉例來說，像是 AWS 的 EC2、GCP 的 Compute Engine，他們就都是屬於 IaaS 的服務（因為他就是直接提供一台 VM 給我們，讓我們自由去運用）。\nIaaS 的優點 # 因為 IaaS 提供完整的 VM 存取權，所以靈活性非常高，想幹嘛就幹嘛！ IaaS 的缺點 # 因為雲端服務商只會提供一台 VM 給你，所以凡事都得自己來，上到安裝 Java 版本、下到網路防火牆設定，全部都得靠自己完成。 2. 什麼是 PaaS？ # PaaS 是 Platform as a Service 的簡寫，中文翻譯為「平台即服務」，而到了 PaaS 這裡之後，就沒有了 VM 的概念。\n因此假設有一個雲端服務是 PaaS，那麼 他只會要求你上傳你的程式碼，然後他就會像變魔法一樣，直接幫你把這個程式運行起來了，magic！\n所以當你使用了 PaaS 的服務之後，你就再也碰不到 VM 層了（或是非常難），雲端服務商會把你的程式運行在一個「容器 Container」裡面，你只要告訴他你要幾個容器就好，剩下的雲端服務商會全部包辦。\n因此 PaaS 也可以稱為是懶人部署法，你不需要像上面的 IaaS 一樣，自己去搞 VM 然後自己安裝 Java 版本，你要做的，就是寫好程式，上傳，然後剩下的雲端服務商會全部幫你搞定，世界和平！\n舉例來說，像是 AWS 的 Elastic Beanstalk、GCP 的 App Engine、或是 Zeabur、Heroku、Vercel…等等的網站，他們就都是屬於 PaaS 的服務（因此我們就只要直接上傳我們的程式就好，不需要處理任何環境安裝的問題）。\nPaaS 的優點 # 只需要上傳程式碼即可運作，降低維運的人力和時間成本。 PaaS 的缺點 # 靈活度比較低，碰不到實際的 VM 層級，沒辦法直接連線到容器裡面做特別的設定。 通常會限制程式語言，只支援熱門的，太冷門的不支援。 收費較貴（不過貴不是他的缺點，是我的🥹。 小結：IaaS 和 PaaS 的區別 # 所以從上面的 IaaS 和 PaaS 的介紹，大概可以感覺得出來 IaaS 和 PaaS 其實是一個對立的關係。\nIaaS 就是直接丟一個最原始的 VM 給你，你愛蓋什麼就蓋什麼，有點像是給你一塊地你自己自由發揮。\n而 PaaS 則像是一棟蓋好的大樓，裡面的設施非常先進漂亮，你只要提著你的行李箱（程式碼）就可以入住，但缺點就是你不能隨便更動大樓裡面的管線，只能照著他們既定的規則走這樣。\n所以如果你只是要做一個小型的 Project，不想要管環境的安裝問題，那就可以直接採用 PaaS 的服務來部署；而如果你是想要自己掌握所有控制權，想要自己處理防火牆、軟體版本\u0026hellip;等等的控制，或是你想省點錢的話😂，那就可以考慮採用 IaaS 來部署。\n3. 什麼是 FaaS？ # 了解了經典的 IaaS 和 PaaS 的概念之後，接著我們可以來看一下什麼是 FaaS。\nFaaS 是 Function as a Service 的簡寫，中文翻譯為「函式即服務」或是「功能即服務」。\n相較於 IaaS 和 PaaS，FaaS 其實是近十年才被提出來的新概念，所以雖然 FaaS 也是屬於 XaaS 家族的一員，但其實他和上面的 IaaS 和 PaaS 沒什麼關係。\nFaaS 的概念，是 「把程式當成方法來執行」，即是讓程式不用一直運行著，而是當有請求來時，就快速啟動這個程式，然後請求走的時候就 shutdown 這個程式，簡單的說就是不讓程式一直啟動著，而是有需要的時候才開啟他，這就是 FaaS 的概念！\n大家也可以想像一下，一般我們在寫後端程式的時候，通常就是把程式運行起來，然後這個程式就會一直運行著，等著去接收前端的請求，即使沒有前端的請求過來，這個程式仍舊會一直運行著。\n而 FaaS 即是想要提出一個新概念，就是只有當前端發請求過來的時候，才會去運行起這個後端程式去處理前端的請求，當請求執行完畢後，就關掉這個後端程式，不讓他在那邊空轉，把「程式」當成是一個「方法」來運行，即是 FaaS 的概念。\n舉例來說，像是 AWS 的 Lambda、GCP 的 Cloud Functions，他們就都是屬於 FaaS 的服務。\nFaaS 的優點 # 只需要在使用時付費，不需付錢讓程式空轉。 FaaS 的缺點 # 功能要拆分的比較細，每一份程式要保持在處理非常輕量化的小功能，像是處理一張圖片的 resize…等。 和雲端服務綁比較深，萬一將來要下雲會比較麻煩。 補充：FaaS 也稱為 Serverless（無伺服器運算） # 在這裡也補充一下，其實 FaaS 服務還有另一個稱呼，即是 Serverless（無伺服器運算）。\nFaaS 之所以能夠被稱為 Serverless，是因為從定義上來說，我們並沒有長期運行一個 server，而是當前端請求來時，我們才啟動這個 server，並且當前端請求走了之後，這個 server 也被關掉了。所以在定義上，我們「並沒有」長期運行一台 server，傻傻的去等待前端發送請求過來，因此這種部署方式，就稱為是 FaaS，也叫做 Serverless（無伺服器）。\n所以 FaaS 和 Serverless，他們指的其實都是同一件事情，就是把程式當成方法一樣來使用，用完即丟，不會長期運行某份程式這樣。\n補充：其實我一開始有點不能接受 Serverless 的定義😂，因為他就是有運行 server 啊！只是中間的過程很短我們看不見而已！！不過這邊的定義就是這樣，所以建議大家就先接受這個定義吧🥹，FaaS 就是 Serverless，Serverless 就是 FaaS，他們指的是同一件事情。\n4. 什麼是 SaaS？ # 介紹完前面的 IaaS、PaaS、以及 FaaS 之後，最後我們可以來看一下什麼是 SaaS。\nSaaS 是 Software as a Service 的簡寫，中文翻譯為「軟體即服務」。\nSaaS 其實就是泛指 Gmail、Google Drive 這種已經很成熟的軟體，SaaS 跟工程師其實沒有什麼特別的關係，通常只是在提到 IaaS、PaaS 時，會一起拿出來被介紹到。\n舉例來說：\n我們在工作上，可以使用 Jira、Trello 這類的 SaaS 的軟體，幫助我們管理敏捷看版的流程。 我們也可以","date":"2024-11-26","objectID":"ba956c5655eec6c31b9044fbebbe8de5","title":"雲端服務中的 IaaS、PaaS、FaaS、SaaS 的差別在哪裡？","url":"https://kucw.io/blog/iaas-paas-faas-saas-intro/"},{"categories":["其他技術分享"],"content":"哈囉，我是古古！之前有在 iThome 鐵人賽 - 得《優選》獎項的寫作心法 的文章中，和大家分享我得獎的寫作心法，這篇文章則是會分享在 iThome 鐵人賽得獎之後，出書過程中的一些幕後花絮，如果你也對出書感興趣的話，歡迎繼續觀看本文章～\n目錄 這本書《Spring Boot 零基礎入門》在介紹什麼？ 出書的幕後花絮 書稿要用 Word 檔繳交 書稿的中英之間不能有空白鍵 封面文案、封底文案設計 結語 這本書《Spring Boot 零基礎入門》在介紹什麼？ # 首先先介紹一下我所出版的書籍，這本書是改編自 iThome 鐵人賽的得獎文章《Spring Boot 零基礎入門》，當初會想用 Spring Boot 零基礎入門這個主題參賽，就是因為自己剛入門 Spring Boot 時，發現單純透過網路上零散的介紹，很難完整了解 Spring Boot 的運作邏輯是什麼（一開始覺得IoC 好難…🥹），一度覺得很挫折。\n所以希望可以透過這本書，系統性的去整理 Spring Boot 的知識，讓想要入門 Spring Boot 的人有個方向，至少在看完這本書之後，能夠學到：\nSpring IoC、Spring AOP 的概念和用法 Spring MVC 的用法 Spring JDBC 的用法 能夠使用 Spring Boot，開發出一個簡易的後端系統（書中使用圖書館管理系統作為範例） 如果你也對 Spring Boot 有興趣、或是打從心底想要從頭開始學習 Spring Boot，那麼這本書真心推薦給你！\n出書的幕後花絮 # 以下僅列出我在寫書中覺得很意外 or 很新鮮的事，記錄的不是很完全，大家就看個開心就好～\n書稿要用 Word 檔繳交 # 這個應該是在寫書時痛苦指數最高的事情🥹，在出版社真的拿著書稿內容去排版之前，會需要作者先用 Word 檔把全部的內容整理起來（包含各章標題、圖號、程式碼樣式），先給編輯看過一遍之後，編輯才會把 Word 檔交給美編，交由美編後續去排版。\n但是在習慣使用 Markdown、Notion 這類的筆記軟體之後，突然要回頭使用 Word 檔.…真的是只有想哭可言🥲（我從學校畢業之後就沒打開過了）。\n首先 Word 的排版就真的很難搞，再來就是 Mac 上的 Word app 常常會閃退（我不知道是我電腦有問題還是 Word 有問題），反正就是要花很多時間和 Word 戰鬥.…如果大家將來也想要出書的話，建議先跟你家 Word 打好關係，因為你真的會很依賴他🥹。\n給大家看看我的 Word 檔，以及給美編排版過的成果：\n這樣看下來，美編是不是真的很神！！！只要給她醜醜的 Word 檔，她就可以幫你排出好看的排版，出這本書真的不能沒有美編XDD，感謝美編！！！\n書稿的中英之間不能有空白鍵 # 又是一個撰寫書稿的痛苦（出書大概有 80% 的痛苦都是在寫書稿，其他部分相較還好），一般我在寫文章的時候，中英文之間會有空白鍵，但是出版社要我們繳交的書稿，竟然要把中英文間的空白鍵刪掉！！！（好像是因為排版軟體的設定，所以必須要刪掉空白鍵，這樣子弄出來的書稿才會正常）\n反正這部分也是折磨我很久…就算用「取代」功能一鍵把所有空白鍵刪掉，也需要整份稿子重新檢查有沒有缺漏的部分。最可怕的是在改稿的時候，手會不小心習慣在中英之間按下空白鍵，然後事後發現之後又要整個回頭重改🥹，我只能….哭惹😭。\n反正中英不能有空白鍵這件事真的是造成我心理陰影，甚至還想跟編輯說我之後不想再寫書了XDD，但老實說現在回頭看起來也是一次特別的經驗就是了，畢竟是第一次出書，再怎麼樣都是一次新鮮的體驗！\n封面文案、封底文案設計 # 這部分算是我很意外的部分！我沒想到出版社可以讓我們自己想封面和封底設計，其實對於作者來說彈性還滿大的，先給大家看看我的封面和封底設計（沒錯編輯竟然是給我一張這樣的展開圖，我第一次收到有嚇到XDD）：\n其中有關書名、封面的大圖、封面文案、封底文案、作者簡介，這些都是可以讓作者設計的，所以作者可以根據你自己的書，填上你想放的宣傳語。\n舉例來說，下面這些都是我提供給編輯的文案：\n不得不說，真的是當了作者之後，才發現原來一本書的封面、封底設計，都是有意義的！！所以大家下次再走進書店買書時，建議可以仔細研究一下封面上的各種小字，每一行小字其實都是作者精心放上去的內容，絕對沒有那種來湊數的文字存在！\n然後在設計封面和封底文案時，中間也有發生一件很好笑的事，因為我實在是不知道怎麼寫文案比較好，我就跑去附近的諾貝爾書局，然後一本一本翻以前鐵人賽的書是怎麼寫的，邊翻邊拍照，我大概拍了 20 幾本有（還好店員沒有覺得我很奇怪🤣），在書局待了一整個下午就只為了參考其他書是怎麼寫的，現在回想起來，真的是很特別的一次經驗XD。\n結語 # 呼～大概是這樣吧！雖然上面吐嘈了一些寫書稿的痛苦，但是老實說看到自己寫的書上架還是滿有成就感，如果你也對出書有興趣的話，非常推薦參加一年一度的 iThome 鐵人賽，希望大家都可以成功出版你人生的第一本書👍。\n如果你對後端技術有興趣的話，也歡迎免費訂閱《古古的後端筆記》電子報 ，每週二為你送上一篇後端技術分享，那我們就下一篇文章見啦！\n補充：我開設的 Spring Boot 零基礎入門、Spring Security 零基礎入門、GitHub 免費架站術 已在 Hahow 平台上架啦！輸入折扣碼「HH202601KU」即可享 85 折優惠。\n","date":"2024-11-19","objectID":"72d052c07d994fb85a23ef2db475c5fc","title":"iThome 鐵人賽 - 出書的幕後花絮","url":"https://kucw.io/blog/ithome-write-a-book/"},{"categories":["職涯相關"],"content":"在面試找工作時，選擇一家心儀的公司絕對是最重要的事，以下分享 2 點找工作的建議給 1-3 年年資的工程師：\n1. 找工作時，發展性 \u0026gt; 錢 # 這個階段其實大家都還是新手，成長性仍舊很高，所以在考慮要不要去某間公司時，要思考的是：「3 年後你離開這間公司時，你有哪些武器可以拿來面試下一間公司」。\n舉例來說，如果 A 公司是 65k（新創），B 公司是 50k（台灣大型企業），那麼你願不願意為了「大企業鍍金」的價值，屈就自己去領 50k 的薪水。這沒有正確答案，就只是個人選擇而已，沒有誰能為你的人生負責，只有自己能為自己負責。\nPS: 但如果真要說，我會建議選擇大公司，畢竟大公司將來要跳新創比較容易，新創要跳大公司會稍微難一點，考量到人生很長，有大公司的經歷還是不錯的。\n2. 學習是下班的重要活動，健身之餘也要健腦 # 有很多人入職之後就疲於工作奔命，沒有留時間給自己繼續精進，其實這是風險很高的事情，因為你沒辦法跟新鮮人拉開差距。\n畢竟你當初可能是努力了一年才成功轉職，如果你不繼續往前走，那麼被其他新鮮人努力一年之後取代，只是遲早的事。\n長江後浪推前浪，身為前浪，真的要避免死在沙灘上😂。\n結語 # 如果你想保持學習的步調，歡迎免費訂閱《古古的後端筆記》電子報，每週二為你送上一篇後端技術分享，大家一起變強💪！\n補充：我開設的 Spring Boot 零基礎入門、Spring Security 零基礎入門、GitHub 免費架站術 已在 Hahow 平台上架啦！輸入折扣碼「HH202601KU」即可享 85 折優惠。\n","date":"2024-11-14","objectID":"876708626555369ba865ccefb2d0c9cf","title":"給工程師的求職建議（年資 1-3 年）","url":"https://kucw.io/blog/developer-interview-suggestion/"},{"categories":["其他技術分享"],"content":" 目錄 什麼是 GitHub Actions？ GitHub Actions 在 CI/CD 中的用途 實戰：使用 GitHub Actions 架設第一個 CI/CD GitHub Actions 在網路爬蟲中的用途 實戰：使用 GitHub Actions 實作網路爬蟲 GitHub Actions 總結 結語 什麼是 GitHub Actions？ # 所謂的 GitHub Actions，是 GitHub 所提供的一個自動化集成服務，簡單的說的話，就是我們可以自由指定：「當有 commit 被 push 到 GitHub 中的某個 repository 時，我們要 GitHub 做什麼事」。\n舉例來說，我們可以設定成：「當有 commit 被 push 到 mytest 這個 repository 時，我們要求 GitHub 要傳送一則訊息到 Slack 裡面通知大家」，所以當我們添加了這一個 GitHub Action 之後，以後只要有人 push 了任一個 commit 到 mytest 中，GitHub Action 就會被觸發，因此就會傳送一筆訊則到 Slack 群裡面通知大家了。\n所以 GitHub Actions 他最一開始被發明出來的目的，就是為了「程式的自動化集成」，也稱為是「CI/CD」（Continuous Integration/Continuous Deployment）。\nGitHub Actions 在 CI/CD 中的用途 # 如上面所介紹到的，GitHub Actions 本來就是為了「程式的自動化集成」而發明，簡單的說的話，就是我們可以預先設定好「當工程師上傳 code 之後，要 GitHub Actions 做什麼事」，所以這裡就延伸出各式各樣的用法。\n舉例來說，有的團隊會設定成：\n當工程師上傳 code 之後，自動執行單元測試，檢查所有測試是否能夠成功通過 當工程師上傳 code 之後，自動執行 ESLint、SonarCube 這類的檢查，確保程式的品質正常 當工程師上傳 code 之後，自動將該程式部署到 dev 環境 …等等 而上述這些用法，如果要給他們一個統稱的話，就稱為是「CI/CD」，也就是「持續整合/持續部署」 （Continuous Integration/Continuous Deployment），所以當大家在工作中聽到 CI/CD 時，基本上就是在對我們所上傳的程式做一些「後處理」，確保一些無聊的重複工作可以被自動化執行，這就是 CI/CD 的目的！\n實戰：使用 GitHub Actions 架設第一個 CI/CD # 了解了 GitHub Actions 的概念之後，接著我們也可以試著到 GitHub 上設定看看 GitHub Actions，實作第一個 CI/CD 程式。\n老實說要在 GitHub 中設定一個 GitHub Actions 真的比想像中容易🤣，只要在 GitHub repo 中添加一個 .github 資料夾，並且在裡面再創建一個子資料夾 workflows（也就是 .github/workflows），接著就可以在裡面撰寫 GitHub Actions 的設定了！\n所以創建好 .github/workflows 這兩層資料夾之後，接著可以在裡面添加一個 demo-github-action.yml 的檔案，表示這是一個 action（檔案的檔名可以隨意取，要叫做 demo-github-action.yml 或是 xxx.yml 都可以，每一個檔案就是一個 action）。\n此時在 demo-github-action.yml 裡添加下列程式之後：\nname: GitHub Actions Demo run-name: GitHub Actions Demo # 觸發此 action 的時機 on: push: branchs: # 只要有任何一個 commit 被 push，就會觸發此 action \u0026#39;*\u0026#39; workflow_dispatch: # 可以手動執行此 action # 預先定義此 action 要幹嘛 jobs: demo: runs-on: ubuntu-latest steps: - run: echo \u0026#39;執行成功\u0026#39; 只要這樣寫之後，就可以在「任何一個 commit 被 push」以及「手動執行此 action」這兩個時機點，去觸發這一個 GitHub Action。\n因此當有 commit 被 push 上來時，此 action 就會輸出執行成功的結果，如下圖所示：\n所以透過在 .github/workflows 中添加 demo-github-action.yml 的檔案（檔名可以隨意取），我們就可以為這個 GitHub repo 去添加他專屬的 GitHub Actions，因此就可以用 GitHub Actions 不斷的去集成這份程式，實作 CI/CD 的效果了！\n另外大家以後在查看程式時，如果有發現某份程式有 .github/workflows，就表示他有使用 GitHub Actions，所以就不會看不懂這資料夾到底是在幹嘛的了～（在知道有 GitHub Actions 這功能之前，我一直都以為 .github/workflows 只是 GitHub 產生的檔案，沒啥用處，真的是誤會大了🤣）。\n補充：因為篇幅有限，所以沒辦法詳細介紹 GitHub Actions 中每一行程式的用途，如果大家有興趣的話，可以再查詢 GitHub Actions 的用法介紹。\nGitHub Actions 在網路爬蟲中的用途 # 而 GitHub Actions 除了可以用在最經典的 CI/CD 用途上之外，同時 GitHub Actions 其實也是可以拿來實作爬蟲的！\n之所以可以將 GitHub Actions 用來實作爬蟲，是因為 GitHub Actions 被觸發的時機點，除了可以設定成「當任何一個 commit 被 push 時觸發此 action」之外，也可以設定成 「定時觸發此 action」，而就是這個「定時觸發此 action」的功能，讓我們可以拿來活用他，進而實作網路爬蟲。\n實戰：使用 GitHub Actions 實作網路爬蟲 # 如果要使用 GitHub Actions 實作網路爬蟲的話，首先需要先在 mytest 中新增一份爬蟲程式（此處以 crawler.py 為例）。\n接著在 .github/workflows 中創建一個新的 action 檔案 crawler-demo.yml（檔名可以隨意取），並且在 crawler-demo.yml 中添加下列程式：\nname: Crawler Demo Action run-name: Crawler Demo Action # 觸發此 action 的時機 on: schedule: - cron: \u0026#34;55 12 * * *\u0026#34; # UTC 每天下午 12:55 執行此 action（等同於台灣晚上 8:55 執行） workflow_dispatch: # 可以手動執行此 action # 預先定義此 action 要幹嘛 jobs: crawler-demo: runs-on: ubuntu-latest steps: - name: Checkout uses: actions/checkout@v3 - name: Setup Python uses: actions/setup-python@v4.5.0 with: python-version:","date":"2024-11-12","objectID":"a8e7e9a9542e440e76870f69e9653a55","title":"免費仔萬歲！使用 GitHub Actions 實作 CI/CD、網路爬蟲","url":"https://kucw.io/blog/github-actions-intro/"},{"categories":["其他技術分享"],"content":" 目錄 什麼是資料庫的 ACID？ Transaction（交易）是什麼？ 例子：銀行轉帳 使用 Transaction 解決轉帳的問題 Transaction 和資料庫 ACID 的關聯 資料庫的 ACID 總結 結語 什麼是資料庫的 ACID？ # 在常見的關聯式資料庫中（例如：MySQL、PostgreSQL、MS SQL），都會有 ACID 的特性，而 ACID 即是：\nAtomicity（原子性） Consistency（一致性） Isolation（隔離性） Durability（永久性） 也因為有 ACID 這四個特性，使得 MySQL 這類的資料庫支援 「Transaction（交易）」 的操作，所以接下來我們就直接用一個例子，來了解一下什麼是「Transaction（交易）」，以及了解 ACID 在其中的用途是什麼。\nTransaction（交易）是什麼？ # 在資料庫中，有一種用法叫做 Transaction，而他的中文可以被翻譯成「交易管理」或是「事務管理」。\n而 Transaction 的用途，就可以在「一個 Transaction 裡面，包含多個資料庫的操作，並且這些資料庫的操作，要嘛全部一起成功，要嘛全部一起失敗，也就是 All or Nothing 原則」。\n例子：銀行轉帳 # 舉例來說，假設我們現在要實作一個轉帳的功能，讓 A 可以轉 1000 元給 B，那麼在實作轉帳的功能時，就需要對資料庫進行兩次操作：也就是先將 A 的存款減去 1000 元，再將 B 的存款增加 1000 元，這樣子就可以完成轉帳的實作。\n所以像是在上面的 transfer() 方法中，就是會先去對 A 的帳戶減去 1000 元（A 的存款從 3000 變成 2000），再為 B 的帳戶增加 1000 元（B 的存款從 500 變成 1500），進而完成轉帳的操作。\n不過，在這段 transfer() 的程式中，其實是有一個潛在的問題的。\n舉例來說，我們在執行這段程式時，一開始一樣是先從 A 的帳戶中減去 1000 元（A 的存款從 3000 變 2000），但是！假設這時程式突然出現了錯誤（有可能是程式出現 bug、或是機器故障、機房停電…等因素），導致在扣完 A 的錢之後，程式沒辦法繼續往下運行，再去 B 的帳戶中增加 1000 元。\n因此最終結果就會變成 A 損失了 1000 元、但是 B 卻沒收到 1000 元，導致 1000 元就這樣消失了！這種狀況一定是大家不想看見的。\n所以為了解決這個問題，Transaction 就被發明出來了！\n使用 Transaction 解決轉帳的問題 # 在資料庫中，他支援一種用法叫做 「Transaction（交易）」，當我們使用 Transaction 來管理這整個轉帳的流程之後，那麼「扣掉 A 的錢」以及「增加 B 的錢」這兩件事情，他們就只能夠一起成功，或是一起失敗。\n舉例來說，在 Spring Boot 程式中，我們可以在某個方法上面加上 @Transacional，這樣子就可以宣告「使用一個 Transaction 來管理這個方法」，因此在這個例子中，當我們在 transfer() 方法上面添加 @Transactional 時，就表示我們創建了一個 Transaction，來管理這個 transfer() 方法。\n而當某個方法被 Transaction 來管理時，那麼 「在那個方法中的所有資料庫操作，要嘛全部一起成功、要嘛全部一起失敗，也就是 All or Nothing 原則」。\n因此在這個例子中，首先 A 一樣是會先被減去 1000 元沒錯（所以 A 的存款從 3000 變成 2000），然後這時候一樣，程式遇到了錯誤，因此程式就只能夠被迫中斷，沒辦法繼續往下執行，為 B 的帳戶增加 1000 元。\n但是這個時候，因為我們有在 transfer() 方法上面加上 @Transactional，用一個 Transaction 來管理此方法，因此此時 Transaction 就會復原（也稱為 rollback）前面做過的所有資料庫操作，也就是會將 1000 元還給 A，所以 A 的存款又從 2000 元變回 3000 元，就像是剛剛那個扣除的 SQL 語法從來沒有執行過一樣，A 和 B 的存款都回到最初的樣子，這就是 Transaction 的厲害之處！！\n所以對於轉帳這種「涉及多個資料庫操作」的功能而言，如果我們想要確保轉帳中的所有資料庫操作要嘛一起成功、要嘛一起失敗，這時候就可以使用資料庫所支援的 Transaction 用法，使用 Transaction 來保護這整筆轉帳的交易過程了。\n也因為 Transaction 會確保方法中的所有資料庫操作，要嘛全部一起成功、要嘛全部一起失敗，因此這也稱為是 All or Nothing 原則。\n補充：Transaction 只能確保「同一個資料庫」中的交易會一起成功、一起失敗而已，如果涉及到多個資料庫（像是分散式資料庫），那麼使用 Transaction 的情況會變得複雜得多，大家有興趣的話，可以再上網查詢「分散式交易（Distributed Transactions）」的相關資訊。\nTransaction 和資料庫 ACID 的關聯 # 了解了 Transaction（交易）要解決的問題之後，我們終於可以說回到最一開始的「資料庫的 ACID」的特性了！\n我們在前面有提到，常見的關聯式資料庫中（例如：MySQL、PostgreSQL、MS SQL），都會有 ACID 的特性，而 ACID 即是：\nAtomicity（原子性） Consistency（一致性） Isolation（隔離性） Durability（永久性） 也因為有 ACID 這四個特性，所以 MySQL 這類的資料庫才能支援 Transaction 的操作。所以換句話說的話，假設某個資料庫他不具備 ACID 的特性的話，那他是不能使用 Transaction 的操作的！！！\n舉例來說，假設你使用的資料庫是 NoSQL（例如 MongoDB、Elastic Search），那麼即使你有在 Spring Boot 程式中添加 @Transactional，指定這段方法要使用 Transaction 來管理，但是因為 NoSQL 他不支援 ACID 啊！所以他就不支援 Transaction 的操作🥹。\n因此不管你在程式中加了多少個 @Transactional，那段程式仍舊是沒有受到 Transaction 的交易保護的，所以就算程式運行中出現錯誤，仍舊是沒辦法 rollback 成原始數據的，這是大家在使用 Transaction 時，一定要注意的細節！\n補充：軟體變化瞬息萬變，現在也已經有些 NoSQL 資料庫支援 ACID 的特性、進而支援 Transaction 了，大家在使用之前，建議也可以參考一下你使用的 NoSQL 資料庫介紹。\n而如果我們把 ACID 展開來，一一對應到 Transaction 中的概念的話，就可以發現他真的每一條都是為了 Transaction 來設計的：\n特性 描述 Atomicity（原子性） Transaction 是一個不可被分割的單元 Consistency（一致性） Transaction 執行的前後，必須確保數據的完整性是一致的 Isolation（隔離性） 資料庫同時處理多個 Transaction 時，各個 Transaction 之間不能互相影響 Durability（永久性） Transaction 一旦提交之後，他對資料庫所做的改變永久有效，不會因為系統重啟","date":"2024-11-05","objectID":"7024481b7855732aacf6dc82a3051845","title":"資料庫的 ACID、Transaction（交易）介紹","url":"https://kucw.io/blog/db-acid-transatcion/"},{"categories":["自媒體經營"],"content":"哈囉，我是古古，這篇文章是每月一次的自媒體月報，主要分享我經營《古古的後端筆記》個人品牌的幕後秘辛，如果你也對於「自媒體創業」有興趣的話，歡迎繼續閱讀本文～\n補充：如果想了解《古古的後端筆記》電子報的起源，也可以先查看創刊號的文章。\n2024.10 月粉絲追蹤數、電子報訂閱人數 # 本月份（2024.10）的粉絲成長人數如下：（因為剛好前面的數據也都還在，就放上來做個對比）\n2024/9/24 人數 2024/10/29 人數 10 月份總成長人數 Facebook 粉專追蹤數 2687 4150 +1463 電子報訂閱人數 1195 1632 +437 Threads 粉絲追蹤數 535 2557 +2022 IG 粉絲追蹤數 130 247 +117 從這個誇張的線圖可以看到，這個月份真的是被流量眷顧一波🤣，會造成這麼誇張的粉絲數成長，是因為我在 10/24 時有 Po 了一篇「周杰倫演場會搶票系統 - 拓元售票背後的架構」，裡面有提到拓元是架設在 AWS 的環境上，然後網路上各種大神、對架構有興趣的人，就紛紛轉貼這則貼文，然後就變成爆文了😂（當時的貼文在這 Threads 貼文、FB 貼文）。\n不得不說，經過這一次完全體會到什麼叫流量爆炸，人生第一次粉絲數漲那麼快，手機真的一整個晚上都在響通知，謝謝周杰倫🙏（雖然我還是沒搶到你的演唱會門票🥲）。\n不過事後覆盤一下的話，我發現中間還是有很多有趣的演算法運作的！\n首先對於 Facebook 來說，我發現真正要讓文章能擴散出去，是要靠大粉專幫忙分享，像是在這篇貼文中，就是在 科技工作講 Tech Job N Talk 大大先分享了我的貼文之後，後面才引發一連串的流量爆炸（不知道有多少朋友是透過科技工作講知道我的呢？）。\n所以對於 Facebook 而言，如果今天要寫一篇爆文，可能不是得靠你自己的粉絲分享，而是得讓某個大粉專也幫忙分享，這樣子的瞬間流量才會起來，Facebook 才會覺得這篇文章可能是爆文，因此演算法才會把文章推播出去，進而觸及到更多受眾。\n當然目前這都還只是我自己的猜想啦XD，沒有人知道 Facebook 演算法是如何運作的，我能做的事情仍舊沒有變，就是盡力分享我覺得有價值的內容，至於有沒有受演算法青睞….就隨緣吧🤣。\n不過經過這次的周杰倫事件之後，我之後確實會更加注意有沒有時事可以蹭一下（盡量是和後端有關的時事），畢竟偶爾蹭一下時事，還是對破圈漲粉絲滿有幫助的，這樣子對長期經營自媒體來說，可能會是更健康的循環。\n至於 Threads 的話，要讓文章能擴散出去，是靠大家的按讚、回覆、分享。我自己感覺 Threads 目前比較去中心化，文章是依靠「話題性」決定他是不是一篇爆文，像是在 Threads 上常常會滑到追蹤數 100 人以內、但是按讚數一兩千以上的貼文。\n也因為 Threads 是看文章的話題性決定觸及人數，所以老實說要在 Threads 上要寫爆文就更飄渺了😂，因為你沒辦法抱大腿取暖，完全就是看 Threads 心情要不要把你推播出去這樣。\n不過畢竟 Threads 也還在發展階段，演算法應該也是一直持續在改，所以 Threads 我可能要再摸一段時間之後，才能有更多心得可以跟大家分享～\n本月學習內容：詹雨安的創業筆記（Heptabase 創辦人） # 這個月的自媒體學習內容，是我意外在 Medium 上逛到的「詹雨安的創業筆記」，這系列總共有 5 集，我把連結都貼在下面這裡，大家有興趣也可以看一下這些文章：\n創業筆記（一）：休學創業學到的七件事 創業筆記（二）：在美國開公司的大小事 創業筆記（三）：在錄取 Y Combinator 之前 創業筆記（四）：核心指標的成長 創業筆記（五）：種子輪籌資 我自己最喜歡的是 「創業筆記（三）和（四）」，在新創軟體界中，Y Combinator（簡稱 YC）是最知名的孵化器，眾多新創軟體（ex: Zapier、PagerDuty、GitLab、Dropbox、Twitch…等），都是從 YC 出來的，而且每年 YC 也會舉辦 Demo Day，可以說是新創界的盛事，所以能夠入選 YC 的新創團隊，真的都是非常厲害的團隊！\n而 Heptabase，這個筆記軟體的新創團隊，就真的入選了 YC，然後大神還把他準備的過程全部寫出來，真的是滿滿乾貨！！超級推薦！！！\n雖然我自己沒有用 Heptabase，但是這個系列不需要你使用過 Heptabase 也能看（當然如果你看完之後願意付費使用 Heptabase，大神應該會很開心XD），推薦對創業有興趣、或是單純想了解看看 YC 到底在幹嘛的人閱讀這系列的文章。\n以下也節錄我自己最有感觸的幾段話，分享給大家：\n再多的方法論和聰明才智，重要性都比不上創業者自己的信念和決心。（出自創業筆記一） MVP 推出去功能太少、太爛、沒有人用，這些一點都不是問題。每一次更新 MVP 都是一次學習、一次揮棒。揮棒多了才有可能打安打、打全壘打。MVP 從來都不該一次到位，而是要能高速迭代、變得愈來愈好。（出自創業筆記三） 一家新創公司的基本要素 — 產品、客戶、團隊、市場，空有宏大願景，但是缺乏足夠執行力和商業思維的新創公司，九成以上會在第一年就陣亡。（出自創業筆記三） 流量可以用廣告買，但是留存率就完全取決於你的產品實力。（出自創業筆記四） 作為自媒體創業者，真的是對 「流量可以用廣告買，但是留存率就完全取決於你的產品實力」 這句話感到當頭棒喝🥹。\n其實我在創作的過程中，還是很容易會被流量綁架（特別是剛經歷周杰倫的爆文漲粉），但看到這句話之後，就是要常常提醒自己：流量是假象，留存率才是真相，我也想和 Heptabase 一樣，盡力做一個能幫助到大家的產品，以後也會繼續朝著這個目標努力的💪。\n總之這份創業系列文真的很推薦大家閱讀！對創業有興趣的話，真的推薦一看～～\n本月撰寫的電子報主題、文章 # 這邊記錄了我這個月撰寫了哪些電子報和文章，大家如果對於其中的內容有興趣的話，也可以前往查看：\nTDD 是什麼？認識 Test-Driven Development（測試驅動開發） Git 的好用技巧介紹 - Cherry-Pick 和 git reset HEAD^ 工程師如何和 PM 共事？PM 親自來解答！ RabbitMQ 介紹（一）- 什麼是 Message Queue？ RabbitMQ 介紹（二）- RabbitMQ 用法介紹 RabbitMQ 介紹（三）- RabbitMQ 安裝教學 + Web 管理介面導覽 淺談搶票系統 2024.10 月報總結 # 呼～總之這個月的月報大概就是這樣吧！感覺周杰倫真的是印象最深刻的了XDD，啊還有能發現詹雨安的寶藏創業筆記也很讚！！真的是處處有驚喜，到處都可以挖寶🤣。\n最後也是感謝從 Hahow 時代一路追蹤以來的老粉、以及剛加入訂閱的新粉們支持！後續也會盡力分享後端知識、以及經營自媒體的幕後祕辛給大家的，那我們就下個月的月報再見啦～\n如果你對後端筆記有興趣，也歡迎免費訂閱《古古的後端筆記》電子報，每週二為你送上一篇後端技術分享，一起變強💪\n","date":"2024-11-05","objectID":"04f9f3423bf35271e52b552100ed51d9","title":"軟體工程師的自媒體之路 - 2024.10 月報","url":"https://kucw.io/blog/as-a-content-creator/monthly-report-202410/"},{"categories":["其他技術分享"],"content":"搶票系統，一直是後端工程師在面試時的一大難題，而搶票系統又與我們的生活息息相關（例如：周杰倫演唱會搶票、雙 11 搶購），因此這篇文章就會淺談一下搶票系統的設計和遇到的挑戰，帶大家簡易入門搶票系統的實作。\n補充：搶票系統真的是一個很難的題目，我其實也不到真的很懂，所以這篇文章真的只是淺淺談一下，和大家分享目前我所學習過的內容，大家如果有什麼想法也歡迎留言，一起學習成長💪\n目錄 創建一筆訂單的實作 解決商品超賣的問題 補充：系統設計的 Functional Requirement 和 Non-functional Requirement 如何應對高流量？ 補充：拓元的搶票系統架構 結語 創建一筆訂單的實作 # 在我們實作高流量的搶票系統之前，萬事都得從平地開始做起，所以我們就先從最基本的功能開始設計，並且也在設計的過程中，討論搶票系統可能會出現的潛在問題。\n一般來說，在搶票時，不管今天是搶周杰倫的票、搶五月天、或是搶 iPhone…等等，都是要執行 「創建一筆訂單，並且將商品庫存 -1」 的操作，所以如果用程式來實作的話，可以寫成下面這個樣子（此處使用 Spring Boot 程式當作範例）：\n所以到這裡，我們就完成最基本的下訂單的雛形了。不過這個實作其實是有問題的，在一次只有一個人來下訂單時，這段程式可以正常運作，但是只要「多人同時一起來下訂單」，這段程式就會出現「商品超賣」的情形。\n解決商品超賣的問題 # 在上面的實作中，雖然程式看起來很正確沒錯，但是在「多人同時下單」時，也就是「多個 Thread 同時去執行這段程式」時，就會出現商品超賣的問題。\n大家可以想像一下，假設現在資料庫中還有 1 個商品庫存，然後此時有三個人同時執行到了第 11 行的 getProductAmount() 程式的話，那麼這三個人都會覺得：「現在資料庫中還有 1 個商品庫存，太棒了！這最後一個就是我的了！！」，所以這三個人都會繼續往下執行後面的程式，去創建一筆訂單，並且將商品的庫存 -1。\n但是這樣子的行為，就會導致資料庫中的商品庫存被減了 3 次（也就是被賣了 3 次），但是我們實際上只剩下 1 個商品庫存啊！！所以這時候就會導致商品超賣的問題出現，也就是我們賣超過自己擁有的庫存，導致有些消費者付了錢、但是拿不到真正的商品。\n要知道，商品超賣這件事在公關危機上算是非常嚴重的事件，所以為了避免這個問題，我們就必須修改這段程式，也就是 「為他加上一個同步鎖，確保一次只會有一個人執行這段程式」，因此我們就可以將這段程式改寫成下面這樣：\n（Java 中的同步鎖是用 synchronized 來實作，不熟悉 Java 語法的人可以不用管細節沒關係，只要知道這裡是加一個同步鎖就好）\n也因為我們改寫了上面這段程式，在第 11 行的地方加上了一個 synchronized 的同步鎖，因此這個同步鎖一次只會放一個人進去執行第 14～19 行的程式，就可以避免商品超賣的問題了！\n所以到這裡，我們才真的算是完成了「下訂單」的基本功能實作，也就是先確保我們的程式運行是正確的，至少不會產生商品超賣的問題。\n而一般在系統設計的流程中，當我們實作完「基本功能」之後，就可以來探討「怎麼承受住高流量」這類的問題了。\n補充：系統設計的 Functional Requirement 和 Non-functional Requirement # 在實作「能承受高流量的搶票系統」之前，我們先跳出來補充一下系統設計的相關概念。\n系統設計通常分兩塊，一塊是 Functional Requirement（功能性需求）、另一塊是 Non-functional Requirement（非功能性需求）。\n所謂的 Functional Requirement（功能性需求），就是「你是否能夠正確的解決問題」，譬如說你是否能夠實作出一個不會商品超賣的訂單系統、你是否能夠實作出一個 url 的短連結跳轉…等等，所以所謂的 Functional Requirement，就是你先把這個功能真的實作出來這樣。\n而至於 Non-functional Requirement（非功能性需求），則是「你能夠多厲害的解決問題」，譬如說你這個訂單系統，是否能夠承受 1000 人的流量？是否能夠承受 1 萬人的流量？是否能夠承受 100 萬人的流量？或是你這個訂單系統，他的可用性是多少？有沒有辦法確保 99.9999% 的時間不會當機？…等等。\n因此所謂的 Non-functional Requirement，就是在考驗你的系統到底有多強、執行效率有多高、可用性有多好…等。\n所以在進行系統設計時，可以總結成一句話：「先求有，再求好」。\n首先是 「求有」，也就是一定要先確保 Functional Requirement 能正常運作，這種最最最基本的功能一定要先完成，至少要先確保商品不要超賣，討論後面的高流量才有意義。\n等到最基本的 Functional Requirement 實作完畢之後，再來就是 「求好」，也就是處理 Non-functional Requirement 的問題，例如高流量、高性能、高可用，這類的三高問題（沒錯系統設計跟血糖一樣，也有三高問題🥹）。\n當然一般在系統設計中，面試官更關注的是 Non-functional Requirement 的部分，也就是你的系統能夠架設到多厲害這樣，所以 Non-functional Requirement 也可以說是在準備系統設計時，最需要花大量時間準備的地方（因為牽涉範圍又深又廣），不過在實作上，還是會建議大家「先求有，再求好」，沒有一步到位的系統，Don’t Over Design，Facebook 也不是第一天就長成那麼龐大的架構，都是慢慢跟著需求一起變化而來的。\n如何應對高流量？ # 在了解系統設計的概念之後，如果我們回到最一開始的問題的話，現在我們已經把「創建訂單」的功能實作出來了，所以現在我們可以開始探討，要如何提升這個系統，讓他可以應付更高的流量。\n現在在這個架構中，因為我們是使用 synchronized 這個同步鎖，強制讓同時湧進來的許多人被擋在 synchronized 上，一次只允許一個人執行第 14 ～ 19 行的程式，因此雖然可以確保商品不會超賣，但是卻讓使用者會被同步鎖卡太久，導致使用者體驗不好。\n一個較常見的解法，就是改用 Redis 來取代同步鎖，即是將商品庫存的數據改成暫存到 Redis 中，然後 Redis 中可以使用 lua 腳本確保原子性（參考 Bilibili 影片介紹、阿里雲介紹）。\n圖片來源： 阿里雲官方幫助文檔 因此這個優化的概念，就是用 Redis 來取代 Java 內建的同步鎖，進而達到更高的效能。但是具體的實作細節，抱歉我也不是很熟悉、也沒有真的實作過，所以這樣子的作法到底能夠支撐多少流量呢？我可能也沒辦法給大家一個很好的量化數字🥹。\n我目前所學習到的知識，大概就是停在 Redis 這裡而已，後面的部分我也還在探索中，所以目前還沒辦法給大家答案🥹，如果大家有興趣的話，可以在 Bilibili 上面搜尋關鍵字「秒殺系統」，大陸那邊有很多類似的影片介紹可以參考，如果想找英文資源的話，也可以搜尋「How to design a Ticketmaster」，也會有滿多相關的討論可以看一下。\n也希望將來的某一天，我可以重寫這篇主題，重新深入探討搶票系統，到時候如果有學到更多新的知識，也想再重新整理出來分享給大家！\n補充：拓元的搶票系統架構 # 以台灣來說，比較知名的搶票系統為「拓元售票」，如果大家對拓元售票的系統架構感興趣的話，也可以參考 AWS 於 2020 年提供的公開資料（t","date":"2024-10-29","objectID":"50c01260e3da79653f23bda28b19ff06","title":"淺談搶票系統","url":"https://kucw.io/blog/ticket-system/"},{"categories":["其他技術分享"],"content":"寫稿中….✍️\n有需要的人可以先參考這個 Github repo 中的 code，感謝！\nhttps://github.com/kucw/spring-boot-demo/tree/master/spring-boot-demo-rabbitmq\n","date":"2024-10-23","objectID":"c3373c4dfd0ca897c7aeb377c69c3556","title":"RabbitMQ 介紹（四）- 在 Spring Boot 中串接 RabbitMQ","url":"https://kucw.io/blog/rabbitmq4/"},{"categories":["其他技術分享"],"content":" 目錄 RabbitMQ 安裝教學 Web 管理介面導覽 查看 Queue 的整體運行情況 查看/新增 Exchange 查看/新增 Queue Admin 管理 結語 RabbitMQ 安裝教學 # 需要先安裝 docker-desktop，可以到 Docker 官網下載\n可以使用 docker 在自己的電腦上快速架設起 RabbitMQ 以及 RabbitMQ 專屬的 Web 管理介面。\n推薦使用 rabbitmq:management 的 docker image，不僅可以幫我們架設起一個 RabbitMQ，還可以順便為我們架設起一個用來管理該 RabbitMQ 的 web 管理介面，非常方便。\n執行以下方法，就可以順利啟動這個 docker image：\ndocker run --name rabbitmq -d -p 15672:15672 -p 5672:5672 \\ -e RABBITMQ_DEFAULT_USER=root -e RABBITMQ_DEFAULT_PASS=admin1234 \\ rabbitmq:management 在上面的方法中，可以自己修改 RABBITMQ_DEFAULT_USER 和 RABBITMQ_DEFAULT_PASS 的參數去自定義帳號密碼，像是此處就是設定帳號為 root、密碼為 admin1234。\n啟動好 docker image 之後，RabbitMQ 使用的 port 預設是 5672，而 RabbitMQ 的 Web 管理介面使用的 port 預設是 15672，因此只要訪問 http://localhost:15672，就會出現 RabbitMQ 的 Web 管理介面，此時就可以在輸入剛剛運行 docker image 所設定的帳號密碼登入進去。\n到這裡 RabbitMQ 就安裝好了，所以就可以使用 SpringBoot 連接上此 RabbitMQ 了。\nWeb 管理介面導覽 # 查看 Queue 的整體運行情況 # 登入之後就會進到 Overview 頁面，在 Overview 頁面可以查看 Queue 的整體狀況以及 cluster node 的 cpu/memory 使用狀態。\n查看/新增 Exchange # 點擊上方的 Exchanges tab 可以進到 Exchanges 頁面，可以查看目前已存在的 Exchange，以及新增一個新的 Exchange。\n點擊其中一個已存在的 Exchange，可以查看該 Exchange 的詳細資訊：\n查看/新增 Queue # 點擊上方的 Queue tab 可以進到 Queue 頁面，可以查看目前已存在的 Queue，也可以新增一個新的 Queue。\n同理，點擊其中一個已存在的 Queue，可以查看該 Queue 的詳細資訊，也可以對該 Queue 進行一系列的操作（這裡和 Exchange 的操作差不多，因此就不重複列出）。\nAdmin 管理 # 點擊上方的 Admin tab 可以進到 Admin 頁面，然後在 Admin 裡點擊右側的 Users tab，可以查看/新增 RabbitMQ 的使用者，也可以查看該使用者允許 access 的 virtual host。\n點擊右側的 Virtual Hosts tab，可以查看/新增 RabbitMQ 的 virtual host。\n補充： 在 RabbitMQ 裡面有一個 virtual host 的概念，可以想像成是分組，也就是一個 virtual host 就是一組。\n當 RabbitMQ 運行時，預設會產生一個 virtual host 叫做 /，然後如果不特別調整的話，所有的 Queue 都是創建在這個 / 的 virtual host 裡面，而 user 預設也是被設定成能存取 /。\n所以如果想要在 RabbitMQ 裡面做分組的權限控管的話，只要多創建幾個 virtual host，user 就可以在不同的 virtual host 下創建 Queue 和 Exchange，不同 virtual host 裡的 Queue 和 Exchange 無法互通，然後也可以去限制說某些 user 只能存取某些 virtual host。\n結語 # 這篇文章我們介紹了如何透過 Docker 安裝 RabbitMQ，並且也介紹了 RabbitMQ 管理介面中的使用方法，了解要如何透過 RabbitMQ 管理介面新增、查看 Queue 和 Exchange 的資訊。\n如果你對 RabbitMQ 的其他文章有興趣，也可以直接點擊下列連結跳轉到該文章：\nRabbitMQ 介紹（一）- 什麼是 Message Queue？ RabbitMQ 介紹（二）- RabbitMQ 用法介紹 RabbitMQ 介紹（三）- RabbitMQ 安裝教學（本文） RabbitMQ 介紹（四）- 在 Spring Boot 中實作 RabbitMQ 如果你對後端技術有興趣的話，也歡迎免費訂閱《古古的後端筆記》電子報，每週二為你送上一篇後端技術分享，那我們就下一篇文章見啦！\n補充：我開設的 Spring Boot 零基礎入門、Spring Security 零基礎入門、GitHub 免費架站術 已在 Hahow 平台上架啦！輸入折扣碼「HH202601KU」即可享 85 折優惠。\n","date":"2024-10-23","objectID":"91e16b378a5ceeffbc9b2723d9507f18","title":"RabbitMQ 介紹（三）- RabbitMQ 安裝教學 + Web 管理介面導覽","url":"https://kucw.io/blog/rabbitmq3/"},{"categories":["其他技術分享"],"content":" 前期提要：如果不了解什麼是 Message Queue，可以先參考 RabbitMQ 介紹（一）- 什麼是 Message Queue？ 的介紹\n目錄 什麼是 RabbitMQ？ RabbitMQ 中常見的 5 種模式 1. Direct 模式 2. Worker 模式 3. Publish/Subscribe 模式 4. Routing 模式 5. Topics 模式 RabbitMQ 總結 結語 什麼是 RabbitMQ？ # RabbitMQ 是在各企業中最為廣泛使用的 Message Queue，而在 RabbitMQ 的世界中，有三個重要的角色需要了解，分別是：\nProducer（生產者）：負責發送 message 到 Queue Consumer（消費者）：負責從 Queue 中接收 message Queue：暫存 message 的地方 以下圖為例，綠色的「訂單系統」是 Producer，藍色的「數據分析系統」是 Consumer，而橘色的「Message Queue」則是 Queue。\n在 RabbitMQ 的世界，Producer、Consumer、以及 Queue，是最重要的三個名詞，因此先了解這些名詞的意義，可以說是認識 RabbitMQ 的第一步。\nRabbitMQ 中常見的 5 種模式 # 在 RabbitMQ 中，常見的 5 種模式如下（所有模式可參考 RabbitMQ 官網）：\nDirect 模式 Worker 模式 Publish/Subscribe 模式 Routing 模式 Topics 模式 1. Direct 模式 # Direct 是最簡單的模式，也就是只有一個 Producer 負責發送 message 到 Queue 裡，並且也只有一個 Consumer 會從 Queue 中接收 message，接著處理該 message。\n像是以上面的「訂單系統」和「數據分析系統」的例子來說，他們其實就是使用最簡單的 Direct 模式，由「訂單系統」這個 Producer 負責發送 message，並且由「數據分析系統」這個 Consumer 接收 message。\n2. Worker 模式 # Worker 模式和 Direct 模式很像，差別只在 Worker 模式「同時有多個 Consumer」一起去接收 Queue 裡面的 message，進而提升 message 消化的速率。\nWorker 模式是 RabbitMQ 中滿常用的一個模式，假設今天 Queue 突然有很多 message 要處理，就可以多叫幾台 Consumer 來一起消化，因此可以輕易的達成「橫向擴展」，在實作上非常的好用！\n3. Publish/Subscribe 模式 # Publish/Subscribe 模式也是 RabbitMQ 中很常用的一種模式。從這個模式之後，在 Producer 和 Queue 之間，就會多出一個叫做 「Exchange」 的角色。\n所以在 Publish/Subscribe 模式中，Producer 就不會直接把 message 丟到 Queue 裡面了，Producer 反而是會先把 message 丟給 Exchange，然後再交由 Exchange 去決定要把這個 message 丟到哪個 Queue 裡面。\n所以換句話說的話，就是 Producer 再也不會直接和 Queue 溝通了，而是會藉由一個中間人 Exchange 去處理這樣。\n而在 Exchange 中，他有 3 種類型（type）可以選（direct、fanout、topic），所以在下面不同的模式中，就會搭配不同的 Exchange 設定來實作。\n像是在 Publish/Subscribe 的模式中，Exchange 使用的是 fanout 設定，也就是當 Producer 把 message 丟給 Exchange 時，Exchange 會把這個 message 丟到「他綁定的所有 Queue」中。\n舉例來說的話，假設今天 Producer 發送了一個 message 給 Exchange，那麼 Exchange 除了會將這個 message 丟到上面那條 Queue 裡面之外，同時 Exchange 也會 「複製一份 message」，然後將他丟到下面那條 Queue 裡面。\n所以在上下這兩條 Queue 中，裡面都會各自有一份 message 存在！\n因此即使 Producer 只傳送了一個 message 給 Exchange，Exchange 也會透過「複製」的方式，在每一條 Queue 中都添加同樣的 message，這樣子就可以確保所有的 Consumer 都可以接收到這個 message 了！\n也因為 Publish/Subscribe 模式的特性非常好用，因此通常在實作「訂閱」的情境下，就會採用 Publish/Subscribe 模式來實作。\n像是你在 Facebook 上追蹤了某個粉專，只要該粉專發文，你就會收到貼文通知，這就是一種 Publish/Subscribe 的應用，即是「粉專主（Producer）」發送一個貼文給 Exchange，而「每一位粉絲（Consumer）」都可以收到這個貼文的通知。\n而如果以前面提到的例子來說的話，假設今天除了「數據分析系統」想要取得訂單數據之外，其他的系統如「物流系統」、「倉管系統」也都想要取得訂單數據的話，那麼這時就可以採用 Publish/Subscribe 的方式來實作，這樣子「訂單系統（Producer）」一樣是丟出一份訂單數據給 Exchange，而「每一個想要獲得通知的微服務」就都可以從 Queue 中取得到這筆訂單數據了！\n4. Routing 模式 # Routing 模式也是一個用到 Exchange 的模式，他所使用的是 Exchange 的 direct 設定。\n在 Routing 模式中，當 Producer 將 message 丟給 Exchange 時，Producer 同時要在這個 message上面添加一個 routing key，因此 Exchange 就會根據這個 routing key，將 message 丟到指定的 Queue 上（Exchange 和 Queue 之間要用什麼 routing key 綁定，需要先行設置)。\nRouting 模式雖然使用上沒有 Publish/Subscribe 模式來的常用，但是他的重點在於 「可以多重綁定」，也就是同一個 routing key 可以綁到多條 Queue 上，因此就可以拿來實作收集 Log 的 Queue。\n像是在下圖中，我們可以將 info、error、warning 這三個 routing key，綁到記錄一般 Log 的 Queue 上，然後再將 error 這個 routing key，再綁定到另一條記錄 Error Log 的 Queue 上，這樣子就可以實作出一份帶有全部 Log 的 Queue、以及一份只有 Error Log 的 Queue 了。\n不過，雖然使用 Routing 模式可以很容易的實作出上述的收集 Log 的 Queue，但是因為他的重要邏輯都寫在 Exchange 上，所以如果對 RabbitMQ 或是 Exchange 不太熟練的話，就會不知道要去哪裡改這些設定（Exchange 的設定要進到 RabbitMQ 的系統中改）。\n因此在實作上，建議大家是慎用這個模式，除非團隊中的每個人真的都很熟悉 RabbitMQ，不然的話用這個模式可能會導致後期維護不易。\n5. Topi","date":"2024-10-22","objectID":"f6fde12fda103096a161745f55199a4a","title":"RabbitMQ 介紹（二）- RabbitMQ 用法介紹","url":"https://kucw.io/blog/2020/11/rabbitmq/"},{"categories":["其他技術分享"],"content":"RabbitMQ 是目前使用上最廣泛的 Message Queue，但是在了解 RabbitMQ 之前，必須先了解 Message Queue 的概念和特性，才會比較好上手。\n因此此系列文會先從 Message Queue 開始介紹，接著介紹 RabbitMQ 的用法、如何在電腦上安裝 RabbitMQ、以及如何在 Spring Boot 中實作 RabbitMQ。\n如果你對 RabbitMQ 的其他文章有興趣，也可以直接點擊下列連結跳轉到該文章：\nRabbitMQ 介紹（二）- RabbitMQ 用法介紹 RabbitMQ 介紹（三）- RabbitMQ 安裝教學 RabbitMQ 介紹（四）- 在 Spring Boot 中實作 RabbitMQ 而在這篇文章中，我們就會先來介紹什麼是 Message Queue，所以我們就開始吧！\n目錄 什麼是 Message Queue？ 例子：郵差送信 Message Queue 的具體應用場景 Message Queue 的優缺點 Message Queue 的優點 Message Queue 的缺點 結語 什麼是 Message Queue？ # Message Queue 是一種系統設計的技術，大陸是翻譯成「消息隊列」，台灣這邊好像沒有準確的譯名，所以通常大家還是直接用 Message Queue 來稱呼。\n而 Message Queue 的用途，就是「信箱」的概念，因此 Message Queue 就擁有了「非同步處理」以及「功能解耦」的兩大優點。\n上面的描述看起來可能有點抽象，所以我們可以直接透過一個例子，來了解 Message Queue 的概念。\n例子：郵差送信 # 舉例來說，假設你家沒有郵箱的話，那麼今天郵差如果想要送信給你，郵差就只能夠來你家按門鈴時，然後你就得從沙發上爬起來、走到樓下開門、並且當著郵差的面簽收這封信，這樣子你才能夠拿到這封信。\n所以在沒有信箱的時代，你和郵差「必須同一時間」出現在家裡大門口，這樣子郵差才能把信件親手交給你。\n但是，如果我們使用了「信箱」的話，狀況就不一樣了！\n如果你家有安裝信箱的話，那麼郵差想要送信給你時，就只要直接把信投遞到你家的信箱裡面，然後郵差就可以繼續去處理其他事情了，完全不用等你下樓來開門！而你也可以等到之後有空時，再自己下來收這封信。\n因此在有了信箱之後，你和郵差就「不需要同一時間」出現在家裡大門口，而是郵差先把信件投遞到信箱中，並且將這封信暫存在信箱裡，等到你之後有空時再來收信。\n因此「信箱」的概念，就是 Message Queue 的用途，也就是能夠 「暫存消息的傳遞」，進而達到兩個服務之間的非同步處理！\nMessage Queue 的具體應用場景 # 透過上面的例子，先大概了解「Message Queue = 信箱」這個概念之後，接著我們也可以用更具體的真實情境，來介紹 Message Queue 的用途。\n舉例來說，假設現在在電商網站中有兩個微服務：訂單系統、數據分析系統，那麼當使用者下了一筆訂單之後，這時候訂單系統就必須 call 數據分析的 api，將使用者購買了哪些商品傳給數據分析系統，讓他背後去進行大數據分析。\n所以在沒有使用 Message Queue 之前，微服務的架構會像是下面這樣子：\n這個架構也沒有說不好，但是想像一下，假設今天數據分析系統出現問題，導致 call api 請求超時、或是直接出現 500 錯誤，那這樣子就會導致使用者沒辦法成功下訂單：\n但是對於使用者而言，他根本不想要使用數據分析系統！他只是想要下訂單而已，但是卻會因為數據分析系統出現問題，導致使用者被連累著也出現問題。\n所以這個時候，就可以透過引入「Message Queue」這項技術，來解決這個問題！\n假設我們在「訂單系統」和「數據分析系統」之間，添加了一組 Message Queue 的話，那麼步驟就會變成下面這樣：\n使用者下單 訂單系統處理訂單的邏輯 訂單系統將這筆訂單的數據，傳送到 Message Queue 裡面來暫存 回傳下單的結果給使用者 所以當我們使用了 Message Queue 之後，在使用者下訂單的過程中，完全不會受到數據分析系統的干擾，而是可以專心的執行下訂單的操作了。\n而數據分析系統也可以在自己有空時，主動到 Message Queue 中查看是否有尚未處理的訂單數據，如果有的話，就抓取這一筆訂單數據來處理。並且他也可以慢慢的去分析這筆訂單數據，不用為了要搶快、要盡快回覆使用者，而逼迫自己要分析的非常迅速。\n所以透過 Message Queue 的設計，我們就可以將「訂單系統」和「數據分析系統」的功能給拆分開來，讓他們不需要同一時間處理完所有步驟，而是可以分批步驟慢慢執行，進而達到「非同步處理」以及「功能解耦」的效果了！\n所以最終的架構圖就會如下圖所示：\nMessage Queue 的優缺點 # 了解了 Message Queue 的具體使用情境之後，接著我們也可以來探討一下使用 Message Queue 的優缺點。\nMessage Queue 的優點 # 使用 Message Queue 有四大優點：\n非同步處理（Asynchronous Processing） 功能解耦（Decoupling） 易於橫向擴展（Horizontal Scalability） 流量速率限制（Rate Limiting） 其中關於「非同步處理」和「功能解耦」的部分，在上面的例子中已經有介紹到這一塊了。\n而至於「易於橫向擴展」和「流量速率限制」這部分，因為比較複雜，大家有興趣的話，可以再參考 ByteByteGo 的相關介紹。\nMessage Queue 的缺點 # 而至於使用 Message Queue 的缺點，則有：\n系統變得更複雜、增加維護成本（因為我們多添加了一個新功能到微服務架構中，勢必得多花一份心力去維護他） 上游無法知道下游的執行結果為成功 or 失敗 消息可能會丟失、或是會重複傳遞 也因為 Message Queue 在使用上不是萬能的，所以大家在引入 Message Queue 進來之前，一定要仔細思考：「這項技術是否適用於目前的架構？他是否真的能解決目前你遇到的問題？你是否願意多維護一份功能？」，只有當 Message Queue 真的能解決你的問題時，才有引入他的意義。\n而這也是大家想要邁向資深工程師的必經過程，即是有能力評估某一個功能的優缺點，並且決定是否要採用此項技術。\n不過老實說 Message Queue 是真的滿好用的啦🤣，而且也真的很常見，所以多了解一點是絕對不會虧的！\n結語 # 這篇文章我們先介紹了 Message Queue 是什麼、並且也比較了 Message Queue 的優缺點，希望能讓大家對 Message Queue 的用途有更多的了解。\n如果你對 RabbitMQ 的其他文章有興趣，也可以直接點擊下列連結跳轉到該文章：\nRabbitMQ 介紹（二）- RabbitMQ 用法介紹 RabbitMQ 介紹（三）- RabbitMQ 安裝教學 RabbitMQ 介紹（四）- 在 Spring Boot 中實作 RabbitMQ 如果你對後端技術有興趣的話，也歡迎免費訂閱《古古的後端筆記》電子報，每週二為你送上一篇後端技術分享，那我們就下一篇文章見啦！\n補充：我開設的 Spring Boot 零基礎入門、Spring Security 零基礎入門、GitHub 免費架站術 已在 Hahow 平台上架啦！輸入折扣碼「HH202601KU」即可享 85 折優惠。\n","date":"2024-10-21","objectID":"8676a9b63fbd39ca3d7f8df16e889f25","title":"RabbitMQ 介紹（一）- 什麼是 Message Queue？","url":"https://kucw.io/blog/rabbitmq1/"},{"categories":["其他技術分享"],"content":"哈囉大家好，我是古古。身為一個工程師，在工作上多多少少都得和 PM 打交道，可能有的人會好奇 PM 的工作內容是什麼、或是不知道怎麼跟 PM 相處比較好。\n所以這篇文章，我們邀請到了 PM 大大來為我們工程師們解惑一下，分享 PM 的工作內容是什麼、以及工程師如何和 PM 共事，所以我們就開始吧！\n前言 # Hello 我是 Eileen，目前任職於 Hahow 好學校的產品經理，約擔任 PM 經歷 4 年，同時也是 Taiwan Product Managers 臉書社團的管理員，近一年舉辦了許多產品經理及軟體產品從業者的小聚，希望透過這篇文章跟大家分享及交流。\n也容許我在開始前打個預防針，產品經理的日常幾乎沒有正確答案，只有最合適的答案，因此在不同團隊中可能有所差異。本篇文章僅能代表我自身體驗及所觀察到周遭產品經理的經驗！那就讓我們開始吧～\n目錄 前言 1. Project Manager（PJM）和 Product Manager（PDM）的差異 2. PM 的工作範圍到哪裡？如果遇到灰色模糊地帶的事情，如何權責劃分？ 3. PM 都是如何規劃一個專案的發想到執行？有沒有推薦的課程或是文章可以參考？ 4. 想知道 PM 的職責會幫忙拆分 User Story 嗎？ 5. PM 是如何評估專案工時的？ 6. 請問 PM 面對比較陌生的開發專案，例如：要修改很陳舊的專案，接手的工程師都不知道要怎麼抓開發時間，PM 要怎麼抓時程？ 7. RD 後期真的都會轉 PM 嗎？網路上看到不少案例 8. 當 PM 說「他不懂技術」、或是「不要跟他說技術」時，該怎麼辦？ 9. RD 和 PM 之間應該如何和平相處呢？有時候和 PM 溝通都會很無力\u0026hellip; 總結（by 古古） 1. Project Manager（PJM）和 Product Manager（PDM）的差異 # 這題問題是我在擔任 PM 第一年，最常被 PM 前輩問到的 101 問題，「你覺得產品經理跟專案經理有什麼不一樣」？網路上有許多文章說明產品經理與專案經理的差異，以下先列出普遍對於專案經理及產品經理職務上的要求差異。\n產品經理（PDM）：\n主要負責產品的整體策略和方向 關注產品的長期發展和市場需求 決定產品功能和優先順序 與各個部門協調，確保產品符合公司目標和用戶需求 專案經理（PJM）：\n負責具體專案的執行和時程管理，以確保專案按時完成 管理專案資源和團隊協調 控管專案中的風險和問題 簡單而言，產品經理（PDM）專注於「價值交付」，專案經理（PJM）則專注於「專案交付」。\n舉例而言，如果是一個串流影音平台，產品經理可能會負責與營運、業務行銷單位討論預計推出新的影片類型、預計在市場上的定位及策略進而思考對應功能（如互動式影片、離線觀看等），以滿足用戶需求並提升平台競爭力。而專案經理則可能負責管理這些新功能的開發進度，確保各個團隊（如開發、設計、內容）能夠協調一致，按時完成專案。\n雖說如此，在實際的日常中，這兩個職稱的界限可能會有所模糊。許多公司的PM職位可能是複合型的，例如：在多數公司並沒有額外招募專案經理，而是由產品經理身兼專案經理的角色。或雖然職稱掛產品經理，卻實際上被期待作為客戶經理、業務的角色。\n各家 PM 實際要負責的範圍五花八門，我和幾位 PM 朋友也常開玩笑說「工程師不做的事就是 PM 的守備範圍」，因此當在分工有疑惑時，建議大家可以參考自己公司的 PM 的 JD（職缺敘述） 或直接跟自己主管、或 PM 聊聊！\n2. PM 的工作範圍到哪裡？如果遇到灰色模糊地帶的事情，如何權責劃分？ # 延續上題，由於各個產品團隊所包含的成員不同，例如是否擁有 UI designer、UX Researcher、數據分析師、測試工程師等，影響了 PM 所扮演的角色。而當 PM 所需擔任的角色越多，時間固定情況下，可以做到的顆粒度，與勢必有所影響。\n我自己認為 PM 的工作在一個專案中（Epic 或 Story），為了避免認知不同造成誤會或浪費工程資源，至少須確保以下內容有被定義：\n目標定義： 開發這個功能是為了達成什麼目的？我們的專案規模是多大？是 POC 或是一個長期使用的功能？了解目標也可以幫助工程師想到更好的解法及考慮維運性。 功能想像對焦： 不管是流程圖、PRD（規格文件）、wireframe、設計稿、技術開發文件，目的都是用來對齊團隊成員對於功能的想像跟期待，最終期待是所有人能夠具備共識。 驗收條件定義： 驗收的內容包含但不限於：開發是否如設計稿、是否使用者正向流程及負向流程都被考量、Bug 的優先序定義等，甚至如果公司內有多個團隊，本次上線是否對於其他產品或功能造成影響，都是 PM 在功能發布前須考慮的內容。 即使如此我想大家還是有很多疑問，常見的灰色地帶，例如：帶領會議究竟是技術主管還是 PM 負責？PM 到底要不要畫出流程圖？萬一沒有設計稿，工程師要自己做嗎？ 答案是「都可以」（被揍）XD\n在不同的公司、不同團隊甚至同一個團隊的不同專案都有可能有所差異，這一切都要取決於 「團隊所擁有的資源」。例如：我們有一位 App 工程師主管為了讓使用者體驗更好，在沒有設計資源的情況下，主動發起了 Dark mode 的導入，再請設計師做 design review ，反轉了由 PM 主導需求的角色。\n因此，如果遇到灰色地帶時，最好的方式就是在 retro 當中提出，甚至工程團隊也可以發起討論會議，了解彼此的期待及難處。希望能讓大家理解，讓開發順利推動是所有專案成員的責任，大家的付出都會幫助團隊運作更為順暢！\n3. PM 都是如何規劃一個專案的發想到執行？有沒有推薦的課程或是文章可以參考？ # 古古補充：這段比較多專有名詞，如果覺得有點複雜可以先跳過這題\n在目前的公司，我們透過公司層級定義的 OGSM（年度目標）來制定產品部門及組別層級的 OGSM。這包含了目標、策略（如何實現）以及衡量指標（如何確認完成）。\n舉例來說，今年的一個目標是能夠檢驗和衡量使用者的學習成效。經過對國內競品、市場分析、國外領導產業的研究，以及團隊腦力激盪後，我們選擇了透過「測驗」功能來量化學習效果作為策略。考慮到 Hahow 現有的技術架構、使用者和創作者的使用習慣，我們發現要提供「測驗」服務，需要完成 A、B、C 三項任務。為了在目標期限內完成這項策略，我們還定義了這三個專案各自的目標、時程安排，以及可用的工程資源和時間。\n接下來，PM 會根據這些資訊進行更深入的競品調查和使用者研究，以了解「測驗功能」（Epic）需要滿足哪些使用者情境（Story）及其具體流程。這個階段也就是撰寫「產品規格文件」（PRD，Product Requirement Document）的必要環節。由於這個專案預計運用 AI 技術，我們還額外進行了工程 POC 來評估新技術的可行性。確認可行後，我們將任務交給產品設計師進行 Wireframe 和設計稿的繪製，並反覆討論使用者體驗和操作介面。在這個過程中，我們也邀請工程師評估設計流程的開發可行性。\n最後，我們進入 Scrum 流程中的 Pre-refinement、Refinement 和 Planning 會議，將任務交給工程團隊進行 Task 的切分和開發實作。但這還不是終點。為了確保測驗功能上線後能達到目標使用人數並驗證假設，我們還需要規劃數據埋點，以及與行銷團隊討論產品行銷策略。上線後，PM 還需要負責數據分析和後續迭代規劃。\n每一個大型專案上線都像生了一個孩子，從發想到執行的過程總是充滿驚喜（嚇）。也幸好團隊中擁有產品設計師、工程師和測試工程師各自的專業，透過不斷的討論，才能確保產出最佳的解決方案。\n","date":"2024-10-15","objectID":"f7dc5e167f6e5ee522fdafbd5c7e288c","title":"工程師如何和 PM 共事？PM 親自來解答！","url":"https://kucw.io/blog/pm-for-developer/"},{"categories":["其他技術分享"],"content":"Git 可以說是工程師使用上最頻繁的技術，這篇文章會分享兩個我覺得 Git 的好用技巧給大家，分別是：\nCherry-Pick： 擷取某個 branch 中的某個 commit git reset HEAD^： 撤銷最新的 commit 所以我們就開始吧！\n目錄 Git 好用技巧之一：Cherry-Pick（擷取某個 branch 中的某個 commit） Git 好用技巧之二：git reset HEAD^（撤銷最新的 commit） 結語 Git 好用技巧之一：Cherry-Pick（擷取某個 branch 中的某個 commit） # 如果說 Git 有什麼隱藏的特殊技能的話，Cherry-Pick 絕對是我心目中的第一名！\nCherry-Pick 的用途，是「擷取某個 branch 中的某個 commit」，這個聽起來是有點抽象，所以下面就透過一個實際的例子來示範 Cherry-Pick 的用法。\n像是目前在 master branch 中，在 resources 資料夾底下只有一個 application.properties 的檔案：\n如果這時候，我們切到 test 這個 branch 上，然後在 resources 底下新增一個 123.txt 的檔案，並且成功 commit 的話，結果就會像下圖一樣，在「步驟 3」的地方新增了一個 123 的 commit 出來。\n這時如果再接著新增一個 456.txt 的檔案，並且也成功 commit 的話，結果就會和下圖一樣，在「步驟 2」的地方新增了一個 456 的 commit 出來。\n所以到目前為止，在 test branch 就新增了兩個 commit：\n一個是 123 的 commit（包含 123.txt 檔案） 另一個則是 456 的 commit（包含 456.txt 檔案） 而 master branch 中則是維持原樣，沒有任何新增的 commit，resources 底下也只有 application.properties 一個檔案。\n這時候，神奇的需求來了！！如果現在有人要你切回到 master branch，並且要求你將 test branch 中的 123.txt 的檔案移植到 master branch 的話，你該怎麼辦？\n在還不會使用 Cherry-Pick 時，第一直覺反應是將 test merge 進 master，並且想辦法把 456 的 commit 刪掉，這樣子就能夠只保留 123 的 commit。\n這種做法雖然也能夠解決問題，但是當 commit 數一多的時候，就會變的很混亂，無法確保自己是否有保留到正確的 commit。\n所以這時候，就是 Cherry-Pick 上場的時候了！\n當我們在 master branch，想要擷取 test branch 中的某個 commit 時，只要在 IDE 上點擊右鍵（在這個例子中，就是對 123 這個 commit 點擊右鍵），然後選擇 Cherry-Pick：\n點擊之後，就可以看到在 master branch 的 resources 資料夾中，就多出了一個 123.txt 的檔案！並且在 master branch 中，也多出了一個新的 commit 123，所以這也就表示，我們就成功的將 test branch 中的 commit，偷到 master branch 中了！\n因此大家以後如果有「擷取別的 branch 中的某個 commit」的需求時，就可以使用 Cherry-Pick 幫助我們非常方便的做到！\n補充：Cherry-Pick 的「偷」的動作不是真的偷過來，而是將 test branch 中的 123 commit 中的內容，複製同樣的一份到 master branch 上，所以 master branch 的 123 commit 和 test branch 中的 123 commit，兩者之間是沒有任何關係的，在 Git 的線圖上，他們會是兩個獨立的 commit。\n雖然 Cherry-Pick 的使用情境看起來真的很少見，但老實說我在實際的工作中真的有用過一兩次，而且那次幫助真的滿大的，超級感謝發明 Cherry-Pick 的人XD。\n那時候我是在某條 branch（ex: TICKET-112）上開發，但是後來因為各種原因所以要棄用這條 branch，換到另一條 branch 開發（ex: TICKET-917），這時候我就在新的 branch 上使用 Cherry-Pick 去拉有用的 commit 過來，真的很好用！！\nCherry-Pick 就是屬於一年不開張、開張吃一年的指令，建議大家可以先把他的情境記下來，等到將來有一天真的也遇見這種神奇的狀況時，再回頭來查看他的使用方法就好～\nGit 好用技巧之二：git reset HEAD^（撤銷最新的 commit） # git reset HEAD^ 是我個人愛用的 Git 指令，他可以用來撤銷最新的 commit，但是不會刪除該 commit 中的內容，所以適合用在「上一個 commit 沒寫好，想要重新 commit」的情境上。\n舉例來說，目前在 test branch 中，有兩個 commit：\n一個是 123 的 commit（包含 123.txt 檔案） 另一個則是 456 的 commit（包含 456.txt 檔案） 如果這時候我發現「啊！我少添加了一個 789.txt 的檔案」，那麼我就可以先執行 git reset HEAD^ 的指令，先將 commit 456 給撤銷（注意此時 456.txt 的檔案仍舊存在，只是變回尚未 commit 的狀態）：\n此時我就可以自由添加想要的程式（ex: 789.txt），然後後續就可以將 456.txt 和 789.txt 一起加到 commit 裡，將他們存放在同一個 commit 中。\n之所以會特別介紹 git reset HEAD^，是因為我在工作上還滿常用這個指令的。根據以往的經驗，我發現將多個相關的檔案儲存在同一個 commit 裡面，這樣後續如果要排查程式的話，放在同一個 commit 中的檔案會比較好查。\n像是在 IntelliJ 這個 IDE 中，點擊「456 + 789」的 commit，就會在右側呈現這一次 commit 中的檔案有哪些，所以就可以透過這個線索，去查詢和他有相關的改動為何。\n所以在實作上，我個人會偏好盡量把相關的程式 commit 在一起，也算是幫助自己後續排查問題時比較好查詢這樣。\n不過老實說 commit 的頻率和檔案數，這個真的就很看大家自己的喜好，所以大家就自由參考，或是說如果有什麼更好的做法，也歡迎在下方留言！\n補充：如果想要在 IntelliJ 中達到 git reset HEAD^ 的效果，可以直接在該 commit 上點擊「Undo Commit」，這樣子就可以得到和 git reset HEAD^ 一樣的「撤銷 Commit」的效果了！\n結語 # 這篇文章我們有分享了 Git 中的好用技巧：Cherry-Pick 和 git reset HEAD^ 給大家，雖然這兩個指令的使用頻率不是很高，但是這兩個都是我自己用過，真心覺得好用的指令～\n如果你對後端技術有興趣的話，也歡迎免費訂閱《古古的後端筆記》電子報，每週二為你送上一篇後端技術分享，那我們就下一篇文章見啦！\n補充：我開設的 Spring Boot 零基礎入門、Spring Security 零基礎入門、GitHub 免費架站術 已在 Hahow 平台上架啦！輸入折扣碼「HH202601KU」即可享 85","date":"2024-10-08","objectID":"b2173f3817c7d0d77e13397a7327a048","title":"Git 的好用技巧介紹 - Cherry-Pick 和 git reset HEAD^","url":"https://kucw.io/blog/git-tip/"},{"categories":["其他技術分享"],"content":"對於軟體工程師來說，「撰寫單元測試」已經是一個必須具備的技能，撰寫好的單元測試不僅能夠確保程式運行正確，也能夠降低後期重構、維護的成本，可以說是一舉多得！\n而在單元測試越來越重要的情況下，就誕生了 「TDD（測試驅動開發）」 的開發流程，因此這篇文章我們就來介紹一下，TDD 到底是什麼、以及要如何使用 TDD 來開發程式吧！\n目錄 什麼是 TDD（Test-Driven Development）？ 傳統的開發流程 TDD 的開發流程 步驟 1：只宣告功能的方法名稱，不實作內部程式 步驟 2：撰寫單元測試，並且單元測試運行失敗（紅燈） 步驟 3：實作主功能程式 步驟 4：單元測試運行成功（綠燈） 小結：TDD 開發流程 vs 傳統開發流程 TDD（Test-Driven Development）總結 結語 什麼是 TDD（Test-Driven Development）？ # TDD 的全稱是 Test-Driven Development，中文翻譯為「測試驅動開發」，而 TDD 的核心理念，就是 貫徹「先寫測試、再寫開發」的精神。\n也因為 TDD 的核心理念「先寫測試、再寫開發」比較抽象，所以以下我們就直接透過一個例子，來比較一下「傳統的開發流程」和「使用 TDD 的開發流程」的差別在哪裡。\n傳統的開發流程 # 一般我們在開發程式時，比較常見的流程為：\n接到需求 開始寫程式，實作該功能出來 最後撰寫單元測試，確保功能運行正確 所以在傳統的開發流程中，當我們拿到需求時，基本上就是先動手寫程式，先去實作該功能出來，而等到功能都實作的差不多之後，最後再補足單元測試，確保程式運行正確，這樣子就算完成這個功能的開發了。\n舉例來說的話，假設我們現在要實作一個「計算機的加法功能」，那麼我們就可以先寫出下圖左的程式（以 Java 為例），去實作加法功能出來。\n而當我們實作完左邊的加法功能時，就可以再去撰寫右邊的單元測試，使用單元測試去驗證我們所寫的程式是否正確，因此到最後，我們就實作完「主功能程式」和「單元測試」的程式了。\n所以上述這樣子的做法，就是最常見的傳統開發流程，也就是照著「先寫開發、再寫測試」的步驟，去完成一個功能的開發。\nTDD 的開發流程 # 而在了解了傳統的開發流程之後，接著我們就可以來介紹 TDD 的開發流程是什麼了！\n步驟 1：只宣告功能的方法名稱，不實作內部程式 # 當我們使用 TDD 時，首先第一步，就是 「只宣告功能的方法名稱，但卻不實作他的內部程式」。\n所以舉例來說的話，假設我們想要實作「計算機的加法功能」，那我們第一步，就只能夠先去宣告這個 add() 方法，但是不能夠去實作這個功能內部的程式。\n這一步對於習慣傳統開發流程的工程師來說，其實就是非常反人類的一步了😂，人生從來沒遇過只需要宣告方法名稱、但是不需要實作程式的要求！\n但是沒關係，建議大家就先接受 TDD 就是這樣的流程，所以當我們使用 TDD 時，第一步就是只宣告方法名稱，但是不實作他的內部程式。\n步驟 2：撰寫單元測試，並且單元測試運行失敗（紅燈） # 宣告完方法之後，接著也是很反人類的第二步來了。在第二步中，我們就要 「先根據這個方法的用途，憑空寫出他的單元測試出來」。\n舉例來說的話，因為我們想要實作的是「計算機的加法功能」，所以邏輯上，這個功能應該要能夠正確執行加法的操作才可以。因此我們可以直接在右邊撰寫一個單元測試，並且在這個單元測試中，就去測試 add() 方法的行為是否正確。\n所以在這個單元測試中，當我們去 call add(1, 2) 方法時，就「預期」他的返回結果應該要是 3 才對（因為抽象的邏輯意義上，add() 方法就是要去執行加法操作，所以 1+2 要等於 3 才對），程式如下圖右所示。\n所以在 TDD 的第二步中，我們就會直接根據這個方法的抽象邏輯，直接去撰寫單元測試出來，去「預期」這個方法的行為為何。\n不過當然啦，因為我們目前在 add() 方法中還沒有實作任何一行程式，所以當我們運行這一段單元測試的程式時，單元測試就會運行失敗，因此產生「紅燈」的結果（雖然此時單元測試運行失敗，但是這也是 TDD 的開發流程一環，因此這裡出現紅燈是正常現象）。\n老實說步驟二是大家一開始在接觸 TDD 時，最容易碰壁的一步，因為通常我們在實作程式時，會一不小心就往下鑽研去思考實作細節，但是卻忽略了「這個方法本身的用途」為何。\n因此在使用 TDD 開發程式時，我們就得換個角度來思考，在真正實作程式的細節之前，反而是要先從大方向去規劃每一個方法的用途為何，這樣子後續在實作程式時，才能夠寫出功能拆分完整、職責分明的程式了！\n步驟 3：實作主功能程式 # 在我們經歷了第二步最難熬的一關之後，後續的步驟就比較容易了！\n因為在第二步中，我們已經寫好測試 add() 方法的單元測試了，所以在第三步中，我們就可以回頭去實作 add() 方法中的邏輯，將這個功能真正的實作出來。\n步驟 4：單元測試運行成功（綠燈） # 而在我們實作完 add() 方法中的程式之後，這時候我們再回頭去運行單元測試，理論上就要能夠運行成功了！因此當我們運行單元測試時，單元測試就會顯示「綠燈」，表示單元測試成功通過。\n所以透過 TDD 的開發流程，我們最終也是可以實作完「主功能程式」和「單元測試」的程式了！\n小結：TDD 開發流程 vs 傳統開發流程 # 所以透過這兩個流程也可以發現，不論我們使用的是「傳統的開發流程」、還是「TDD 的開發流程」，我們最終所實作完的程式，其實是一模一樣的，就是會包含「主功能程式」和「單元測試」這兩部分，因此不論我們使用哪一種方式來開發，最終的產出都是一樣的。\n只不過 TDD 相對於傳統的開發流程而言，就是提供了另外一種開發思路給我們，讓我們在真正實作程式的細節之前，能夠先從大方向去規劃每一個方法的用途為何，進而寫出功能拆分完整、職責分明的程式了！\nTDD（Test-Driven Development）總結 # 所以總結上述的介紹的話，現在我們回頭來看 TDD 的定義，就可以更了解 TDD 的核心理念是什麼了。\nTDD 的全稱是 Test-Driven Development，中文翻譯為「測試驅動開發」，也因為 TDD 是透過「撰寫單元測試」去驅動「程式的開發」，所以 TDD 的核心理念，就是貫徹「先寫測試、再寫開發」的精神。\n而 TDD 的開發流程，也可以總結成下面這張圖：\n所以大家如果有興趣想嘗試 TDD（測試驅動開發）的話，就只要照著上述的步驟實作，就可以體驗 TDD 的開發流程了！\n結語 # 這篇文章我們有去介紹了 TDD（Test-Driven Development，測試驅動開發）的核心理念是什麼，並且也介紹了 TDD 的開發流程，了解要如何透過「撰寫單元測試」去驅動「程式的開發」。\n如果你對後端技術有興趣的話，也歡迎免費訂閱《古古的後端筆記》電子報，每週二為你送上一篇後端技術分享，那我們就下一篇文章見啦！\n補充：我開設的 Spring Boot 零基礎入門、Spring Security 零基礎入門、GitHub 免費架站術 已在 Hahow 平台上架啦！輸入折扣碼「HH202601KU」即可享 85 折優惠。\n","date":"2024-10-01","objectID":"c9d0981b02ac0e6e301d5523d31d1d43","title":"TDD 是什麼？認識 Test-Driven Development（測試驅動開發）","url":"https://kucw.io/blog/test-driven-development/"},{"categories":["自媒體經營"],"content":"哈囉，我是古古，正如之前在創刊號中有提到，雖然我一開始是意外踏入自媒體，但現在我是認真的要經營《古古的後端筆記》這個個人品牌，剛好現在也滿流行 Build in Public 的創業模式，所以就想來彙整一下到目前所經營的成果，寫個月報出來總結一下，也當作給自己的一個記錄。\n補充：還沒看過創刊號的人，也可以先查看一下 電子報創刊號，了解一下前情提要。\n2024.8～9 月粉絲追蹤數、電子報訂閱人數 # 自從電子報創刊號（2024/8/6）以來，到目前為止（2024/9/24）的粉絲成長人數如下：\n初始人數 2024/9/24 人數 總成長人數 Facebook 粉專追蹤數 2480 2687 +207 電子報訂閱人數 326 1195 +869 Threads 粉絲追蹤數 29 535 +506 IG 粉絲追蹤數 96 130 +34 雖然從這張圖上可以看到人數成長的很快，兩個月電子報就破 1000 人訂閱了，但我覺得這是因為我本身已經有經營 Facebook 粉專、有開過線上課程，所以目前已經有一定的粉絲數了，因此我是可以到 Facebook 社團宣傳、或是到課程中宣傳，將一部分粉絲數轉化為電子報訂閱者的。\n所以說到底，現在人數會漲得這麼快，完全就是吃老本😂，目前我已經把 Backend 社團的宣傳量能、自己線上課程的宣傳量能都用完了，下一步真的就是開始拼內容，只有製作出更有價值的內容，才能靠內容獲取大家的芳心💪。\n但有一點讓我滿意外的是，就是 Threads 粉絲的人數漲得也太快了吧！不知道大家有沒有玩過 Threads，我自己也是為了做自媒體才去下載 Threads 來用。\n據說 Threads 上的台灣用戶大概有 350 萬人左右，佔全球第 7 名，我自己是覺得根本原因是因為台灣人沒有被 Twitter（現 X 平台）佔據市場，所以在 「純文字的熱點討論」 這一塊，就被 Threads 給吃下來了。\n如果大家閒著沒事滑滑 Threads 的話，我是覺得可以比 Facebook 看到更多同溫層以外的討論，雖然也稱不上每一篇都很有收穫啦，但是就看看同溫層以外的世界也滿有趣的。\n然後有一點觀察也滿有趣的，就是 IG 的粉絲數真的是慘不忍睹XDD，一下子就被 Threads 超車到看不到車尾燈，我想這應該還是「內容呈現形式」所導致的差異。\n以 Facebook、Threads 和電子報來說，他們全部都是以 「文字」 的形式來傳播，但是 IG 則是以圖片、短影音來傳播，也因為後端技術這種比較硬的知識，大部分都還是以文字為主，所以我這個主題跟 IG 的粉絲受眾調性不同，因此在 IG 的粉絲數才一直起不來吧。\n後續應該會再觀察一段時間，如果 IG 流量真的不太好，現階段就直接放生吧XD，把時間拿去做更重要的事！\n本月學習內容：SEO 優化 # 既然是要認真經營自媒體，我覺得這對於我來說完全是一個新的領域，而我踏入新的領域的第一步，就是 「先認真看一堆書」，至少要把這個領域的基本知識搞懂、知道自媒體運作的原理，這樣子後續自己在實戰時，才不會像無頭蒼蠅一樣到處亂飛。\n所謂 「知識就是力量」，真的是非常好的一句話！\n這個月我看了《SEO白話文：贏得免費流量，創造長期營收的「SEO行銷指南」》這本書，作者是邱韜誠 Frank Chiu。\n會先挑 SEO 這個主題下手，是因為既然我的文章調性是以長文、部落格為主，那麼把 SEO 做好，可以說是一個 「長期有效」 的事。\n所謂的 SEO，全稱是 Search Engine Optimization（搜尋引擎優化），而 SEO 簡單的說的話，就是盡量讓你的網站在 Google 中排名變高，就是這麼簡單暴力。\n舉例來說，大家現在到 Google 上搜尋「Java lombok」的話，那就可以看到我所寫的「Java - 五分鐘學會 Lombok 用法」文章，出現在搜尋排名的第 2 名。\n而排名越靠前，就表示被使用者點擊的機率越高，因此我所寫的文章就越可以被大家看見、進而提升《古古的後端筆記》的影響力。\n所以在我不斷精進自己的後端技術能力的同時，我也得維護好 SEO，盡量讓自己寫的文章靠前，這樣子才能夠達到長期有效的成長。\n當然啦，SEO 效益這麼高，一定是所有人都搶著要把排名拉高🥹，而我現在也就只有一篇 Lombok 是排名比較靠前的，而且這也只是剛好運氣好賽到（當時根本不知道什麼是 SEO）。\n所以有關 SEO 的部分，後續我仍舊會投入練習經營，雖然目前也不知道成效怎樣，但是至少知道 SEO 的玩法規則之後，再上戰場跟其他網站廝殺，希望成功率可以高一點吧🤣。\n本月撰寫的電子報主題、文章 # 這邊記錄了我這兩個月內撰寫了哪些電子報和文章，大家如果對於其中的內容有興趣的話，也可以前往查看。\n《古古的後端筆記》創刊號 iThome 鐵人賽 - 得《優選》獎項的寫作心法 RESTful API 設計指南，3 個必備條件缺一不可！ 一文搞懂 Http Status Code，詳細解析 200、301、401、403、500、503 Spring Boot - 監控工具 Actuator AI 名詞和概念介紹 - NLP、LLM、RAG Vertical Scaling 和 Horizontal Scaling 介紹 Docker 是什麼？他和 VM 的差別在哪裡？ Nginx 是什麼？認識反向代理、負載平衡 如何準備面試？後端工程師的求職全攻略 2024.8～9 月報總結 # 綜合以上的數據的話，雖然到目前為止都只是吃老本，但是老實說看到這個粉絲數的成長我真的超開心的🥹😭，超級感謝大家的支持和訂閱，沒想到電子報訂閱可以破 1000 人，我真的是又驚又喜！\n後續除了努力撰寫後端知識分享的文章之外，也會多花一些時間學習自媒體、行銷這方面的知識，我覺得創業者就是得當個 「多面手」，什麼事情都必須要會，才能夠解決大大小小的各種問題。\n老實說，雖然在學習的過程中可能會有很辛苦的地方、也會有很累的地方，但是能夠學習其他領域的知識，其實我還滿興奮的😆，這可是坐在辦公室寫程式接觸不到的！所以後續希望也能多揭露一些自媒體的幕後祕辛給大家～\n另外，創業的路上不是自己一個人閉門造車就好，多聆聽用戶的反饋也是非常重要的！所以大家如果有什麼想法，也歡迎隨時寄信給我（service@kucw.io），每一封信我都會看的。\n這條創作之路仍在繼續前行中，期待下個月的月報！\n如果你對後端筆記有興趣，也歡迎免費訂閱《古古的後端筆記》電子報，每週二為你送上一篇後端技術分享，一起變強💪\n","date":"2024-09-24","objectID":"934bbacd668676b9f89c09d91d8ac9d1","title":"軟體工程師的自媒體之路 - 2024.8～9 月報","url":"https://kucw.io/blog/as-a-content-creator/monthly-report-202408-09/"},{"categories":["職涯相關"],"content":"在軟體工程師的世界中，大家可能常常聽到「漲薪水就是要靠跳槽」，但是，在跳槽之前，做好面試的準備是非常重要的！所以這篇文章就會來分析一下後端工程師在求職時，有哪些注意事項要準備。\n目錄 後端工程師的求職全攻略 履歷部分 履歷長度要濃縮成一頁 剛轉職後端，沒有過往的工作經驗該怎麼辦？ 履歷不要只描述產品本身，而是要描述「你做了什麼」 履歷不要有形容詞 海投履歷，渣男/渣女式求職法 先用中文寫履歷，再一口氣翻譯成英文 履歷小結 面試部分 面試前的心態準備 如果我是面試官… 1. 會做事 2. 能跟面試官溝通順暢 3. 認真負責任 面試小結 後端工程師的求職全攻略總結 結語 後端工程師的求職全攻略 # 在求職時，主要會分成兩個流程：「履歷審查」和「面試」，雖然這句話聽起來很像廢話沒😂，但是在求職時，一定要分清楚自己目前是處在哪個階段。\n如果你是海投了 100 家公司，但是連一封面試邀請信都沒有收到，那你就是「履歷」的部分有問題，需要回頭調整履歷呈現方式；相反的，如果你是滿手面試邀請信，但是沒有一家順利拿到 offer，那就是「面試」的部分有問題。\n所以大家在求職時，除了要好好準備面試大魔王之外，履歷的準備也是非常重要的！這兩項是相輔相成的，缺一不可！\n所以這篇文章也會分別從「履歷」和「面試」這兩個不同的角度，分別來介紹在這不同的階段該如何進行準備。\n補充：本篇文章主要是針對 Junior（初階）後端工程師所撰寫的求職攻略，Senior（資深）的部分會稍微提到一點，但是不會深入太多，所以大家如果是資深工程師、或是主管大大等級的話，這篇文章可能幫助不大🥹。\n履歷部分 # 履歷長度要濃縮成一頁 # 在撰寫履歷時，首先一定要把自己的豐功偉業濃縮成一頁，常見的履歷就真的是只有一頁而已（可能 HR 們也來不及全部看完，只會看一頁），所以想盡辦法把自己做過的事情濃縮成一頁是非常重要的。\n剛轉職後端，沒有過往的工作經驗該怎麼辦？ # 如果是剛轉職比較沒有過往工作經驗的話，那麼會建議可以放一些你自己實作的小專案，如果是轉職的話，通常是會跟著資策會、或是線上課程學習，所以就可以把那些學習過程中所實作的專案，當成是你的求職作品集這樣，比起什麼都沒放會好很多！\n至於後續有累積越來越多工作經驗之後，就可以把作品集的部分拿掉了，把履歷的空間留給你最新的工作經驗。\n履歷不要只描述產品本身，而是要描述「你做了什麼」 # 在撰寫履歷時，建議不要只描述產品、作品集本身，而是要描述「你做了什麼」。\n舉個例子來說的話：\n❌ 我使用 Spring Boot 實作了一個電商網站，裡面包含會員功能、訂單功能、商品功能。 ✅ 我使用 Spring Boot 實作了一個電商網站，裡面包含會員功能、訂單功能、商品功能，其中用到的技術有 Spring Boot、RESTful API、Spring MVC、Spring JDBC、單元測試。 在上面的例子中，上面的 ❌ 錯誤寫法，就只是在描述這個電商網站本身有什麼功能這樣，其實對於面試官來說，你實作的產品是什麼不重要，重點是你在實作的過程中，使用到了哪些技術，這個才是最重要的！\n所以在撰寫履歷時，建議可以改成下面的 ✅ 正確寫法，描述你在實作電商網站的過程中，使用到了哪些技術，像是 Spring Boot、RESTful API、Spring MVC…等等，這樣子面試官後續才可以透過這些關鍵字，延伸去考察你是否了解這些技術的運用。\n履歷不要有形容詞 # 在撰寫履歷時，還有一個很重要的重點，就是在履歷中 「不要出現形容詞」！！！\n舉例來說的話：\n❌ 我實作了一個具有高吞吐量、高擴展性的搶票功能，並且撰寫易於維護的程式，有效減少後期維護成本。 ✅ 我實作了一個能負擔 1000 人同時在線搶購的搶票功能，其中使用了限流器中的令牌桶算法（Token Bucket），確保伺服器不會因為過量的人流導致崩潰。並且我使用 JUnit 撰寫單元測試，單元測試覆蓋率為 80%。 透過上面這兩個例子，可以看到上面的 ❌ 錯誤寫法，用了非常多很厲害的形容詞，像是「高吞吐量」、「高擴展性」、「易於維護」…等，但老實說，這些形容詞對面試是一點幫助都沒有的，所以透過上面那句話所得到的資訊，就只有「你實作了一個搶票功能」而已。\n而至於下面的 ✅ 正確寫法，就提供了很多資訊，像是面試官就能知道你實作了一個能負擔 1000 人的搶票功能（對後端來說，能同時負擔 1000 人和 10 萬人是不同等級的系統架構），然後後面也呈現了你所用到的技術，像是限流器、令牌桶算法、JUnit 單元測試…等等。\n因此面試官之後在面試時，就可以根據你這份履歷中所提到的關鍵字，具體的問你「那你了解限流器是什麼嗎？請解釋一下你為什麼採用令牌桶算法」…等等，等於是埋了許多關鍵字給面試官問這樣。\n所以在撰寫履歷時，建議改成正確的寫法，就是 「在履歷中盡量不要出現形容詞」，反而是要好好的把你的實作給 「量化」 出來，這才是最重要的！\nPS: 這時候有的人可能會有疑問，啊我都離職了，要怎麼取得到當初我實作的系統數據？沒錯，你拿不到的（如果你拿得到，公司的資安就完了）。\n所以履歷其實是要在工作的過程中隨時更新的，建議是當你做完一個大案子的時候，就可以回頭拉一下數據、更新一下你的履歷，這樣子後續要求職的時候，才不會苦無找不到數據來佐證自己的情況出現🥹。\n海投履歷，渣男/渣女式求職法 # 抱歉這一個小節的標題有點聳動，但是這是我真實的想法😂。\n在投履歷時，除了那種「你上了也完全不想去的公司」不用投之外，其餘的公司，但凡你有一點點興趣，建議履歷就是直接給他大膽地投下去，等到你真的上了之後，再考慮要不要去。\n很多人在投履歷時，可能會陷入一個迷思，就是「我已經正在面試某幾家公司了，我還要繼續投履歷嗎？」，這個答案，一定是 Yes！ 在你真的拿到 offer 入袋之前，有幾家你就投幾家，每天照三餐投，反正就是有幾家就投幾家就對了！\n這樣子海投履歷的好處，就是 「你能掌握主動權」，舉例來說：\n假設你今天突然面試到一半被刷掉了，這時候就不需要特別擔心，因為你還有備胎 假設你今天同時得到 2 家公司以上的 offer，那太棒了，你們 2 家公司去打架吧，看誰給的錢高、待遇好、發展性好，我就去哪家 所以對於求職者來說，手上掌握越多 offer 通常是越好的，這代表你在市場上有競爭力，所以大家都搶著要你，所以你就越有底氣和 HR 談更好的薪資待遇，因此在求職時，如果時間允許的話（畢竟面試也是需要時間準備），還是會建議大家可以海投履歷，為自己掌握更多的主動權。\nPS：之所以說海投履歷是渣男/渣女式的求職法，是因為在還沒有正式交往（還沒有正式簽 offer）之前，你都還有許多備胎（其他公司）可以選擇；同樣的，公司也是除了你之外，還養著無數的備胎求職者，所以這就是一個比賽誰備胎比較多的世界，根本就是逼人當渣男/渣女😂。\n所以建議大家，在找工作時，就先放下你善良的感情觀，用渣男/渣女的方式來求職，讓自己成為許多公司搶著要的對象，才能成為真正的贏家！\n先用中文寫履歷，再一口氣翻譯成英文 # 這點我真的是恨不得早點發現🥹，在一剛開始求職時，我也常常遇到履歷寫不出來的情況出現，本來還怪說是不是自己英文太爛了才寫不出來，但是後來當我嘗試用中文寫寫看時，嗯.…我發現我還是寫不出來XDD。\n這就像是英文作文一樣，拿不到高分時，以為是自己英文不夠好、名言佳句背不夠多，才寫不到高分，後來才發現原來是自己中文不好，用中文寫的文章結構就很糟了，這樣就算翻譯成英文，仍然沒辦法變成一篇好作文，進而拿到高分的。\n所以就建議大家，一開始可以先用中文寫履歷，等到全部寫完之後，再叫 ChatGPT 幫我們翻譯成英文，最後","date":"2024-09-17","objectID":"8e2404cbfc70a6fe672eabf550114f95","title":"如何準備面試？後端工程師的求職全攻略","url":"https://kucw.io/blog/backend-developer-interview/"},{"categories":["其他技術分享"],"content":"Nginx 可以說是在大型的微服務架構中，必備的核心功能之一，所以這篇文章我們就來介紹一下 Nginx 到底是什麼，以及介紹一下反向代理、負載平衡的概念吧！\n目錄 什麼是 Nginx？ 在 Nginx 被發明出來之前：單體式架構 微服務架構所碰到的問題 Nginx 的反向代理 Nginx 介紹 反向代理（Reverse Proxy） 負載平衡（Load Balancing） Http Cache Nginx 總結 補充：什麼是正向代理（Forward Proxy）？ 結語 參考資料 什麼是 Nginx？ # Nginx 是一個輕量級的 Web 伺服器，通常用在以下三種情境：\n反向代理（Reverse Proxy） 負載平衡（Load Balancing） Http Cache 不過在我們開始了解 Nginx 的這三種特性之前，要先回頭來介紹一下 Nginx 最一開始要解決的問題是什麼，了解了 Nginx 要解決的問題之後，我們才能夠延伸去介紹「反向代理」、「負載平衡」、以及「Http Cache」的概念。\n補充：Nginx 的唸法是「Engine X」（中文發音近似於「安金 欸可斯」），也就是「引擎 X」的意思，這裡開頭的 N 字母就是使用到英文語法中常見的縮寫。像是 How are you 可以簡寫成 How r u、而 Airbnb 其實是 AirBed \u0026amp; Breakfast 的簡寫（n 的發音近似於 \u0026amp;），所以在這裡就是用到了英文的語法，將「Engine X」縮寫為「Nginx」。\n在 Nginx 被發明出來之前：單體式架構 # 在我們一開始學習後端程式時，我們就是寫好一個後端程式（ex: Spring Boot 程式），然後運行他，接著我們就可以用 Postman 這類的工具，去發起一個 API call，去請求我們電腦上所運行的後端程式，而這個就是最簡單的 單體式架構（Monolithic），也就是同時間我們只會有一個後端程式存在。\n不過當有越來越多使用者，慕名前來使用我們的後端服務時，這時候就會導致流量上升，使得一台 Server 沒辦法支撐住這麼高的流量。\n所以這時候，為了確保 Server 能負擔這麼高的流量，我們就有兩個選擇：\n使用 Vertical Scaling（垂直擴展），為這台 Server 升級 cpu、ram…等設備，讓他從一台普通的「2 核 cpu、4 GM ram」的電腦，變成是一台「64 核 cpu、128 GB ram」的超級電腦。 使用 Horitontal Sclaing（水平擴展），也就是多新增幾台 Server 出來，大家人多勢眾，一起對付更高的流量。 如果這時我們選擇 Vertical Scaling（垂直擴展）的話，就只是從一台普通的 Server，進化成一台超級電腦而已。這個選擇對整體的架構沒有影響，仍舊是只有一個後端程式在運行，所以此時依舊是單體式的架構，因此不需要 Nginx 上場。\n但如果我們選擇的是 Horitontal Sclaing（水平擴展）的話，那麼我們在同一時間，就會有非常多台的 Server 聚集在一起，準備聯合起所有 Server 的力量，一起對付高流量。所以這時候，整個後端的架構，就會從「單體式架構（Monolithic）」變成「微服務架構（Microservices）」，也就是同時間有多個後端程式在運作。\n所以這個時候，我們就會遇到微服務架構所要面對的問題，因此就需要 Nginx 上場了！\n補充：如果想更了解 Vertical Scaling（垂直擴展）和 Horizontal Scaling（水平擴展）的介紹，可以參考 Vertical Scaling 和 Horizontal Scaling 介紹 文章的介紹。不過這邊只要先知道 Horizontal Scaling 的概念是新增許多台 Server 出來，就可以繼續閱讀本文對 Nginx 的介紹了。\n微服務架構所碰到的問題 # 在微服務的架構中，因為同時間會有多個後端 Server 在運作，所以這時候對於前端而言，最最最大的問題，就是他不知道要去 call 哪一台 Server 的 API（對這個聽起來有點笨，但是前端就真的不知道啊！）。\n像是在下面這張圖中，同時間有 3 台後端 Server 在運作，這時候前端就會很困惑，他現在到底是要請求哪一台 Server？或是當流量又升高之後，這時候我們添加到 10 台 Server 來處理時，這時候要怎麼通知前端，現在有 10 台 Server 可以接受前端的請求？\n所以為了解決這個問題，Nginx 就被發明出來了！\nNginx 的反向代理 # Nginx 其中的一個核心功能，就是 「反向代理（Reverse Proxy）」，而所謂的反向代理，就是讓 Nginx 一個人擋在所有後端程式的最前面，由 Nginx 作為統一的守門人。\n所以當前端想要來請求後端的 API 時，前端就會改成請求 Nginx，由 Nginx 決定這一次的請求要分配到哪一台後端 Server 上，而這個行為，就是反向代理（Reverse Proxy）了！\n所以有了 Nginx 之後，Nginx 就可以作為所有後端 Server 的守門人，因此今天當前端來請求後端的 API 時，前端就必須改成去 call Nginx，由 Nginx 將這個請求「轉發」給任一台後端 Server（轉發規則由 Nginx 說了算），達到反向代理的效果。\n所以透過 Nginx 的反向代理，我們就可以統一的處理所有前端傳遞過來的請求了！\nNginx 介紹 # 透過上面的例子大概了解 Nginx 的概念之後，我們也可以回頭正式來介紹一下 Nginx 的用途。\nNginx 是一個輕量級的 Web 伺服器，通常用在以下三種情境：\n反向代理（Reverse Proxy） 負載平衡（Load Balancing） Http Cache 而透過上述的例子，現在我們也了解了反向代理的概念是什麼：\n反向代理（Reverse Proxy） # 所謂的「反向代理」，其實就只是 Nginx 一個人擋在所有後端 Server 的最前面，由 Nginx 作為後端 Server 的守門人，因此所有前端傳遞過來的請求，都一定都要先經過 Nginx，再經由 Nginx 後續去轉發給內部的後端 Server。\n而使用反向代理的好處非常多，因為在反向代理中，是由 Nginx 一個人扛住所有對外的連接，所以我們只需要在 Nginx 中設定好 Https 的憑證即可，因此內部的後端 Server 就不需要處理網路相關的憑證問題。\n又像是防火牆的問題，我們只要統一的在 Nginx 處理好 DDoS 之類的駭客攻擊就好，就不需要每一個後端 Server 都去處理，也大大的節省了資訊安全的維護成本。\n如果大家有用過 AWS、GCP…這類雲端服務的話，其實 AWS 中的 API Gateway，就會擋在 Amazon EC2 前面（EC2 就是 AWS 中提供 VM 的服務），由 API Gateway 統一處理所有對外的溝通。所以如果你的 Server 是部署在 AWS 上的話，那麼可以直接選擇 AWS 的 API Gateway 來負責反向代理的部分，因此就不用自己架一台 Nginx 來維護了。\n圖片來源： Amazon API Gateway 負載平衡（Load Balancing） # 只要講到反向代理，那麼就一定會提到 負載平衡（Load Balancing），他們是必定會一起出現的一對名詞。\n在前面我們有提到，Nginx 會作為所有後端 Server 的守門人，透過反向代理的機","date":"2024-09-10","objectID":"593611e9a7391a7aae30598c88a8b605","title":"Nginx 是什麼？認識反向代理、負載平衡","url":"https://kucw.io/blog/nginx/"},{"categories":["其他技術分享"],"content":"作為軟體工程師，大家可能多多少少聽過什麼是 Docker，但是卻不了解 Docker 實際要解決的問題是什麼、以及他和 VM 之間的區別。\n所以這篇文章就會來介紹一下，到底什麼是 Docker、什麼又是 VM，並且他們兩個之間的差別又是什麼，那我們就開始吧！\n目錄 什麼是 VM？ 使用 VM 的注意事項 補充：常見的 VM 例子 什麼是 Docker？ 有了 VM 之後，我們還需要 Docker 嗎？ VM 和 Docker 總結 結語 什麼是 VM？ # 在了解 Docker 之前，一定要先了解什麼是 VM 才可以，所以我們先來介紹一下 VM 是什麼。\nVM 的全稱是 Virtual Machine，中文翻譯為「虛擬機」，而 VM 要解決的問題，就是要達到「硬體資源的共享」。\n在很久以前 VM 還沒被發明出來的時代，這時候如果我們想要在一台電腦上運行程式，那我們首先要做的，就是要先帶著你的錢錢，先到 3C 商店買一台實體的電腦回家之後，你才能夠在那台電腦上面運行你所寫的程式。\n所以在 VM 被發明出來以前的時代，我們所有的程式，就都是直接運行在實體的主機上。\n不過隨著網路的發展，大家就漸漸發現，每次在運行程式之前，都還得要提前去買一台實體的電腦，這真的是太麻煩了！所以大家就開始思考：「我們是否能夠讓一台實體的電腦，分身成無數台電腦？」，這樣子我們就再也不用提前去購買實體的主機了，只要按一下按鍵就可以生成一部新的電腦出來。\n而正是這個想法，就造就了 VM（虛擬機）的出現了！\n所謂的 VM，就是將「一台實體的主機」，拆分成「許多個作業系統」的技術。 所以舉例來說的話，假設我們有一台超強的實體主機（64 核 cpu、128 GB ram），那麼我們就可以透過 VM 的技術，將這台實體主機「拆分」成是三台電腦，而每一台電腦，我們就可以自由的選擇我們想要灌哪個作業系統。\n所以像是在下圖中，在 VM 虛擬機 1 這台電腦上，我們可以灌 Linux 這個作業系統；而在 VM 虛擬機 2 這台電腦上，我們可以灌 Windows 這個作業系統…等等，所以當我們使用了 VM 之後，我們就只要購買一台實體的主機，就可以拆分成許多台小電腦出來，因此就達到了 「硬體資源的共享」 了！\n使用 VM 的注意事項 # 在使用 VM 時，因為 VM 本質上是去共享一台實體主機，所以所有 VM 的運算資源，都是從實體主機上面瓜分出來的。\n所以像是在上面的例子中，假設實體主機的運算能力是 64 核 cpu、128 GB ram，那麼 VM 1 可能只會分到 2 核 cpu、4G ram，VM 2 可能會分到 4 核 cpu、8G ram…等等，每一台 VM 都可以依照自身的需求，去和實體的主機請求適量的運算資源。\n也因為 VM 的運算資源都是從實體主機上面瓜分出來的，所以一台實體主機能創建的 VM 也是有限的，沒辦法無限的創建下去，所以萬一 VM 的需求越來越多的話，仍舊是會需要我們提前去購買新的實體主機回來的。\n補充：常見的 VM 例子 # 其實大家平常在用的雲端服務，就是 VM 最常見的用法。像是我們可以用滑鼠點一點，就能夠在 AWS 中去租用一台 EC2 的 VM 出來。\n像是在下圖中，AWS 預設就是租用 t2.micro 的 VM 給我們，所以這一台 VM 就是擁有 1 核 cpu、並且有 1G 的 ram，而運行這台 VM 的實體主機，就是 AWS 提前採購好的實體主機。\nOK 所以到這邊為止，我們已經了解到什麼是 VM 了，所謂的 VM，就是要達到「硬體資源的共享」。\n那麼在了解了 VM 的概念之後，接著我們可以來了解一下，什麼是 Docker？他和 VM 又有什麼差別？\n什麼是 Docker？ # 如果說 VM 的目的，是為了要達到「硬體資源的共享」，那麼 Docker 的目的，則是要達到「應用程式的隔離」。\n大家可以想像一個情境，假設你今天上網看到了一段爬蟲程式，然後你想把他載下來使用，但是這段程式要求要使用 Python 2.x 的環境才能夠運行，所以你為了運行這段程式，你就努力的在你的電腦上安裝好 Python 2.x 的環境，最後就成功的運行了這段程式。\n但是，當你好不容易處理完環境的問題之後，假設你又要執行另一段網頁程式，他所需要的是 Python 3.x 的版本，這時候你又得大費周章，努力的去研究要怎麼將 Python 2.x 更新到 Python 3.x、以及怎麼樣同時在你的電腦上安裝 Python 2.x 和 Python 3.x 的開發環境。\n這時候，你可能心已經累了，你明明只是想去運行網路上的那段程式而已，但是你卻得花非常多的心力，去處理架設開發環境的設定。\n所以為了解決這個問題，Docker 就被發明出來了！\n所謂的 Docker，他的目的是要達到「應用程式的隔離」，所以在你的電腦中，就會有很多個「容器」存在，每一個容器都是一個箱子，裡面會放置你想運行的程式、以及該程式需要的開發環境，並且每一個箱子之間不會互相干擾。\n所以像是在下圖中，在 VM 1 這個 Linux 的作業系統裡面，我們就可以創建許多個 Docker 容器出來，而每一個 Docker 容器，我們都可以安裝不同的開發環境、並且運行不同的程式，這樣子就可以達到開發環境之間的隔離，進而節省我們反覆架設開發環境的時間。\n所以舉例來說的話，我們就可以將「爬蟲程式 + Python 2.x 的開發環境」，放置在 Docker 容器 1 裡面，而我們也可以將「網頁程式 + Python 3.x 的開發環境」，放置在 Docker 容器 2 裡面。因此當我們之後想要執行爬蟲程式的時候，就直接去運行 Docker 容器 1 就好，而如果我們想要運行的是網頁程式，那就是改成運行 Docker 容器 2。\n所以透過 Docker 容器的概念，我們就可以達到「應用程式之間的隔離」了！\n有了 VM 之後，我們還需要 Docker 嗎？ # 在了解了 VM 和 Docker 的概念之後，接著我們也可以來討論一下一個很常見的問題，那就是：有了 VM 之後，我們還需要 Docker 嗎？\n在看完了上面的介紹之後，大家心裡可能會有一個疑惑，就是上述的 Python 環境的問題，我們創建兩個 VM 出來，不就也可以解決了？譬如說我們可以創建一個 VM 1，裡面安裝 Linux 的作業系統，並且安裝 Python 2.x 的環境，然後我們也可以再創建 VM 2，裡面也是安裝 Linux 的作業系統，但是改成安裝 Python 3.x 的環境，這樣不是也能解決上面的開發環境的問題嗎？\n確實透過創建兩個 VM 的方法，是可以解決 Python 的環境問題沒錯，不過相較來說，Docker 的解法會更加輕量化。\n因為對於傳統的 VM 來說，每一個 VM 都需要安裝一個作業系統（ex: Linux），然後才能在這個作業系統上面安裝 Python 的開發環境。但是在作業系統中，其實是包含非常多的功能的（ex: 操作介面、驅動程式、網路管理…等等），所以每當我們創建一個 VM 出來，就必須要一起創建這些我們根本用不到功能出來，所以我們就會浪費不少的運算資源，在維護這些不必要的功能上。\n而 Docker 之所以可以更加輕量化，是因為他是在同一個作業系統底下，去創建許多的容器出來，然後再在每一個容器中，各自去安裝需要的開發環境。所以這些容器，他們就會共享同一個作業系統的所有功能，所以我們就不需要重複去安裝驅動程式這類的功能，因此就可以節省許多的運算資源，降低 cpu 的負擔了。\n所以 Docker 之所以這麼好用，就是因為他除了能夠達到「應用程式的隔離」之外，同時他","date":"2024-09-03","objectID":"05ae48f286c2740f347cd181b9dd8c16","title":"Docker 是什麼？他和 VM 的差別在哪裡？","url":"https://kucw.io/blog/docker-vs-vm/"},{"categories":["其他技術分享"],"content":"你有沒有曾經好奇過，在雲端的世界裡 Server 是如何進行擴展的呢？\n這篇文章我們就來介紹一下雲端服務中兩種常見的擴展方式：Vertical Scaling 和 Horizontal Scaling 吧！\n目錄 什麼是 Vertical Scaling 和 Horizontal Scaling？ 什麼是 Vertical Scaling（垂直擴展）？ 什麼是 Horizontal Scaling（水平擴展）？ 小結 Vertical Scaling（垂直擴展）的優缺點、以及適用的情境 Vertical Scaling 的優缺點 Vertical Scaling 的適用情境 Horizontal Scaling（水平擴展）的優缺點、以及適用的情境 Horizontal Scaling 的優缺點 Horizontal Scaling 的適用情境 Vertical Scaling 和 Horizontal Scaling 總結 結語 什麼是 Vertical Scaling 和 Horizontal Scaling？ # 想像一下，假設現在你正在經營一間新創公司，一開始的流量很小，所以就只要到 AWS 或是 GCP 上面，隨便租用一台 VM（虛擬機）當作你的 Server，就可以直接應付這些使用者的流量了。\n但是，當你的業務慢慢擴張時，這時候當初租用的那台 Server 已經不夠用了，那麼這時候，你該怎麼辦？所以為了讓 Server 能夠應付更高的流量，這時候就是 Vertical Scaling 和 Horizontal Scaling 出場的時候了！\n什麼是 Vertical Scaling（垂直擴展）？ # 所謂的 Vertical Scaling（垂直擴展），就是表示「直接在該 VM 上加一堆 cpu 和 ram，讓這台 VM 變成一台超級強大的 VM」，讓他能夠對付更高的流量。\n所以在 Vertical Scaling 中，你就只會有一台 VM，只是你把這台 VM 從一台小型的「2 核 cpu、4 GM ram」Server，變成是一台「64 核 cpu、128 GB ram」的超級電腦而已。\n另外英文口語中的「Scale Up」，就是表示 Vertical Scaling（垂直擴展）的意思。\n什麼是 Horizontal Scaling（水平擴展）？ # 而所謂的 Horizontal Scaling（水平擴展），則是表示「多新增幾台小型的 VM 出來，大家人多勢眾，一起對付更高的流量」。\n所以在 Horizontal Scaling 中，你就會從「只有一台小型的 VM」，變成是「擁有很多台小型的 VM」，所以你就可以聯合這些小型的 VM 們，一起去對付更高的流量。\n注意在 Horizontal Scaling 中，你所擁有的一定是「很多台小型的 VM」，而不是「很多台超級電腦」，因為 Horizontal Scaling 的定義就是水平擴展，即是聯合許多小型的 VM，一起去克服龐大的流量。所以假設今天其中一台 VM 倒下了、或是流量又撐不住了，那麼就趕快再招一個小型的 VM 來加入戰場，而不是為戰場中的 VM 們升級裝備（添加 cpu、ram），這個是在了解 Horizontal Scaling 的定義時，一定要特別注意的一點。\n另外在英文口語中的「Scale Out」，則是表示 Horizontal Scaling（水平擴展）的意思。\n小結 # 所以到這邊先小結一下的話，Vertical Scaling 是「為一個 VM 不斷增強他的添加 cpu、ram，將他變成一台超級電腦，以應付更高的流量」，而 Horizontal Scaling 則是「添加許多小型的 VM，一起聯合起來對付更高的流量」，而他們兩種方式所要解決的問題，就都是 克服更高流量的問題。\n而在了解了 Vertical Scaling 和 Horizontal Scaling 的概念之後，接下來我們就可以來比較一下這兩種方式的優缺點，以及在什麼樣的情境下，更適合選擇哪一種 Scaling 機制了。\nVertical Scaling（垂直擴展）的優缺點、以及適用的情境 # Vertical Scaling 的優缺點 # 因為 Vertical Scaling 的方式，就是不斷為一台 VM 中添加 cpu、ram，將他變成一台超級電腦，來應對更高的流量，所以在 Vertical Scaling 的世界中，就只會有一台 VM 來處理請求，因此他的優點，就是維護和升級非常容易，所以我們只要管好這一台 VM 就好，不需要處理多台 VM 所帶來的分散式系統（Distributed System）的問題。\n不過 Vertical Scaling 的缺點，就是他的擴展是有限的，因為就算不斷的為一台 VM 添加 cpu、ram，在物理上總是有極限的，不可能真的無限擴展下去，所以 Vertical Scaling 的缺點，就是他的擴展是有限的，到一定程度之後一定得改成 Horizontal Scaling 擴展方式。\nVertical Scaling 的適用情境 # 其實在業務擴張的初期，Vertical Scaling 是非常好用的選擇，因為我們只要無腦的為那一台 VM 不斷的添加 cpu 和 ram 就好（錢給到位，什麼都給你加），不需要額外處理多台 VM 所帶來的分散式系統的問題。所以在業務擴張的初期，只要啟動資金足夠，Vertical Scaling 會是一個滿不錯的選擇。\n不過當業務漸漸擴展時，這時候用 Vertical Scaling 的效益就不太好、而且可能也無法應付大量的使用者流量，所以這時候就會需要一次大型的重建，將程式改為分散式系統，後續改為使用 Horizontal Scaling 來擴展。\n所以如果是去很早期的新創、或是自己做 Side Project 的話，就可以考慮先用 Vertical Scaling 來撐住，至少讓公司先活下去這樣，但是後續如果想要長期發展、或是想要進大公司的話，那就一定要了解 Horizontal Scaling 和分散式系統的概念，因為大公司的流量通常都不是一台 VM 可以抵擋得住的。\nHorizontal Scaling（水平擴展）的優缺點、以及適用的情境 # Horizontal Scaling 的優缺點 # 因為 Horizontal Scaling 的方式，是聯合一群小型的 VM 們，一起應對更高的流量，所以 Horizontal Scaling 的優點，就是擴展沒有極限，只要流量變大，那我就多添加一台小型的 VM 到群組裡，增加更多的戰力來應對更高的流量。\n不過 Horizontal Scaling 的缺點，就是他在維護上會比較麻煩，因為有了多台 VM 的概念，所以就必須要建立一個分散式系統（Distributed System），並且處理分散式系統所會帶來的相關問題。\n所以 Horizontal Scaling，他就是屬於前期需要投入許多的成本，去架設分散式系統、並且處理分散式系統所帶來的問題，但是一但建立起來之後，後期可以無限制擴張的一種擴展方式（用遊戲的術語來描述的話，他就是一個前期發育緩慢、但是大後期很強的角色）。\nHorizontal Scaling 的適用情境 # 因為要使用 Horizontal Scaling 的話，首先就需要建立分散式系統，所以確實會對開發帶來一定的成本，但是如果只要後續業務有成長的話，後期通常都會轉成 Horizontal Scaling。\n所以如果在開發時有餘裕的話，建議一開始在設計系統時，最好就直接朝「分散式系統」來設計，這","date":"2024-08-27","objectID":"6ec464750dc6d6c024767316bb8bf655","title":"Vertical Scaling 和 Horizontal Scaling 介紹","url":"https://kucw.io/blog/vertical-and-horizontal-scaling/"},{"categories":["其他技術分享"],"content":"最近實在是看到太多 AI 的專有名詞了（ex: NLP、LLM、RAG），雖然我不搞 AI，但是稍微理解一下這些名詞在幹嘛還是有必要的，不然搞得好像全世界都在追一場很好看的劇，但是自己卻完全跟不上🥹。\n所以這篇文章就會從頭來介紹一下 AI 的概念和邏輯（不需要任何程式背景也能看得懂），以及介紹常見的 AI 名詞，那麼我們就開始吧！\n目錄 什麼是 NLP（自然語言處理）？ 什麼是 LLM（大型語言模型）？ 什麼是 RAG（檢索增強生成）？ 結語 什麼是 NLP（自然語言處理）？ # 在談 LLM、RAG、GPT 這類的 AI 名詞之前，首先最最最重要的，是要先搞懂他們是要解決什麼問題。\n這一系列 AI 的名詞，他們最根本的，是要解決「自然語言處理」的問題，而這個白話來說的話，就是要讓這些 AI 們「能夠說人話」（我們平常說的語言就是自然語言）。\n像是在 AI 出現之前的時代，程式的運作是非常直覺的，工程師會寫一堆 if...else... 的判斷句，就是「當什麼事情發生時\u0026hellip;.程式就做什麼反應」。\n所以在以前的年代，工程師就會寫出 if 有人說 \u0026quot;你好\u0026quot;，程式就輸出 \u0026quot;Hello World\u0026quot; 這種程式，所以假設到時候，真的有人來說了 \u0026ldquo;你好\u0026rdquo;，那麼程式就會輸出 \u0026ldquo;Hello World\u0026rdquo; 這個字串，就是這麼簡單直覺暴力（所以這也是為什麼以前的客服機器人很笨，因為他就是只看得懂特定的句子，然後回覆固定的罐頭回答）。\n但是自從 ChatGPT 出現之後，世界就開始變得不一樣了！\n所謂的 ChatGPT，他是屬於一種生成式 AI，而他最大的不同點，就是「他會自己決定他要回覆什麼答案」。\n所以當我們使用了 ChatGPT 之後，工程師就再也不用寫出 if 有人說 \u0026quot;你好\u0026quot;，程式就輸出 \u0026quot;Hello World\u0026quot; 這種死板的程式了，工程師要做的，反而是告訴 ChatGPT 各式各樣的情境，讓 ChatGPT 自己去旁觀學習這樣。\n所以譬如說工程師可能就會輸入下面這兩段對話給 ChatGPT：\nA：你好 B：哈囉你好，你吃飽了沒？ A：還沒，正要去吃，你要一起嗎？ B：好啊！走吧 C：你好 D：心情不好，滾 C：別這樣嘛，走請你吃飯 D：你請客，謝謝 而當 ChatGPT 在「旁觀」完這兩段對話之後，他心中可能就會對於 \u0026ldquo;你好\u0026rdquo; 這兩個字，有自己的理解（這就像是人類在學習一樣，小時候都是透過旁觀父母的行為，決定自己的成長人格）。\n所以下一次當你對 ChatGPT 說 \u0026ldquo;你好\u0026rdquo; 的時候，他的反應可能會是：\n你：你好 ChatGPT：滾 又或是\n你：你好 ChatGPT：哈囉滾 所以對於 ChatGPT 會回答什麼，你是完全不會預先知道的，甚至就連養出他的工程師也不知道他會回什麼😂，因為實際上工程師所做的，就只是輸入一大堆片段的對話範例，讓 ChatGPT 自己去感悟理解而已。\n也因為對於每一個 ChatGPT 的模型而言，他們都是獨一無二的孩子，所以每一個孩子都會針對「同樣的對話範例」，會有「不一樣的理解」，而這個不斷拿範例對話去給 ChatGPT 旁觀學習的過程，就是俗稱的「訓練模型」。\n所以實際上 ChatGPT 能夠長成什麼樣子，初始的範例對話是影響非常大的（就跟父母的言行對於孩子的影響很大一樣），所以這也是為什麼 ChatGPT 剛上市的時候常常被吐嘈中文很奇怪，估計就是因為初始的範例對話數據很少中文，啊就父母不會講中文，孩子不會講中文也很合理吧🤣🤣🤣。 󠀠 所以到這邊先小結一下的話，就是 ChatGPT 所要解決的問題，就是要解決「自然語言處理（NLP）」的問題，而這個白話來說的話，就是要讓 AI「能夠說人話」。\n至於 ChatGPT 的解決方法，就是透過不斷的輸入初始的範例數據，去「訓練 ChatGPT 的模型」，進而養出一個獨一無二的孩子（ex: GPT-3、GPT-4、GPT-4o\u0026hellip;等），然後再來比較看看誰養的好這樣（天下父母心，我家的孩子就是要比別人家的好！）。\n什麼是 LLM（大型語言模型）？ # OK 在了解了 ChatGPT 要解決的是「自然語言處理」的問題之後，接下來要理解 LLM 和 RAG 就比較容易了。\n其實在「自然語言處理」這個領域中，有一個分類，叫做 LLM（Large Language Models），也就是「大型語言模型」，只要是透過前面所提到的「不斷輸入初始化的範例數據，去訓練一個語言模型出來」的流程，那這個被訓練出來的模型，就叫做「大型語言模型（LLM）」。\n所以其實 ChatGPT 在定義上，就是屬於 LLM 分類中的一種實作，只不過因為 ChatGPT 實在太紅了，所以他的傳播度才大於 LLM 這樣，但是在定義上，LLM 是比較廣泛的定義，但凡是被訓練出來的語言模型，就都可以是屬於 LLM 的一種。\n所以像是目前市面上常見的 Gemini、GPT-4、Claude\u0026hellip;等等，這些都是一個一個的大型語言模型（只是父母不同人而已，像是 Google、OpenAI\u0026hellip;等），所以這些語言模型，就都是屬於 LLM 的一種實作。\n所以簡單的說的話，LLM 就是「大型語言模型」，而市面上常見的 AI 產品，就都是屬於 LLM 中的一種實作，目的都是為了解決「自然語言」的問題（就是要讓 AI 說人話）。\n什麼是 RAG（檢索增強生成）？ # 而至於 RAG，就是比較新的概念了。所謂的 RAG，是一種結合 「大型語言模型」+「外部數據來源」 的技術。\n舉個例子來說的話，假設 Google、OpenAI 他們透過很大量的初始範例對話，生成了一個一個的語言模型 Gemini、GPT-4\u0026hellip;出來，而當你真的訂閱了這個模型來用的時候，你就會發現，怎麼 AI 所回答出來的內容，好像都是幾個月前的內容，就沒辦法回答最近兩天的內容這樣。\n譬如說 GPT-4 只能告訴你：「籃球比賽的規則是什麼」，但是他卻沒辦法告訴你：「昨天獲勝的 NBA 球隊是哪一隻」，因為在 GPT-4 的初始訓練數據裡面，並沒有昨天獲勝的 NBA 球隊，所以他就不懂，所以他就沒辦法告訴你到底是誰獲勝。\n而如果要解決這個問題的話，最直觀的想法，可能是「啊那就把昨天獲勝的 NBA 球隊也拿去訓練一下 GPT-4 不就好了？」，老實說拿著新數據重新去訓練 GPT-4 這條路是可行的，但是成本代價太高，所以基於成本考量，一般不太會這樣做。\n所以為了要解決這個問題，RAG 就出現了！ 󠀠 所謂的 RAG，可以把他想像成是一個補丁包，就是你訂閱了一個 GPT-4 來用之後，你可以再跟他說：「這裡有昨天的 NBA 比賽數據，啊你不用訓練自己沒關係，你把他當小抄，如果我來問你 NBA 的比賽情況，你就順便看一眼這個小抄，然後再回答我就好」。\n所以當我們在 GPT-4 這個模型之上，再去添加了 RAG 之後，就可以讓這個 GPT-4 在「不需要重新訓練模型」的情況下，也能夠「理解最新的客製化數據」，這樣子不僅可以省下許多成本，也可以達到取得到最新數據的目的了。\n也因為 RAG 他是一種結合「大型語言模型」+「外部數據來源」的技術，讓 GPT-4 就像是得到了一堆小抄一樣，可以知曉外部數據中的內容。所以目前 RAG 比較常見的用法，就是透過 RAG 的技術，將 GPT-4 和企業內部的數據結合在一起，讓 GPT-4 變身成為一個知曉企業內部數據的強大語言模型！\n有關 RAG 和語言模型的介紹，也","date":"2024-08-24","objectID":"82a229f7509edb56a080bfe52ee44686","title":"AI 名詞和概念介紹 - NLP、LLM、RAG","url":"https://kucw.io/blog/ai-intro/"},{"categories":["Spring Boot"],"content":" 本文使用的 Spring Boot 版本：3.3.2\nActuator 是 Spring Boot 所提供的監控功能，可以用來查看當前的 Spring Boot 程式運行的情況，像是可以查看當前運行的健康指標、查看 Spring Boot 所創建的 beans、以及獲取當前的 applicaiton.properties 的屬性的值。\n目錄 使用 SpringBoot Actuator Actuator 提供的常見的 api 開啟受保護的 Actuator 監控 api 的方法 結語 使用 SpringBoot Actuator # 如果要使用 SpringBoot Actuator 提供的監控功能，需要先加入相關的 maven dependency。\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-actuator\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 只要加上了這個 maven dependency，Spring Boot 在運行時，就會自動開啟 /actuator/health 這個 api 給我們使用，因此當我們去請求 http://localhost:8080/actuator/health 這個 api 時，就可以查看當前 Spring Boot 程式的運行狀況。\n像是下圖中就顯示，當前的 Spring Boot 運行狀態為 UP，UP 即為正常運行的意思。\nActuator 提供的常見的 api # 除了上述自動開啟的 /actuator/health api 之外，Actuator 其實還提供更多樣化的 api，讓我們可以從不同的角度，去監控 Spring Boot 程式（不過因為安全因素考量，大部分的 api 都需要另外設定才能夠開啟，詳細的設定方式在下方介紹）。\n因為監控 api 眾多，以下僅列出常用的監控 api，所有監控 api 可查閱 Spring 官方文件\nHTTP 方法 Endpoint 描述 GET /actuator 查看有哪些監控的 api 有開放使用 GET /actuator/env 查看此 Spring Boot 程式載入了哪些 application.properties 的值（不過為了保護安全資訊，所以會自動碼掉帶有 key、password、secret 等關鍵字的 properties 的值） GET /actuator/flyway 查看 flyway DB 的 migration 資訊 GET /actuator/health 查看當前 Spring Boot 程式的運行健康指標，UP 即為正常運行 GET /actuator/heapdump 取得 JVM 當下的 heap dump，會下載一個檔案 GET /actuator/metrics 查看有哪些指標的數據可以看（ex: jvm.memory.max、system.cpu.usage），可再使用 /actuator/metrics/{metric.name} 分別查看各個指標的詳細資訊 GET /actuator/scheduledtasks 查看定時任務的資訊 POST /actuator/shutdown 唯一一個需要 POST 請求的 api，關閉這個 Spring Boot 程式 開啟受保護的 Actuator 監控 api 的方法 # 因為安全的因素，所以 Actuator 預設只會開啟 /actuator/health 這個監控的 api 讓我們使用，如果要開放其他的 api 的話，需要額外在 application.properties 中進行設定\n# 可以這樣寫，就會開啟所有的 api（但不包含 shutdown） management.endpoints.web.exposure.include=* # 也可以這樣寫，就只會開啟指定的 api，像是此處就只會再額外開啟 /actuator/beans 和 /actuator/mappings 這兩個 api management.endpoints.web.exposure.include=beans,mappings # exclude 可以用來關閉某些 api # exclude 通常會和 include 一起搭配使用，就是先去 include 全部進來，然後再 exclude 想要關閉的部分 # 像是此處就是關閉 /actuator/info 這個 api management.endpoints.web.exposure.include=* management.endpoints.web.exposure.exclude=info # 如果要開啟 /actuator/shutdown api 的話，需要額外再加這一行 management.endpoint.shutdown.enabled=true 除此之外，也可以改變 /actuator 的路徑，自定義成自己想要的 url 路徑\n# 這樣寫的話，原本內建的 /actuator/xxx 的 url 路徑，就都會變成 /my/xxx # 這樣做可以防止 Actuator 的監控 api 路徑被其他人猜到 management.endpoints.web.base-path=/my 結語 # 本篇文章介紹了 Spring Boot Actuator 的用法，以及列出的常見好用的監控 api 有哪些，提供給大家參考。\n如果你對後端技術有興趣的話，也歡迎免費訂閱《古古的後端筆記》電子報，每週二為你送上一篇後端技術分享，那我們就下一篇文章見啦！\n如果想了解更多 Spring Boot 的用法，也歡迎參考我開設的線上課程 Java 工程師必備！Spring Boot 零基礎入門 （輸入折扣碼「HH202601KU」即可享 85 折優惠）。\n","date":"2024-08-21","objectID":"d5a6783b07fef638dd2933a6e3f40b6b","title":"Spring Boot - 監控工具 Actuator","url":"https://kucw.io/blog/2020/7/spring-actuator/"},{"categories":["其他技術分享"],"content":"大家在 call API 時，是否曾經好奇過他所返回的 200、401、403、500\u0026hellip;等數字是代表什麼意思？其實這些 3 位數的數字，就是 Http Status Code（又稱 Http 狀態碼）。\n因此這篇文章我們就來詳細介紹一下，Http Status Code 的用途到底是什麼，以及常見的 Http Status Code 有哪些吧！\n目錄 什麼是 Http Status Code（Http 狀態碼）？ 常見的 Http Status Code 1xx：資訊 2xx：成功 3xx : 重新導向 4xx : 前端請求錯誤 5xx : 後端處理有問題 Http Status Code 總結 結語 什麼是 Http Status Code（Http 狀態碼）？ # 所謂的「Http Status Code」，中文是翻譯成「Http 狀態碼」，而他的目的，就是 「用一個簡短的值，快速的表示當前 API 的請求結果是什麼」。所以舉例來說的話，大家常見的「200」的回覆，其實就是表示這一次的 API 請求成功了，就只是這麼簡單的用途而已。\n而在 Http Status Code 的世界裡面，除了有「200」這個值可以使用之外，也是有其他的返回值可以使用的，而這些 Http Status Code 的返回值，我們是可以根據他們的 首位數字，去分成是五個大類：\n1xx : 資訊 2xx：成功 3xx：重新導向 4xx：前端請求錯誤 5xx：後端處理有問題 所以舉例來說的話，但凡是 2 開頭的 Http Status Code，不管你是 200、201、還是 202…等等，只要你是 2 開頭，那就是屬於「2xx」那一個大類，就都是表示「成功」的意思。\n又或是說 400、401、403…等等的這些值，因為他們都是 4 開頭，所以他們就都是屬於「4xx」那一個大類，所以就都是表示「前端請求錯誤」的意思。\n所以透過這個 Http Status Code，我們就可以快速的知道，這一次 API 的請求結果為何了！\n常見的 Http Status Code # 在我們了解了 Http Status Code 的用途之後，接下來我們就可以來看一下，常見的 Http Status Code 有哪些（以下分別介紹各大類常使用的值）。\n1xx：資訊 # 很神奇的是，明明 Http Status Code 有定義 1xx 這個分類出來，但是在實際的應用中，基本上很少很少會用到 1xx 的返回值，因此在這個大類裡面，沒有常見的 Http Status Code。\n2xx：成功 # 在 2xx 開頭的大類中，所有的 Http Status Code，就都是表示 「請求成功」 的意思。而在 2xx 的大類裡面，常見的 Http Status Code，就有 200、201、以及 202。\n200 OK # 首先是「200 OK」，200 這個 Http Status Code，這個估計是大家最最最熟悉的值XD，就是表示這一次的 API 請求成功了的意思。\n不過大家觀察一下的話，就可以發現，在 200 的後面，多了一個「OK」的英文單詞，而這個「OK」的英文單詞，其實就是每一個 Http Status Code 的專屬短語，就是簡單描述一下當前這個 Http Status Code 的用途是什麼。\n所以像是「200 OK」裡面的這個「OK」，就是表示 200 這個 Http Status Code，他的意義是代表請求成功的意思。\n不過老實說，這個短語其實幫助不大😂（我個人感覺啦），每次遇到不熟悉的 Http Status Code 時，還是得要乖乖的上網查詢他的用途，而那些常見的 Http Status Code（ex: 401、403、500），又已經熟悉到像呼吸一樣自然，不需要看短語就也可以直接回想起他的意思，所以這個短語的用途，大家就作為參考就好～\n201 Created # 在 2xx 的大類中，另一個常見的 Http Status Code 則是「201 Created」，201 所代表的，不僅僅是請求成功而已，他還有另一個含義，就是「有一個新的資源被成功創建出來了」。\n所以當 API 返回 201 的時候，就是表示這一次的請求成功、並且也有成功的去創建一筆數據出來，而也因為在 REST 風格中，POST 方法通常就是拿來表示對應到資料庫的 Create 操作，因此「201 Created」這個 Http Status Code，通常就是會用在 POST 方法的 API 返回值上（就是用來表示有一個數據被創建出來了）。\n補充：不熟悉 RESTful API 的話，可以參考這篇 RESTful API 設計指南 文章的介紹\n202 Accepted # 而在 2xx 的大類中，「202 Accepted」所代表的，是「這一次的請求已經被接受，但是尚未處理完成」這樣。\n所以當前端收到 202 的返回值時，前端就可以知道，後端已經有收到這一次的請求了，但是因為這個任務實在要做太久，所以後端就先返回 202 的 Http Status Code 給前端，用來表示「我已經開始做了！」的意思，所以當前端收到 202 之後，前端就可以先去處理其他的事情，而不用被這個 API 給 blocked 住這樣。\n3xx : 重新導向 # 看完了 2xx 的大類之後，接下來我們接著來看 3xx 的大類。\n在 3xx 開頭的大類中，所有的 Http Status Code，就都是表示 「重新導向」 的意思。而在 3xx 的大類中，常見的 Http Status Code，有 301 和 302。\n301 Moved Permanently # 所謂的「301 Moved Permanently」，就是表示這個 url 「永久的」 搬家了，注意這裡的關鍵字是「永久的」。\n所以假設當前端去請求某個 API，但是該 API 返回 301 時，那這時候就是表示，前端所請求的這個 API 的 url，他已經永久搬家了，而至於這個 API 搬去哪裡呢？通常就是會放在 Response header 的 Location，告訴前端說「我搬去了哪裡」。\n所以前端就可以再去請求 Response Header 中的這個新的 url，進而就可以真正的取得到新的 API 所返回的數據了。\n舉例來說的話，像是我之前在架設個人網站時，就有從 https://kucw.github.io，搬家到 https://kucw.io，所以現在如果請求舊的 https://kucw.github.io 的網站的話，就會返回 301 的 Http Status Code，告訴前端這個網站已經永久性的搬家了，並且會將新家的網址（也就是 https://kucw.io），放在 Response header 中的 Location 的裡面。\n302 Found # 如果說 301 是表示「永久的」搬家的話，那麼「302 Found」所表示的，就是 url「暫時性」的搬家。\n所以假設某個 API，他只是「暫時性」的搬家的話（ex: 這個 API 目前可能正在調整功能中），那麼就可以回傳 302 的值給前端，就是去告訴前端，你這一次先去請求這個臨時的 url 這樣。\n所以 302 和 301 一樣，就都是會將新的 url，放在 Response header 的 Location 裡面，告訴前端「我搬去了哪裡」，就讓前端可以再去 call Location 中所提供的網址，找到確切的新 url。\n不過老實說，對於後端工程師而言，通常是感覺不太到 301 和 302","date":"2024-08-20","objectID":"ee57f8d7c8ccc8bc453faec92a2fca6a","title":"一文搞懂 Http Status Code，詳細解析 200、301、401、403、500、503","url":"https://kucw.io/blog/http-status-code/"},{"categories":["其他技術分享"],"content":"RESTful API 可以說是在後端日常的開發中，很常見的一種設計 API 的方式，因此這篇文章我們就來介紹一下，到底要如何才能設計出一個正確的 RESTful API 吧！\n目錄 什麼是 RESTful API？ 如何設計出 RESTful API？ 1. 成為 RESTful API 的條件一：使用 Http method，表示要執行的資料庫操作 2. 成為 RESTful API 的條件二：使用 url 路徑，描述資源之間的階層關係 3. 成為 RESTful API 的條件三：Response body 返回 JSON 或是 Xml 格式 設計 RESTful API 的總結 補充：我們真的需要 RESTful API 嗎？ 結語 什麼是 RESTful API？ # 所謂的 RESTful API，他是一種設計 API 的風格，而他的目的，就是為了 「簡化工程師之間的溝通成本」。\n所以 RESTful API，他的目的其實非常單純，就只是為了簡化工程師之間的溝通成本，才提出了一系列的方法，去統一不同工程師所設計出來 API 的風格。\n不過在這邊要先強調一下，RESTful API 他只是一種設計風格而已，並不是強制的規定，所以如果你在設計上，完全不遵守 RESTful API 的建議，也是完全沒問題的！\n只不過因為 RESTful API 的設計風格，他非常的通用，所以有非常多工程師，都很喜歡使用 RESTful API 的設計方式，因此了解 RESTful API 的設計理念，還是會非常吃香的～\nOK 那所以，我們就來看一下，到底什麼是 RESTful API。\n那如果我們把「RESTful API」這兩個單字給拆解一下的話，就可以將他們拆解成是「RESTful」和「API」。\n那後面的 API 的部分就比較簡單，基本上就是設計出一個 url，然後讓前端可以去 call 這個 url，去和後端請求數據這樣，那不過前面的 RESTful，他就大有來頭了！\n其實 RESTful，他是一個形容詞，意思是「符合 REST 風格的」，所以 RESTful API 合在一起看的話，就是指「設計出一套符合 REST 風格的 API」。\n那 RESTful 在這裡，他其實是用到了英文的文法邏輯，在英文的文法中，如果想要把一個「名詞」，變成是「形容詞」的話，那就只要在後面加一個 ful 就好。\n所以像是在英文裡面：\nbeauty 是名詞（意思是漂亮），beautiful 是形容詞（意思是漂亮的） peace 是名詞（意思是和平），peaceful 是形容詞（意思是和平的） 所以同樣的道理，REST 是名詞，表示「REST 設計風格」，而 RESTful 是形容詞，就是表示「符合 REST 設計風格的」。\n所以當我們在說 RESTful API 的時候，我們實際上所表示的，就是指「你的 API 設計的很符合 REST 的風格」，或是更白話一點，就是表示「欸～你的 API 很 REST 哦😏」，所以這個 RESTful，他本質上是一個形容詞，用途就是用來形容目前這個 API，是不是符合 REST 這個設計風格。\n那所以當大家看到某個 API 很符合 REST 的設計風格時，就可以稱呼這個 API，他是一個 RESTful API，那就表示他是一個「很符合 REST 風格的 API」了！\n如何設計出 RESTful API？ # 當大家了解了 RESTful API 的概念之後，接下來我們就可以來探討一下，什麼是「REST 設計風格」，而我們又要如何將我們的 API，去設計成「符合 REST 風格」的 API 了。\n如果我們想要設計出一個「符合 REST 設計風格」的 API，也就是設計出一個 RESTful API 的話，那這個 API，就必須要滿足 3 個條件。\n1. 成為 RESTful API 的條件一：使用 Http method，表示要執行的資料庫操作 # 如果想要設計出 RESTful API 的話，那麼這個 API，他就必須要使用 Http method，去表示這個 API 的行為動作。\n舉例來說的話，目前在 Http 的世界中，就有非常多的 Http method 可以選擇，像是大家如果有安裝 Postman、或是 Chrome 的擴充功能 - Talend API Tester 這類的 api 請求工具的話，那麼在請求的時候，就有非常多種的 Http method 可以選擇（如下圖所示）。\n而要怎麼樣在設計 API 的時候，去選擇合適的 Http method，這個就非常的重要了！\n如果我們想要去設計出 RESTful API（也就是設計出符合 REST 風格的 API）的話，那麼這個 API，他就必須要 「使用 Http method，去對應到資料庫的 CRUD 操作」。\n這邊我們先題外話補充一下「資料庫中的 CRUD 操作」的概念，在資料庫中，CRUD 就是描述了資料庫中的四個基本操作，也就是：\nCreate（新增） Read（查詢） Update（修改） Delete（刪除） 也因為這四個操作，他們可以說是資料庫中最基本的數據操作，因此他們也常常合稱為「CRUD」，即是「增查改刪」（或是也有人稱「增刪改查」）。\n而在我們了解了資料庫中的 CRUD 的概念之後，如果我們想要去設計出 RESTful API 的話，那我們在設計 API 的時候，就必須要去 「使用 Http method，去對應到資料庫的 CRUD 操作」。\n在 RESTful API 的定義中，假設這個 API 想要執行的，是 Create（新增數據）的操作的話，那麼 REST 風格就會建議，要在 Http method 中使用 POST 方法來請求；而如果這個 API 想要執行的，是 Delete（刪除數據）的操作，那麼 REST 風格就會建議，在 Http method 中要使用 DELETE 方法來請求。\n所以在設計一個 RESTful API 時，基本上我們就是會去依據這個 API 想要執行的操作，去設計成要使用哪一個 Http method 來請求。\n所以簡單的說的話，如果大家都使用 REST 的風格來設計 API 時，那麼以後當我們看到某個 API 是使用 GET 方法來請求時，那我們就可以快速的知道，這個 API 是要去執行 Read（讀取數據）的操作；而假設這個 API 是使用 POST 方法來請求時，那我們也可以快速的知道，這個 API 是要去執行 Create（新增數據）的操作。\n所以假設我們想要設計出 RESTful API 的話，那麼第一個必要條件，就是 「使用 Http method，去對應到資料庫的 CRUD 操作」。\n2. 成為 RESTful API 的條件二：使用 url 路徑，描述資源之間的階層關係 # 而至於成為 RESTful API 的第二個條件，則是 「使用 url 路徑，描述資源之間的階層關係」，那這個聽起來可能有點抽象，所以我們就直接透過一個例子，來了解一下這個概念是什麼。\n假設現在我們有一個使用 GET 方法來請求的 API，即是 GET /users，那麼當我們第一眼看到這個 API 時，因為這個 API 是使用 GET 方法來請求，所以我們可以知道他是要去執行 Read（讀取數據）的操作，所以這個 GET /users 的含義，就是「取得所有 user 的數據」。\n那麼假設現在，我們又有一個使用 GET 方法去請求的 API，即是 GET /users/123，那麼這個 GET /users/123 的含義，就是「取得 user id 為 123 ","date":"2024-08-13","objectID":"52d8dbf5dc05a514a4da30669c51ff05","title":"RESTful API 設計指南，3 個必備條件缺一不可！","url":"https://kucw.io/blog/restful-api/"},{"categories":["自媒體經營"],"content":" 記錄經營《古古的後端筆記》個人品牌的重大事件\n最後更新時間：2025.7.7\n2025 年 # 2025.7.7：暫時休刊（因為新工作原因，無法兼顧兩者，因而暫時休息，詳情查看 2025.5～6 月報） 2024 年 # 2024.12.10：Threads 經營 4 個月破 5000 人追蹤（2024.8.27～2024.12.10） 2024.11.12：出版人生中的第一本書，Spring Boot 零基礎入門：從零到專案開發，古古帶你輕鬆上手（iThome鐵人賽系列書） 詳細記錄：2024.11 月自媒體活動：我出書了！！ 2024.8.6：夢開始的地方，《古古的後端筆記》個人品牌誕生，發送第一封電子報創刊號 ","date":"2024-08-10","objectID":"292478d572aba809ff5d18ba7620b2af","title":"軟體工程師的自媒體之路 - 創業大事記","url":"https://kucw.io/blog/as-a-content-creator/milestone/"},{"categories":["其他技術分享"],"content":"哈囉，我是古古！最近又到了 iThome 鐵人賽的開賽期（每年 9 月附近），在 2023 年時我也有報名參加過 iThome 鐵人賽，題目是《Spring Boot 零基礎入門》，當時有幸得到了《優選》的獎項（得獎名單），因此希望可以透過這篇文章，分享一些寫作心法給大家。\n不過要先在此申明一下，我不是什麼技術大神，並且也不是得到最高級別的《冠軍》的獎項，所以以下的分享，就單純只是我個人的參賽心得而已，不具有 iThome 鐵人賽任何的官方效力唷！\n目錄 iThome 鐵人賽官方得獎評判標準 道理我都懂，但是要如何選題？ 題目挑好了，然後呢？ 題目挑好了、大綱也寫好了，再來呢？ 文章段落 文章的易讀性 上面我都照做了，但是還是沒得獎怎麼辦… 結語 iThome 鐵人賽官方得獎評判標準 # 但凡是參加 iThome 鐵人賽的參賽者們，可能或多或少目的都是為了得獎去的，因為得獎可以出書啊哈哈哈哈！！！我能理解出書真的是很誘人的一個因素（我自己其實也是為了出書來的😆），所以假設我們今天參賽是以「得獎」為目標的話，那麼搞懂 iThome 官方的得獎判斷標準就很重要。\n以下內容擷取自 2024 年 iThome 鐵人賽的官方活動簡章：\n陸、 主題競賽評審要點： - 主題：主題規劃符合該組別的立意，並能充份切合所選參賽主題下，參賽者所訂定之議題 - 結構：30 篇文章組織良好、其所規劃結構足以引導讀者理解參賽者訂定之議題 - 內容：文章內容的技術或經驗具備專業性、豐富性、深入性 - 表達：透過適當文字、圖片、程式碼或影片等方式，讓人更容易理解 透過這份官方活動辦法也可以看到，想要得獎的話，必須要有 「組織良好」 的文章，並且該文章的內容，需要具備 「專業性」、「豐富性」、「深入性」，而且需要在文章中添加 「圖片」 或是 「程式碼」 的輔助，使人更容易理解。\n所以這個簡單的說的話，就是除了你的主題要寫的夠深、夠豐富之外，也需要寫出一個結構良好，並且有圖、有程式碼的文章。\n所以只要抓好這幾個重點的話，就能盡量提升得獎的機率，最終拿到出書的資格了！\n道理我都懂，但是要如何選題？ # 當我們了解了 iThome 鐵人賽官方的得獎標準之後，再來就可以進到選題的部分了！\n不得不說，選題的好壞真的影響很大，因為得獎的標準之一是 「專業性」 和 「深入性」，所以如果你今天挑的題目是「XXX 入門」的話，那麼在「深入性」上就會比較吃虧（因為你沒辦法真的寫得很深入）。\n舉例來說，我當時參賽的題目是《Spring Boot 零基礎入門》，因為我的定調是「入門」文章，所以其實這個選題，就注定了我在「深入性」這一點上，沒辦法寫的太詳盡。\n如果拿 2023 那一年「Software Development 區」的冠軍名單出來看的話：\n《為你自己學 Ru\u0026hellip;..st》— 高見龍 《圖解C++影像處理與OpenCV應用：從基礎到高階，深入學習超硬核技術！》— VincentYeh 就可以發現，得到冠軍的這兩位大大，他們寫的內容真的都是很有深度的內容，更別說其中一位參賽者，還是很有名的高見龍老師，所以這個廝殺真的是只有激烈可言😂。\n所以假設你想要得獎，那麼寫一個超級深入的硬派文章，確實可能會提升得獎的機率。不過老實說，我其實不是很建議大家一定要挑超級艱深的題目寫，因為這樣你只是為了寫而寫而已，就算這樣的文章得獎了，裡面也沒有靈魂的啊！！！\n所以會比較建議大家，你所寫的文章，盡量還是和你自己課業上所學、工作上有接觸的部分會比較好，因為自己熟悉的題目才是最好發揮的，而且就算挑的題目是「XXX 入門」的題目，只要掌握好文章結構的話，仍舊是能拿到《優選》或是《佳作》的獎項的（而且其實這兩個獎項也都可以出書的！）。\n所以就建議大家，不用太糾結《冠軍》這兩個字，建議還是挑你平常接觸最多、你最熟悉的那個主題來寫，這樣子寫起來才會快樂，得獎的時候成就感才會爆棚啊XDD（媽！這我寫的！）。\n題目挑好了，然後呢？ # 題目挑好之後，就可以「Welcome to 寫作地獄」了🤗。（我是指，Welcome to 快樂的寫作人生了）\n好啦說正經的，其實邊挑題目的時候，大家就可以開始思考：「我這篇文章是要寫給哪類人群看的？」，這個問題非常的重要，重要到會影響你整體的文章編排架構，所以一開始多花一點時間練習思考這個問題，是非常有意義的。\n舉例來說，像是我之前參賽的《Spring Boot 零基礎入門》主題，因為我的定調是入門文章：\n所以我預設的讀者人群，就是「完全沒有碰過（甚至沒聽過） Spring Boot」的人 而我希望這些人在看完我的文章之後，就「能夠使用 Spring Boot，實作出一個簡易的後端系統」 所以其實我在開始動筆寫第一篇文章之前，我就已經先決定了這 30 篇文章的走向，而我的目標，就是讓完全沒用過 Spring Boot 的人，在看完這 30 篇文章之後，就能夠去實作出一個簡易的後端系統這樣。\n所以圍繞著這個目標，我就可以開始思考，我要如何去介紹 Spring Boot 的基本用法、要如何去示範這些程式給大家看，然後就可以慢慢把 30 天的大綱給生出來了。\n所以總結來說的話，在我真的開始動筆寫第一篇文章之前，我其實就已經把這 30 篇文章的大綱都列好了。所以我會先列出說，我大概要講哪幾個部分、並且每個部分大概要佔幾篇文章的內容，所以就會像是下面這個樣子，就是先列出哪幾天要介紹哪些主題這樣：\nDay 1～4：Spring Boot 簡介、開發環境安裝 Day 5～12：Spring 框架的特性 - IoC 和 AOP Day 13～23：Spring MVC 介紹 Day 24～28：Spring JDBC 介紹 Day 29：實戰演練：打造簡易的圖書館系統 Day 30：Spring Boot 零基礎入門總結 如果要我說的話，「文章編排」這件事，可以說是整個 iThome 鐵人賽最難的地方，因為在這個環節中，你必須要去思考：「你想要介紹哪些內容？」、「你想要怎麼編排這些內容？」，而這個過程，等於是你要去逼自己，要想盡辦法的把你心目中零碎的知識片段，組織成一個完善的 30 篇文章架構。\n老實說這件事真的是最難的，所以一開始大家如果覺得很難排的話，是非常正常的，你在這個階段可能會覺得腦袋中東西很多、很混亂，不知道怎麼下手將他們呈現，有這些情況都是很正常的。\n所以我會建議大家，如果你真的覺得很混亂、不知道該怎麼下手，那你可以先跳過「文章編排」這一關，直接就動筆開始寫吧！等到你寫了一次、兩次，更有經驗之後，下一次參賽時，可以再回頭來挑戰「文章編排」這個大魔王。\n而等你真的克服這個大魔王之後，你就會發現自己的寫作技巧好像昇華了！以後不管是寫技術文件、或是寫其他的教學文章，都會寫得比以前還要順手，說不定等到那一天，就會換你在網路上分享寫作心法給其他參賽者了～（期待那一天的到來！）。\n題目挑好了、大綱也寫好了，再來呢？ # 當大家克服最難的大魔王「文章編排」之後，再來就是努力的寫稿子寫稿子\u0026hellip;loop，然後配上超級堅持不懈的精神，最終就可以順利完賽了！！\n不過其實寫稿子這件事，也是有一些心法可以分享給大家的，那就是要掌握好「文章的段落」，以及「文章的易讀性」。\n文章段落 # 以「文章段落」來說，其實當大家在閱讀這篇文章時，如果仔細觀察一下的話，就會發現我會使用 「H2（二級標題）」，為每個段落進行分段。\n所以像是在這篇文章中，一開始的段落標題就是「iThome 鐵人賽官方得獎評判標準」，這一段我們談的就是 iThome 的官方得獎標準；而像是目前這一段的標題就是「題目挑好了、大綱也寫好了，再來呢？」，談的就是文章寫作的內容","date":"2024-08-08","objectID":"ec2a594722d7de8181108e39fca0f7a4","title":"iThome 鐵人賽 - 得《優選》獎項的寫作心法","url":"https://kucw.io/blog/ithome-sharing/"},{"categories":["自媒體經營"],"content":"哈囉，我是古古，我的本業是軟體工程師，但是卻誤打誤撞走進了自媒體這條路。\n這個專欄裡面記錄了我作為一個軟體工程師，是如何踏入自媒體這條路，並且也記錄了我是如何在接觸了許多創作者之後，下定決心要認真嚴肅的看待自媒體這份事業。\n這份專欄不只是寫給我自己，也想寫給對自媒體有興趣的你，不管你的職業和身份是什麼，都希望這份專欄可以為你帶來一點幫助。\n現在時間是 2024.8.6，我在這裡寫下我的第一篇電子報《古古的後端筆記》的創刊號，作為我認真開始經營自媒體的起點，後續也會持續更新這份專欄，如果有興趣的話，也歡迎訂閱電子報：https://kucw.io/bio。\n踏入自媒體的起因 # 那！雖然有點突然，不過我還是先來個自我介紹吧XD\n我是古君葳，大家也可以叫我古古，我大學和研究所念的都是資工系（陽明交大資工系、台大資工所），然後在唸研究所的時候，我有申請去北京大學交換過半學期，所以也就剛好，在畢業之後，就在北京找過一份 Java 後端工程師的工作，這份工作大概是做了一年左右。\n然後在 2019 年初，大概是在 3 月附近，我因為家裡的事情，就決定回到台灣發展這樣，所以後續我就是加入 Garmin，負責開發 Java 後端程式，然後，就意外的開啟了這條自媒體之路了。\n所以如果回顧一下我的求學經歷、以及工作經歷的話，就也可以發現，在求學和工作的過程中，我真的是完全跟自媒體沾不上邊，就是一個照著社會安排的資工系學生的路線，穩穩地去做工程師的工作這樣。\n不過，我現在之所以能夠坐在這裡，寫著這個《古古的後端筆記》的創刊號，其中一個很大的轉折點，就是當時的我，接觸到了「線上課程」這件事。\n我當時在北京工作的時候，我身邊的同事、朋友，每一個人，真的不誇張，真的是每一個人，都是在談「你學了什麼課？」、或是「你最近買了什麼課？」，當然我的經驗不能代表所有人的經驗，不過這對於當時的我而言，完全就是文化衝擊XDD，就…沒想過在這個世界上，還有「線上課程」這麼好用的東西可以學習。\n比起實體課，不得不說我自己是更愛上線上課程，因為線上課程有字幕！！有動畫！！而且老師講廢話的時候還可以跳過（大家不要學🤣）！！還可以開 2 倍速看！！！完全就是超級高效率的學習方式！！！\n也就是因為當時在北京工作的時光中，我接觸到了不一樣的觀點和想法，所以也就間接導致我後續回台灣之後，會因緣際會投入到線上課程的教學。\n回台灣的發展期 # 所以在 2019 年回到台灣之後，我就進了 Garmin，就開始了 Java 後端工程師的工作了。\n不過在工作之餘，我就一個手癢，想說要不買點課來學吧XDD，但我一查了之後就發現，台灣怎麼好像….想要買課還買不到？可能是當時台灣的技術課程比較少人錄、也有可能是 Udemy 上面的英語課程就很實用了，反正就是當時在台灣的線上課程領域中，其實沒有多少選項可以選擇。\n那所以這時候我就想啦！如果我試著幫大家整理一下，把我所了解到的 Spring Boot 知識，都把他整理起來，然後錄製成課程，這樣子大家就有一個中文的課程可以考慮了嘛！所以大家就不用再去聽 Udemy 上面的印度老師的口音，然後很克難的，自己一個一個的去查這個英文單字的翻譯是什麼了（說的就是我🥹，有時候上課我都不知道是在學技術還是學英文\u0026hellip;）\n所以那時候我的想法很單純，就是想要結合我自己的工作經驗，幫大家整理出一個講中文、然後又是台灣用語的 Spring Boot 課程，就讓大家可以不用學的那麼克難這樣～\n但，事情的轉折點，就是這個「線上課程」！\n就是因為我錄製了線上課程，所以我開始有機會，去接觸到其他的創作者，去了解到他們是如何去進行創作的。然後我也慢慢的去了解到，原來身為一個創作者，除了要去創作你的原創內容之外（像是錄製線上課程），同時，你也必須要去經營你的粉絲、維護你的社群、打造你的影響力、進而讓你的個人品牌變得越來越茁壯。\n所以其實對於「自媒體」這條路而言，他並不只是「錄製線上課程」這麼單純而已，他要投入的，是更多角化的經營、是更嚴肅的態度，是要把這條自媒體的賽道，當成是一個事業來經營。\n所以在我了解到這個事實之後，我就開始思考，作為一個不小心踏進線上課程領域的工程師，我當初完全就是運氣好，所以才能夠走到這裡（再次感謝各位同學的支持🙏），但是，老天把我帶到了這裡，接下來我到底要不要認真嚴肅的，去看待這份自媒體的事業，就是我必須做出的決定了。\n那當然啦～我的決定就是「Yes！」，不然應該就沒有這個專欄文章了XDD，也因為我的決定是 Yes，所以接下來，我想要認真的，去經營自媒體這條路，我想試試看，到底可以將《古古的後端筆記》這個個人品牌，去成長到什麼樣的地步。\n所以接下來，就歡迎大家跟我一起，收看這個大型的真人秀吧！\n歡迎收看大型真人秀：軟體工程師的自媒體之路 # 打字打到這裡，我們終於可以來介紹《古古的後端筆記》的電子報了！\n簡單的說的話，這份電子報，就是我嘗試經營自媒體的第一步！不知道大家有沒有聽過國外一個很紅的後端技術分享的作者，就是 ByteByteGo，我之所以第一步會想要經營電子報，也是受到 ByteByteGo 影響，就覺得每週可以學習一點後端知識也很讚這樣！\n那既然我們都創刊了，夢想還是要有的，所以我就先來畫個餅，就希望可以把這份《古古的後端筆記》的電子報，做成是台灣的 ByteByteGo！\n不過當然我自己也知道，我本身的後端技術能力還不到頂尖，所以目前我離 ByteByteGo，仍舊是有一大段距離需要努力，但是，就希望可以透過這份電子報，每週輸出後端知識給大家，然後也藉著這份動力，能夠讓自己的後端技術可以更精進這樣。\n所以大家的訂閱，對我而言是一份責任、也是一份動力，所以大家如果後續對於電子報中的任何主題，有任何的想法的話，都歡迎直接回信給我，每一封我都會看的！電子報的優勢就是這樣，只要你回信，我就一定能收到，而且信件內容也不會公開，所以如果大家有什麼想對我說的話，都很歡迎大家回覆～\n結語 # 好啦！大概是這樣，總而言之這個大型的真人秀：軟體工程師的自媒體之路，仍舊會持續下去，我有打算把這個系列變成是一個專欄，就是會定期的跟各位老闆們回報一下，我目前的經營進度這樣XDD。最近不也挺流行 Build in Public 的創業模式嗎？那我就剛好也來把這份自媒體的創業之路，一起分享給大家～\n最後，我是古君葳（古古），是一個軟體工程師、同時也是一個自媒體的創業者，感謝大家的訂閱！就讓我們一起見證下去吧！\n如果你對後端筆記有興趣，也歡迎免費訂閱《古古的後端筆記》電子報，每週二為你送上一篇後端技術分享，一起變強💪\n","date":"2024-08-06","objectID":"ab09bb72d5b85a690065100ce1b0f361","title":"軟體工程師的自媒體之路 - 電子報創刊號","url":"https://kucw.io/blog/as-a-content-creator/1/"},{"categories":["Spring Boot"],"content":"哈囉大家好，我是古古。\n終於來到本系列文的最後一個文章啦！能看到這裡的你真的非常厲害！！這篇文章會總結一下，我們在這 30 篇文章中都介紹了哪些部分，最後也會補充一些有關 Spring Boot 的學習路徑，所以我們就開始吧！\n目錄 所以，我們到底學到了哪些東西？ Spring IoC Spring AOP Spring MVC Spring JDBC 實戰演練 Spring Boot 的學習路徑 深度：深入了解 Spring Boot 廣度：Spring 全家桶、軟體工程師的通用知識 關注我，學習更多後端知識 總結 所以，我們到底學到了哪些東西？ # 在最一開始，大家可能還不太熟悉 Spring Boot（甚至沒聽過 Spring Boot），不過經過了這 30 篇文章的介紹之後，大家基本上可以掌握：\nSpring IoC # 了解 IoC、DI、Bean 的概念 能夠在 Spring Boot 中創建一個 Bean、注入一個 Bean、初始化一個 Bean 能夠讀取 application.properties 中的設定值到 Bean 裡面 Spring AOP # 了解 AOP 中切面的概念 能夠在 Spring Boot 中運用 AOP 的用法 Spring MVC # 了解 Http request 和 response 中各項欄位的意義、JSON 格式的寫法 能夠在 Spring Boot 中運用四種註解，接住前端傳遞過來的參數 能夠在 Spring Boot 中設計和實作出 RESTful API Spring JDBC # 能夠在 Spring Boot 中執行 INSERT、UPDATE、DELETE、SELECT 的 SQL 語法，存取資料庫中的數據 了解 MVC 架構模式的概念 能夠在 Spring Boot 中套用 Controller-Service-Dao 三層式架構 實戰演練 # 能夠使用 Spring Boot，架設出一個簡單的圖書館管理系統（包含 CRUD 四大功能） 能夠熟練運用 IntelliJ 軟體開發 Spring Boot 程式 所以透過這 30 篇文章的介紹和練習，大家目前就具備 Spring Boot 的基礎實作能力了！恭喜！！\nSpring Boot 的學習路徑 # 而在看完此系列的 Spring Boot 零基礎入門文章，後續還想要進階學習 Spring Boot 的相關知識的話，建議可以分別朝「深度」和「廣度」來學習。\n深度：深入了解 Spring Boot # 以 Spring Boot 技術的深度來說，可以朝下列幾個方向下手：\nSpring MVC 的進階用法 # 驗證請求參數的方式：@Valid、@NotNull\u0026hellip;等用法 Controller 層的異常處理：@ControllerAdvice + @ExceptionHandler 攔截器（Interceptor）的用法 Spring JDBC 的進階用法 # @Transactional 交易管理 Spring Boot 單元測試 # JUnit、MockMvc、Mockito\u0026hellip;等用法 H2 資料庫的用法 測試驅動開發 TDD 的理念 套件管理工具 # Maven 或是 Gradle 廣度：Spring 全家桶、軟體工程師的通用知識 # Spring 全家桶 # 在了解了上述較進階的 Spring Boot 用法之後，接下來也可以學習 Spring 全家桶中的其他功能，增加知識的廣度，像是：\nSpring Security：資訊安全的驗證 Spring Cloud：微服務整合 軟體工程師的通用知識 # 或者也可以學習軟體工程師的通用知識，像是：\nGit RabbitMQ 或是 Kafka Elasticsearch \u0026hellip;等等 總之技術是沒有學完的一天的！只要隨時保持精進自己的步伐，不斷的累積實力，就能越變越強的💪。\n關注我，學習更多後端知識 # 如果你看完此系列文之後仍意猶未盡，也可以參考我開設的 Spring Boot 線上課程，裡面有針對 Spring Boot 做更完整的介紹，以及一個全新的實戰演練（實作簡易的電商網站），歡迎參考課程簡介 （輸入折扣碼「HH202601KU」即可享 85 折優惠）。\n又或是可以訂閱我經營的《古古的後端筆記》電子報，在這份電子報中就不僅僅是 Spring Boot 的介紹，而是會延伸出去分享更多後端工程師必備的知識，如系統設計、JWT 的用法\u0026hellip;等等，希望能夠在後端這條路上和大家一起學習成長！\n總結 # 寫在此系列文的最後，最後我要吶喊：「我終於寫完稿子，成功出書啦！！！好感動🥹！！！」能夠堅持到這一天真的是各種千辛萬苦，很感謝所有支持我創作的每一位粉絲、朋友，以及感謝你能耐心的閱讀到這裡。\n今後我仍舊會繼續精進後端知識，並且努力分享給大家的💪，那我們就在電子報《古古的後端筆記》中再見啦！\n","date":"2024-07-30","objectID":"c3530ce406f99e62a5eec16363ef5766","title":"Spring Boot 零基礎入門 (30) - Spring Boot 零基礎入門總結","url":"https://kucw.io/blog/springboot/30/"},{"categories":["Spring Boot"],"content":"哈囉大家好，我是古古。\n在前面的文章中，我們有介紹了 Spring Boot 中的許多用法，包含 Spring IoC、Spring AOP、Spring MVC（和前端溝通）、以及 Spring JDBC（和資料庫溝通），並且我們也介紹了 MVC 架構模式的概念，以及 Controller-Service-Dao 三層式架構的實作。\n所以接著的這篇文章，我們就會來做個實戰演練，總和前面所學習到的所有功能，練習實作一個圖書館的管理系統出來，所以我們就開始吧！\n補充：本文中所使用的完整程式碼會放在 GitHub 上 springboot-library，建議可以搭配觀看，學習效果更好。\n目錄 功能分析：圖書館管理系統 資料庫 table 設計 1. 實作「查詢某一本書」的功能 BookController（Controller 層）的實作 BookService（Service 層）的實作 BookDao（Dao 層）的實作 API Tester 實際測試 補充：時間格式的設定 2. 實作「新增一本書」的功能 BookController（Controller 層）的實作 BookService（Service 層）的實作 BookDao（Dao 層）的實作 API Tester 實際測試 3. 實作「更新某一本書」的功能 BookController（Controller 層）的實作 BookService（Service 層）的實作 BookDao（Dao 層）的實作 API Tester 實際測試 4. 實作「刪除某一本書」的功 BookController（Controller 層）的實作 BookService（Service 層）的實作 BookDao（Dao 層）的實作 API Tester 實際測試 圖書館管理系統總結 總結 功能分析：圖書館管理系統 # 在我們開始動手寫程式去實作圖書館管理系統之前，首先可以先來分析一下，在這個圖書館的管理系統中，我們想要提供什麼樣的功能。\n像是圖書館管理系統顧名思義，就是用來管理「書」的，所以我們針對「書」這個資源，就可以去實作他的 CRUD 四大基本操作，也就是「新增一本書」、「查詢某一本書」、「更新某本書的資訊」、「刪除某一本書」。\n因此下面就會分別來介紹，要如何在 Spring Boot 中設計和實作出「書」的 CRUD 四個功能，完成一個簡易的圖書館管理系統。\n資料庫 table 設計 # 在設計資料庫 table 時，因為是針對「書本」這個資源來設計，因此我們可以設計一個 book table，去儲存書本的相關資訊。以下是創建 book table 的 SQL 語法：\nCREATE TABLE book ( book_id INT NOT NULL PRIMARY KEY AUTO_INCREMENT, title VARCHAR(128) NOT NULL, author VARCHAR(32) NOT NULL, image_url VARCHAR(256) NOT NULL, price INT NOT NULL, published_date TIMESTAMP NOT NULL, created_date TIMESTAMP NOT NULL, last_modified_date TIMESTAMP NOT NULL ); 其中各個欄位的含義如下：\nbook_id：表示 book 的唯一 id，由資料庫自動遞增\ntitle：表示此書的書名\nauthor：表示此書的作者\nimage_url：儲存此書的圖片連結\nprice：此書的販售價格\n補充：在實務上只要牽扯到「金錢」的部分，通常會用 BigDecimal 特別處理，不過由於此專案主要在練習 Spring Boot 的基礎結構和用法，因此此處使用 Integer 類型來簡化實作細節。\npublished_date：此書的上架時間\ncreated_date：創建這筆數據的時間\nlast_modified_date：最後修改這筆數據的時間\n而設計好資料庫 table 之後，就可以將這段 SQL 語法貼到 IntelliJ 中的 console 上，在 IntelliJ 中執行這個 SQL 語法，就可以在 myjdbc database 中創建 book table 出來。\n1. 實作「查詢某一本書」的功能 # 創建好 book table 之後，接下來我們就可以開始來實作 Spring Boot 程式了！\n通常在實作基礎的 CRUD 功能時，建議可以先從「查詢功能」開始實作，因此我們就先從「查詢一本書」這個功能開始實作。\nBookController（Controller 層）的實作 # 首先我們可以先在 BookController 中，添加如下的程式：\n@GetMapping(\u0026#34;/books/{bookId}\u0026#34;) public ResponseEntity\u0026lt;Book\u0026gt; getBook(@PathVariable Integer bookId) { Book book = bookService.getBookById(bookId); if (book != null) { return ResponseEntity.status(HttpStatus.OK).body(book); } else { return ResponseEntity.status(HttpStatus.NOT_FOUND).build(); } } 補充：由於程式的篇幅過長，因此本文中只會擷取部分重點來介紹，完整的程式碼可以前往 GitHub springboot-library 查看。\n在 BookController 中，因為他是屬於 Controller 層，所以他會使用 @GetMapping，去接住前端放在 url 路徑中的 bookId 的參數。\n而在接到 bookId 的值之後，BookController 就會直接往後傳給 BookService 去做後續處理，即是將商業邏輯寫在 Service 層，讓 Controller 層保持「和前端溝通」的部分。\n而當 BookService 返回查詢到的 book 數據之後，BookController 就可以根據「是否有查詢到數據與否」，去決定要返回給前端的 Http status code 為何。\n像是在下面的程式中，if 區塊就呈現出「當 book 不為 null 時，就返回 200 OK 的 Http status code 給前端，並且把 book 數據放在 response body 中」的資訊。而在 else 區塊中，則是呈現「當 book 為 null 時，就返回 404 Not Found 的 Http status code 給前端」。\nif (book != null) { return ResponseEntity.status(HttpStatus.OK).body(book); } else { return ResponseEntity.status(HttpStatus.NOT_FOUND).build(); } 補充：如果不熟悉 Http status code 的話，可以回頭參考 Day 23 - Http Status Code（Http 狀態碼）介紹 的文章。\nBookService（Service 層）的實作 # 實作完 BookController 之後，接著我們往下實作 BookService。\n當 BookService 收到 Controller","date":"2024-07-29","objectID":"f227444e5177b9eaae91ec02e663308b","title":"Spring Boot 零基礎入門 (29) - 實戰演練 - 打造一個簡單的圖書館系統","url":"https://kucw.io/blog/springboot/29/"},{"categories":["Spring Boot"],"content":"哈囉大家好，我是古古。\n在上兩篇文章中，我們有介紹了 Spring JDBC 中的兩個核心用法 update() 和 query()，因此大家就可以透過這兩個方法，在 Spring Boot 中執行想要執行的 SQL 語法了。\n而在介紹完 Spring JDBC 的核心用法之後，接著這篇文章要介紹的，是軟體工程中一個很重要的概念，即是「MVC 架構模式」，所以我們就開始吧！\n目錄 什麼是軟體工程？ 什麼是 MVC 架構模式？ Model Controller View 小結 MVC 架構模式的優點 Controller-Service-Dao 三層式架構 Controller 層 Service 層 Dao 層 小結 實際使用 Controller-Service-Dao 三層式架構 在使用 Controller-Service-Dao 三層式架構之前\u0026hellip; 使用 Controller-Service-Dao 三層式架構之後！ Controller 層：StudentController Service 層：StudentService Dao 層：StudentDao 小結 使用 Controller-Service-Dao 三層式架構的注意事項 注意事項一：透過 Class 名字結尾，表示這是哪一層 注意事項二：將 Controller、Service、Dao，全部變成 Bean 注意事項三：不能在 Controller 中直接使用 Dao 注意事項四：Dao 層只能執行 SQL 語法，不能添加商業邏輯 小結 總結 什麼是軟體工程？ # 在介紹什麼是「MVC 架構模式」之前，我們可以先來看一下，「軟體工程」到底是個什麼樣的概念。\n所謂的軟體工程，即是「在面對一個大型的系統時，工程師們要如何分工合作，一起去解決問題？」，在這句話裡面有兩個重點，分別是「大型的系統」和「如何分工合作」。\n所以簡單的說的話，當你今天要寫的是一個超過一兩千行的程式，並且在你們的團隊中，是由好幾位工程師一起分工合作來開發，在這種情況下，就會開始需要去注重「軟體工程」了。\n補充：當然小型的系統也可以注重軟體工程，不過效益相對不會那麼大。另外也因為在實際的工作中，都是會由許多工程師共同合作、一起合力開發某個大型的功能的，因此掌握好軟體工程的概念可以說是非常重要！\n什麼是 MVC 架構模式？ # 大概了解了軟體工程的概念之後，我們可以接著來介紹「MVC 架構模式」的概念是什麼，在了解了MVC 架構模式的概念之後，我們會再來介紹，要如何在 Spring Boot 中去套用 MVC 架構模式的概念。\n所謂的「MVC 架構模式」，他是軟體工程中的一種軟體架構，而 MVC 架構模式的用途，就是將一個系統，去拆分成「Model、View、Controller」三個部分，並且讓每一個部分都各自負責不同的功能。\n因此在 MVC 架構模式中，各個部分的功能如下：\nModel # 在 MVC 架構模式中，Model 負責的是「實作商業邏輯，並且處理數據」。\n由於 Model 是負責商業邏輯的實作，所以我們都會將核心的商業邏輯，寫在 Model 這個部分裡面。\n也因為 Model 同時要負責處理數據，因此 Model 也會需要去跟資料庫做溝通，將這些數據的改動給儲存起來。\nController # 在 MVC 架構模式中，Controller 負責的是「轉發 Http request」。\n所以簡單來說，當 Controller 收到來自前端的 Http request 之後，Controller 就會負責將這些 reque轉發給 Model，讓 Model 去處理後續的操作。\nView # 在 MVC 架構模式中，View 負責的是「使用 Html 的模板去呈現數據」。\n不過因為近幾年提倡「前後端分離」的關係，所以版面設計就都會交給前端去處理，因此後端就不需要處理 Html 的版面部分了，只需要改成回傳 JSON 格式的數據給前端即可。\n也因為後端不需要處理 Html 的部分（會交由前端處理），因此 View 在現今的後端架構中，相對來說就沒有那麼重要了。\n小結 # 所以在這裡先簡單小結一下的話，MVC 架構模式是軟體工程中的一種架構，會將系統拆分成「Model、View、Controller」三個部分，並且讓每一個部分都各自負責不同的功能。\n不過雖然 MVC 架構模式會將程式拆分成三個部分，但是他實際上並不會去修改程式，MVC 架構模式只是將我們所寫的程式分類一下而已，可能你今天寫的這段程式是屬於 Model 部分、又或是你今天所寫的程式是屬於 Controller 部分，僅此而已，MVC 架構模式並不會添加什麼新功能到你的程式裡面。\n所以當大家以後看到 MVC 架構模式時，就不用太緊張，他只是試圖要將我們所寫的程式進行分類，這樣在開發大型的系統時，才能更好的進行管理和維護。\n補充：MVC 架構模式之所以被稱為是 MVC，原因就是取自於 Model-View-Controller 這三種分類的第一個字母的縮寫，所以才簡稱為 MVC 架構模式。\nMVC 架構模式的優點 # 當我們使用了 MVC 架構模式，將後端程式區分成 Model-View-Controller 這三個部分之後，可以得到以下幾個好處：\n職責分離，更容易維護程式 使程式結構更直覺，有利於團隊分工 可重複使用寫好的程式 也因為使用 MVC 架構模式的好處非常多，因此在現今的 Spring Boot 開發中，基本上統統都是按照這個模式來開發程式，因此了解 MVC 架構模式的概念可以說是非常重要！我們日常的開發基本上都會按照這個模式進行開發。\nController-Service-Dao 三層式架構 # 了解了 MVC 架構模式的運作方式和優點之後，接著我們就來介紹一下，要如何在 Spring Boot 中，中，去套用 MVC 架構模式的概念。\n補充：MVC 架構模式其實是一個比較抽象的概念，具體要怎麼實作，就會依照不同的框架，而有不同寫法。\n在 Spring Boot 中，會將「MVC的架構模式」轉化成是 「Controller-Service-Dao 的三層式架構」 來實作。 因此大家以後只要在 Spring Boot 中看到「Controller-Service-Dao」這種三層式架構時，就可以知道他是套用了 MVC 的架構模式在設計了！\n而在 Controller-Service-Dao 的三層式架構中，其實就是將一份 Spring Boot 專案，區分成 Controller、Service、以及 Dao 這三層來管理，讓每一層都去負責不同的功能。\n像是在下圖中就列出了 Controller、Service、Dao 這三層架構之間的關係，以及他們個別負責的功能：\nController 層 # 首先 Controller 層的用途，是負責去「接收前端傳過來的 Http request，並且去驗證請求參數」。\n所以像是我們在 Spring MVC 中所介紹的那些註解，如 @RequestMapping、@RequestParam\u0026hellip;等等，只要是和「前端」進行溝通的部分，就都會放在 Controller 層裡面。\nService 層 # 而當 Controller 層接收到前端傳過來的 Http request、並且對其進行驗證之後，這時候 Controller 就會去 call Service層，讓 Service 負責去接手後續的處理。\n而 Service 層的用途，主要是負責「商業邏輯的處理」，所以主要的核心商業邏輯，通常都會放在 Se","date":"2024-07-28","objectID":"97b05627e5b3cd8adaf0bf35374d5dff","title":"Spring Boot 零基礎入門 (28) - MVC 架構模式 - Controller-Service-Dao 三層式架構","url":"https://kucw.io/blog/springboot/28/"},{"categories":["Spring Boot"],"content":"哈囉大家好，我是古古。\n在上一篇文章中，我們有介紹了 Spring JDBC 中的 update() 的用法，了解要如何透過 update() 方法，去執行 INSERT、UPDATE、DELETE 這三種 SQL 語法。\n那麼這篇文昭，我們就會接著來介紹 Spring JDBC 中的另一個方法，也就是 query() 的用法，了解要如何透過 query() 方法去執行 SELECT SQL。\n目錄 query() 方法的用法 RowMapper 的用途 實作 RowMapper 使用 query() 方法查詢數據 實際測試 query() 方法的用法總結 總結 query() 方法的用法 # 在 Spring JDBC 中，query() 方法的用途是「執行 SELECT SQL 語法」，因此我們就可以使用 query() 方法，去查詢資料庫中的數據。\n而 query() 的用法其實和前一篇文章我們所介紹的 update() 方法非常相似，前兩個參數都和 update() 方法一樣，都是先放入「想要執行的 SQL 語法」，接著再放入「動態決定 SQL 變數的 map 參數」。\n因此在學習 query() 的用法之前，建議大家一定要先學會 update() 的用法，這樣子在學習 query() 方法時才會更好上手。\n不過 query() 方法特別的地方，就在於他的第三個參數 RowMapper，RowMapper 可以說是影響 query() 方法的核心參數，因此接下來我們就來介紹一下，RowMapper 的用途為何、以及要如何實作 RowMapper。\nRowMapper 的用途 # 在 query() 方法中的第三個參數 RowMapper，他的用途是「將資料庫查詢出來的數據，轉換成是 Java object（物件）」。\n舉例來說，我們可以創建一個新的 class，名字叫做 StudentRowMapper，並且讓這個 class 去 implements RowMapper interface（此處要注意 implements 的是 org.springframework.jdbc.core.RowMapper 底下的 RowMapper，要小心不要選到其他的 RowMapper）。\n讓 StudentRowMapper 去 implements RowMapper interface 之後，接著我們可以在這個 class 中點擊右鍵，然後選擇「Generate…」，並且選擇「Implement Methods」。\n然後選擇實作 mapRow() 這個方法，接著按下 OK 鍵。\n操作到這裡，我們其實就完成 RowMapper 的實作雛形了！因此接下來我們只要實作剛剛所生成的 mapRow() 方法，就可以將資料庫中查詢出來的數據，轉換成 Java 物件，最後再返回給前端了。\n實作 RowMapper # 在這個 RowMapper 的實作中，我們的目的是「將資料庫中所查詢出來的數據，轉換成是一個 Java 物件」，因此我們的目標，就是要提取出下面這條 SQL 語法中的 id 和 name 的欄位的值，並且將他轉換成 Student 物件中的 id 和 name 變數。\nSELECT id, name FROM student 所以在 StudentRowMapper 中，我們可以依照下面的方式來實作 mapRow() 方法，這樣子就可以將資料庫中查詢出來的 id 和 name 的欄位，轉換成是 Student 物件中的 id 和 name 變數的值了。\npublic class StudentRowMapper implements RowMapper\u0026lt;Student\u0026gt; { @Override public Student mapRow(ResultSet rs, int rowNum) throws SQLException { Student student = new Student(); student.setId(rs.getInt(\u0026#34;id\u0026#34;)); student.setName(rs.getString(\u0026#34;name\u0026#34;)); return student; } } 使用 query() 方法查詢數據 # 在實作完上述的 StudentRowMapper 之後，接著我們就可以回到 StudentController，並且就可以在 StudentController 裡，使用 query() 方法去執行 SELECT SQL，進而從資料庫中查詢數據出來了。\n所以我們可以在 StudentController 中，實作下列的程式：\n@RequestMapping(\u0026#34;/getStudents\u0026#34;) public List\u0026lt;Student\u0026gt; query() { String sql = \u0026#34;SELECT id, name FROM student\u0026#34;; Map\u0026lt;String, Object\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); StudentRowMapper rowMapper = new StudentRowMapper(); List\u0026lt;Student\u0026gt; list = namedParameterJdbcTemplate.query(sql, map, rowMapper); return list; } 當我們這樣子寫之後，到時候當前端來請求 /getStudents 這個 API 時，Spring Boot 程式就會去執行第 34～45 行的程式，而當 Spring Boot 執行到第 42 行程式時，就會使用 query() 方法去執行 \u0026quot;SELECT id, name FROM student\u0026quot; 的 SQL 語法，從資料庫中的 student table 中查詢數據出來，並且將查詢出來的 Student 數據，儲存在第 42 行的 List\u0026lt;Student\u0026gt; list 的變數中，最終再將這些數據返回給前端。\n因此透過這樣的實作，就可以達到「在 Spring Boot 中查詢資料庫中的數據」的效果了！\n實際測試 # 完成上述的程式之後，我們可以運行這個 Spring Boot 程式，來測試一下效果。\n成功運行 Spring Boot 程式之後，接著我們可以回到 API Tester 中，並且填上以下的請求參數：\n填寫完畢之後，就按下右側的 Send 鍵，去發起一個 Http 請求。\n而當請求成功之後，這時候往下拉的話，在下方的 response body 區塊中，就可以看到 Spring Boot 程式返回了「資料庫中的所有學生數據」給前端，因此在這裡就呈現了 3 筆數據，分別是：\nid 為 1 的 Judy id 為 3 的 John id 為 4 的 Bob 而這就和 IntelliJ 中所呈現的 student table 的數據，是一模一樣的。\n所以這就表示，我們就成功的透過了 Spring JDBC 的 query() 方法，在 Spring Boot 中執行 SELECT SQL 語法，從資料庫中查詢數據出來了！因此後續我們就可以透過這種寫法，從資料庫中查詢想要的數據出來了。\n補充：除了上述最基礎的 query() 的用法之外，大家也可以試試看像上一篇文章一樣，去修改 SQL 語法、以及在 map 參數中添加相關的變數的值，這樣就可以根據不同的查詢參數，從資料庫中查詢出指定的數據了。\nquery","date":"2024-07-27","objectID":"2f27b167f7928a070222cda985071865","title":"Spring Boot 零基礎入門 (27) - Spring JDBC 的用法（下）- 執行 SELECT SQL","url":"https://kucw.io/blog/springboot/27/"},{"categories":["Spring Boot"],"content":"哈囉大家好，我是古古。\n在上一篇文章中，我們有在 Spring Boot 中載入了 Spring JDBC 的功能，並且也有設定好了 MySQL 資料庫的連線資訊。\n那麼接著這篇文章，我們就會正式來介紹，要如何使用 Spring JDBC 的功能，在 Spring Boot 程式中執行 SQL 語法，進而去操作資料庫內部的數據。\n目錄 Spring JDBC 用法介紹 補充：怎麼背哪種 SQL 語法用哪個方法來執行？ update() 的基本用法 步驟一：注入 NamedParameterJdbcTemplate Bean 步驟二：撰寫 SQL 語法 步驟三：新增一個 Map\u0026lt;String, object\u0026gt; 的 map 變數 步驟四：使用 update() 方法 實際測試 update() 中的 map 參數用法 例子：根據前端的參數，動態的決定 SQL 中的值 前置準備 修改 SQL 語法、添加 map 變數中的值 實際測試 update() 方法的用法總結 總結 Spring JDBC 用法介紹 # 在 Spring JDBC 中，會根據 SQL 語法區分成兩大類，分別是「update 系列」和「query 系列」。\n在 update 系列的方法中，可以執行 INSERT、UPDATE、DELETE 這三種 SQL 語法 而在 query 系列的方法中，只能執行 SELECT 這一種 SQL 語法 因此大家如果想要執行的是 INSERT SQL，那就是得使用 update() 方法來執行，而如果想執行的是 SELECT SQL 的話，則是得改用 query() 方法來執行。\n也因為 update() 和 query() 這兩個方法在用法上會有點差別，因此接下來我們就會分成上、下兩篇文章，分別來介紹這兩種方法的用法。\n因此在這篇文章中，我們就會先來介紹 update() 的用法。\n補充：怎麼背哪種 SQL 語法用哪個方法來執行？ # 因為在 Spring JDBC 中，INSERT、UPDATE、DELETE 這三種 SQL 語法，必須要用 update() 方法來執行，而 SELECT 這一種 SQL 語法，則是得改用 query() 方法來執行，所以大家一開始接觸的時候，可能會怕自己忘記哪種 SQL 語法要用哪個方法來執行。\n不過這個對應關係其實是不用特別背的！因為我們可以透過「方法的名稱」，去推敲出當下這個 SQL 語法要用哪種方法來執行。\n舉例來說，像是 update() 方法代表的是「更新資料庫中的數據」的意思，所以在 INSERT、UPDATE、DELETE 這三種情境中，都是廣義的表達「改變資料庫中儲存的數據」的含義。\nINSERT：在資料庫中「新增」一筆數據 UPDATE：在資料庫中「修改」一筆已存在的數據 DELETE：在資料庫中「刪除」一筆數據 因此對於 INSERT、UPDATE、DELETE 這三種 SQL 語法，就都可以使用 update() 方法來執行。\n而同樣的道理，因為另一個 query() 方法代表的是「查詢資料庫中的數據」的意思，所以他就會去對應到 SELECT 這一種 SQL 語法，專門去查詢資料庫中的數據。因此針對 SELECT SQL，就是只能使用 query() 方法來執行。\n所以大家以後在使用 Spring JDBC 時，就不用特別背誦哪種 SQL 要用哪一個方法來執行，只要直接從方法名稱上去推敲就可以了！\nupdate() 的基本用法 # 大概了解了 update() 和 query() 方法之間的差別之後，接著我們就可以來詳細介紹一下，要如何使用 update() 方法去執行 INSERT、UPDATE、DELETE 這三種 SQL 語法。\n要使用 update() 方法去執行 INSERT、UPDATE、DELETE 這三種 SQL 語法的話，可以分成四個步驟來實作：\n步驟一：注入 NamedParameterJdbcTemplate Bean # 使用 update() 的第一步，就是要先在你的 Bean 裡面，去注入 NamedParameterJdbcTemplate 進來。\n因此我們就可以在 StudentController 中，先使用 @Autowired，去注入 NamedParameterJdbcTemplate 這個 Bean 進來（如下圖中的第 14～15 行所示）。\n@Autowired private NamedParameterJdbcTemplate namedParameterJdbcTemplate; 而我們之所以可以直接在 StudentController 中去注入 NamedParameterJdbcTemplate 這個 Bean，就是因為這個 Bean 是由 Spring JDBC 自動幫我們生成的 Bean，他會負責去處理和資料庫溝通的所有事項，因此後續我們就可以透過 NamedParameterJdbcTemplate，去執行想要執行的 SQL 語法了。\n所以簡單來說，當我們在使用 Spring JDBC 的功能時，其實很大部分的時間都是在和 NamedParameterJdbcTemplate 打交道，即是學習要如何使用 NamedParameterJdbcTemplate 中所提供的 update() 和 query() 方法，去執行我們想執行的 SQL 語法。\n步驟二：撰寫 SQL 語法 # 在 StudentController 中注入好 NamedParameterJdbcTemplate 進來之後，接著第二步，就是去寫出我們想要執行的 SQL 語法。\n所以我們可以先在 StudentController 中創建一個 String 類型的變數 sql，並且在裡面寫上我們想要執行的 SQL 語法（如下圖中的第 20 行所示）。\n舉例來說，下方就是將一條 INSERT SQL 的語句，儲存在 sql 的變數裡面，而這條 INSERT SQL 的用途，就是「在 student table 中插入一筆 id 為 3、並且 name 為 John」的數據。因此到時候當 Spring JDBC 去執行這條 SQL 時，就會在 student table 中插入 John 這筆新數據。\nString sql = \u0026#34;INSERT INTO student(id, name) VALUES (3, \u0026#39;John\u0026#39;)\u0026#34;; 步驟三：新增一個 Map\u0026lt;String, object\u0026gt; 的 map 變數 # 撰寫完想要執行的 SQL 語句之後，接著第三步，就是去新增一個類型為 Map\u0026lt;String, object\u0026gt; 的 map 變數出來。\n因此就可以在 StudentController 中添加下方的程式（如下圖中的第 22 行所示）：\nMap\u0026lt;String, Object\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); 補充：我們後續就會介紹這個 map 變數的用途了，因此目前就先照抄即可。\n步驟四：使用 update() 方法 # 當前面的步驟都完成之後，最後要做的第四部，就是去使用 namedParameterJdbcTemplate 中的 update() 方法，並且把上面所宣告的 sql 和 map 這兩個變數，依照順序傳進去 update() 方法裡面（如下圖中的第 24 行所示）。\nnamedParameterJdbcTemplate.update(sql, map); 只要完成了這四個步驟，我們","date":"2024-07-26","objectID":"6b090b179c5eb8394d9d8e15b25daeda","title":"Spring Boot 零基礎入門 (26) - Spring JDBC 的用法（上）- 執行 INSERT、UPDATE、DELETE SQL","url":"https://kucw.io/blog/springboot/26/"},{"categories":["Spring Boot"],"content":"哈囉大家好，我是古古。\n在上一篇文章中，我們先介紹了 Spring JDBC 的用途是什麼，先讓大家對 Spring JDBC 有一個簡單的認識。\n那麼接著這篇文章，我們就會實際的去創建一個資料庫，並且將 Spring Boot 程式連線到此資料庫上，同時也會補充要如何運用 IntelliJ 中的好用工具，去管理資料庫中的數據（僅限 IntelliJ 付費版才有此功能），所以我們就開始吧！\n目錄 回顧：什麼是 Spring JDBC？ 在 Spring Boot 中設定資料庫連線資訊 在 pom.xml 中載入 Spring JDBC 的功能 在 application.properties 中設定資料庫連線資訊 補充：IntelliJ 中的資料庫管理工具（僅限 IntelliJ 付費版） 在 IntelliJ 中添加 MySQL 資料庫連線 創建 myjdbc database 創建 student table 查看 student table 中的數據 總結 回顧：什麼是 Spring JDBC？ # Spring JDBC 的用途，就是「讓我們能夠在 Spring Boot 中執行 SQL 語法，進而去存取資料庫中的數據」，因此我們之後就可以透過 Spring JDBC 的功能，在 Spring Boot 中執行資料庫的 SQL 語法，因此就可以在資料庫中執行查詢數據、新增數據…等等的操作了！\n在 Spring Boot 中設定資料庫連線資訊 # 在 pom.xml 中載入 Spring JDBC 的功能 # 如果想要在 Spring Boot 中使用 Spring JDBC 的功能的話，首先會需要在 pom.xml 檔案中新增下方的程式，這樣才能夠將 Spring JDBC 的功能、以及 MySQL 資料庫的 driver 給載入進來。\n因此大家可以先打開左邊側邊欄中的 pom.xml 檔案，然後在第 29 行～第 37 行的地方，添加下面的程式：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-jdbc\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.mysql\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mysql-connector-j\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;8.0.33\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 添加好上述的程式之後，此時在 pom.xml 的右上角會出現一個 M 符號，這時記得要點擊一下這個 M 符號，這樣才能夠更新 Spring Boot 程式，把 Spring JDBC 的功能、以及 MySQL 資料庫的 driver，一起給載入進來。\n補充：如果大家在其他的 Spring Boot 專案中使用的是其他的資料庫（ex: PostgreSQL、SQL Server），則上圖中的第 33 行～第 37 行需要改成該資料庫的 driver。\n在 application.properties 中設定資料庫連線資訊 # 載入好 Spring JDBC 和 MySQL 的 driver 之後，接著我們就可以在 Spring Boot 中設定 MySQL 資料庫的連線，這樣我們後續就能夠在 Spring Boot 程式裡面，去操作 MySQL 資料庫中的數據了。\n而要在 Spring Boot 中設定資料庫的連線資訊的話，就只要先打開 application.properties 檔案，並且在裡面添加下列的程式，這樣就能完成 MySQL 資料庫的連線設定了！\nspring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver spring.datasource.url=jdbc:mysql://localhost:3306/myjdbc?serverTimezone=Asia/Taipei\u0026amp;characterEncoding=utf-8 spring.datasource.username=root spring.datasource.password=springboot 補充：application.properties 檔案是 Spring Boot 的設定檔，用來存放 Spring Boot 中的設定值。如果有點忘記 application.properties 的用法的話，也可以回頭參考 Day 10 - 讀取 Spring Boot 設定檔 - @Value、application.properties 的介紹。\n在 application.properties 檔案中添加好上述的程式之後，我們也可以分別來介紹一下，這四行程式的用途是什麼：\nspring.datasource.driver-class-name\nspring.datasource.driver-class-name 是表示「要使用的是哪種資料庫的 driver」，此處我們填寫的即是 MySQL 的 driver。\nspring.datasource.url\nspring.datasource.url 是表示「要連接到哪台資料庫上」。像是前面的 jdbc:mysql://localhost:3306 是表示要連接到我們自己電腦上的 MySQL 資料庫，而後面跟著的 /myjdbc，則是指定要連線到 MySQL 資料庫中的 myjdbc database。\n並且在 myjdbc 後面的 ? 中，我們也有加上兩個參數：\n其中 serverTimezone=Asia/Taipei 是表示我們指定時區為台北時區 而 characterEncoding=utf-8 則表示我們所使用的編碼是 utf-8，這樣後續在處理中文時，才不會出現亂碼 spring.datasource.username\nspring.datasource.username 是要我們填入 MySQL 資料庫中的帳號，此處就填上預設的帳號 root。\nspring.datasource.password\nspring.datasource.password 則是要我們填入上面那個帳號的密碼，因此此處就填上 springboot（這裡所填上的密碼 springboot，其實就是我們一開始在安裝 MySQL 時，所設定的那組密碼。當時有建議大家可以和此系列文一樣設定為 springboot，不過如果你所當初不是使用 springboot 當作密碼，那麼這裡即是填入你當時所設定的密碼）。\n在了解了這四行程式所代表的意義、並且也有在 application.properties 檔案中設定好這四行程式之後，這樣 Spring Boot 到時候就會去根據這四行程式，去連線到我們所指定的資料庫了！\n所以到目前為止，大家只要先完成 application.properties 的設定即可，有關 Spring JDBC 的用法，我們在下一篇文章會繼續介紹。\n補充：IntelliJ 中的資料庫管理工具（僅限 IntelliJ 付費版） # 在設定好 application.properties 中的資料庫連線之後，其實我們就可以使用 Spring JDBC 的功能，在 Spring Boot 中操作 ","date":"2024-07-25","objectID":"8c62d0731d34f823c8d75b05631c4b3c","title":"Spring Boot 零基礎入門 (25) - 資料庫連線設定、IntelliJ 資料庫管理工具介紹","url":"https://kucw.io/blog/springboot/25/"},{"categories":["Spring Boot"],"content":"哈囉大家好，我是古古。\n在前面的文章中，我們介紹了 Spring MVC 中的許多特性，因此大家現在就可以在 Spring Boot 中，透過 Spring MVC 和前端進行溝通了。\n而在了解了如何和前端溝通之後，在接下來的文章中，我們就會來介紹另一個也很重要的部分，即是如何透過 Spring JDBC，去和「資料庫」進行溝通，所以我們就開始吧！\n目錄 回顧：前端和後端的差別、Spring MVC 負責的部分 什麼是 Spring JDBC？ 補充一：Spring JDBC 和 Spring Data JPA 的差別在哪裡？ 補充二：什麼是 CRUD？ 總結 回顧：前端和後端的差別、Spring MVC 負責的部分 # 在前面的文章中我們曾經提到，在現今的網站架構中，前端是負責進行排版設計，後端則是負責數據處理。而前端除了設計網頁的排版之外，同時也需要去問後端：「這裡應該要呈現哪些商品？」，這樣前端才能夠將數據和排版結合再一起，最後再將結果呈現給使用者看。\n也因為如此，所以在上一個 Spring MVC 的部分中，我們就都是在介紹：要如何透過 Spring MVC 去和「前端」溝通。\n但是這些商品的數據，我們總是得在後端程式中找個地方來儲存，因此後端通常就會將這些商品數據，存放在「資料庫」裡面。 所以後續當前端來詢問：「這裡要呈現哪些商品？」時，後端就可以從資料庫中查詢商品數據，接著再將這些商品的數據返回給前端。\n所以在接下來的 Spring JDBC 的部分中，我們就是要來介紹，要如何透過 Spring JDBC，去和「資料庫」溝通，進而存取資料庫中的數據。\n什麼是 Spring JDBC？ # 大概了解了 Spring JDBC 的用途之後，接著我們可以回頭來看一下 Spring JDBC 的定義。\nSpring JDBC 的用途，就是「讓我們能夠在 Spring Boot 中執行 SQL 語法，進而去存取資料庫中的數據」，因此我們之後就可以透過 Spring JDBC 的功能，在 Spring Boot 中執行資料庫的 SQL 語法，所以就可以透過這些 SQL，在資料庫中執行查詢數據、新增數據\u0026hellip;等等的操作了！\n補充：因此在閱讀後續的文章時，建議大家一定要預先了解資料庫的 SQL 語法，這樣子才會比較好上手。\n補充一：Spring JDBC 和 Spring Data JPA 的差別在哪裡？ # 在上面的那張圖中，大家可能有發現在上方的紅字中，不僅出現了「Spring JDBC」的文字，也出現了「Spring Data JPA」的文字（如下圖黃底處所示）。\n其實「在 Spring Boot 中操作資料庫數據」這件事，是有許多工具可以選擇的！\n像是在 Spring Boot 中，常見的操作資料庫的工具有：\nSpring JDBC MyBatis Spring Data JPA Hibernate \u0026hellip;等等 而在這些操作資料庫的工具中，又可以將他們分成兩類：\n在 Spring Boot 中執行 SQL 語法，使用 SQL 語法操作資料庫\n這一類的工具，就是直接在 Spring Boot 中執行原始的 SQL 語法，然後透過這些 SQL 語法去新增或是修改資料庫中的數據。Spring JDBC 和 MyBatis 都屬於這一類。\n使用 ORM 的概念操作資料庫\n這一類的工具，則是會透過 ORM（Object Relational Mapping）的概念，在 Spring Boot 操作資料庫。因此在使用這類的工具時，基本上就很少寫 SQL 語法了，反而是會使用 ORM 的概念，去存取資料庫的數據。Spring Data JPA 和 Hibernate 都屬於這一類。\n所以回到最一開始的問題：「Spring JDBC 和 Spring Data JPA 的差別在哪裡？」的話，簡單來說，Spring JDBC 是透過執行 SQL 語法去操作資料庫，而 Spring Data JPA 則是透過 ORM 的概念去操作資料庫。\n也因為這兩種概念差異比較大，因此在此系列文中只會介紹 Spring JDBC 的部分，而不會介紹 Spring Data JPA 的用法。如果大家後續對 Spring Data JPA 有興趣，也可以再上網查詢相關的資料。\n補充二：什麼是 CRUD？ # 其實在前面的 Day 22 - RESTful API 實作 - @GetMapping、@PostMapping\u0026hellip; 文章中，我們曾經短暫的提到過 CRUD 這個關鍵字，不過當時我們沒有針對 CRUD 進行太多的介紹，因此這裡我們可以正式的來介紹一下，CRUD 所代表的含義是什麼。\nCRUD 所代表的，是資料庫中的「Create（新增）、Read（查詢）、Update（修改）、Delete（刪除）」這四個操作的統稱，用來表示資料庫中最基礎的行為。\n而這四個操作之所以會簡稱為 CRUD，是因為如果我們把這四個操作擺成直排來看的話，就會發現 CRUD 這個單字，只是各取他們的第一個英文字母來簡稱而已。\nCreate（新增） Read（查詢） Update（修改） Delete（刪除） 之所以說 CRUD 是資料庫中最基礎的實作，是因為不管我們想要實作什麼功能（ex: 商品功能），我們通常都得去實作數據的「新增、查詢、修改、刪除」這四個操作，因此實作 CRUD 可以說是後端工程師必備的基礎能力！建議大家一定要好好掌握才行。\n總結 # 這篇文章我們先回顧了前端和後端之間的區別，接著也介紹了 Spring JDBC 的用途是什麼，以及補充 Spring JDBC 和 Spring Data JPA 的差異在哪裡，讓大家先對 Spring JDBC 有一個簡單的認識。\n那麼下一篇文章，我們就會接著來介紹，要如何透過 Spring JDBC 的功能，在 Spring Boot 中設定資料庫的連線資訊，那我們就下一篇文章見啦！\n補充：本文是擷取自我開設的線上課程 Java 工程師必備！Spring Boot 零基礎入門 的內容，如果你想了解更多的 Spring Boot 的用法，歡迎參考課程簡介 （輸入折扣碼「HH202601KU」即可享 85 折優惠）。\n","date":"2024-07-24","objectID":"2ece26d99d1e6bc11ff38512bea21546","title":"Spring Boot 零基礎入門 (24) - Spring JDBC 簡介","url":"https://kucw.io/blog/springboot/24/"},{"categories":["Spring Boot"],"content":"哈囉大家好，我是古古。\n在上一篇文章中，我們有介紹要如何去設計和實作 RESTful API，因此大家就可以透過前面所學到的內容，實際的在 Spring Boot 中實作出 RESTful API 出來了。\n那麼接著這篇文章，我們就會回頭來介紹一下 Http response 中也很重要的一個部分，也就是 Http status code（Http 狀態碼），所以我們就開始吧！\n目錄 什麼是 Http status code（Http 狀態碼）？ Http status code 中的分類 常見的 Http status code 1xx：資訊 2xx：成功（200、201、202） 3xx：重新導向 4xx：前端請求錯誤 5xx：後端處理有問題 常用的 Http status code 總結 總結 什麼是 Http status code（Http 狀態碼）？ # Http status code 又稱為 Http 狀態碼，他是屬於 Http response 的一部分，而 Http status code 的用途，就是「用來表示這次 Http 請求的結果為何」。\n所以簡單來說，Http status code 就是會透過一個簡短的數字，呈現這一次請求結果為何，因此前端就可以透過 Http status code，快速的知道這一次的 Http 請求是成功還是失敗了。\nHttp status code 中的分類 # 在 Http status code 的世界中，可以根據「首位數字」，分成 5 個大類，分別是：\n1xx：資訊 2xx：成功 3xx：重新導向 4xx：前端請求錯誤 5xx：後端處理有問題 而在每一個大類中，可以再去細分出更多的 Http status code 出來。不過其實只要在同一個大類中的 Http status code，他們的意思都是類似的！\n舉例來說，只要是 2 開頭的 Http status code，不管你是 200、201、還是 202\u0026hellip;等等，只要你是 2 開頭，就都是屬於「2xx」那一個大類，也就是表示「成功」的意思。\n像是我們之前在 API Tester 中發起 Http 請求時，就會看到 Spring Boot 回傳了「200」的 Http status coe 給我們。而這個「200」，就是屬於「2xx」的大類，也就是表示「請求成功」的意思。\n所以透過 Http status code 的簡短數字，我們就可以快速的知道這一次 Http 請求的結果為何了！\n常見的 Http status code # 大概了解了 Http status code 的用途之後，接下來我們就詳細的來介紹一下，每一個大類底下都有哪些常見的 Http status code。\n補充：因為 Http status code 的數量還滿多的，因此這邊只會列出比較常見的 Http status code，如果大家在工作上遇到比較罕見的 Http status code 時，可以再上網查詢一下相關的含義。\n1xx：資訊 # 首先我們先從 1 開頭的大類開始看起，1 開頭的 Http status code 代表的是「取得資訊」的意思。\n不過因為在實際的應用中，1 開頭的 Http status code 非常少用，因此在這個大類中，就沒有常見的 Http status code。\n2xx：成功（200、201、202） # 看完了 1 開頭的大類，接著我們可以看 2 開頭的大類。\n2 開頭的 http status code 所代表的，就都是「請求成功」的意思。 而 2 開頭的 Http status code，他們在使用上可以說是非常頻繁了，常見的有以下三個：\n200 OK # 首先第一個是 200 OK，200 所代表的，就是「這一次的 Http 請求成功了」。\n200 可以說是使用最廣泛的一個 Http status code，通常只要看到 200，就表示這一次的請求成功了（特殊情境例外），因此 200 可以說是工程師裡面的天使等級的角色。\n201 Created # 接著是 201 Created，201 所代表的，不僅是這一次的 Http 請求成功而已，他還額外表示「有一個新的資源成功的被創建了」的含義。\n也因為 201 除了表示請求成功之外，還多表示了「創建資源成功」的含義，因此 201 通常會被用在 POST 請求的 response 中（因為 REST 風格中的 POST 就是對應到資料庫的創建操作）。\n202 Accepted # 最後一個則是 202 Accepted，202 所代表的，是「這一次的請求已經被接受了，但是尚未處理完成」。 因此大家可以把 202 想像成是「你拜託別人去買東西，但是他還在買的路上，還沒幫你買好」這樣。\n所以當大家以後看到 202 時，就表示後端已經開始處理這件事情了，只是他目前還沒處理完成，因此先返回一個 202 給你，告知你需要再等待一段時間才能完成。\n補充：每一個 Http status code 其實都會有一個專屬的英文短語，用來表達這個 Http status code 的意思，像是 200 他所對應的英文短語是「OK」，而 202 所對應的短語是「Accepted」。\n而這個短語的用途，其實就只是簡短的去描述這個 Http status code 是什麼意思而已，目的是為了幫助工程師了解這個 Http status code 的含義是什麼，因此當大家遇到不熟悉的 Http status code 時，也可以參考他的短語描述。\n3xx：重新導向 # 看完了 2 開頭的 Http status code，接著我們可以來看 3 開頭的大類。\n3 開頭的 http status code 所代表的，都是「重新導向」的意思。 而在 3 開頭的大類中，常見的有以下兩個：\n301 Moved Permanently # 首先是 301 Moved Permanently，301 所代表的，是「這個 url 永久性的搬家了」，注意這裡的重點是 「永久性」。\n所以當前端去請求某個 API，但是該 API 返回 301 時，就是表示這個 API 搬家了。並且後端在回傳 301 時，通常會將新的 url 放在 response header 中的 Location 中，告訴我們新的搬家地址在哪，因此前端就可以改成去請求新的 url，進而訪問搬家後的網址了。\n舉例來說，我之前在架設個人網站時，就有從 https://kucw.github.io 搬家到 https://kucw.io，所以現在如果請求舊的 https://kucw.github.io 網站的話，GitHub 就會返回 301 的 Http status code，告訴前端這個網站已經永久性的搬家了，並且 GitHub 也會將新家的網址（也就是 https://kucw.io）放在 response header 中的 Location 中，因此前端就可以改成去請求新的 url https://kucw.io，進而去訪問搬家後的網址了。\n所以當 url 永久性的搬家時，後端就可以返回 301 的 Http status code，用來表示這種情況。\n302 Found # 而至於 302 Found，他就和 301 有點細微的差別。302 所代表的，則是「這個 url 暫時性的搬家」，注意這裡的重點是 「暫時性」。\n所以假設某個 API 只是「暫時性」的搬家的話（ex: 這個 API 的功能目前正在調整中），那麼後端就可以回傳 302 的值給前端，並且臨時的 ","date":"2024-07-23","objectID":"ed484ff4570803aca2b5b97205e1c531","title":"Spring Boot 零基礎入門 (23) - Http Status Code（Http 狀態碼）介紹","url":"https://kucw.io/blog/springboot/23/"},{"categories":["Spring Boot"],"content":"哈囉大家好，我是古古。\n在上一篇文章中，我們有介紹了什麼是 RESTful API，以及在設計 RESTful API 時，需要滿足哪三個設計條件，先讓大家對 RESTful API 有基本的認識。\n而在了解了 RESTful API 的概念之後，接著這篇文章，我們就會實際到 Spring Boot 上，練習要如何在 Spring Boot 中設計和實作出 RESTful API，所以我們就開始吧！\n目錄 回顧：什麼是 RESTful API？ 設計 RESTful API 在 Spring Boot 中實作 RESTful API 指定 Http method 的方式：@GetMapping、@PostMapping\u0026hellip;等 Spring Boot 中常用的 RESTful API 註解 具體實作 前期準備 實作 POST /students（創建 Student 數據） 實作 GET /students/123（查詢 Student 數據） 實作 PUT /students/123（更新 Student 數據） 實作 DELETE /students/123（刪除 Student 數據） 實作成果 總結 回顧：什麼是 RESTful API？ # RESTful API 指的是「你所設計的 API 符合 REST 風格」，而 RESTful API 的目的，是為了「簡化工程師之間的溝通成本」，當每個工程師都安照共同的默契來設計 API 時，大家就可以設計出更一致的 API，因此就可以把溝通所花費的時間節省下來，進而提升開發的效率。\n而要設計出 RESTful API 的話，需要符合以下三個條件：\n使用 Http method，表示要執行的資料庫操作 使用 url 路徑，描述資源之間的階層關係 Response body 返回 JSON 或是 XML 格式 只要同時滿足這三個條件，就可以將你的 API 稱為是 RESTful API 了！\n設計 RESTful API # 了解了 RESTful API 的概念之後，接著我們也可以試著去設計出一套 RESTful API 出來，並且了解要如何透過 Spring Boot 程式，去實作這套 RESTful API。\n舉例來說，我們可以先設計出一個 Student class，並且在裡面新增 id 和 name 兩個變數，用來表示這個學生的 id 和名字，程式如下：\npublic class Student { Integer id; String name; } 接著，我們可以為 Student 這個資源，去設計出一連串的 RESTful API：\n像是我們需要一個「創建學生」的 API ，這樣子才能新增新同學的數據到資料庫 我們也需要一個「查詢學生」的 API，這樣子才能去查詢某一筆學生的數據 \u0026hellip;等等 所以針對 Student 這個「資源」，通常我們會設計四個最基本的 RESTful API 給他，也就是 CRUD（Create 新增、Read 查詢、Update 修改、Delete 刪除），具體設計方式如下圖所示：\n所以透過這四個 RESTful API，就可以完成 Student 的「新增、查詢、修改、刪除」的四個基本操作了！\n補充：「Create 新增、Read 查詢、Update 修改、Delete 刪除」這四個操作，又可以簡稱為 CRUD，幾乎每一種資源（ex: 商品、訂單、會員\u0026hellip;等），都會需要這四個操作，因此 CRUD 也可以說是大家剛入門 Spring Boot 時，最常撰寫的程式。\n在 Spring Boot 中實作 RESTful API # 指定 Http method 的方式：@GetMapping、@PostMapping\u0026hellip;等 # 當我們設計好 Student 資源的四個基本 RESTful API 之後，因此前端到時候想要去新增一筆 Student 數據時，前端就要使用 POST，去請求 /students 這個 url 路徑，這樣子才能夠創建一筆新的 Student 數據到資料庫中。\n而在 Spring Boot 中，有兩種方式可以「限制」前端只能用某個 Http method 來請求 url 路徑，分別是：\n@RequestMapping(value = \u0026#34;/students\u0026#34;, method = RequestMethod.POST) 以及\n@PostMapping(\u0026#34;/students\u0026#34;) 上面這兩種寫法，都可以限制前端只能使用 POST，去請求 /students 的 url 路徑，他們的差別就只是一行寫起來比較長、一行寫起來比較短而已。\n在之前的文章中，我們都是使用上面的 @RequestMapping 的寫法來設計 url 路徑，而他的缺點，就是寫起來比較冗長，不利於後續維護。\n因此一般在實作上，通常會改成使用下方的 @PostMapping 的寫法，直接透過 @PostMapping 這個註解，去「限制」前端只能使用 POST 來請求，這樣子的寫法會更簡潔、更一目瞭然，所以一般在設計 RESTful API 時，通常就是會採用下方的 @PostMapping 來實作！\nSpring Boot 中常用的 RESTful API 註解 # 在 Spring Boot 中，除了可以使用 @PostMapping，去限制前端只能使用 POST 來請求之外，Spring Boot 也是有提供其他好用的註解，讓我們去限制其他的 Http method 的。\n像是 Spring Boot 就提供了以下四個註解給我們使用：\n@GetMapping：限制前端只能使用 GET 來請求該 url 路徑 @PostMapping：限制前端只能使用 POST 來請求該 url 路徑 @PutMapping：限制前端只能使用 PUT 來請求該 url 路徑 @DeleteMapping：限制前端只能使用 DELETE 來請求該 url 路徑 不過這些註解大家不需要死背，因為大家如果觀察一下的話，可以發現「這些註解都是以 Http method 當作開頭」來設計，像是 @GetMapping 就是 Get + Mapping，而 @PostMapping 則是 Post + Mapping。\n所以當大家以後看到這些註解時，只要直接觀察註解的名稱（XXX + Mapping），就可以知道他想要限制的是哪一種請求方法了！\n具體實作 # 設計好 RESTful API，並且也了解了 Spring Boot 中的 @GetMapping、@PostMapping\u0026hellip;等註解的用法之後，接下來我們就可以實際到 Spring Boot 中，去實作這四個 RESTful API 出來了！\n前期準備 # 首先大家可以先刪除 MyController class，這個 class 後續不會再使用到了。刪好之後，接著在 Spring Boot 中創建一個新的 class 出來，並且命名為 Student class，然後在裡面寫上兩個變數 id 和 name，用來表示這個學生的 id 和名字，具體程式如下：\npublic class Student { private Integer id; private String name; public Integer getId() { return id; } public void setId(Integer id) { this.id = id; } public String getName","date":"2024-07-22","objectID":"b8c42fc984465890f8ba65a9f7be324f","title":"Spring Boot 零基礎入門 (22) - RESTful API 實作 - @GetMapping、@PostMapping...","url":"https://kucw.io/blog/springboot/22/"},{"categories":["Spring Boot"],"content":"哈囉大家好，我是古古。\n在前幾篇文章中，我們分別介紹了 Spring Boot 中「取得前端參數」的四個註解，因此大家就可以根據不同的情境，使用不同的註解來取得前端傳遞過來的參數了。\n那麼這篇文章，我們就會介紹現今前後端開發非常流行的一種設計風格，也就是 RESTful API，所以我們就開始吧！\n目錄 什麼是 API？ 什麼是 RESTful API？ 1. 成為 RESTful API 的條件之一：使用 Http method，表示要執行的資料庫操作 2. 成為 RESTful API 的條件之二：使用 url 路徑，描述資源之間的階層關係 3. 成為 RESTful API 的條件之三：Response body 返回 JSON 或是 XML 格式 小結：滿足 RESTful API 的三個條件 補充：RESTful API 的注意事項 總結 什麼是 API？ # 在開始介紹「RESTful API」之前，大家需要先了解「API」是什麼，要先掌握 API 的概念，才能夠學習 RESTful API 的相關知識，因此我們就先來介紹一下，API 到底是什麼。\n所謂的 API，指的是「用工程師的方式，去說明某個功能的使用方法」，所以換句話說的話，API 就是用特定的格式，去表示某個功能到底要怎麼使用，等於是一個使用說明書的概念。\n舉例來說，假設我們在 Spring Boot 中實作了一個「取得商品列表」的功能，那麼當我們想要將這個功能開放給前端使用的話，總不可能直接把 Spring Boot 的程式貼給對方看（因為對方可能不熟悉 Spring Boot、或是他根本不了解 Java 程式語言），因此就會造成溝通效率低落。\n而為了解決這個問題，API 就出現了！\n因為 API 的目的，就是「用工程師看得懂的方式，去說明某個方法要如何使用」，所以我們就可以用下圖中的格式，去定義「取得商品列表」這個 API 的使用方法。\n像是在下圖中，就會說明「取得商品列表」這個 API，必須要使用 GET 來請求。並且這張圖也有詳細列出前端在請求時，可以帶上什麼樣的請求參數（query parameter），以及這個 API 可能返回的 Http response 為何。\n所以當前端拿到這份 API 文件時，前端就能夠照著上面的定義，去使用 GET 請求 /getProducts 這個 url 路徑，並且在請求時，帶上 size=5 這個請求參數（表示要取得 5 筆數據），這樣子就可以成功的去使用「取得商品列表」的功能，進而去取得 5 筆商品數據出來了！\n因此透過這份 API 文件，大家就可以更清楚的知道某個功能的使用方式，進而提升前後端溝通的效率！\n補充：一般在口語上，大家可能會聽到有人說「這支 API 要怎麼 call？」或是「你可以去 call 商品功能的 API」這種說法，其中的「call API」，其實就是指「對該 API 發起 Http 請求」的意思。\n所以假設我們在 Spring Boot 中實作了一個 API，他的 url 路徑是 /test，那麼當前端去請求 http://localhost:8080/test 時，就可以說「前端去 call 了 /test 這一支 API」。\n因此「call API」這個說法，在實務上是非常常見的講法，所以建議大家也要熟悉一下這個講法會比較好！\n什麼是 RESTful API？ # 了解了 API 的概念之後，接著就可以來介紹什麼是「RESTful API」了！\n所謂的「RESTful API」，就是表示去設計出一套「符合 REST 風格的 API」出來，所以換句話說的話，只要我們在設計 API 時，有去套用 REST 風格，那就可以稱呼我們所設計出來的這組 API，是 RESTful API 了！\n補充：大家看到這邊，可能會疑惑「REST 風格」和「RESTful」之間到底是什麼關係，其實這裡只是用到英文的文法特性而已。\n在英文的文法裡面，有一種用法，就是在字尾加個 ful，就可以把名詞轉成形容詞。\n舉例來說：\nBeauty 是名詞（意思是美麗），而 Beautiful 則是形容詞（美麗的） Peace 是名詞（意思是和平），而 Peaceful 則是形容詞（和平的） 因此同樣的邏輯，REST 是一個名詞，表示「REST 風格」，而 RESTful 就是形容詞，表示「符合 REST 風格的」，所以 RESTful API 的意思，就是表示「這個 API 是很符合 REST 風格的」！\n大概了解 REST 和 RESTful 的差別之後，所以現在我們知道，所謂的「RESTful API」，就是設計出一個「符合 REST 風格的 API」，而如果我們想要設計出一個「符合 REST 風格的 API」，那麼這個 API 就必須要滿足三個條件：\n1. 成為 RESTful API 的條件之一：使用 Http method，表示要執行的資料庫操作 # 如果想要設計出 RESTful API 的話，首先第一點，就是這個 API 必須要「使用 Http method，去表示要執行的資料庫操作」，也就是賦予了 Http method 更多的意義。\n在 REST 風格中，REST 風格會把 POST、GET、PUT、DELETE 這四種 Http method，分別去對應到資料庫的 Create、Read、Update、Delete 操作上。\n所以在 REST 風格中，只要看到某支 API 是使用 GET 來請求，那就是在暗示這個 API 會去資料庫中執行「Read（查詢數據）」的操作。或是如果該 API 是使用 POST 來請求，那就是在暗示這個 API 要去執行「Create（新增數據）」的操作。\n因此在 RESTful API 的世界裡面，Http method 影響的不僅僅是 GET、POST 這些請求參數的傳遞而已，也是在「暗示」這支 API 後續會去執行資料庫中的哪種操作。\n所以如果我們想要設計出一個 RESTful API 的話，那麼第一個必要條件，就是要「使用 Http method，去表示要執行的資料庫操作」。\n2. 成為 RESTful API 的條件之二：使用 url 路徑，描述資源之間的階層關係 # 成為 RESTful API 的第二個條件，就是「使用 url 路徑，描述資源之間的階層關係」。\n在 REST 風格裡面，url 路徑代表的是「每個資源之間的階層關係」，這個聽起來可能有點抽象，所以我們可以直接透過一個例子，來了解什麼是資源之間的階層關係。\n假設現在有一個使用 GET 來請求 API 為 GET /users，首先因為這個 API 是使用 GET 來請求，因此根據上面的條件一的介紹，GET 就是對應到 Read（讀取數據）的操作，又因為後面的 url 路徑是 /users，所以我們就可以知道他是要去「取得所有 user 的數據」。\n此時假設我們又有另一個 API GET /users/123，因為這個 API 也是使用 GET 來請求，所以也是去讀取數據，並且他的 url 路徑是 /users/123，因此這個 API 的含義，就是「取得 user id 為 123 的那個 user 的數據」。\n而到這邊，REST 風格的階層概念其實就出現了！\n大家可以把 url 路徑中的每一個斜線 /，想像成是一個個的階層，也就是一個子集合的感覺。或是說得更白話一點，就是可以直接把這個斜線 /，替換成是中文的「的」。\n所以像是上面的 GET /users，就是表示去「取得所有 user 的數據」 而下面的 GET /users/123，則是表示","date":"2024-07-21","objectID":"ca1d15f9cdcb71e6503e1cc35406019e","title":"Spring Boot 零基礎入門 (21) - RESTful API 介紹","url":"https://kucw.io/blog/springboot/21/"},{"categories":["Spring Boot"],"content":"哈囉大家好，我是古古。\n在上一篇文章中，我們有分別介紹 @ReqestParam 和 @RequestBody 的用法，了解要如何透過 @ReqestParam 取得 url 後面的參數，以及如何透過 @RequestBody 取得 request body 中的 JSON 數據。\n那麼這篇文章，我們就會接著來介紹另外兩個取得請求參數的註解，也就是 @RequestHeader 和 @PathVariable，那我們就開始吧！\n補充：想了解 @ReqestParam 和 @RequestBody 的用法的話，可以參考上一篇文章 Day 19 - 取得請求參數（上）- @RequestParam、@RequestBody 的介紹。\n目錄 3. @RequestHeader：接住放在 request header 中的參數 在 Spring Boot 中練習 @RequestHeader 的用法 4. @PathVariable：接住放在 url 路徑中的值 在 Spring Boot 中練習 @PathVariable 的用法 使用 @PathVariable 的注意事項之一：「url 路徑」和「參數的名字」要一致 使用 @PathVariable 的注意事項之二：參數類型需一致 小結：@PathVariable 用法總結 補充：為什麼我們需要 @PathVariable？ 總結 3. @RequestHeader：接住放在 request header 中的參數 # @ReqeustHeader 的用途，就是「接住放在 request header 中的參數」。\n雖然一般在開發上，不太會使用到 request header 來傳遞一般的參數（通常只有「權限驗證」或是「通用資訊」，才會使用 request header 來傳遞），不過我們仍舊可以來看一下 @RequestHeader 的用途為何，先對這個註解有個印象。\n在 Spring Boot 中練習 @RequestHeader 的用法 # 首先因為 request header 是不論使用哪一種 Http 請求都可以添加的參數，所以換句話說畫的，即是 GET、POST、PUT、DELETE…等請求，都可以添加 request header 的通用參數。\n舉例來說，如果前端在請求時，想要在 request header 中添加參數的話，那麼就可以在 API Tester 中，先去點擊 Add header 的按鈕，這樣子就可以去添加一個新的 request header 出來。\n在點擊 Add header 按鈕之後，就會出現一對 key-value 的格子讓我們填寫（沒錯 request header 也是使用 key 和 value 的方式來存放的），因此左邊就是這個 request header 的名字（也就是 key），而右邊就是這個 header 的值（也就是 value）。\n所以像是在下圖中，info 就是這個 request header 的 key、而 hello 就是他的 value 值。\n當我們這樣填寫之後，前端到時候在請求時，就會將 info: hello 這個 request header 的 key: value 的資訊，去傳遞給後端了。\n而當前端傳遞了 request header 的資訊過來之後，如果我們想要在 Spring Boot 中去接住這個 info: hello 的 request header 的值的話，那麼我們就可以像下圖一樣，在 test3() 方法的實作中，先新增一個 String 類型的參數 info，並且在 info 前面加上一個 @RequestHeader，這樣子就可以成功的取得到前端傳遞過來的 header 的值了！\n所以如果我們實際到 Spring Boot 上練習的話，就只要在 MyController 中，新增一個新的 test3() 方法，並且在裡面寫上下列的程式，這樣就可以取得前端所傳遞過來的 header 的值。\n@RequestMapping(\u0026#34;/test3\u0026#34;) public String test3(@RequestHeader String info) { System.out.println(\u0026#34;info 的值為: \u0026#34; + info); return \u0026#34;請求成功\u0026#34;; } 實作完 MyController 之後，接著就運行一下 Spring Boot 程式。\n運行成功之後，就回到 API Tester 中，並且在 Http method 中選擇 GET 請求（其實選擇哪一種請求方法都可以，此處以 GET 為例），url 的地方填上 http://localhost:8080/test3，然後 request header 的地方新增 info: hello 這組數據，這樣就可以模擬前端的請求。\n這時當我們按下 Send 鍵之後，在右下角的 response body 中，就會出現 Spring Boot 所回傳的「請求成功」的訊息。\n而當我們回到 IntelliJ 上查看的話，在下方的 console 中，就會出現「info 的值為: hello」的字串。\n所以這就表示，我們就成功的透過 @RequestHeader，接住前端放在 request header 中所傳遞的參數了！因此大家以後就可以透過這個寫法，去取得 request header 中的參數的值了。\n4. @PathVariable：接住放在 url 路徑中的值 # 在介紹完前面三個註解 @RequestParam、@RequestBody、@RequestHeader 之後，最後我們要來介紹第四個註解，也是跟其他人長得最不一樣的註解，即是 @PathVariable（前面的註解都是以 @Request... 開頭，只有他是以 @Path... 開頭）。\n@PathVariable 的用途，就是「接住放在 url 路徑中的值」，這句話的重點在於**「url 路徑」**，這也是 @PathVariable 和其他三個註解最不一樣的地方。\n舉例來說，假設我們今天有一個 url 如下：\nhttp://localhost:8080/test4/123 在這段 url 網址中，他的 url 路徑的值為 /test4/123，而如果我們想要取得到 url 路徑 /test4/123 中的 123 的值的話，那麼就要透過 @PathVariable 來取得。\n補充：此處大家先不用思考「為什麼我們需要讀取 url 路徑中的值？」，只要先學習 @PathVariable 的使用方法就好，後續會再回頭來解釋「為什麼我們需要 @PathVariable？」以及「@PathVariable 的應用場景為何」。\n在 Spring Boot 中練習 @PathVariable 的用法 # 大概了解了 @PathVariable 的概念之後，我們也可以實際到 Spring Boot 中，來練習一下 @PathVariable 的用法。\n舉例來說，假設前端今天請求了 http://localhost:8080/test4/123 這個 url，那麼在這個 url 裡面，他的 url 路徑即是 /test4/123。\n而如果我們想要在 Spring Boot 中，去接住 url 路徑 /test4/123 中的 123 的值的話，就必須要做兩件事：\n首先我們要先修改一下 @RequestMapping 的寫法，即是將 @RequestMapping 所對應的 url 路徑，改","date":"2024-07-20","objectID":"03ee78e64ae9f5a47e6076f55f2eadd7","title":"Spring Boot 零基礎入門 (20) - 取得請求參數（下）- @RequestHeader、@PathVariable","url":"https://kucw.io/blog/springboot/20/"},{"categories":["Spring Boot"],"content":"哈囉大家好，我是古古。\n在上一篇文章中，我們先介紹了 Http method 的概念，並且也介紹了兩個常見的 Http method：GET 和 POST，分別了解他們是如何傳遞參數給後端的。\n那麼接著這篇文章，我們就會回到 Spring Boot 上，來介紹一下要如何在 Spring Boot 中，去接住前端所傳過來的這些參數的值。\n補充：不過也因為在 Spring Boot 有許多種方式可以接住前端所傳遞過來的參數，因此這裡會分成上、下兩篇文章來介紹，因此這篇文章我們就會先介紹 @RequestParam 和 @RequestBody 的用法。\n目錄 在 Spring Boot 中接住參數的四個註解 1. @RequestParam：接住添加在 url 後面的參數 在 Spring Boot 中練習 @RequestParam 的用法 使用 @RequestParam 的注意事項之一：參數名字須一致 使用 @RequestParam 的注意事項之二：參數類型需一致 小結：@RequestParam 用法總結 2. @RequestBody：接住放在 request body 中的參數 在 Spring Boot 中練習 @RequestBody 的用法 小結：@RequestBody 用法總結 總結 在 Spring Boot 中接住參數的四個註解 # 在 Spring Boot 中，有四個註解可以去接住前端傳遞過來的參數，分別是：\n@RequestParam @RequestBody @RequestHeader @PathVariable 這四個註解雖然長得有點像（都是以 @Request 開頭），但是他們功能是完全不同的！所以接下來這兩篇文章，我們就會分別來介紹這四個註解要如何使用。\n而在這篇文章中，我們就會先來介紹前兩個註解，也就是 @RequestParam 和 @RequestBody 的用法。\n1. @RequestParam：接住添加在 url 後面的參數 # 首先我們先來看第一個註解，也就是 @ReqeustParam。\n@ReqeustParam 的用途，就是「接住那些放在 url 後面的參數」，所以像是我們在上一個章節中所介紹到的 GET 請求，就是會把請求參數放在 url 的最後面來傳遞：\n因此當前端使用 GET 來請求時，我們就可以在 Spring Boot 中寫上 @ReqeustParam，去接住前端所傳遞過來的參數（query parameter）。\n在 Spring Boot 中練習 @RequestParam 的用法 # 大概了解了 @ReqeustParam 的概念之後，我們也可以實際到 Spring Boot 上來練習一下 @ReqeustParam 的用法。\n舉例來說，當前端使用 GET 來請求、並且在 url 的最後面加上了一個 id=123 的參數時，那麼前端的實際請求就會如下圖所示：\n而這個時候，如果我們想要在 Spring Boot 中去接住 id=123 的參數的話，那我們就可以像下圖一下，先在 test1() 方法中，新增一個 Integer 類型的參數 id，並且在 id 的前面加上一個 @RequestParam，這樣子就可以成功的取得到前端傳遞過來的 id=123 的值了！\n所以如果我們實際到 Spring Boot 上練習的話，就只要改寫一下 MyController，將他改成下面的程式：\n@RestController public class MyController { @RequestMapping(\u0026#34;/test1\u0026#34;) public String test1(@RequestParam Integer id) { System.out.println(\u0026#34;id 的值為: \u0026#34; + id); return \u0026#34;請求成功\u0026#34;; } } 寫上上述的程式之後，就可以運行一下 Spring Boot 程式。\n運行成功之後回到 API Tester 上，接著在 Http method 中選擇 GET 請求，url 填上 http://localhost:8080/test1?id=123，這樣子就可以模擬前端的請求。\n因此當我們按下 Send 鍵之後，在右下角的 response body 中，就會出現 Spring Boot 所回傳的「請求成功」的訊息。\n此時當我們回到 IntelliJ 上查看的話，在下方的 console 中，就會出現「id 的值為: 123」的字串。\n所以這就表示，我們就成功的透過 @RequestParam，接住前端放在 url 中所傳遞的參數了！\n使用 @RequestParam 的注意事項之一：參數名字須一致 # 在使用 @RequestParam 去接住 url 後面的參數時，首先有一個重點需要注意，就是在 Spring Boot 中的「變數的名字」，必須要和「url 中的參數的名字」一樣才可以。\n舉例來說，假設 url 中所添加的參數是 id=123，那麼在 Spring Boot 所使用的參數名字，就必須也是 id；又或是說假設 url 中添加的是 name=Judy，那麼在 Spring Boot 中所使用的參數名字，就必須是 name。\n假設參數名字不一致的話，@RequestParam 是沒有辦法成功取得到 url 中的參數的，因此大家在使用上，就要特別注意這兩個地方的名字一定要一致才可以！\n補充：如果真的發生參數名字不一樣的情況出現，那麼透過一些額外的設定，其實也是可以讓 @RequestParam 生效的。\n舉例來說，假設前端傳遞的參數為 myId=123，但是如果想要在 Spring Boot 上使用 id 來接住這個 myId 的參數的話，那麼就要改寫成 @RequestParam(name = \u0026quot;myId\u0026quot;) Integer id) 的寫法（也就是在 @RequestParam 後面多加上了 (name = \u0026quot;myId\u0026quot;) 的額外設定），這樣子才能夠將前端的 myId 對應到 Spring Boot 中的 id 參數。\n不過雖然 @RequestParam 有支援這種特殊的設定，但一般在實作上，還是會建議大家盡量讓「前端傳遞的參數」和「Spring Boot 中使用的參數名稱」一致，這樣子就不用多寫額外的程式來轉換，實作上也比較直覺方便，比較不會出問題。\n使用 @RequestParam 的注意事項之二：參數類型需一致 # 使用 @RequestParam 去接住 url 參數的第二個重點，就是「參數的類型需要一致」。\n舉例來說，假設前端在 url 中所添加的參數是 id=123，那麼就是在暗示這個 id 的值是一個整數，因此我們在 Spring Boot 中，就需要將該參數宣告為 Integer 類型或是 int 類型，這樣才能成功接住前端所傳過來的參數。\n又或是前端在 url 中所添加的參數是 name=Judy，那麼就是在暗示這個 name 參數的值是一個字串，因此我們在 Spring Boot 中，就需要將該參數宣告為 String 類型，這樣也才能成功接住前端所傳過來的參數。\n因此只有當類型一致時，Spring Boot 才有辦法成功的接住該參數，將該參數的值給轉換過來，否則的話 Spring Boot 可是會出錯的！會回傳一個請求失敗的資訊給前端。\n小結：@RequestParam 用法總結 # 綜合以上的介紹，我們可以先做個 @RequestParam 的用法總結。\n@Req","date":"2024-07-19","objectID":"1eeb69c6fce6b7717d562ff1753f8c9e","title":"Spring Boot 零基礎入門 (19) - 取得請求參數（上）- @RequestParam、@RequestBody","url":"https://kucw.io/blog/springboot/19/"},{"categories":["Spring Boot"],"content":"哈囉大家好，我是古古。\n在前面的文章中，我們有介紹了 Spring MVC 的 @RequestMapping 和 @RestController 的用法，所以我們現在已經可以接住前端傳過來的請求，並且也能夠回傳 JSON 格式的數據給前端了。\n那麼這篇文章，我們就會回頭來探索 Http 協議中的其他部分，因此這篇文章我們就先來介紹一下，Http method 是什麼，以及常見的 Http method 有哪些。\n目錄 回顧：什麼是 Http Method？ GET 的用法和特性 POST 的用法和特性 GET 和 POST 的比較 總結 回顧：什麼是 Http Method？ # 在一個 Http reqeust 中，我們除了一定要填上 url 之外，另一個必填的資訊，就是 Http method。\n而 Http method 所表示的，是這一次請求所使用的「請求方法」，他的值有好幾種可以選，像是 GET、POST、PUT、DELETE…等等，不同的請求方法，會有不同的特性。\n而在這篇文章中，我們會來介紹最廣泛使用的兩個 Http method，也就是 GET 和 POST 的用法。\nGET 的用法和特性 # GET 是最常使用的 Http Method，大家可以把 GET 想像成是「明信片」的概念，所以換句話說，就是 「當你使用 GET 來請求時，你所傳遞的參數就會被別人看見」。\n補充：前端在發起 Http request 時，也是可以「傳遞參數」給後端的，就像是 Java 中的方法一樣，方法和方法之間是可以傳遞參數的。在前面的文章中我們還沒介紹到「傳遞參數」的實作方式，從這篇文章開始就會介紹到這部分。\n也因為當前端使用 GET 來請求時，他所傳遞的參數是完全公開、可以被大家所看見的，因此這就像是明信片一樣，你所寫的信件內容全部都會被大家所看見，所以才會說 GET 是明信片的概念。\n以下面這張圖為例，當我們使用 GET 來請求時，如果我們想要傳遞參數的話，那就只能夠在 url 的最後面，寫上 id=123\u0026amp;name=Judy 的字串，表示我們要傳遞兩個參數， 一個是「id 為 123」，另一個則是「name 為 Judy」。\n而在撰寫 GET 請求的參數時，有兩個重點要注意：\n參數以 key=value 的格式來撰寫，像是 id=123 就是表示「id 的值為 123」的意思 參數之間要用 \u0026amp; 隔開，像是在上面的例子中，在 id=123 這組參數後面，就要先寫上一個 \u0026amp;，後面才可以寫上下一組參數 name=Judy 另外這種「添加在 url 後面的參數們」，我們會稱呼這些參數為「query parameter」，因此在上圖中的 id=123\u0026amp;name=Judy，他們就稱為是 query parameter。\n所以總結來說，當前端使用 GET 來請求時，前端就必須將參數（query parameter）添加在 url 的最後面，同時也因為 url 是公開的、所有人都能看見，因此當前端使用 GET 來請求時，他所傳遞的參數就會被別人看見，所以 GET 也被稱為是「明信片」的概念。\nPOST 的用法和特性 # 了解了 GET 的用法之後，接下來我們也可以來看一下 POST 的用法和特性。\nPOST 作為也很常使用的 Http method 之一，他就和 GET 完全不一樣了！大家可以把 POST 想像成是「信封」的概念，因此「當你使用 POST 方法時，你所傳遞的參數就可以隱藏起來，不被別人看見」。\nPOST 之所以可以隱藏參數，就是因為在使用 POST 請求時，前端要將「參數放在 request body 中傳遞」，並且 request body 在傳遞的過程中會整個被封裝起來，不會被別人看見，因此放在裡面的參數就不會洩漏，所以才會說 POST 是信封的概念（因為請求的參數不會被別人看見）。\n舉例來說，當我們使用 POST 來請求時，就可以使用 JSON 格式，將「id 的值為 123、name 的值為 Judy」的資訊，放在 request body 中來傳遞：\n因此當前端使用 POST 來請求時，前端就可以將參數放在 request body 中來傳遞，又因為 request body 在傳遞的過程中是封裝起來、不會被別人看見的，因此當前端使用 POST 來請求時，他所傳遞的參數就可以隱藏起來，不被其他人看見，所以 POST 也被稱為是「信封」的概念。\n補充：透過上面的例子也可以發現一個亮點，就是在 request body 中的參數，通常都是用 JSON 格式來撰寫的！所以學好 JSON 格式真的很重要啊！！他在使用上非常廣泛，在各個地方都可以看到 JSON 的身影。\n如果不熟悉 JSON 用法的話，也可以回頭參考 Day 16 - 結構化的呈現數據 - JSON 格式介紹 的介紹。\nGET 和 POST 的比較 # 所以總結上面的介紹的話，我們可以將 GET 和 POST 的特性整理成下面這張表格：\nGET POST 概念 明信片 信封 用途 將參數添加在 url 後面傳遞 將參數放在 request body 中來傳遞（使用 JSON 格式） 參數可見度 所有人都能看到參數的資訊，安全性較低 參數是不公開的，其他人看不見傳遞的參數，安全性較高 因此後續我們就可以在不同的時機點，使用較適合當前情況的請求方式了。\n總結 # 這篇文章我們介紹了 Http method 中常用的兩個 method：GET 和 POST，並且也介紹了他們在傳遞參數之間的差別。\n在了解了 GET 和 POST 傳遞參數的差別之後，接著下一篇文章，我們就會回到 Spring Boot 上，來介紹要如何在 Spring Boot 中，去接住前端傳遞過來的參數，那我們就下一篇文章見啦！\n補充：本文是擷取自我開設的線上課程 Java 工程師必備！Spring Boot 零基礎入門 的內容，如果你想了解更多的 Spring Boot 的用法，歡迎參考課程簡介 （輸入折扣碼「HH202601KU」即可享 85 折優惠）。\n","date":"2024-07-18","objectID":"b8f0882e76131c5152920dbdc97aad40","title":"Spring Boot 零基礎入門 (18) - 常見的 Http method - GET 和 POST","url":"https://kucw.io/blog/springboot/18/"},{"categories":["Spring Boot"],"content":"哈囉大家好，我是古古。\n在上一篇文章中，我們有介紹了 JSON 格式的寫法，所以之後我們就可以使用 JSON 格式，更簡單直覺的去呈現數據，進而提升前後端溝通的效率了。\n那麼接著的這篇文章，我們就會回到 Spring Boot 程式中，來看一下要如何將 MyController 所回傳的值，改成是以 JSON 的格式來返回，讓前端能夠取得到 JSON 格式的數據。\n目錄 回顧：到目前為止的返回數據 如何將 Spring Boot 的返回值轉換成 JSON 格式？ 步驟一：在 class 上面加上 @RestController 步驟二：將該方法的返回值，改成是「Java 物件」 小結：將 Spring Boot 的返回值轉換成 JSON 格式的步驟 補充：@Controller 和 @RestController 的差別在哪裡？ 總結 回顧：到目前為止的返回數據 # 在上兩篇文章中，我們有在 MyController 中添加了一個新的 product() 方法，並且為他添加對應的 url 路徑 /product，程式如下：\n所以目前當前端去請求 http://localhost:8080/product 時，後端的 Spring Boot 程式就會在 response body 中，返回「第一個是蘋果，第二個是橘子」的數據給前端。\n不過在我們了解了 JSON 格式的寫法之後，我們現在就可以將「第一個是蘋果，第二個是橘子」這種人類語言的句子，改成是以下列的 JSON 格式來撰寫：\n{ \u0026#34;productList\u0026#34;: [\u0026#34;蘋果\u0026#34;, \u0026#34;橘子\u0026#34;] } 因此在這篇文章中，我們的目標，就是要去修改 MyController 中的 product() 方法，將他的 return 返回值，從「第一個是蘋果，第二個是橘子」改成是返回上面的 JSON 格式的數據，這樣子才能夠成功的返回 JSON 格式的數據給前端。\n如何將 Spring Boot 的返回值轉換成 JSON 格式？ # 如果我們想要將 Spring Boot 程式中的某個方法，將他的返回值改成是以 JSON 格式來傳遞的話，那麼就需要兩個步驟：\n在該 class 上面加上 @RestController 將該方法的返回值，改成是「Java 中的物件」 只要完成了這兩個步驟，就可以改成用 JSON 格式去返回數據給前端了！\n步驟一：在 class 上面加上 @RestController # 在 Spring MVC 中，有一個非常厲害的註解 @RestController，他可以說是集多功能於一身的超強註解！只要在某個 class 上面加上 @RestController 之後，那麼就可以達到以下的效果：\n使這個 class 成為一個 Bean 讓該 class 中的 @RequestMapping 能夠生效 能夠將返回值自動轉換成 JSON 格式 因此 @RestController 在使用上可以說是非常的方便，一箭三鵰！\n而如果我們回頭看一下之前所寫的程式，其實我們已經有在 MyController 中添加 @RestController 這個註解了：\n所以其實到目前為止，我們已經完成了第一個步驟，也就是在 class 上添加 @RestController 了！\n步驟二：將該方法的返回值，改成是「Java 物件」 # 而當我們有在 class 上加上 @RestController 之後，那麼下一步，就是要將這個方法的返回值，改成是「Java 物件」。\n這裡的運作邏輯是這樣的：首先 Spring Boot 程式會將 Java class 中的變數，一一的去轉換成 JSON 格式中的 key，並且該 key 的 value 值，就是 Java class 中的變數所儲存的值。\n這個聽起來可能有點複雜，所以下面我們就透過一個例子，來了解一下他的運作邏輯。\n舉例來說，假設我們有一個 Student class，他裡面有兩個變數：一個是 Integer 類型的變數 id、另一個是 String 類型的變數 name，並且在這個 class 中，也有實作這兩個變數各自的 getter() 和 setter() 方法。\npublic class Student { private Integer id; private String name; public Integer getId() { return id; } public void setId(Integer id) { this.id = id; } public String getName() { return name; } public void setName(String name) { this.name = name; } } 此時，如果我們改寫一下 MyController 中的 test() 方法，將他的返回值，改成是回傳 Student 類型的話：\n@RequestMapping(\u0026#34;/test\u0026#34;) public Student test() { Student student = new Student(); student.setId(123); student.setName(\u0026#34;Judy\u0026#34;); return student; } 那麼這個時候，當前端來請求 http://localhost:8080/test 時，Spring Boot 就會執行第 11～14 行的程式，最終去回傳一個 student 物件給前端。\n而在 Spring Boot 在回傳 student 物件給前端時，Spring Boot 就會將這個 student 物件，先去轉換成 JSON 格式，最後才回傳給前端，因此前端最終所收到的結果，就會是 JSON 格式的數據了！\n所以透過這個邏輯，我們就可以用一樣的方式去改寫 product() 方法，將他的返回值，從 String 類型改為是其他的 Java 物件，這樣子就可以回傳 JSON 格式的數據給前端了！\n因此我們可以先去創建一個新的 class，該 class 的名字為 Store，並且其中的程式如下：\npublic class Store { public List\u0026lt;String\u0026gt; productList; public List\u0026lt;String\u0026gt; getProductList() { return productList; } public void setProductList(List\u0026lt;String\u0026gt; productList) { this.productList = productList; } } 接著我們用一樣的邏輯，回頭改寫一下 product() 方法，所以我們先將返回的類型改成是 Store，並且將「蘋果」和「橘子」這兩個值，添加到 store 中的 productList 變數裡面：\n@RequestMapping(\u0026#34;/product\u0026#34;) public Store product() { Store store = new Store(); List\u0026lt;String\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); list.add(\u0026#34;蘋果\u0026#34;); list.add(\u0026#34;橘子\u0026#34;); store.setProductList(list); return store; } 因此後續當前端來請求 http://localhost:8","date":"2024-07-17","objectID":"1c96e5f4bb7861d4e0e5dab6ff6aaf62","title":"Spring Boot 零基礎入門 (17) - 返回值改成 JSON 格式 - @RestController","url":"https://kucw.io/blog/springboot/17/"},{"categories":["Spring Boot"],"content":"哈囉大家好，我是古古。\n在上一篇文章中，我們有去要如何使用 @RequestMapping，將 url 路徑對應到 Spring Boot 程式的方法上。\n那麼這篇文章，我們就接著來介紹，要如何透過 JSON 格式，結構化的去呈現返回給前端的數據。\n目錄 回顧：到目前為止的返回數據 什麼是 JSON？ JSON 格式介紹 使用 {} 表示 object（物件） Key 和 Value 的概念 新增多組 Key-Value 使用 JSON 的注意事項 JSON 格式所支援的類型 補充：JSON 中的 List 概念 最後，讓我們回到最一開始的問題 總結 回顧：到目前為止的返回數據 # 在上一篇文章的最後面，我們有添加了一個新的 product() 方法，並且為他添加對應的 url 路徑 /product，程式如下：\n如果我們觀察一下的話，可以發現在這個 product() 方法中，他的 return 返回值是使用「字串」來表達「第一個是蘋果、第二個是橘子」的資訊，而這其實是非常人類語言的表達方式，因此對於電腦的程式語言來說，是很難辨別的。\n所以為了讓程式語言可以更有效率的讀取數據、呈現數據，因此 JSON 這個格式就被發明出來了！\n什麼是 JSON？ # JSON 是一種數據呈現的格式，而他的目的，就是用「更簡單、更直覺的方式去呈現數據」，因此當我們使用了 JSON 之後，就可以在前後端之間更有效率的傳遞數據，所以就不用再和上面一樣，藥用人類的語言去形容複雜的數據了。也因為 JSON 格式的應用非常廣泛，因此熟練掌握 JSON 格式的應用，可以說是對實務上非常有幫助！\n舉例來說，當我們使用了 JSON 之後，就可以將「我的學號是 123，名字是 Judy」這句話，改成用下面的 JSON 格式來呈現：\n{ \u0026#34;id\u0026#34;: 123, \u0026#34;name\u0026#34;: \u0026#34;Judy\u0026#34; } JSON 格式介紹 # 大概了解了 JSON 的好處之後，接下來我們也可以來看一下，要如何才能撰寫出 JSON 格式的數據。\n使用 {} 表示 object（物件） # 首先在 JSON 格式中，可以使用一組大括號 {} 來表示一個 object（物件），譬如說當我們寫出下面這一段 JSON 格式的數據時，就表示我們 new 出了一個 object：\n{ //.... } Key 和 Value 的概念 # 而在寫好一對大括號 {} 之後，我們就可以在大括號 {} 裡面，去定義「key 和 value 的配對」，這個 key 的地位就等同於是去宣告一個 Java 中的變數，而 value 就是去設定這個變數的值。\n舉例來說，假設我們在大括號裡面加上一行程式 \u0026quot;id\u0026quot;: 123，就表示我們去創建了一組 key-value 的配對，其中 key 就是 id，而 value 就是冒號右邊的 123。\n{ \u0026#34;id\u0026#34;: 123 } 所以在上面這行程式中，\u0026quot;id\u0026quot;: 123 就是表示「有一個變數 id，他的值為 123」的意思。\n所以在 JSON 格式中，我們就可以透過 key-value 的寫法，去新增許多組 key-value 出來了。\n新增多組 Key-Value # 延續上面的例子，現在在 JSON 的大括號中，我們已經寫上一組 \u0026quot;id\u0026quot;: 123 的 key-value 了，而 \u0026quot;id\u0026quot;: 123 所表達的邏輯意義，就是「我的 id 的值為 123」的意思。\n如果這時候，我們想要在大括號中再去新增一組 key-value 的話，那首先我們就要先在 \u0026quot;id\u0026quot;: 123 的後面加上一個逗點 ,，接著換行，然後輸入第二組 key-value 配對的值，譬如說寫上 \u0026quot;name\u0026quot;: \u0026quot;Judy\u0026quot;，用來表示「我的名字為 Judy」。\n{ \u0026#34;id\u0026#34;: 123, \u0026#34;name\u0026#34;: \u0026#34;Judy\u0026#34; } 所以在上面這個寫法中，\u0026quot;name\u0026quot;: \u0026quot;Judy\u0026quot; 中的 key 就是 name，表示我們創建了一個變數叫做 name，然後這個 name 變數的值，就是冒號右邊的 Judy。因此我們就可以用 \u0026quot;name\u0026quot;: \u0026quot;Judy\u0026quot; 這一行寫法，去表達「我的名字為 Judy」的意義。\n而當我們實作到這裡，如果現在回頭看這整個 JSON 的話，目前在這整個 JSON 裡面就表達了兩個資訊，分別是 \u0026quot;id\u0026quot;: 123（我的 id 為 123），以及 \u0026quot;name\u0026quot;: \u0026quot;Judy\u0026quot;（我的名字為 Judy）這兩個意義了！\n因此透過 JSON 格式的寫法，就可以用更簡單的結構去呈現數據，因此就可以簡化開發，進而提升前後端溝通的效率了！\n使用 JSON 的注意事項 # 在使用 JSON 時，有一個很重要的注意事項要留意，就是 「在 JSON 中的所有 key，都必須要加上雙引號 \u0026quot; \u0026quot; 來框住才可以」。\n像是在我們前面所撰寫的 JSON 例子，就有在 id 和 name 這兩個 key 的前後，使用一對雙引號，把這個 key 給框起來：\n{ \u0026#34;id\u0026#34;: 123, \u0026#34;name\u0026#34;: \u0026#34;Judy\u0026#34; } 這個是在撰寫 JSON 格式時，一定要注意的細節！因此大家後續在實作上，就要多加小心這個部分。\nJSON 格式所支援的類型 # 透過上述的介紹，現在我們知道，在 JSON 中是會透過 key-value 的配對，去創建許多組的變數和他對應的值的。\n而在這些值中，JSON 支援以下幾種類型，分別是：\nJSON 支援的類型 例子 整數 \u0026quot;id\u0026quot;: 123 浮點數 \u0026quot;score\u0026quot;: 1.111 字串 \u0026quot;name\u0026quot;: \u0026quot;Hello\u0026quot; Boolean \u0026quot;option\u0026quot;: true List \u0026quot;list\u0026quot;: [1, 2, 3] 因此大家在使用上，就可以根據不同的需求，去為 key 設定不同類型的 value 值了。\n補充：JSON 中的 List 概念 # 在 JSON 中，value 的值除了可以使用基本類型的整數、浮點數、字串\u0026hellip;等之外，value 的值也是可以設定成一個 List 的，因此我們就可以像 Java 一樣，在 List 裡去添加許多值（用法類似於 Java 中的 List）。\n而要在 JSON 中創建一個 List 的話，就只要寫上一對中括號 []，這樣就可以創建一個 List 出來了，因此我們後續就可以在這個 List 裡面，去填上我們想要放的內容了。\n舉例來說，當我們寫出下面這個 JSON 格式時：\n{ \u0026#34;appleList\u0026#34;: [\u0026#34;apple1\u0026#34;, \u0026#34;apple2\u0026#34;, \u0026#34;apple3\u0026#34;] } 就表示我們去定義了一個 key 叫做 appleList，並且這個 appleList 所對應的 value 值為 List 類型，同時在這個 List 裡面，我們就存放了 3 個值，分別是 apple1、apple2、以及 apple3。\n所以透過這一行 \u0026quot;appleList\u0026quot;: [\u0026quot;apple1\u0026quot;","date":"2024-07-16","objectID":"fb3cb52e0e4aa12ea4c7e12045b793bf","title":"Spring Boot 零基礎入門 (16) - 結構化的呈現數據 - JSON 格式介紹","url":"https://kucw.io/blog/springboot/16/"},{"categories":["Spring Boot"],"content":"哈囉大家好，我是古古。\n在上一篇文章中，我們先介紹了 Http 協議的用途，也介紹了 Http request 和 Http response 的格式規範，並且也有實際到 API Tester 中，練習去發起一個 Http request、以及查看 Http response 的返回值。\n那麼這篇文章，我們就會回到 Spring MVC 中，來介紹要如何使用 @RequestMapping，將 url 路徑對應到 Spring Boot 程式的方法上。\n目錄 回顧：什麼是 Http 協議？ 什麼是 Url？ Url 的格式規範 1. 使用的協議 2. 域名 3. Port（端口） 4. url 路徑 Url 的例子分析 例子一：YouTube 的 url 分析 例子二：Instagram 的 url 分析 Url 路徑對應：@RequestMapping 使用 @RequestMapping 的注意事項：一定要在 class 上加上 @Controller 或是 @RestController 在 Spring Boot 中練習 @RequestMapping 的用法 練習 @RequestMapping 的用法 新增一個 url 路徑對應 總結 回顧：什麼是 Http 協議？ # 在我們開始介紹 @RequestMapping 的用法之前，我們先回顧一下 Http 協議的用途是什麼。\nHttp 協議的目的，是去「規定資料的傳輸格式，讓前端和後端能夠有效的進行資料溝通」，因此前後端就必須要按照 Http 協議的規定，去傳輸資料給對方。\n而在 Http 協議中，可以分為 「Http Request（請求）」 和 「Http Response（回應）」 兩個部分，而一個 Http request 加上一個 Http response，就可以組合成一次完整的 Http 溝通。\n另外 Http request 和 Http response 在使用上，也是有固定的格式規範的，具體的格式可以參考下面這張圖：\n在大概了解了 Http request 和 Http response 之後，那麼這篇文章要介紹的，就是 Http request 中的 url 的部分。\n什麼是 Url？ # 當我們發起一個 Http request 時，我們需要指定 url 的值，才能夠告訴 API Tester，這一次的請求要發送到哪裡去。\n而這個 url，其實就是我們平常在使用瀏覽器時，在上方網址列中會出現的這一串文字，也就是一般所俗稱的「網址」。\n所以其實我們在日常生活中，是很常去使用 url 的！不過 url 在使用上，也是有固定的格式規範要遵守的，因此接下來我們就來看一下，url 的格式規範為何。\nUrl 的格式規範 # Url 本身其實是可以拆解成許多部分，譬如說以我們在前面的文章中常常輸入的網址 http://localhost:8080/test 為例，這個 url 其實是由以下幾個部分所組成：\n1. 使用的協議 # 首先在 url 的最前面，就會呈現這個 url 所使用的協議是什麼。\n像是在這個例子中，我們所使用的就是「Http 協議」。\n2. 域名 # 在協議的後面，會有一個 :// 做為分隔，接著後面所寫上的就是這個 url 的「域名」。\n像是在上面的例子中，這個 url 的域名就是「localhost」。\n3. Port（端口） # 而在域名的後面，就是這個 url 所使用的 port（端口）。如果在域名的後面有加上一個 :，並且在 : 後面有加上一個數字的話，那這個數字就是 url 所使用的 port。\n所以像是在上面的例子中，因為在 : 後面有寫上 8080，因此就表示這個 url 所使用的 port 為 8080。\n不過在某些情況下，port 有時候可以省略不用寫，所以大家有時候在某些 url 中會看到 port、有時候又看不到，這個是正常的現象。\n補充：port 的概念稍微進階一點，因此建議大家先有個印象就好，基本上在這個系列文中不會再對 port 有更多的深入介紹，因此大家就只要先知道有這個東西存在即可。\n4. url 路徑 # 而在 port 之後的東西，就非常重要了！！\n當我們在 port 的後面，再加上一個斜線 / 之後（或是沒有 port 的話，就是在域名後面的斜線 /），從這個斜線 / 之後的所有東西，就是這個 url 的路徑。\n因此像是在上面的例子中，url 路徑的值就是 /test。\nurl 路徑的概念非常重要，他會決定這個 url 最終要去對應到 Spring Boot 程式中的哪一個方法上，因此大家在開發 Spring Boot 程式之前，一定要先搞懂「url 路徑」是位於整條 url 中的哪個部分，這樣子後續在實作 Spring Boot 程式時，才能夠更清楚了解他們之間的對應關係。\nUrl 的例子分析 # 因為 url 路徑實在是太重要了，他是在實務上使用頻率非常高的一項技術，因此這邊我們就多舉幾個例子，來讓大家更了解 url 路徑的計算方式。\n例子一：YouTube 的 url 分析 # 舉例來說，如果有一個 YouTube 的 url 如下：\nhttps://www.youtube.com/channel/UC3yK8-EsoU7vZNiLnuep1tQ/videos\n那麼這一條 url，就可以拆分成下圖所示，所以 url 路徑的值就會是 /channel/UC3yK8-EsoU7vZNiLnuep1tQ/videos。\n例子二：Instagram 的 url 分析 # 再舉一個例子，假設有另一個 Instagram 的 url 如下：\nhttps://www.instagram.com/p/CHNDtIVl_BS\n那麼這一條 url 就可以拆分成如下圖所示，所以 url 路徑的值就會是 /p/CHNDtIVl_BS。\nUrl 路徑對應：@RequestMapping # 在了解了 url 的格式規範、以及了解如何「計算 url 的路徑」之後，那麼我們就可以進到這篇文章的重頭戲，也就是來介紹要如何使用 @RequestMapping，將 url 路徑對應到 Spring Boot 程式的方法上了。\n所以回到我們最一開始的例子（也就是 http://localhost:8080/test），對於這個 url 來說，他的 url 路徑就是最後面的 /test。\n如果我們想要將這個 /test 的 url 路徑，去對應到 Spring Boot 的方法上的話，那我們就只要使用 @RequestMapping 這個註解就可以達成了！\n舉例來說，當我們在 MyController 中的 test() 方法上：\n先加上 @RequestMapping 並且在後面的小括號中，指定 url 路徑的值為 /test 只要完成上面這兩個步驟，就可以將 url 路徑 /test，去對應到下面的 test() 方法上了！！\n所以這時候，當前端發出一個 Http request、並且他的 url 路徑為 /test 時，那麼 Spring Boot 就會去找到這個 @RequestMapping(\u0026quot;/test\u0026quot;) 這一行程式，並且去執行他下面的 test() 方法了，所以這個就是「url 路徑的對應」，也就是 @RequestMapping 的運作邏輯了！\n使用 @RequestMapping 的注意事項：一定要在 class 上加上 @Controller 或是 @RestController # 在使用 @RequestMapping 去對應 url 的路徑","date":"2024-07-15","objectID":"6ba5ff7e82c1ba0dfa8f400574d64b1d","title":"Spring Boot 零基礎入門 (15) - Url 路徑對應 - @RequestMapping","url":"https://kucw.io/blog/springboot/15/"},{"categories":["Spring Boot"],"content":"哈囉大家好，我是古古。\n在前一篇文章中，我們先介紹了 Spring MVC 的用途是什麼，先讓大家對 Spring MVC 有一個簡單的認識。\n不過在我們開始介紹 Spring MVC 之前，會需要大家先對前後端溝通的協議有一些基本的認識，因此這篇文章，我們就會先來介紹前後端溝通最基礎的部分，也就是「Http 協議」。\n目錄 什麼是 Http 協議？ Http 協議的定義 Http Request（Http 請求）的格式規範 Http method 介紹 Url 介紹 Request header 介紹 Request body 介紹 Http Response 的格式規範 Http status code 介紹 Response header Response body 在 API Tester 中練習發起 Http request、查看 Http response API Tester 介面導覽 在 API Tester 中發起一個 Http request 在 API Tester 中查看 Http response 補充：發起 Http request 的工具 總結 什麼是 Http 協議？ # 所謂的「Http 協議」，就是「負責去規定資料的傳輸格式，讓前端和後端能夠有效的進行資料溝通」，所以換句話說，Http 協議就是訂定規則的裁判，只要前後端想要透過 Http 協議溝通，那就必須得按照 Http 協議的規則來走。\n舉例來說，像是 Http 協議可能會規定，當前後端在溝通時，每一句話都要加上「您好」，所以前後端的溝通就會變成這樣：\n前端會說：「您好，我想要商品列表」 接著後端會說：「您好，第一個是蘋果，第二個是橘子」 所以 Http 協議的用途，就是去「規範前後端溝通的格式」，因此前後端在溝通時，就會照著 Http 協議所定義的格式走，這樣子就可以讓前後端溝通的格式變得更規範，進而提升溝通效率了！\nHttp 協議的定義 # 大概了解了 Http 協議的概念之後，接著我們可以回頭來看一下 Http 協議的定義。\n所謂的「Http 協議」，就是「負責去規定資料的傳輸格式，讓前端和後端能夠有效的進行資料溝通」，因此前後端就必須要按照 Http 協議的規定，去傳輸資料給對方。\n而在 Http 協議中，可以分為 「Http Request（請求）」 和 「Http Response（回應）」 兩個部分，而一個 Http request 加上一個 Http response，就可以組合成一次完整的 Http 溝通。\n舉例來說：\n當前端向後端詢問：「我想要商品列表」時，這就是一個 Http request（也稱為 Http 請求） 當後端回應前端：「第一個是蘋果，第二個是橘子」時，這就是一個 Http response（也稱為 Http 回應） 而「一個 Http request + 一個 Http response」，就構成了一次完整的 Http 溝通，所以換句話說的話，就是前後端之間有來有往，這樣子就是一次完整的 Http 溝通了。\n當大家了解了 Http request 和 Http response 之間的運作邏輯之後，接著我們就可以詳細的來介紹一下，有關 Http request 和 Http response 的格式規範了！\nHttp Request（Http 請求）的格式規範 # 在一個 Http request 中，可以分成四個部分，分別是：\nHttp method Url Request header Request body 以下我們就分別來介紹一下，每個部分所代表的含義是什麼。\nHttp method 介紹 # Http method 所表示的，是這個 Http request 所使用的 「請求方法」。\nHttp method 有多種值可以選，像是常用的有 GET、POST、PUT、DELETE……等等，不同的請求方法會有不同的特性。\n在後續的文章中，我們會再對常見的兩個 Http method：GET 和 POST，進行更完整的介紹。\nUrl 介紹 # Url 所表示的，其實就是這個網站的網址，也就是會出現在瀏覽器上方網址列中的那一串文字。\nRequest header 介紹 # Request header 主要是放一些請求時的通用資訊，這部分相對比較進階，所以大家可以先略過這部分沒關係。\nRequest body 介紹 # Request body 的用途，是用來 「傳遞請求的參數」，並且只有在使用 POST 或是 PUT 這類的請求方法時，才可以使用 request body 來傳遞參數。\n這部分一樣是會在後續的文章中做更詳細的介紹，所以大家這邊只要先有個概念就可以了。\nHttp Response 的格式規範 # 看完了 Http request 的格式之後，接著我們也可以來看一下 Http response 的格式。\n在一個 Http response 裡面，則是會分成三個部分，分別是：\nHttp status code Response header Response body 以下也是來針對每一個部分，介紹他們所代表的含義是什麼。\nHttp status code 介紹 # Http status code 的中文翻譯為「Http 狀態碼」，用途是表達「這一次 Http 請求的結果為何」。\n譬如說在這次的 Http status code 裡面，如果顯示的是「成功」的狀態碼的話，那就表示這一次 Http 請求成功了；相反的，如果 Http status code 呈現的是「失敗」的狀態碼的話，那就表示這一次的 Http 請求失敗了。\n因此大家可以把這個 Http status code，想像成是一個 「快速確認次 Http 請求是成功還是失敗」 的依據，透過 Http status code，我們就可以快速的判斷這一次的 Http 請求到底是成功還是失敗，進而去執行後續的處理了。\n有關 Http status code 中常見的狀態碼，我們一樣是會在後續的文章中做更詳細的介紹，所以大家一樣先有個概念即可。\nResponse header # Response header 和上面的 Request header 類似，都是放一些通用的資訊，因為他也是屬於比較進階的部分，因此大家也是可以先略過這部分沒關係。\nResponse body # Response body 可以說是在 Http response 中最重要的部分！在 Response body 中所放的，就是「後端要回傳給前端的數據」。\n因此當前端收到了一個 Http response 時，如果這一次的請求是成功的話，前端就會去取得 Response body 中的數據，並且前端會將這些數據，去和前端的排版設計結合在一起，最終就可以呈現完整的網頁給使用者了！\n有關 Response body 的部分，我們也是會在後續的文章中詳細介紹他的用法，因此大家現在只要先知道 Response body 很重要就可以了。\n在 API Tester 中練習發起 Http request、查看 Http response # API Tester 介面導覽 # 了解了 Http request（Http 請求）和 Http response（Http 回應）的格式之後，接著我們也可以實際到 API Tester 中，來練習一下要如何發起一個 Http request。\n補充：此處提到的 API Tester，指的就是我們當初在 Day 2 - 開發環境安裝（Mac 版） 和 Day 3 - 開發環境安裝（","date":"2024-07-14","objectID":"4607b08045e91a80e7b9a3ae73f2aa91","title":"Spring Boot 零基礎入門 (14) - Http 協議介紹","url":"https://kucw.io/blog/springboot/14/"},{"categories":["Spring Boot"],"content":"哈囉大家好，我是古古。\n在前面的文章中，我們介紹了 Spring 框架中最重要的兩個特性：IoC 和 AOP，所以到目前為止，大家對於 Spring Boot 的基本用法，就不會那麼陌生了。\n那麼從這篇文章開始，就會進入到下一個部分，也就是 Spring MVC 的介紹，Spring MVC 可以說是在 Spring Boot 中使用最頻繁的功能之一，所以我們就開始吧！\n目錄 回顧：前端和後端的差別 什麼是 Spring MVC？ 補充：原來我們已經用過 Spring MVC 了？ 總結 回顧：前端和後端的差別 # 在我們正式介紹 Spring MVC 之前，我們可以先來回顧一下「前端」和「後端」之間的差別。\n在現今的網站架構中，可以分成「前端」和「後端」兩部分：\n在現今的網站架構中，可以分成「前端」和「後端」兩部分：\n前端：負責網頁的排版設計。 所以像是網頁中要使用什麼顏色的按鈕、按鈕要放在哪裡、標題大小要多大…等等，這些都是屬於前端的範疇。 後端：負責數據處理。 所以像是商品的價格是多少、每一筆評價的留言內容是什麼…等等，這些有關數據內容的，都是屬於後端的範疇。 所以簡單來說，前端工程師就是去負責實作「這個網頁要長什麼樣子」，而後端工程師則是負責去處理「要在這個網頁上賣什麼東西」，所以前端工程師處理的是排版設計，而後端工程師處理的則是動態的數據。\n不過我們平常所瀏覽的網頁，其實是前端和後端整合在一起的結果，所以前端除了設計網頁的排版之外，同時也需要去問後端：「這裡應該要顯示哪些商品？」，而後端在收到詢問之後，就會提供商品的數據給前端，告訴前端「這裡要呈現的商品數據是什麼」。\n因此當前端拿到這些商品數據之後，前端就會將商品數據、以及網頁的排版設計結合在一起，最後再將結果呈現給使用者看。\n所以我們平常所瀏覽的網頁，就是由 「前端的排版」 加上 「後端的數據」，所組合出來的成果。\n而在這之中，要怎麼樣讓前端和後端之間能夠順暢溝通、傳遞商品的數據，就是 Spring MVC 所負責的範圍了。所以 Spring MVC 所負責的，就是解決「前端和後端之間的溝通問題」。\n所以換句話說的話，在接下來的 Spring MVC 的部分中，我們所介紹的所有內容，就都是在講「要如何和前端進行溝通」。\n什麼是 Spring MVC？ # 大概了解了 Spring MVC 功能的用途之後，接著我們可以回頭來看一下 Spring MVC 的定義。\nSpring MVC 的用途，就是「讓我們能夠在 Spring Boot 中，實作前後端之間的溝通」，這樣我們就可以透過 Spring MVC 的功能，在 Spring Boot 中創建一個 API 出來、或是去接住前端所傳過來的參數了！\n補充：原來我們已經用過 Spring MVC 了？ # 其實在前面的文章中，我們就已經有使用到 Spring MVC 的功能了！\n在 Day 4 - 第一個 Spring Boot 程式 的那篇文章中，我們在 Spring Boot 程式裡面，有去創建了一個 MyController 出來。當時是告訴大家，只要我們運行起 Spring Boot 程式，然後在瀏覽器中輸入 http://localhost:8080/test 時，這樣 Spring Boot 就會去執行 MyController 中的 test() 方法。\n因此我們在前面的文章中，就一直借用了這個方式，去練習前面的 IoC 和 AOP 的部分。\n而我們之所以在瀏覽器中輸入 http://localhost:8080/test，Spring Boot 就會去執行 MyController 中的 test() 方法，就是因為我們有在 MyController 中添加了 @RestController 和 @RequestMapping 這兩個註解，因此才能夠達到這個效果。\n而這兩個註解 @RestController 和 @RequestMapping，其實就是 Spring MVC 所提供的好用註解！\n所以在後面的文章中，我們就會來介紹 Spring MVC 中的好用功能，也會來介紹 @RestController 和 @RequestMapping 這些註解，他們分別的用途又是什麼。\n所以接下來的幾篇文章，就讓我們一起來探索 Spring MVC 的厲害之處吧！\n總結 # 這篇文章我們先回顧了前端和後端之間的區別，並且也介紹了 Spring MVC 的用途是什麼，先讓大家對 Spring MVC 有一個簡單的認識。\n不過在我們正式進入 Spring MVC 的介紹之前，會需要大家先了解什麼是「前端和後端之間的溝通協議」，因此下一篇文章，我們就會先來介紹前後端溝通最基礎的部分，也就是 Http 協議，那我們就下一篇文章見啦！\n補充：本文是擷取自我開設的線上課程 Java 工程師必備！Spring Boot 零基礎入門 的內容，如果你想了解更多的 Spring Boot 的用法，歡迎參考課程簡介 （輸入折扣碼「HH202601KU」即可享 85 折優惠）。\n","date":"2024-07-13","objectID":"1ea76aeb970db398f5900eeccc22e2e8","title":"Spring Boot 零基礎入門 (13) - Spring MVC 簡介","url":"https://kucw.io/blog/springboot/13/"},{"categories":["Spring Boot"],"content":"哈囉大家好，我是古古。\n在上一篇文章中，我們有去介紹了 Spring AOP 的概念和原理，讓大家先對 Spring AOP 有一個初步的認識。\n那麼這篇文章，我們就會接著來介紹，要如何在 Spring Boot 中使用 Spring AOP 的功能。\n補充：目前在實務上，其實已經不太會直接實作 Spring AOP 的程式了，所以本章節的內容大家就有個印象就好，等到將來真的有需要實作 Spring AOP 時，再回來查看本章節的 @Aspect 用法即可。\n目錄 回顧：什麼是 Spring AOP？ 在 pom.xml 載入 Spring AOP 的功能 創建切面的方法：@Aspect 在切入點方法「執行前」執行切面：@Before 如何解讀 AOP 程式？ 步驟一：先閱讀 @Before 小括號中的程式 步驟二：查看前面的註解是什麼 步驟三：要執行的切面方法 小結：綜合上述的三個步驟 在 Spring Boot 中練習 @Aspect 和 @Before 其他時機點的用法：@After、@Around @After 的用法 @Around 的用法 補充一：切入點（Pointcut）如何撰寫？ 補充二：Spring AOP 的發展 總結 回顧：什麼是 Spring AOP？ # 在上一篇文章中有提到，AOP 的全稱是 Aspect-Oriented Programming，中文翻譯成「切面導向程式設計」或是「剖面導向程式設計」，而 AOP 的概念，就是「透過切面，統一的去處理方法之間的共同邏輯」。\n因此當我們使用了 AOP 之後，就再也不用去複製貼上程式了，我們只需要在切面裡面寫好測量時間的程式，之後就可以在任何地方去使用這個切面，讓這個切面替我們完成測量時間的功能了。\n在 pom.xml 載入 Spring AOP 的功能 # 如果想要在 Spring Boot 中使用 Spring AOP 的功能的話，首先會需要在 pom.xml 檔案中新增下列的程式，這樣才能將 Spring AOP 的功能給載入進來，後續我們才能夠在 Spring Boot 中使用 Spring AOP 所提供的註解。\n所以大家可以先打開左邊側邊欄中的 pom.xml 檔案，然後在第 25 行～第 28 行處，添加下面的程式：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-aop\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 添加好上述的程式之後，此時在 pom.xml 的右上角會出現一個 M 符號，這時記得要點擊一下 M 符號，才能夠成功更新這個 Spring Boot 程式，把 Spring AOP 的功能給載入進來。\n載入好 Spring AOP 的功能之後，接下來我們就可以在 Spring Boot 中使用 Spring AOP 專屬的註解，去實作一個 AOP 的切面出來了！\n創建切面的方法：@Aspect # 如果想要使用 Spring AOP 去創造一個新的切面出來的話，我們就只要在 class 上面，去加上一個 @Aspect 的註解，這樣子就可以成功創建一個切面出來了。\n譬如說我們可以先創建一個新的 class 叫做 MyAspect，然後在上面加上 @Aspect，這樣就可以將 MyAspect 變成是一個切面了。\n不過在使用 @Aspect 去創建新切面時，有一點一定要特別注意，就是「只有 Bean 才可以變成一個切面」。\n所以換句話說的話，在使用 @Aspect 去創建一個新的切面時，同時也必須要使用 @Component，將這個 class 變成是一個 Bean，這樣子 @Aspect 的切面設定才會真的生效！！如果單純只有在 class 上面加上 @Aspect 的話，是完全沒有任何效果的！\n所以大家在實作時一定要記得，在創建切面時，「@Component 和 @Aspect 要一起使用」 就對了。\n在切入點方法「執行前」執行切面：@Before # 創建好切面 MyAspect 這個切面 class 之後，我們就可以在這個 class 裡面，去撰寫切面的方法了。\n舉例來說，我們可以在 MyAspect 裡面，先寫上一個 before() 方法，然後在這個 before() 方法裡面，輸出一行「I\u0026rsquo;m before」的訊息到 console 上。\n接著，只要我們在這個 before() 方法上面，去加上一個 @Before 註解，並且在後面的小括號中，去指定想要的切入點，這樣子就可以在這個切入點的方法 「執行前」，去執行這個 MyAspect 中的 before() 方法了。\n不過看到這裡，大家可能還是會對 @Aspect 和 @Before 的用法有點疑惑（畢竟真的有點抽象），所以接下來我們可以再試著來拆解一下這段程式，了解要如何解讀這些 AOP 的程式。\n如何解讀 AOP 程式？ # 到目前為止，我們已經有在 MyAspect 中，先寫上了一個 before() 方法，並且在這個 before() 方法的上面，也有去加上了一個 @Before 的註解，完成這個切面的實作。\n不過其實上面這一段程式，他是可以拆成三個步驟來解讀的：\n步驟一：先閱讀 @Before 小括號中的程式 # 在 @Before 後面的小括號中的程式，稱為「切入點（Pointcut）」，即是去指定哪個方法要被切面所切。\n舉例來說，假設我們想要測量的是「HpPrinter 中的所有方法的時間」，那麼 HpPrinter 中的所有方法，就是切入點（Pointcut）。\n所以在下面這一段程式中，在 @Before 後面的小括號中的程式，即是去指定「切入點（Pointcut）」，表示我們想要使用這個 MyAspect 的切面，去切哪些方法。\n步驟二：查看前面的註解是什麼 # 確認好了切入點之後，接著就是查看前面所加上的 AOP 註解是什麼。\n像是在這個例子中，我們所加上的就是 @Before 註解，而 @Before 的用途，就是表示要在切入點 「執行前」，去執行 @Before 下面的方法（也就是 before() 方法）。\n所以簡單來說，前面的這個 @Before 註解，他指定的就是 「時機點」，而 @Before 所對應的時機點，就是在切入點的方法「執行前」執行。\n因此在步驟二這裡，就是去確認「切面方法執行的時機點」。\n補充：除了 @Before 之外，AOP 也有提供其他不同時機點的註解（像是 @After 和 @Around）給我們使用 ，本篇文章後面也會介紹這兩個註解給大家。\n步驟三：要執行的切面方法 # 當我們確認好「切入點」和「時機點」之後，最後就可以在下面的 before() 方法中，去實作切面的程式了。\n像是在這一段程式中，我們就只有在 before() 方法裡面寫上一行程式，去輸出「I\u0026rsquo;m before」的資訊到 console 上。\n小結：綜合上述的三個步驟 # 所以綜合上述的三個步驟，我們就可以去解讀這一段 AOP 的程式的含義是什麼了！\n步驟一：指定了「切入點」為「HpPrinter 中的所有方法」 步驟二：在切入點的方法「執行之前」 步驟三：執行下面的 before() 方法 因此最後的結果，就會長的像是下圖這樣：\n在 Spring Boot 中練習 @Aspect 和 @Before # 看完了上述對 @Aspect 和 @Before 的介紹之後，","date":"2024-07-12","objectID":"88d6e1e4b02eb9520333149225fd52f3","title":"Spring Boot 零基礎入門 (12) - Spring AOP 的用法 - @Aspect","url":"https://kucw.io/blog/springboot/12/"},{"categories":["Spring Boot"],"content":"哈囉大家好，我是古古。\n在前面的文章中，我們有介紹了 Spring IoC 的特性，先讓大家了解要如何在 Spring Boot 中創建、注入、以及初始化 Bean，為後續的部分打穩基礎。\n那麼從這篇文章開始，我們就會接著來介紹 Spring 框架中的另一個也很重要的特性，也就是 AOP，所以我們就開始吧！\n目錄 什麼是 Spring AOP？ 例子：測量時間的故事 透過 AOP（切面）來輔助 Spring AOP 的定義 總結 什麼是 Spring AOP？ # AOP 的全稱是 Aspect-Oriented Programming，中文翻譯成「切面導向程式設計」或是「剖面導向程式設計」，而 AOP 的概念，就是「透過切面，統一的去處理方法之間的共同邏輯」。\n這個「切面」聽起來可能有點抽象，所以我們就先透過一個例子，來了解一下 AOP（切面導向程式設計）到底是什麼。\n例子：測量時間的故事 # 假設我們有一個 HpPrinter，並且在這個 HpPrinter 裡面只有一個 print() 方法，在 console 上印出傳進來的參數：\n如果我們想要測量一下「執行 print() 方法需要花費多久的時間」的話，那麼最簡單的做法，就是直接在這個方法的最前面和最後面，分別去記錄開始時間和結束時間，最後再將這兩個時間相減，就可以計算出 print() 方法總共執行多久了。\n不過，雖然透過上面的寫法，是可以測量出 print() 方法的運作時間沒錯，但是大家如果觀察一下這段程式的話，就可以發現在這個 print() 方法裡面，充斥了許多跟「印東西」這個功能無關的程式。\n像是原本這個 print() 方法，他本來要做的事情，就只是在 console 上面輸出「HP 印表機: ..….」這一行資訊而已，但是因為我們想要測量 print() 方法的執行時間，所以加了許多不相關的程式進去，進而讓這個方法變得很複雜，不利於後續的程式維護。\n而且上面這樣子的寫法，也有可能會產生「過多程式重複」的問題。\n譬如說我們在 HpPrinter 裡面多新增了一個方法 printColor()，然後我們也想要去測量這個 printColor() 方法的時間的話，那我們就得從 print() 方法中複製所有測量時間的程式，然後貼到 printColor() 方法裡面。\n現在只有這兩個方法要測量時間，所以這樣的複製貼上大家可能覺得還好，但是如果有很多方法都需要測量執行時間時，這樣子的複製貼上就不會是一個好選項。\n所以為了解決這個問題，Spring AOP 就登場了！\n透過 AOP（切面）來輔助 # 我們可以透過下面這張圖來看一下，Spring AOP 是如何解決上面那個複製貼上的問題的。\n如果我們把剛剛的 HpPrinter 畫成圖的話，就可以畫成是下面這個樣子：\n上圖中呈現了 HpPrinter 中的兩個方法：print() 和 printColor()，每一個箭頭代表的是一個方法，而箭頭右邊的程式，就是這個方法裡面所寫的程式。\n在這張圖中可以看到，在這兩個方法裡面，一開始都會去記錄方法的開始時間，接著去執行「印東西」的程式，最後再是去記錄方法的結束時間，並且將結束時間和開始時間相減，計算總共執行多久。\n所以這時候，Spring AOP 就提出一個想法了，既然這些測量時間的程式是每個方法都要使用的共同邏輯，那我們就把這些共同邏輯的程式，去獨立出來成一個「切面」，由這個切面去橫貫所有的方法，替他們做測量時間的部分。\n所以當我們使用了 Spring AOP 之後，我們就不用在方法裡面再去寫上任何測量時間的程式了！我們只要將測量時間的共同邏輯，統一的交給切面去做處理，這個切面會去橫貫所有的的方法，分別去測量每一個方法的執行時間，所以每個方法就只要專注在各自要做的事情就好了，讚！！\n而這種使用「切面」的寫法，就會稱為 AOP，也就是 Aspect-Oriented Programming（切面導向程式設計）了！\nSpring AOP 的定義 # 大概了解了 Spring AOP 的概念之後，我們也可以回頭來看一下 AOP 的定義。\nAOP 的全稱是 Aspect-Oriented Programming，中文翻譯成「切面導向程式設計」或是「剖面導向程式設計」，而 AOP 的概念，就是「透過切面，統一的去處理方法之間的共同邏輯」。\n因此當我們使用了 AOP 之後，就再也不用去複製貼上程式了，我們只需要在切面中寫好測量時間的程式，之後就可以在任何地方去使用這個切面，讓這個切面替我們完成測量時間的功能了，讚啦！\n總結 # 這篇文章我們先透過測量時間的例子，介紹了 Spring AOP 的原理，讓大家更好去理解 Spring AOP 的核心概念是什麼（切面真是一個神奇的東西）。\n那麼下一篇文章，我們就會實際到 IntelliJ 中，練習要如何在 Spring Boot 程式中實作 Spring AOP，那我們就下一篇文章見啦！\n補充：本文是擷取自我開設的線上課程 Java 工程師必備！Spring Boot 零基礎入門 的內容，如果你想了解更多的 Spring Boot 的用法，歡迎參考課程簡介 （輸入折扣碼「HH202601KU」即可享 85 折優惠）。\n","date":"2024-07-11","objectID":"2438c13f3655762070f7c46f8d8d0151","title":"Spring Boot 零基礎入門 (11) - Spring AOP 簡介","url":"https://kucw.io/blog/springboot/11/"},{"categories":["Spring Boot"],"content":"哈囉大家好，我是古古。\n在前面的文章中，我們已經對 Spring IoC 有了滿多的認識，並且也能夠在 Spring Boot 中應用 Spring IoC 的核心用法了。\n那麼接著這篇文章，我們就會繼續深入來介紹，要如何透過 @Value，將 Spring Boot 設定檔中的值讀取到 Bean 裡面，讓我們所寫的 Java 程式可以去運用 Spring Boot 設定檔中的值，所以我們就開始吧！\n目錄 什麼是 Spring Boot 設定檔？ application.properties 的寫法 properties 的語法介紹：key=value properties 語法的注意事項之一：不需要加上空白鍵排版 properties 語法的注意事項之二：key 中的 . 是表示「的」的概念 properties 語法的注意事項之三：使用 # 來表示 comment 讀取 Spring Boot 設定檔（application.properties）中的值：@Value @Value 用法介紹 @Value 的運行結果 使用 @Value 的注意事項之一：需要遵守固定格式寫法 使用 @Value 的注意事項之二：@Value 只有在 Bean 和 @Configuration 中才能生效 使用 @Value 的注意事項之三：類型需要一致 使用 @Value 的注意事項之四：@Value 可以設定預設值 小結：所以，@Value 到底要怎麼用？ 補充一：Spring Boot 設定檔的兩種語法（properties 和 yml） 補充二：yml 的語法介紹 key:value 的寫法 用「縮排」表示中文的「的」的概念 小結：properties 和 yml 的差別 總結 什麼是 Spring Boot 設定檔？ # 所謂的 Spring Boot 設定檔，指的是 「放在 src/main/resources 資料夾底下的 applicaiton.properties 檔案」，而這個 application.properties 的目的，就是「存放 Spring Boot 程式的設定值」。\n所以大家以後只要聽到別人在說「Spring Boot 設定檔」，就要第一時間想到他所指的其實是 application.properties 這個檔案。\n如果我們點擊兩下打開 application.properties 檔案的話，可以看到右邊有一行 spring.application.name=demo 的程式，這個是 IntelliJ 在創建 Spring Boot 專案時所自動生成的設定值。\n這裡大家可以自由選擇要不要將 spring.application.name=demo 這一行程式刪掉（刪掉此設定不影響 Spring Boot 運作），如果不想刪除的話，也可以直接按下 Enter 鍵換行，這樣子就可以繼續在這個 application.properties 檔案中，繼續添加其他的設定值了。\n補充：由於版面的緣故，因此在下面的截圖中不會出現 spring.application.name=demo 的設定。\napplication.properties 的寫法 # 如果想要在 application.properties 中，添加 Spring Boot 的相關設定的話，那就要遵循一定的寫法格式才可以。\n首先大家可以觀察一下，application.properties 這個檔案，他是一個「檔名為 application、並且副檔名為 .properties」的檔案。 因此這就表示，這個 application.properties 檔案，是使用 「properties 語法」 來撰寫設定值的。\nproperties 的語法介紹：key=value # 而在 properties 的語法中，是使用 key=value 的格式來撰寫設定值，並且每一行程式，就是一組 key 和 value 的配對。\n像是下面這個例子，我們就在第 1 行寫上了 count=5，所以這一行程式就是表示：我們定義了一個 key（他的名字是 count），並且這個 count 的 value 值，就是 5。\n所以大家其實可以把這個 key=value 的寫法，簡單的想像成是 變數=值 的概念，在前面的 key 就等同於是 Java 中的變數名稱，而後面的 value，就是這個變數的值，所以 properties 語法的概念其實和 Java 是很相近的！\n因此當我們在 application.properties 中，寫上了一行 count=5 的程式時，就表示我們定義了一個變數 count，然後他的值是 5 這樣，就是這麼的簡單暴力！\nproperties 語法的注意事項之一：不需要加上空白鍵排版 # 大概了解了 properties 語法的核心概念 key=value 的寫法之後，接著我們可以來看一些使用 properties 語法的注意事項。\n當我們以前在寫 Java 程式的時候，習慣會在 = 的前後加上空白鍵，去做排版的美化，所以就會像是下面這個樣子：\n// 美化前 int count=5; // 加上空白鍵美化後 int count = 5; 不過在 properties 語法裡面，是 「不需要」 在 = 的前後加上空白鍵，去做排版的美化的，只要全部連在一起寫就好，多加空白鍵反而會導致程式運行時出現問題。\n所以在 properties 語法裡面，建議就使用下面這種寫法，把你的空白鍵收起來，一路連字連到底就對了！\ncount=5 properties 語法的注意事項之二：key 中的 . 是表示「的」的概念 # 在前面我們有介紹到，properties 語法中是使用 key=value 來撰寫程式的，而 key 所代表的，就是變數的名字。\n不過這個 key 在命名上，是允許裡面帶上 . 符號的，並且這個 . 的符號的邏輯意義，就是中文的「的」的意思。\n舉例來說，我們可以在 application.properties 裡面，在第 2 行寫上 my.name=John 的程式，而當我們這樣寫之後，my.name 這個 key 就是變數的名字，其中文意義就是表示「我的名字」（因為 . 是表示「的」的意思）。\n所以 my.name=John 這一整行的意思，就是「我的名字叫做 John」。\n或是我們也可以在下面，再新增一行 my.age=20 的程式，而這一行程式所代表的，就是「我的年齡是 20 歲」的意思。\n所以大家以後在撰寫 properties 語法時，就可以將 key 中的 .，翻譯成是中文的「的」的意思，所以我們就可以透過這種方式，去傳遞更豐富的邏輯意義出來了。\nproperties 語法的注意事項之三：使用 # 來表示 comment # 在 properties 語法中，我們也是可以去添加 comment 的，只要在撰寫程式時，在最前面加上一個 # 的符號，那麼那一行就會被 properties 語法給忽略了（用法和 Java 中的 // 一樣）。\n讀取 Spring Boot 設定檔（application.properties）中的值：@Value # @Value 用法介紹 # 在了解了 Spring Boot 設定檔（也就是 application.properties 檔案）的用途、以及 properties 語法的 key=value 的寫法之後，接著我們就進到這篇文章的重頭戲，也就是來介紹：要如何透過 @Value，將 application.properties 中的設定值讀取到","date":"2024-07-10","objectID":"d9bfafb6bdf8d6694ed8b0cfd5e5cbe7","title":"Spring Boot 零基礎入門 (10) - 讀取 Spring Boot 設定檔 - @Value、application.properties","url":"https://kucw.io/blog/springboot/10/"},{"categories":["Spring Boot"],"content":"哈囉大家好，我是古古。\n在前幾篇文章中，我們分別介紹了 Bean 的相關特性，像是：\n創建 Bean 的方法：@Component 注入 Bean 的方法：@Autowired 以及指定 Bean 名字的方法：@Qualifier 所以到目前為止，我們可以說是對 Bean 有了更多的認識，並且已經可以成功的在 Spring Boot 程式中運用 Bean 了！\n那麼這篇文章，我們就會繼續來探討 Bean 的更多用法，來介紹要如何在創建一個 Bean 出來之後，去「初始化」這個 Bean 的值。\n目錄 什麼是 Bean 的初始化？ 初始化 Bean 的方法：@PostConstruct 使用 @PostConstruct 的注意事項之一：方法有特定格式 使用 @PostConstruct 的注意事項之二：在同一個 class 中，建議只有一個方法加上 @PostConstruct 補充一：我們真的需要 @PostConstruct 嗎？ 補充二：初始化 Bean 的另一種方法：afterPropertiesSet() 總結 什麼是 Bean 的初始化？ # 所謂的「Bean 的初始化」，就是指「在 Bean 被創建出來之後，對這個 Bean 去做一些初始值的設定」，譬如說把他內部的變數的值設定成 5、或是進行一些運算之類的，反正就是對這個 Bean 去做初始的出廠設定就對了。\n舉例來說，我們可以先改寫一下之前所寫的 HpPrinter，先在這個 HpPrinter 中去加上一個 count 變數，用 count 變數計算這台印表機還可以印幾次。\n所以每當我們 call 一次 print() 方法時，這個 count 的數量就要減一，表示已經印過一次了，實際程式如下：\n@Component public class HpPrinter implements Printer { private int count; @Override public void print(String message) { count--; System.out.println(\u0026#34;HP 印表機: \u0026#34; + message); System.out.println(\u0026#34;剩餘使用次數: \u0026#34; + count); } } 又因為我們有在這個 HpPrinter 上面加上 @Component，將他變成 Bean，所以 Spring Boot 到時候就會為我們創建一個 hpPrinter 的 Bean 出來，並且存放在 Spring 容器裡面。\n不過到目前為止，因為我們沒有去設定 Bean 的初始化，因此 Spring Boot 就只會去把這個 Bean 給創建出來，並不會為裡面的 count 值進行初始化，因此在這個 hpPrinter 中的 count 值，預設就會是 0。\n不過，如果我們想要讓 Spring Boot 在創建這個 hpPrinter 出來之後，同時也去為這個 count 變數賦予一個初始值的話，那麼我們就可以透過 @PostConstruct 來幫助我們達成這件事！\n初始化 Bean 的方法：@PostConstruct # @PostConstruct 的用途，就是「為這個 Bean 去進行初始化」，因此我們就可以透過 @PostConstruct，去設定這個 Bean 中的變數的初始值了。\n因此如果我們想要改寫上面的 HpPrinter，將他裡面的 count 變數的值「初始化成 5」的話，那麼我們就可以這樣做：\n首先我們先在 HpPrinter 新增一個新的方法 initialize()（方法名稱可以隨意取，後面會解釋），並且在這個方法上面，加上一行 @PostConstruct，這樣我們等一下就可以在這個方法中， 去初始化 Bean 的值。\n@PostConstruct public void initialize() { count = 5; } 像是我們可以在 initialize() 的方法中，去初始化這個 Bean 的值，譬如說我們可以把 count 的值設成 5，就可以將 count 變數的值初始化成 5。\n所以到時候，當 Spring Boot 創建出 hpPrinter 這個 Bean 之後，Spring Boot 就會接著去執行 initialize() 方法，將 count 的設定成 5，進而就可以完成 Bean 的初始化了！\n使用 @PostConstruct 的注意事項之一：方法有特定格式 # 在上面的實作中，當我們想要初始化 Bean 中的變數的值時，我們需要先在該 class 中，先去新增一個方法出來（像是 HpPrinter 中的 initialize() 方法），接著再為這個方法加上 @PostConstruct，這樣子我們就可以在這個方法裡面， 去實作初始化 Bean 的程式了。\n不過這個 initialize() 方法（也就是被加上 @PostConstruct 的方法），其實也是有一些格式需要遵守的：\n這個方法必須是 public 這個方法的返回值必須是 void 這個方法 「不能」 有參數 這個方法的名字可以隨意取，不影響 Spring Boot 運作 所以綜合以上四點的話，這個「初始化 Bean 的方法」，通常就會長得像是下面這個樣子：\n@PostConstruct public void XXX(); 其中的方法名稱 XXX()，可以替換成大家喜歡的單字，常見的有 setup()、init()、initialize()…等等，這些單字都可以拿來使用，不會影響到 Spring Boot 的運作。\n補充：Spring Boot 在判斷一個 Bean 中有沒有初始化的方法時，是 「尋找有沒有方法加上 @PostConstruct，如果有的話，就執行該方法」。也因為如此，所以這個初始化的方法名稱對 Spring Boot 而言是完全不重要的， 大家就選擇自己喜好的單字（ex: setup()、init()）來使用即可。\n使用 @PostConstruct 的注意事項之二：在同一個 class 中，建議只有一個方法加上 @PostConstruct # 由於當某個方法上面加上 @PostConstruct，該方法就會變成「初始化 Bean 的程式」，因此假設在同一個 class 裡面，同時有多個方法都加上 @PostConstruct 的話，那麼 Spring Boot 就會不知道要先運行哪一個方法去初始化 Bean。\n因此在這種情況下，雖然 Spring Boot 程式不會報錯，但是實際上初始化 Bean 的順序是完全隨機的，因此可能會造成程式邏輯的錯誤，並且後續也很難統一管理初始化的設定。\n所以就建議大家，在使用 @PostConstruct 去初始化 Bean 的時候，在同一個 class 中，只在其中一個方法上面加上 @PostConstruct，統一的去管理初始化 Bean 的設定，這樣子不管是在運作上、還是後續的維護，都是比較好的做法。\n補充一：我們真的需要 @PostConstruct 嗎？ # 由於上面的例子因為比較簡單，所以有的人可能會覺得：「為什麼我們不直接在宣告 count 變數的同時，把 count 值也設成 5 就好？」，就像是下面這個樣子，直接在宣告 count 變數的同時，也將他初始化成 5，這樣子就可以省去 @PostConstruct 的程式了。\n雖然在這個例子中，確實是可以透過上述的方式，簡單的將 count 值初始化成 5，但是在實際的工作中，@PostConstruct 的應用還是很廣","date":"2024-07-09","objectID":"4a09f764cda148a9e520b9c31b98c1b0","title":"Spring Boot 零基礎入門 (9) - Bean 的初始化 - @PostConstruct","url":"https://kucw.io/blog/springboot/9/"},{"categories":["Spring Boot"],"content":"哈囉大家好，我是古古。\n在上一篇文章中，我們介紹了如何使用 @Component 來創建 Bean，也有介紹要如何使用 @Autowired 來注入 Bean。\n那麼接著這篇文章，我們就會來介紹，當 Spring 容器中有 2 個以上同樣類型的 Bean 存在時，該怎麼去選擇要注入的 Bean。\n目錄 回顧：注入 Bean 的方法 - @Autowired 指定注入的 Bean 的名字：@Qualifier 使用 @Qualifer 的注意事項之一：必須搭配 @Autowired 一起使用 使用 @Qualifer 的注意事項之二：指定的是「Bean 的名字」 在 Spring Boot 中練習 @Qualifier 的用法 運行 Spring Boot 程式 總結 回顧：注入 Bean 的方法 - @Autowired # 在前一篇文章中我們有介紹到，我們可以在變數上加上 @Autowired，將想要的 Bean 給注入進來。\n不過在使用 @Autowired 來注入 Bean 時，必須滿足以下事項：\n首先必須要確保 「自己也是一個 Bean」（即是有在 class 上面加上 @Component）。 並且 @Autowired 是透過 「變數的類型」 來注入 Bean。 所以在使用 @Autowired 去注入 Bean 進來時，Spring Boot 就是會透過「變數的類型」，去 Spring 容器中尋找是否有類型符合的 Bean，如果有同類型的 Bean 存在時，即可以注入成功，如果沒有 Bean 存在，則注入失敗，Spring Boot 就會報錯，並且運行失敗。\n所以像是在下面的例子中，因為 Spring 容器中只有 hpPrinter 這個 Bean，並且 hpPrinter 可以向上轉型成 Printer 類型，所以 Spring Boot 就會判定他們類型符合，因此就能夠注入成功。\n但是，假設在 Spring 容器中，同時有兩個一樣類型的 Bean 存在，譬如說像是下面這張圖，在 Spring 容器中同時有 hpPrinter 和 canonPrinter 這兩個 Bean 存在，那麼在這個情況下，Spring Boot 會如何運作呢？\n正確答案是：Spring Boot 會出現錯誤並且運行失敗。\n而 Spring Boot 之所以會出現錯誤，就是因為 hpPrinter 和 canonPrinter 都可以向上轉型成 Printer 類型，所以 Spring Boot 不知道該注入哪一個 Bean 進來，因此就發生錯誤。\n所以會導致這個錯誤的根本原因，就是因為在 Spring 容器中「同時有多個同樣類型的 Bean 存在」，因此 Spring Boot 就無法選擇要注入哪一個 Bean 進來。\n所以為了解決這個問題，就是 @Qualifier 登場的時候了！\n指定注入的 Bean 的名字：@Qualifier # @Qualifier 的用途，是去指定要注入的 Bean 的「名字」是什麼，進而解決同時有兩個同樣類型的 Bean 存在的問題。\n因此在一般的情況下，我們只要使用 @Autowired 就可以注入 Bean，但是假設今天有兩個同樣類型的 Bean 存在時，那麼我們在使用 @Autowired 的時候，就必須同時去搭配 @Qualifier，才能夠去選擇要注入的 Bean 是哪一個。\n所以簡單來說，Spring Boot 就是先由 @Autowired 篩選 Bean 的類型、再由 @Qualifier 篩選 Bean 的名字，透過這樣子的連環組合拳來解決這個問題！\n因此如果我們回頭看剛剛的例子，假設目前在 Spring 容器中有兩個 Bean：hpPrinter 和 canonPrinter，這時候如果我們想要指定要注入 hpPrinter 這個 Bean 的話，那麼就只要在 printer 變數上面，再加上一個 @Qualifier，並且在 @Qualifier 裡面指定「要注入的 Bean 的名字是hpPrinter」，這樣子就可以成功的注入 hpPrinter Bean 進來了！\n使用 @Qualifer 的注意事項之一：必須搭配 @Autowired 一起使用 # 在使用 @Qualifier 去指定「要注入的 Bean」時，一定要搭配 @Autowired 一起使用，單純使用 @Qualifier 是沒有任何用處的。\n其實大家也可以直接把 @Qualifier 當成是 @Autowired 的小弟看待，@Qualifier 只是專門在輔助 @Autowired 的，如果沒有 @Autowired 的話，那麼 @Qualifier 是完全沒有什麼作用的！\n使用 @Qualifer 的注意事項之二：指定的是「Bean 的名字」 # 如同前面所介紹的，@Qualifier 是為了解決「多個類型同時存在」的問題被發明出來的，因此他所指定的是 「Bean 的名字」。 也由於 @Qualifier 指定的是 Bean 的名字，因此掌握 Bean 的名字的生成方式就非常的重要！\n當我們平常使用 @Component 去創建 Bean 時，這些 Bean 的名字，就會是「class 名的第一個字母轉成小寫」。 所以像是由 HpPrinter class 所生成的 Bean，就會叫做 hpPrinter，由 CanonPrinter 所生成的 Bean，名字就會叫做 canonPrinter。\n因此大家在使用 @Qualifier 去指定要注入的 Bean 的名字時，一定要撰寫正確的 Bean 的名字，這樣子才能夠成功的去注入該 Bean 進來。\n補充：有關 Bean 的名字生成機制，可以回頭參考 Day 7 - Bean 的創建和注入 - @Component、@Autowired 的相關介紹\n在 Spring Boot 中練習 @Qualifier 的用法 # 了解了 @Qualifier 的用法之後，我們也可以實際到 Spring Boot 中，來練習 @Qualifier 的用法。\n延續上一篇文章的程式，目前在 Spring Boot 程式中，我們已經創建了 Printer interface 以及 HpPrinter class 出來，並且在 MyController 裡面，我們也使用了 @Autowired 去注入一個 Printer 類型的 Bean 進來。\n由於目前在這個 Spring Boot 程式裡面，只有一個 hpPrinter Bean 有辦法向上轉型成 Printer 類型，因此在 MyController 這裡所注入的，就會是 hpPrinter 這個 Bean。\n如果要練習 @Qualifier 的用法的話，我們可以先在 com.example.demo 這個 package 底下，再去新增一個 CanonPrinter 的 class 出來，並且在這個 CanonPrinter 的 class 中，實作以下的程式：\n@Component public class CanonPrinter implements Printer { @Override public void print(String message) { System.out.println(\u0026#34;Canon印表機: \u0026#34; + message); } } 創建好 CanonPrinter class 之後，整個結構會長得像是下面這個樣子：\n所以當我們這樣寫之後，就等於是 HpPrinter 和 CanonPrinter 這兩個 class，到時候都會被 ","date":"2024-07-08","objectID":"a208e373797918175e1434b646bdbcd5","title":"Spring Boot 零基礎入門 (8) - 指定注入的 Bean - @Qualifier","url":"https://kucw.io/blog/springboot/8/"},{"categories":["Spring Boot"],"content":"哈囉大家好，我是古古。\n在上一篇文章中，我們有介紹了 IoC、DI、和 Bean 的概念，先帶大家了解 Spring IoC 中的重要名詞的含義。\n那麼這篇文章，我們就會實際到 IntelliJ 中，練習要如何在 Spring Boot 程式中創建 Bean，以及要如何將 Bean 去注入到別的 class 中。\n目錄 創建 Bean 的方法：@Component 創建 Bean 的注意事項 注入 Bean 的方法：@Autowired 使用 @Autowired 的注意事項之一：該 Class 也必須也是 Bean 使用 @Autowired 的注意事項之二：@Autowired 是根據「變數類型」尋找 Bean 小結：所以，@Autowired 到底要怎麼用？ 在 Spring Boot 中練習 @Component 和 @Autowired 的用法 練習創建 Bean 的方法：@Component 練習注入 Bean 的方法：@Autowired 補充：為什麼 MyController 能使用 @Autowired？ 運行 Spring Boot 程式 總結 創建 Bean 的方法：@Component # 在 Spring Boot 中，最常見的創建 Bean 的方法，就是在 class 上面加上一行 @Component 的程式。只要在 class 上面加上一行 @Component 之後，就可以將這樣 class 變成一個 Bean 了，Magic！\n所以只要我們將 HpPrinter 改寫成是下面這個樣子（注意在最上面加了一行 @Componenet），就可以將 HpPrinter 變成一個由 Spring 容器所管理的 Bean 了。\n因此當 Spring Boot 程式運行起來之後，Spring Boot 就會去查看有哪些 class 上面加上了 @Component，然後 Spring Boot 就會提前去 new 一個 object 出來，並且存放在 Spring 容器裡面，等著其他人後續來跟他借。\n所以以 HpPrinter 這個例子來說，當 Spring Boot 看到 HpPrinter 上面有加上 @Component 之後，Spring Boot 就會去執行下面這行程式，提前去 new 出一個 HpPrinter 的 object 出來。\nPrinter hpPrinter = new HpPrinter(); 並且 Spring Boot 會將 hpPrinter 這個 object，存放在 Spring 容器中，等著後續其他人來借，因此架構就會長得像是下圖這樣（即是在 spring 容器中存放了一個 hpPrinter 的 object）：\n也因為使用 @Component 來創建 Bean 可以說是非常的神速，只需要在 class 上面加上一行程式就可以完成，因此 @Component 也可以說是在 Spring Boot 中使用頻率最高的註解之一。\n創建 Bean 的注意事項 # 在使用 @Component 來創建 Bean 時，有一個重點要特別提一下，就是這些被創建出來的 Bean，他們的名字，會是「class 名稱的第一個字母轉成小寫」。\n舉例來說，當我們在 HpPrinter class 上面加上一個 @Component 之後，那麼 Spring 所生成出來的 Bean 的名字，就會是 hpPrinter。\n所以同樣的道理，假設我們今天改成是將 @Component 加在 CanonPrinter class 上，那 Spring 所生成出來的 Bean，名字就會是 canonPrinter。\n因此大家之後在創建 Bean 時，就要記得 「Spring 所生成出來的 Bean 的名字，會是 class 名稱的第一個字母轉成小寫」，這個特性在下一篇文章中馬上就會用到，所以也是一個很重要的特性！\n補充：除了在 Class 上面加上 @Component 可以創建 Bean 之外，其實也是可以使用另一種方式 @Bean + @Configuration，去創建一個 Bean 出來的。不過因為這部分相對比較複雜，因此在本系列文中不會特別介紹到 @Bean + @Configuration 的實作。\n注入 Bean 的方法：@Autowired # 了解了創建 Bean 的方法之後，接著我們可以來看一下如何去「注入 Bean」。\n要注入 Bean 也很簡單，只需要在變數上面加上 @Autowired 這行程式，就可以將 Spring 容器中的 Bean 給注入進來了，Magic again！！\n不過，在使用 @Autowired 去注入 Bean 進來時，有兩個很重要的限制一定得遵守！如果不遵守的話，是沒辦法正常去注入 Bean 進來的。\n使用 @Autowired 的注意事項之一：該 Class 也必須也是 Bean # 當某個 class 想要使用 @Autowired 去注入一個 Bean 進來時，這個 class 自己本身也得變成是由 Spring 容器所管理的 Bean 才可以，因為這樣子 Spring 容器才有辦法透過 DI（依賴注入），將我們想要的 Bean 給注入進來。\n所以假設我們是一個 Teacher，然後我們想要使用 @Autowired，把 HpPrinter 這個 Bean 給注入進來的話，那麼 Teacher 本身也必須成為一個 Bean 才可以。\n因此這時候，我們就必須先在 Teacher class 上面，先去加上一行 @Component，將 Teacher 先變成是一個 Bean，這樣後續才可以將透過 @Autowired，將 HpPrinter 這個 Bean 給注入到 Teacher 裡面。\n補充：因此基本上當我們使用了 Spring Boot 這套框架之後，我們就會盡量把所有的 class 都變成 Bean，因為這樣才能夠去注入來注入去的，所以在 Spring Boot 程式裡面看到一堆 @Component 和 @Autowired 是很正常的！\n使用 @Autowired 的注意事項之二：@Autowired 是根據「變數類型」尋找 Bean # 使用 @Autowired 的第二個注意事項，即是 @Autowired 是根據 「變數的類型」來尋找 Bean。\n當我們在 Teacher class 中的 printer 變數上面，加上了一行 @Autowired 的程式之後，其實就表示「我們想要注入一個 Printer 類型的 Bean」，因此 Spring 容器就會查看他裡面有沒有 Printer 類型的 Bean，如果有的話，Spring 容器就會把這個 Bean 注入給 Teacher，如果沒有的話，就會出現錯誤並且停止程式。\n而 HpPrinter class 之所以能夠成功的被注入到 Printer 類型的變數裡面，原因就在於 Java 的多型（polymorphism）特性，使得 HpPrinter class 可以「向上轉型」成 Printer interface，因此透過 Java 的多型，Spring Boot 就能夠成功的將 hpPrinter Bean，注入到 Teacher class 中的 printer 變數了！\n補充：因為這裡牽涉到 Java 的多型特性，因此不熟悉這部分的話，建議要先回頭了解一下 Java 的多型特性會比較好，多型的概念會貫穿整個 Spring Boot 開發，因此這部分建議大家要了解一下會比較好。\n小結：所以，@Autowired 到底要怎麼用？","date":"2024-07-07","objectID":"0465c6cbcb25ff2fe51236ce15465a53","title":"Spring Boot 零基礎入門 (7) - Bean 的創建和注入 - @Component、@Autowired","url":"https://kucw.io/blog/springboot/7/"},{"categories":["Spring Boot"],"content":"哈囉大家好，我是古古\n在上一篇文章中，我們先介紹了 Spring IoC 的原理，以及使用 Spring IoC 的優點，讓大家先對 Spring IoC 有一個初步的認識。\n那麼這篇文章，我們就會接著來介紹，在 Spring IoC 中也很重要的兩個名詞：DI 和 Bean，讓大家更全面的了解 Spring IoC，並且這也是後續在實作 Spring Boot 程式時，一個非常重要的概念。\n目錄 回顧：什麼是 IoC？ 什麼是 DI？ 什麼是 Bean？ 總結 回顧：什麼是 IoC？ # 在上一篇文章中有提到，IoC 的全稱是 Inversion of Control，中文翻譯為控制反轉，而 IoC 的概念，就是「將 object（物件）的控制權，交給了外部的 Spring 容器來管理」，所以所謂的 Control（控制），就是「對於 object 的控制權」。\n所以有了 IoC 的概念之後，以後所有的 object，就都是由外部的 Spring 容器來進行管理，因此當 Teacher 想要去使用印表機時，就只要跟 Spring 容器去借就好了，Teacher 就不需要自己再去「控制」這個印表機的生命週期了。\n什麼是 DI？ # 而只要提到 IoC，就一定會提到另一個名詞 DI，這兩個名詞可以說是相輔相成的，缺一不可。\nDI 的全稱是 Dependency Injection，中文翻譯為「依賴注入」，而其實 DI 依賴注入的概念，我們已經有在前面的 IoC 過程中使用到了！\n像是在上面那張圖中，Spring 容器會預先儲存一個 HpPrinter 印表機，因此每當 Teacher 想要使用印表機時，Spring 容器就會將這個 HpPrinter 借給 Teacher 使用，其中這個「我借你」的動作，其實就是「DI 依賴注入」。\n所以換句話說的話，每當 Spring 容器想要把 HpPrinter 「借」給 Teacher 使用時，就是表示 Spring 容器把 HpPrinter 給「注入」到 Teacher 這個 class 裡面，因此才稱為是 「DI 依賴注入」。\n因此基本上只要有用到「IoC 控制反轉」的地方，一定就要搭配「DI 依賴注入」，因為 IoC 會讓我們把 object 的控制權給交出去，所以後續必定需要搭配 DI，才能夠又把這個 object 「注入」回來給我們使用，因此「IoC + DI」這兩個名詞，可以說是捆綁再一起的概念，他們兩個是相輔相成的！\n補充：這裡不得不佩服當初命名 DI 的人，到底是怎麼想到「注入」這個這麼艱難的詞的，文學造詣也太好了吧！！不過老實說他也真的描述的很形象就是了，就像是打針一樣，把 HpPrinter 給注入到 Teacher 裡面。\n什麼是 Bean？ # 介紹完了 IoC 和 DI，最後我們來介紹一下什麼是 Bean。\n這裡還是舉前面的印表機的例子，當我們使用了 IoC 之後，object 的控制權就會交給 Spring 容器來管理，因此以後所有的 object，他們就都是活在 Spring 容器裡面，由 Spring 容器來管理這個這些 object 的生命週期。\n而這些 「由 Spring 容器所管理的 object，我們就賦予他們一個新的名字，叫做 Bean」，所以 Bean 說穿了，其實就只是一個 object 而已，跟我們用 new 去創建的 HpPrinter 是一模一樣的！只是因為這些 object 是被放在 Spring 容器中來管理，所以他們就有了新的名字，叫做 Bean，就只是這樣子而已！\n所以以後大家在開發 Spring Boot 程式時，看到 Bean 就不用太緊張，想說這是什麼神奇的東西，他其實就只是由 Spring 容器所管理的 object 而已，本質上和我們直接去 new 一個出來的 object 沒什麼區別。\n但也因為 Bean 在 Spring Boot 程式中使用的層面實在是太廣了，後面許多技術都會牽扯到 Bean 的概念，因此建議大家一定要了解 Bean 的意義和用途會比較好！\n總結 # 這篇文章我們延續了上一篇文章對 Spring IoC 的介紹，補足了 Spring IoC 中也很重要的兩個名詞概念：DI 和 Bean，讓大家對於 Spring IoC 有一個更全面的了解。\n那麼下一篇文章，我們就會去實際到 IntelliJ 中應用 Spring IoC 的概念，練習在 Spring Boot 的程式中創建一個 Bean，並且將這個 Bean 注入到其他的 class 中，那我們就下一篇文章見啦！\n補充：本文是擷取自我開設的線上課程 Java 工程師必備！Spring Boot 零基礎入門 的內容，如果你想了解更多的 Spring Boot 的用法，歡迎參考課程簡介 （輸入折扣碼「HH202601KU」即可享 85 折優惠）。\n","date":"2024-07-06","objectID":"c49a44587ce675b2cac65e7615995e04","title":"Spring Boot 零基礎入門 (6) - IoC、DI、Bean 的介紹","url":"https://kucw.io/blog/springboot/6/"},{"categories":["Spring Boot"],"content":"哈囉大家好，我是古古。\n在前面的文章中，我們有先去安裝開發環境，並且成功使用 IntelliJ 這套軟體，去創建出了第一個 Spring Boot 程式，先對如何撰寫 Spring Boot 程式有了一個最基本的了解。\n那麼從這篇文章開始，我們就會開始來介紹 Spring 框架中一個非常重要的特性，也就是 IoC，所以我們就開始吧！\n目錄 什麼是 IoC？ 例子：印表機的故事 新增一個 Teacher class 但是\u0026hellip;如果 HpPrinter 印表機壞掉了怎麼辦？ IoC（Inversion of Control，控制反轉） Spring IoC 的定義 Spring IoC 的優點 1. Loose coupling（鬆耦合） 2. Lifecycle management（生命週期管理） 3. More testable（方便測試程式） 總結 什麼是 IoC？ # IoC 的全稱是 Inversion of Control，中文翻譯成「控制反轉」，不過這個控制是控制什麼、反轉又是反轉什麼，我們可以直接透過一個印表機的例子來了解一下。\n例子：印表機的故事 # 假設今天我們先設計一個印表機 Printer 的 interface，這個印表機裡面只有一個方法，就是 print() 方法印東西，程式如下：\npublic interface Printer { void print(String message); } 而有了 interface 之後，我們就可以去寫一個 class 來實作這個 Printer interface，所以我們可以寫一個 HpPrinter 的 class，表示這是一個 HP 牌子的印表機，程式如下:\npublic class HpPrinter implements Printer { @Override public void print(String message) { System.out.println(\u0026#34;HP印表機: \u0026#34; + message); } } 並且我們也可以再寫一個 CanonPrinter 的 class，表示這是一個 Canon 牌子的印表機，程式如下：\npublic class CanonPrinter implements Printer { @Override public void print(String message) { System.out.println(\u0026#34;Canon印表機: \u0026#34; + message); } } 所以到目前為止，我們就有了兩個 class，一個是 HpPrinter、另一個則是 CanonPrinter，而這兩個印表機裡面，就都會去 implements Printer 這個 interface，去實作他裡面的 print() 方法。\n新增一個 Teacher class # 有了兩個印表機之後，我們可以再去設計一個 Teacher class，然後在這個 Teacher class 裡面，宣告一個 Printer 類型的變數，並且在後面去 new 一個 HpPrinter 出來。\npublic class Teacher { private Printer printer = new HpPrinter(); public void teach() { printer.print(\u0026#34;I\u0026#39;m a teacher\u0026#34;); } } 補充：這裡使用到 Java 中的「多型（polymorphism）」的概念，因此 HpPrinter 才可以被向上轉型成 Printer 類型。如果對於 Java 中的多型概念不熟悉的話，建議一定要回頭去了解一下會比較好，Java 多型的應用，會非常常出現在 Spring Boot 的程式裡面。\n所以到這裡為止，整個結構圖就會像是下面這個樣子，剛剛我們所新增的 Teacher class，他就在 class 裡面宣告了一個 Printer 的變數，並且在裡面去 new 了一個 HpPrinter 出來，然後使用這個 HpPrinter 的印表機去印東西了。\n但是\u0026hellip;如果 HpPrinter 印表機壞掉了怎麼辦？ # 但是假設這個時候，HpPrinter 如果突然壞掉了，那 Teacher 就只能改成去使用 CanonPrinter 印表機，繼續去印東西出來。\n所以這個時候，我們就只能去改寫 Teacher 裡面的程式，將裡面的 Printer 變數，改成是去 new 一個 CanonPrinter 出來，因此結構圖就會變成是下面這個樣子：\n所以到這邊，我們可能就會產生了一個新的想法：就是身為一個 Teacher，我們其實只是想要一台印表機去印東西而已，不論這個印表機是 HP 還是 Canon 品牌，只要他可以印東西出來就好，我們根本不在意我們所使用的是哪個牌子的印表機。\n但是因為我們在 Teacher 的程式裡面，「具體的去指定了」要使用的是哪一牌的印表機，所以每當我們換一次牌子，我們就必須要把所有使用到印表機的程式，全部都修改一遍，因此就會變得非常麻煩（現在只有 Teacher 這個 class 需要修改，所以大家可能覺得還好，大不了就動手改一下，但是當 Project 越寫越大之後，要這樣一個一個修改是非常困難的）。\n所以這時候，Spring 就提出了一個新的概念來解決這個問題，也就是 IoC（Inversion of Control，控制反轉）。\nIoC（Inversion of Control，控制反轉） # 為了解決上面的「替換印表機」的問題，Spring 就提出了一個新的想法，也就是 「將這個 Printer 的 object（物件）交由 Spring 保管，當誰要使用印表機時，就再去跟 Spring 拿就好」。\n反正我們作為 Teacher 來說，也不是很在意使用到的是 HP 印表機、還是 Canon 牌的印表機，我們只要確保能夠拿到一個印表機來印東西就好。\n所以在這個情境下，HpPrinter 和 CanonPrinter 這兩個印表機，就統一交由 Spring 進行保管，而我們作為 Teacher，就不需要提前將 HpPrinter 和 CanonPrinter 的資訊寫死在 Java 程式裡面，所以 Teacher class 就可以改寫成像是下面這樣：\n可以看到在 Teacher class 中，我們只定義了一個 Printer 的變數，並且我們沒有為這個 printer 變數，去 new 一個 HpPrinter 或是 CanonPrinter 出來，因此這個 printer 變數的值，預設就會是 null。\n但是，當 Spring Boot 程式運作起來之後，Spring 就會去啟動一個 「Spring 容器（Spring Contianer）」，然後 Spring 會預先去 new 一台印表機出來（此處以 HpPrinter 當作例子），並且存放在 Spring 容器裡面保存。\n因此後續當 Teacher 想要使用印表機時，Spring 就會把這個預先 new 好、並且存放在 Spring 容器中的 HpPrinter，把他交給 Teacher，因此 Teacher 就可以正常的使用這個 HP 印表機，去印他想印的東西了。\n所以大家也可以簡單的想像成是：Spring 他會預先去買一台印表機，然後儲存在「Spring 容器」裡面，而誰想要印東西，他就去跟 Spring 借，所以印東西的人就再也不用自己去準備一台印表機，只要一直去跟 Spring 借就好了，這個就是","date":"2024-07-05","objectID":"104e6e8f6ff918b90de7c702709635c9","title":"Spring Boot 零基礎入門 (5) - Spring IoC 簡介","url":"https://kucw.io/blog/springboot/5/"},{"categories":["Spring Boot"],"content":"哈囉大家好，我是古古。\n在前兩篇文章中，我們有分別去介紹了一下，要如何在 Mac 和 Windows 中架設 Spring Boot 的開發環境。\n所以這篇文章，我們就可以來使用前面所安裝的工具，建立你的第一個 Spring Boot 程式出來了！\n目錄 啟用 IntelliJ IDEA Ultimate 創建第一個 Spring Boot 程式 建立專案、Project 設定 選擇要載入的 Spring Boot 功能 IntelliJ 的操作介面 實作第一個 Spring Boot 程式 添加 demo 程式 運行 Spring Boot 程式 所以，我們剛剛都做了什麼？ 總結 啟用 IntelliJ IDEA Ultimate # 創建 Spring Boot 程式的第一步，就是要先啟用 IntelliJ IDEA Ultimate 的試用期。所以大家可以先開啟 IntelliJ 的程式，這時候 IntelliJ 就會跳出下面這個視窗，要你去登入帳號，並且確認這個帳號是否已經啟用 IntelliJ 的付費版本。\n如果要啟用 30 天的免費試用的話，只需要點擊右上角的「Start trial」，然後點擊下方的「Start Trial」按鈕，這樣子就可以取得 30 天的免費試用期了。\n補充：點擊 Start Trial 的按鈕之後，瀏覽器會跳出一個 IntelliJ 的頁面，詢問你要不要訂閱電子報，這部分可訂閱可不訂閱，不過不管有沒有訂閱，只要直接回到 IntelliJ 程式，都是可以成功啟用 30 天試用期的。\n創建第一個 Spring Boot 程式 # 建立專案、Project 設定 # 啟用 30 天試用期成功之後，我們就可以開始來創建你的第一個 Spring Boot 程式了！只要點擊 IntelliJ 中間的「New Project」，就可以去創建一個新的 Spring Boot 程式出來。\n接著 IntelliJ 就會跳出下面這個視窗，要我們進行 Project 的設定。這裡先點擊左邊側邊欄的「Spring Boot」，表示我們要創建的是 Spring Boot 的程式，接著右邊就是跟著下圖一樣，選擇一樣的設定即可。\n設定好右邊的 Project 設定之後，我們也可以回頭來看一下，右邊這些值分別代表什麼意思：\nName： 這個 Spring Boot 程式的資料夾名字。 Location： 這個 Spring Boot 程式預計創建出來的位置，預設是放在桌面上。 Language： 使用哪種語言來開發 Spring Boot 程式，預設是 Java。 Type： 選擇要使用哪種工具來構建 Spring Boot 程式，這部分比較複雜，因此先照著選 Maven 即可。 Group、Artifact、Package name： 這些值和上面的 Maven 有關，一樣是比較複雜所以可以先跳過不理他。 JDK、Java： 選擇想要使用的 Java 版本。 Packaging： 打包 Spring Boot 的方式，預設是 Jar，這部分一樣是比較複雜（牽涉到 Tomcat），所以也是可以先跳過不理他。 而當大家設定好右邊的參數設定之後，就可以按下 Next 繼續。\n選擇要載入的 Spring Boot 功能 # 進到下一個視窗之後，就可以在這裡選擇想要使用的 Spring Boot 的版本、以及想要載入哪些功能進來。\n像是在上圖的左上方紅框處，就可以去選擇 Spring Boot 的版本，這裡大家可以直接使用預設的最新版即可，不用特別去做調整。\n而在下方的部分，則是可以去選擇要載入哪些功能到這個 Spring Boot 程式裡面，這裡我們先展開Web，然後勾選裡面的「Spring Web」即可。\n勾選完成之後，就可以點擊右下角的 Create，完成 Spring Boot 程式的創建。\nIntelliJ 的操作介面 # 創建好 Spring Boot 程式後，IntelliJ 會開啟一個視窗，就會根據我們剛剛的設定，去創建這個 Spring Boot 程式出來。\n這時候右下角的進度條會開始跑，第一次創建會需要比較長的常見，並且需要確保網路的暢通（會下載許多 Spring Boot 的 library 下來），等到右下角的進度條跑完之後，就創建完 Spring Boot 程式了（約需要 3-5 分鐘左右）。\n而在 Spring Boot 程式創建的過程中，大家也可以先熟悉一下 IntelliJ 的軟體介面，像是在 IntelliJ 的介面中：\n左側的部分是側邊欄，呈現了這個 demo 資料夾中的所有程式。 右側則是程式的編輯區，只要在左側側邊欄對著檔案點擊兩下，就可以將程式開啟到右邊的編輯區，開始編輯這份程式。 補充：IntelliJ 的編輯區是會自動存檔的，因此大家不用擔心寫程式寫到一半沒存檔怎麼辦，揪甘心！\n另外也補充一下，因為 IntelliJ 預設的字體還滿小的，所以建議大家可以調大程式編輯區的字體，保護眼睛從你我做起。\n只要點擊右上方的齒輪，然後點擊「Settings」，就可以叫出偏好設定，接著在設定裡面，再點擊 Editor 中的 Font，就可以在右側設定編輯區的字型、以及字體大小了！\n實作第一個 Spring Boot 程式 # 設定好 IntelliJ 的字體偏好設定、並且確認右下角的進度條跑完之後，我們終於可以開始來實作我們的第一個 Spring Boot 程式了！\n首先我們先展開左側的資料夾，這時候可以看到，在 src/main/java/com.example.demo 底下，有一個 DemoApplication.class 的檔案，點擊兩下開啟這個檔案之後，在右側就可以看到他的內容。\n而在這個 DemoApplication 的程式裡面，其中最重要的，就是第 6 行的 @SpringBootApplication 程式。\n第一次接觸 Spring Boot 的大家，可能會覺得第 6 行這種前面帶有小老鼠 @ 的程式很奇怪，不過這種前面帶有小老鼠的寫法，在 Java 裡面稱作「annotation」，中文是翻譯為「標註」或是「註解」。\n補充：一般在口語上，會稱呼這種前面帶有小老鼠的程式為「annotation」，不過由於版面因素，後續都會使用「註解」來稱呼。\n第 6 行程式的這種寫法，在一般的 Java 程式中比較少看到，不過在 Spring Boot 裡面卻非常常見，所以在後續的文章中，我們也會介紹在 Spring Boog 中，好用的 annotation（註解）有哪些。\n如果你是第一次接觸「註解」的話，建議可以先把「註解」想像成是賦予一個新的功能，不同的註解所提供的功能不一樣，並且他們的使用方法也會不太一樣。\n所以像是第 6 行這個 @SpringBootApplication，他的用法是要加在 class 上面，而他的用途，則是表示這一個 DemoApplication.class，是這個 Spring Boot 程式的啟動入口。\n也因為我們有在第 6 行加上 @SpringBootApplication，所以在第 7 行的左邊，才會出現一個播放鍵的符號，讓我們可以直接點擊這個播放鍵，去運行這個 Spring Boot 程式。\n所以到這邊為止，我們就大致了解了 @SpringBootApplication 的用途（就是將該 class 變成 Spring Boot 程式的啟動入口），以及如何在 IntelliJ 中運行 Spring Boot 程式了，不過在我們真的去運行這個 Spring Boot 程式之前，我們可以先來添加一些 Java","date":"2024-07-04","objectID":"305d566baa6e7d93ce4e9f4938a5d878","title":"Spring Boot 零基礎入門 (4) - 第一個 Spring Boot 程式","url":"https://kucw.io/blog/springboot/4/"},{"categories":["Spring Boot"],"content":"哈囉大家好，我是古古。\n在上一篇文章中，我們有先針對 Mac 系統的使用者，介紹要如何在 Mac 系統中安裝此系列文會用到的所有開發工具。\n所以這篇文章，我們就接著來介紹一下，要如何在 Windows 系統中安裝此系列文的開發工具。\n補充：如果你是 Mac 系統的使用者，可以略過這篇文章，直接查看下一篇文章 Day 4 - 第一個 Spring Boot 程式 的介紹。\n目錄 此系列文中會使用到的開發工具 1. 安裝 IntelliJ IDEA Ultimate 付費版 下載 IntelliJ IDEA Ultimate 付費版 2. 安裝 Java 21 下載 Java 21 3. 安裝 MySQL 資料庫 下載 MySQL 資料庫 安裝 MySQL 4. 安裝 Chrome 擴充功能 - Talend API Tester 下載 Chrome 擴充功能 - Talend API Tester 5. 安裝 Git 下載 Git 總結 此系列文中會使用到的開發工具 # 此系列文會使用到的開發工具有：\nIntelliJ IDEA Ultimate 付費版（有 30 天試用期） Java 21 MySQL 資料庫 Chrome 擴充功能 - Talend API Tester 另外，雖然在此系列文中不會使用到 Git，但是因為 Git 可以說是工程師必安裝的程式，因此在這裡也會一併介紹安裝。\nGit 所以接下來，我們就一起來把這些開發工具給安裝完畢，為將來的 Spring Boot 之旅架設好開發環境吧！\n1. 安裝 IntelliJ IDEA Ultimate 付費版 # IntelliJ IDEA 這套軟體是目前開發 Spring Boot 的熱門軟體之一，他有分為 Community（社群版）以及 Ultimate（付費版）兩個版本。\nCommunity（社群版）對 Spring Boot 的支援比較少，許多功能都必須要額外裝插件才能使用，而 Ultimate（付費版）則是對 Spring Boot 的支援比較全面，但是就需要付費使用。\n不過因為 Ultimate（付費版）有 30 天免費試用期，因此如果是初學的話，建議可以先使用 Ultimate（付費版）的試用期來學習 Spring Boot，等到摸的比較熟之後，再換成 Community（社群版），這樣子在學習上，才不會一開始就被環境問題搞得心力交瘁。\n補充：如果大家有學生教育信箱，也可以到 JetBrains 的網站申請教育帳號，就能免費使用 Ultimate（付費版）一年（具體細節以 JetBrains 官網為準）。\n下載 IntelliJ IDEA Ultimate 付費版 # 想要下載 IntelliJ IDEA Ultimate 的話，可以點擊 IntelliJ 官網連結，就會進到 IntelliJ 的下載頁面。\n進到 IntelliJ 的下載頁面之後，IntelliJ 官網會自動偵測你的電腦系統，提供 Windows 的下載點給你，所以大家只需要點擊 Download 按鈕下載即可。\n下載好之後，點擊兩下執行安裝檔，並且先一路按下 Next 繼續。直到當 IntelliJ 呈現下面這個視窗時，建議勾選左上角的「Create Desktop Shortcut」，這樣安裝程式就會在桌面建立一個 IntelliJ 的捷徑，方便大家日後執行 IntelliJ 的程式。\n設定好之後，接著後面一路繼續點擊 Next，這樣子就可以完成 IntelliJ 的安裝了。\n有關IntelliJ的用法，會在後續的文章中繼續介紹，所以這裡只要先安裝成功就可以了。\n2. 安裝 Java 21 # 下載 Java 21 # 在開發 Spring Boot 程式時，首先我們必須要先安裝對應的 Java 版本，後續才能夠成功的運行起 Spring Boot 程式。目前市面上有非常多公司都有提供 Java 版本的下載，大家可以自由選擇自己喜歡的版本下載。\n在此系列文中，我們會下載由 Eclipse Adoptium 所維護的開源免費 Java 版本（即是 OpenJDK），大家可以點擊 Adoptium 官網連結，就可以進到 Adoptium OpenJDK 的下載頁面。\n進到 Adoptium OpenJDK 的下載頁面之後，下方可以選擇你的作業系統、以及想要安裝的 Java 版本，因為本文是 Windows 系統的安裝教學，所以我們就在 Operating System 中選擇「Windows」，並且在 Version 中選擇「21 – LTS」，這時網站就會列出相關的載點，提供給你下載。\n補充：Adoptium OpenJDK 有提供了非常多種 Java 版本給大家下載，如果大家之後有需要安裝其他版本的 Java，也可以到這個網站中下載。\n選擇好系統和 Java 版本之後，這時候在下方會出現多個載點，這裡就直接點擊最上面的載點下載即可。\n下載好之後，一樣點擊兩下執行安裝檔，接著在安裝過程中會出現下面這個視窗。這時建議在「Set JAVA_HOME variable」前面的「X」點擊一下左鍵，然後選擇「將安裝在本機磁碟上」。\n這樣子就可以在安裝 Java 版本的過程中，同步設定 JAVA_HOME 的環境變數，所以將來如果有需要透過 cmd 的指令執行 Java 的話，就可以直接使用了！\n所以設定好之後，接著後面就一樣是一直點擊下一步，就可以完成 Java 的安裝了。\n補充：不了解什麼是 JAVA_HOME 環境變數也沒關係，就直接照著上面的建議進行設定就好，反正 JAVA_HOME 就只是我們在安裝 Java 的過程中，順手一起設定好一個變數，在後續的文章中並不會使用到這個部分。\n3. 安裝 MySQL 資料庫 # 下載 MySQL 資料庫 # 因為此系列文會使用 MySQL 資料庫來串接 Spring Boot，因此會需要大家先在自己的電腦上安裝 MySQL，以利後續的文章使用。\n要安裝 MySQL 的話，可以點擊 MySQL Community Server 官網連結，就可以直接進到 MySQL Community Server 的下載頁面。\n進到 MySQL Community Server 的下載頁面之後，需要選擇我們想安裝的 MySQL 版本、以及安裝的作業系統，因為本文是 Windows 系統的安裝教學，所以我們在 Select Version 中選擇「8.0.39」，而 Select Operating System 中則選擇 「Microsoft Windows」，就可以篩選出 Windows 專用的下載載點。\n篩選出 MySQL 的版本之後，下方一樣是有多個載點可以選擇，這時我們先點擊上方的「MySQL Installer」。\n並且在跳轉到下一個頁面之後，再點擊上方的 Download 按鈕，去下載 MySQL 資料庫的安裝程式下來。\n不過在點擊下載的按鈕之後，此時 MySQL 會跳出一個頁面，詢問你要不要註冊新帳號，這時候可以不用管他，直接往下拉，然後點擊下方的「No thanks, just start my download.」，繼續 MySQL 的下載。\n下載好安裝檔之後，一樣是點擊兩下執行安裝檔，開始 MySQL 資料庫的安裝。\n安裝 MySQL # 執行 MySQL 的安裝程式之後，首先 MySQL 會跳出下面的視窗，要我們進行設定。這裡我們就改成勾選第一個「Server only」，這樣就只會安裝 MySQL 資料庫，而不會安裝其他額外的軟體。\n接著幾個視窗，都是直接按下 Next 繼續，直到出現下面這個視窗","date":"2024-07-03","objectID":"0917e578755fab41af488ca3f468b536","title":"Spring Boot 零基礎入門 (3) - 開發環境安裝（Windows 版）","url":"https://kucw.io/blog/springboot/3/"},{"categories":["Spring Boot"],"content":"哈囉大家好，我是古古。\n在學習 Spring Boot 之前，環境的架設也是很重要的，所以這篇文章，我們就先來進行環境設定，為將來的 Spring Boot 之旅架設好開發環境。\n不過因為 Mac 和 Windows 系統的安裝方式差異比較大，所以這邊會拆成兩篇文章來介紹。 如果你的電腦是 Mac 系統，可以直接查看這篇文章，如果你的電腦是 Windows 系統，則可以直接查看下一篇文章 Day 3 - 開發環境安裝（Windows 版） 的介紹。\n目錄 此系列文中會使用到的開發工具 1. 安裝 IntelliJ IDEA Ultimate 付費版 下載 IntelliJ IDEA Ultimate 付費版 2. 安裝 Java 21 下載 Java 21 3. 安裝 MySQL 資料庫 下載 MySQL 資料庫 安裝 MySQL 4. 安裝 Chrome 擴充功能 - Talend API Tester 下載 Chrome 擴充功能 - Talend API Tester 5. 安裝 iTerm2、oh-my-zsh、Homebrew 安裝 iTerm2 安裝 oh-my-zsh 安裝 Homebrew 6. 安裝 Git 總結 此系列文中會使用到的開發工具 # 此系列文會使用到的開發工具有：\nIntelliJ IDEA Ultimate 付費版（有 30 天試用期） Java 21 MySQL 資料庫 Chrome 擴充功能 - Talend API Tester 另外，雖然此系列文中不會使用到下面這些工具，但是因為這些工具非常的好用，可以說是 Mac 開發者必安裝的工具，因此在這裡也會一併介紹安裝。\nHomebrew + iTerm2 + oh-my-zsh Git 所以接下來，我們就一起來把這些開發工具給安裝完畢，為將來的 Spring Boot 之旅架設好開發環境吧！\n1. 安裝 IntelliJ IDEA Ultimate 付費版 # IntelliJ IDEA 這套軟體是目前開發 Spring Boot 的熱門軟體之一，他有分為 Community（社群版）以及 Ultimate（付費版）兩個版本。\nCommunity（社群版）對 Spring Boot 的支援比較少，許多功能都必須要額外裝插件才能使用，而 Ultimate（付費版）則是對 Spring Boot 的支援比較全面，但是就需要付費使用。\n不過因為 Ultimate（付費版）有 30 天免費試用期，因此如果是初學的話，建議可以先使用 Ultimate（付費版）的試用期來學習 Spring Boot，等到摸的比較熟之後，再換成 Community（社群版），這樣子在學習上，才不會一開始就被環境問題搞得心力交瘁。\n補充：如果大家有學生教育信箱，也可以到 JetBrains 的網站申請教育帳號，就能免費使用 Ultimate（付費版）一年（具體細節以 JetBrains 官網為準）。\n下載 IntelliJ IDEA Ultimate 付費版 # 想要下載 IntelliJ IDEA Ultimate 的話，可以點擊 IntelliJ 官網連結，就會進到 IntelliJ 的下載頁面。\n進到 IntelliJ 的下載頁面之後，IntelliJ 官網會自動偵測你所使用的 Mac 是屬於 Intel 晶片、還是屬於 Apple 的M1、M2\u0026hellip;等等的晶片，並且提供相對應的下載檔給你。\n所以大家只需要點擊 Download 按鈕，就可以下載你的晶片所對應的 IntelliJ 程式了（或是也可以點擊右邊的 .dmg，手動選擇你想下載哪一種晶片的程式）。\n下載好之後，開啟 .dmg 檔案，並且將 IntelliJ IDEA Ultimate 的程式拉到「應用程式」的資料夾裡面，就可以完成 IntelliJ 的安裝了。\n有關 IntelliJ 的用法，會在後續的文章中繼續介紹，所以這裡只要先安裝成功就可以了。\n2. 安裝 Java 21 # 下載 Java 21 # 在開發 Spring Boot 程式時，首先我們必須要先安裝對應的 Java 版本，後續才能夠成功的運行起 Spring Boot 程式。目前市面上有非常多公司都有提供 Java 版本的下載，大家可以自由選擇自己喜歡的版本下載。\n在此系列文中，我們會下載由 Eclipse Adoptium 所維護的開源免費 Java 版本（即是 OpenJDK），大家可以點擊 Adoptium 官網連結，就可以進到 Adoptium OpenJDK 的下載頁面。\n進到 Adoptium OpenJDK 的下載頁面之後，下方可以選擇你的作業系統、以及想要安裝的 Java 版本，因為本文是 Mac 系統的安裝教學，所以我們就在 Operating System 中選擇「macOS」，並且在 Version 中選擇「21 – LTS」，這時網站就會列出相關的載點，提供給你下載。\n補充：Adoptium OpenJDK 有提供了非常多種 Java 版本給大家下載，如果大家之後有需要安裝其他版本的 Java，也可以到這個網站中下載。\n選擇好系統和 Java 版本之後，這時候在下方會出現多個載點，這裡就需要根據你自己的 Mac 晶片，去選擇對應的載點。\n如果你的 Mac 是 Apple 的 M1、M2\u0026hellip;等晶片，那就是點擊上方的 aarch64 的載點；如果你的 Mac 是 Intel 晶片，則是點擊下方的 x64 的載點，這部分因為牽涉到比較底層的硬體環境，因此需要小心選擇。\n下載好之後，一樣是雙擊 .dmg 的下載檔，然後一路按「下一步」，就可以完成 Java 的安裝了。\n3. 安裝 MySQL 資料庫 # 下載 MySQL 資料庫 # 因為此系列文會使用 MySQL 資料庫來串接 Spring Boot，因此會需要大家先在自己的電腦上安裝 MySQL，以利後續的文章使用。\n要安裝 MySQL 的話，可以點擊 MySQL Community Server 官網連結，就可以直接進到 MySQL Community Server 的下載頁面。\n進到 MySQL Community Server 的下載頁面之後，需要選擇我們想安裝的 MySQL 版本、以及安裝的作業系統，因為本文是 Mac 系統的安裝教學，所以我們在 Select Version 中選擇「8.0.39」，而 Select Operating System 中則選擇 「macOS」，就可以篩選出 Mac 專用的下載載點。\n篩選出 MySQL 的版本之後，接著在下方的載點中，一樣是需要根據你的 Mac 晶片，選擇對應的下載點。\n如果你的 Mac 是 Apple 的 M1、M2\u0026hellip;等晶片，那就是點擊上方的 aarch64 的載點；如果你的 Mac 是 Intel 晶片，則是點擊下方的 x64 的載點，這裡就必須要小心選擇，以免下載到錯誤版本。\n在確定好晶片的版本之後，就可以點擊對應的下載按鈕，進行 MySQL 的下載。\n不過在點擊下載的按鈕之後，此時 MySQL 會跳出一個頁面，詢問你要不要註冊新帳號，這時候可以不用管他，直接往下拉，然後點擊下方的「No thanks, just start my download.」，繼續 MySQL 的下載。\n下載好安裝檔之後，一樣是雙擊 .dmg 的下載檔，開始 MySQL 資料庫的安裝。\n安裝 MySQL # 執行 MySQL 的安裝程式之後，前面先一直點擊「繼續」和「同意」就好。不過安裝到一半時，MySQL 會跳出下面的視窗，要我們設定資料庫，注意","date":"2024-07-02","objectID":"382444286f2ef82ae30c302df7e35e63","title":"Spring Boot 零基礎入門 (2) - 開發環境安裝（Mac 版）","url":"https://kucw.io/blog/springboot/2/"},{"categories":["Spring Boot"],"content":"哈囉大家好，我是古古。\n這次希望可以透過 30 天的鐵人賽文章，讓沒接觸過（甚至沒聽過）Spring Boot 的人，了解 Spring Boot 到底是什麼，以及如何運用 Spring Boot 搭建一個簡易的後端系統。\n那麼我們就開始吧，Let\u0026rsquo;s go！\n目錄 學習目標（你可以學到什麼？） 哪些人適合閱讀這個系列文（適合誰？） 閱讀前的準備（須具備什麼知識？） 正文開始：什麼是 Spring Boot？ 「前端」和「後端」的差別 「框架」是什麼意思？ 所以，Spring Boot 到底是什麼？ Spring Boot 的優勢在哪裡？ 優勢一：簡化 Spring 開發 優勢二：快速整合主流框架 其他優勢 系列文章規劃 1. Day 1～4：Spring Boot 簡介、開發環境安裝 2. Day 5～12：Spring 框架的特性 - IoC 和 AOP 3. Day 13～23：Spring MVC 介紹 4. Day 24～28：Spring JDBC 介紹 5. Day 29：實戰演練：打造簡易的圖書館系統 Final. Day 30：Spring Boot 零基礎入門總結 總結 學習目標（你可以學到什麼？） # 經過這 30 篇系列文，你可以學到：\n了解什麼是 Spring Boot，以及如何運用 IntelliJ 這套軟體開發 Spring Boot 程式 了解 Spring 框架的兩大特性 - IoC 和 AOP 了解 Spring MVC、Spring JDBC 的基本用法 能夠運用 Spring Boot，實作出一個簡易的後端系統 哪些人適合閱讀這個系列文（適合誰？） # 想學習 Spring Boot，但不知道從何入門 看過 Spring Boot 的相關介紹，但不了解實際要如何運用 閱讀前的準備（須具備什麼知識？） # 閱讀此系列文前，必須具備「Java 程式語言」和「MySQL 資料庫設計」的知識：\nJava：了解基本 Java 的語法，並且至少要知道 「多型（polymorphism）」 的概念 MySQL：了解基本的 SQL 語法（Select、Update、Insert、Delete）即可 另外 Mac / Windows 皆可閱讀，電腦環境不影響。\n正文開始：什麼是 Spring Boot？ # 所謂的 Spring Boot，他是目前 Java 後端中最主流的開發框架，不過在開始介紹什麼是 Spring Boot 之前，我們需要先來了解一下「前端」跟「後端」之間的差別、以及「框架」又是代表什麼意思。\n「前端」和「後端」的差別 # 在現今的網站架構中，可以分成「前端」和「後端」兩部分：\n前端：負責網頁的排版設計。 所以像是網頁中要使用什麼顏色的按鈕、按鈕要放在哪裡、標題大小要多大\u0026hellip;等等，這些都是屬於前端的範疇。 後端：負責數據處理。 所以像是商品的價格是多少、每一筆評價的留言內容是什麼\u0026hellip;等等，這些有關數據內容的，都是屬於後端的範疇。 所以簡單的說的話，前端工程師就是去負責實作「這個網頁要長什麼樣子」，而後端工程師，則是負責去處理「要在這個網頁上賣什麼東西」，所以前端工程師處理的是排版設計，而後端工程師處理的則是動態的數據。\n而在理解了前端和後端的概念之後，接著就可以來理解「框架」的概念了。\n「框架」是什麼意思？ # 透過剛剛的介紹，現在我們知道，前端是負責網頁的排版設計，後端則是負責數據處理。而在前端的世界中，其實是有非常多種的程式語言，都可以去實作出網站的排版設計，所以同樣的道理，在後端的世界中，也是有非常多種的程式語言，可以去實作出數據處理的功能的。\n在後端的世界裡中，比較常被拿來使用的程式語言有 Java、Python、PHP…等等，所以「Java 後端」所表示的，就是使用 Java 來開發的後端程式。\n而在最古早的時代，工程師們就是直接拿著 Java 和 Python 這種程式語言，一筆一畫的把整個後端系統給實作出來，所以使用者就可以透過這個後端系統，在某個電商網站中執行購買商品、或是去查看商品評價……等等的操作。\n但是這些工程師們當時寫著程式就發現，每次開發一個後端系統，都要重新寫一堆相似度非常高的程式，覺得很心累也很浪費時間，因此就有團隊開始開發出了 「框架（Framework）」，試圖提升開發後端系統的效率。\n所以到這邊為止，你可以先簡單的把「框架（Framework）」想像成是一個好用的工具包，在沒有框架以前，你要花非常多時間和力氣，才能夠手動的用螺絲起子，去把整個後端的系統給蓋出來，而在有了框架之後，你就像拿到一把強力電鑽一樣，只要輕鬆的按幾下按鈕，就可以快速的把後端系統給架設出來了。\n所以「加速工程師開發的效率」，就是「框架」被發明出來的目的。\n所以，Spring Boot 到底是什麼？ # 了解了「Java 後端」和「框架」的意義之後，這時候我們回頭看最一開始說的那句話，就比較可以看的懂了。\n我們在最一開始有提到：「Spring Boot 是目前 Java 後端中最主流的開發框架」，所以 Spring Boot 的目的，就是「提供一個好用的工具，讓 Java 後端工程師可以加快開發的效率」。\n也因為 Spring Boot 非常的好用，幾行簡單的設定就可以快速架設出一個後端系統出來，所以 Spring Boot 就成為了目前 Java 業界中最主流的開發框架，甚至已經到了 「不會 Spring，不談就業」 的程度，由此也可知 Spring Boot 對 Java 業界的影響程度。\n補充：「框架」的目的，就是為了提升工程師開發的效率，而不同的程式語言，其實都會有他專屬對應的框架可以使用，譬如說以 Java 為例，他對應的主流框架就是 Spring 框架，而 PHP 的話，對應的主流框架則是 Lavarel 框架，不同程式語言之間的框架是沒辦法混用的。\nSpring Boot 的優勢在哪裡？ # 所以到這邊為止，我們已經大概了解了 Spring Boot 的用途了，基本上 Spring Boot 就是 Java 後端中的一個好用的開發框架，只要你是使用 Java 來開發後端程式，通常就是會使用 Spring Boot 這套框架，來加速你開發後端程式的效率。\n但說了這麼多，使用 Spring Boot 的好處在哪裡？他到底為我們提升了哪些開發的效率？所以以下我們就來探討一下，使用S pring Boot 開發的優勢在哪裡。\n優勢一：簡化 Spring 開發 # 使用 Spring Boot 的第一個好處，就是可以「簡化 Spring 的開發」。\n在很久很久以前，在當時傳統的 Spring 框架開發中，其實工程師是需要進行大量的 xml 設定，才能將 Spring 框架運行起來，而 Spring Boot 的推出，就是希望能夠解決 Spring 框架設定繁瑣的缺點。\n舉個例子來說的話，在傳統 Spring 框架中，你就是會有一堆車子的零件，但是你必須要自己「手動」把他們焊接起來，並且你可能還會焊錯；而新一代的 Spring Boot，則是你直接走進去汽車店裡，直接花錢下單把車開走，所以兩者相較起來，當然是 Spring Boot 更加簡單好用。\n另外大家也可以觀察一下「Spring Boot」這個單字，他其實就是由「Spring」和「Boot」兩個字所組合起來的，其中「Spring」所代表的就是 Spring 框架，而「Boot」所代表的則是開機的意思，所以組合這兩個單字的話，就可以得到「Spring Boot」。\n所以 Spring Boot 本身的目的，就是希望能提供一個按下開機鍵，就可以","date":"2024-07-01","objectID":"956a0a3c39e926e90a215b1f5f642da8","title":"Spring Boot 零基礎入門 (1) - Spring Boot 簡介","url":"https://kucw.io/blog/springboot/1/"},{"categories":["Other tech"],"content":"當 Mac 升級到 Sonoma 14.0 之後，只要按下鍵盤左側的「中/英」鍵（也就是 Caps Lock 鍵），Mac 就會出現一個藍色的游標，提示你現在開啟了 Caps Lock\n要關閉這個藍色游標的話，只需要以下三個步驟\n開啟 Terminal 執行以下兩行指令（分別複製後執行） sudo mkdir -p /Library/Preferences/FeatureFlags/Domain sudo /usr/libexec/PlistBuddy -c \u0026#34;Add \u0026#39;redesigned_text_cursor:Enabled\u0026#39; bool false\u0026#34; /Library/Preferences/FeatureFlags/Domain/UIKit.plist 重新開機 這樣就可以關閉那個討厭的藍色游標了，天下太平啦！！\n","date":"2023-10-27","objectID":"ad544515bd017bcd60bbd400a6b361de","title":"關閉 MacOS Sonoma 的 Caps Lock 游標","url":"https://kucw.io/blog/2023/10/mac-sonoma-disable-caps-lock-indicator/"},{"categories":["Life"],"content":"說到夏天，當然就是陽光、沙灘、海！但是如何在炎炎夏日做好防曬措施，絕對是大家最關心的一項議題，本文會從兩個方向來分析如何挑選防曬乳\n挑選防曬乳之前，先了解太陽中的紫外線！ # 太陽中有很多紫外線，其中對我們影響最大的就是 UVA 和 UVB，而 UVA 和 UVB 這兩個紫外線，可以簡單分成兩部分：\n但凡涉及到美醜的，不論是變黑、變老、曬斑、長皺紋，都是 UVA 造成的，也就是 UVA for Aging（老化） 但凡是涉及到生病死亡的，不論是曬傷、皮膚癌、白內障，都是 UVB 惹的禍，也就是 UVB for Burn（灼傷） 所以到這邊大家可以先有個概念，假設你今天想要防曬的是美醜的部分，你就要挑選 UVA 防護比較高的防曬乳，假設你今天想要的是別那麼早死，那你則是要挑選 UVB 防護比較高的防曬乳\n如果是想要照顧美醜的同時、又別那麼早死，那就是挑選 UVA + UVB 皆有防護的防曬乳，不過想當然就是會比較貴啦！\n我不想那麼早死！如何挑選 UVB 防曬乳？ # 美醜可能不是每個人都在意，不過大家應該都不想早死，所以在談論美醜之前，我們先討論如何挑選避免早死的防曬乳，也就是如何針對 UVB for Burn 進行防曬\n要防曬 UVB 很簡單，就是看 SPF 的指數！\nSPF 50 是最棒、SPF 30 是次棒、SPF 15 是普通，而最猛的是 SPF 50 +++++，後面的 ++ 越多表示越厲害\n當然 SPF 這個指標本身的意義不是這麼簡單暴力，他的實際意思是「能夠延長多少不被曬傷的時間」，不過我是建議一般人也不用了解的那麼詳細，就挑數字最大、++ 最多的買下去就對了\n其實大家如果只是單純想防曬 UVB 的話，防曬乳真的是便宜到有剩，因為萬一你得了皮膚癌，最終還是要花費社會的醫療資源來救你，所以各國政府為了避免醫療人口太多，都會把 UVB 防曬乳的價格定的很便宜\n因此如果你今天有出遊計畫，卻又不知道怎麼挑選防曬乳，那就先去隨便買一條 SPF 50+ 的防曬乳來用就可以了！\n除了不那麼早死之外，我還想保持的漂漂亮亮的！如何挑選 UVA 防曬乳？ # 來，只要一講到美醜，這個砸的錢就沒有上限了🥲\n如果你是想要讓自己不會變黑、變老、曬斑、長皺紋，那就是要針對 UVA for Aging 進行防曬\n你知道，因為大家美不美醜不醜，政府都不會因此而增加醫療負擔，所以各國政府其實不是很 care 這件事，因此在 UVA 的防護上，其實沒有一個各國通用的標準可以參考\n現在市面上就有好幾種國際組織，分別對 UVA 的防護進行評斷，包含：\n日本的 PA 系列 英國的 Boots Star Rating 星星系列 歐盟的 PDD 系列 \u0026hellip;..等等，族繁不及備載 也因為每一個組織都用不同的標準來衡量 UVA 的防護，所以說實話，大家就挑自己喜歡的牌子來買就好，反正也沒有一個權威的公信力可以參考，況且美醜也是比較主觀的看法，所以大家只能多買多看，比較哪一種防曬乳是最適合自己膚質、並且荷包又買得起的\n不過如果真要我推薦的話，我會建議大家參考日系的 PA 標準，PA 後面越多 ++ 越好，所以 PA++++++++ 就是 UVA 防禦力爆表的防曬乳（當然價錢可能也爆表）\n會推薦日系的 PA 標準，是因為畢竟亞洲的人種還是比較像，在意的美醜價值觀也比較相似（要白！要透！），而歐美國家畢竟都是白人居多，白人天生就曬不黑啊XDD，所以如果大家有選擇障礙的話，建議可以先從日系的 PA+++ 的防曬乳開始挑起\n不過大家在挑 UVA 防護高的防曬乳時，記得同時也要看防禦 UVB 的 SPF 係數啊！！如果因為在意漂亮而忽略了身體健康，那就得不償失了😖\n總結 # 最後我列了一張表格，整理了一下文章中提到的資訊，提供給大家參考\nUVA UVB 由來 UVA for Aging（老化） UVB for Burn（灼傷） 影響範圍 美醜 生病死亡 造成的傷害 變黑、變老、曬斑、長皺紋 曬傷、皮膚癌、白內障 防曬指標 日本 PA、歐盟 PDD\u0026hellip;.等等 SPF 簡易挑選準則 PA+++++（++ 越多越好） SPF 50+++++（數字越大越好、++ 越多越好） 價錢 貴 便宜 ","date":"2023-05-03","objectID":"18eab7b5d98b5fa260b6fa09fd1924aa","title":"夏日防曬！五分鐘了解如何正確挑選防曬乳","url":"https://kucw.io/blog/2023/5/sun-and-ultraviolet/"},{"categories":["Life"],"content":"最近剛從宿霧玩回來，記錄一下 2023 宿霧 6 天 5 夜旅遊的行程規劃，也分享給有需要的大家\n出遊時間：2023.4.20 - 2023.4.25（6 天 5 夜） 重點行程：墨寶沙丁魚風暴、歐斯陸鯨鯊共游、薄荷島巧克力山+眼鏡猴 走法：逆時針（機場/宿霧市區 -\u0026gt; 墨寶 -\u0026gt; 歐斯陸 -\u0026gt; 薄荷島 -\u0026gt; 機場/宿霧市區） 人數：2 人 總花費：一人 28328（含機票+飯店+所有行程+按摩+各種喝爆+伴手禮） 行前準備 # 出發前 30 天內，線上申請 菲律賓電子簽證 假設 4/20 出發，就是 3/20 開始可以申請 記得印紙本出來，登機和入境要看 在台灣換好 美金現鈔 帶在身上 帶著美金去菲律賓當地再換披索，是換匯最佳解，有錢想省事的也可以在台灣直接台幣換披索 我們兩人 6 天在當地共花 800 美金（不含機票+飯店），剛剛好全花完沒有剩，供大家參考 列印 數位新冠疫苗證明 文件 登機要看 網路上買 Sim 卡，機場取貨 這個有許多選擇，也可以到當地再買，看自己需求 我們是直接買 KKday 上的 菲律賓 Globe Telecom 5G 網卡 強烈推薦帶一台 GoPro，水上活動好玩好拍很多 我們是自己有所以沒有額外租，不過如果要租的話，建議在台灣租，然後帶過去宿霧比較方便 旅平險 or 旅行不便險，依自己需求購買 Day 1 # 詳細資訊 當天重點行程 搭飛機+搭車至墨寶 當天住宿 Pig Dive Hostel（墨寶的青年旅館） 備註 我們在墨寶有許多行程和包車，都是請 Pig Dive 代訂的，老闆是台灣人會說中文，可以先訂住宿之後再跟他們聯繫幫忙代訂行程 搭乘 星宇航空 週四航班，桃園機場（早上 8:30 起飛） -\u0026gt; 宿霧（中午 11:25 降落）的班機 記得帶一支筆，在宿霧機場還需要填寫紙本入境卡，才能入境 聯絡包車司機，下午 2 點從機場出發前往墨寶 私人包車由 Pig Dive 住宿代訂 中間有請司機順路多停一站 SM Seaside City Cebu（要加一點錢），我們是在這邊換匯，1 美金 = 55 披索 大約傍晚 6 點抵達墨寶 Pig Dive Hostel，晚上自由活動 Day 2 # 詳細資訊 當天重點行程 Kawasan Falls 溯溪、墨寶沙丁魚風暴 當天住宿 續住 Pig Dive Hostel 備註 x 早上 7 點集合前往 Kawasan Falls 溯溪（私人包車，不過是搭乘嘟嘟車） 約莫中午 12 點半結束回到旅館，可休息或是附近晃晃 此行程由 Pig Dive 代訂 下午 2:30 集合前往沙丁魚風暴潛水 我們兩人皆有 OW 證照，所以是直接潛一隻水肺 約 4 點結束回到旅館 此行程也是請 Pig Dive 幫忙代訂 晚上也是在墨寶當地自由活動 Day 3 # 詳細資訊 當天重點行程 歐斯陸鯨鯊共游、搭船至薄荷島 當天住宿 Alona Austria Resort（薄荷島） 備註 x 早上 4 點集合前往 歐斯陸鯨鯊共游（私人包車） 車程大概 1 個半小時，所以約莫是快 6 點抵達歐斯陸 看完鯨鯊大概 8 點多結束 此行程也是請 Pig Dive 代訂（含包車+共游） 鯨鯊結束後請司機載我們到 Quartel Beach，此為搭船到薄荷島的港口 從歐斯陸到薄荷島，只有唯一一家船公司 APEKOPTRAVEL 可以選，船票可以事前線上訂，但是記得船票要印紙本出來，登船要看 因為抵達時間太早，所以我們有先在附近吃早餐 早上 11:30 搭船前往薄荷島 約莫下午 1 點抵達薄荷島 可以直接當地隨意攔一台車嘟嘟車前往飯店 飯店 check-in 後就自由活動，今天比較悠閒 Day 4 # 詳細資訊 當天重點行程 跳島 Island hopping（巴里卡薩島浮潛 + 處女島 or Frencesco島） 當天住宿 續住 Alona Austria Resort 備註 我們在薄荷島兩天的行程，都是找當地的導遊 Lutz Gen 幫忙安排的，他英文很好口音很不重，很推薦（可以叫他 Jay） 早上 6 點旅館接人，到 Alona beach 登船（私人包船） 補充一下 Jay 沒有買船，所以當天陪同的船夫會是其他當地人，雖然行程 Jay 會事先幫忙喬好，但介意的人可以自己斟酌 出海追海豚 Dolphin watching 巴里卡薩島浮潛 Balicasag snorkeling 可以加價租面鏡蛙鞋，我們有租 浮潛完可以在巴里卡薩島吃早餐，不吃也可以，不過我們有吃，浮潛完很餓 處女島拍照玩水 Virgin island 如果遇到漲潮，處女島會被淹沒到只剩下個牌子，這時船夫會問你要不要去隔壁另一個 Francesco 島，可自由選擇 如果兩個島都想去也可以，不過就要加錢，我們有加，想說都來了 大概下午 1 點回到 Alona beach，看你玩的速度，反正私人包船沒人趕，船夫就是捨命陪君子陪你到他下班 抵達 Alona beach 可以打電話給 Jay，他會安排人來接你回旅館 抵達旅館後，下午晚上一樣自由活動 Day 5 # 詳細資訊 當天重點行程 巧克力山 + 眼鏡猴（Chocolate hills + Tarsier） 當天住宿 Henann Resort Alona Beach 備註 這天的行程也是找 Lutz Gen 幫忙安排的 早上 8 點旅館接人（私人包車） 巧克力山 Chocolate hills 有興趣也可以加玩一項自費行程：巧克力山越野車探險 ATV，我們有玩，比起開越野車探險本身，反而是越野車導遊的拍照技術更狂一點XD 看眼鏡猴 Tarsier 人造森林拍美照 Man made forest 5 分鐘可完成的景點，還不錯 Loboc 河竹筏游船+ buffet 午餐 Loboc river cruise + buffet lunch 菲律賓式午餐不期不待不受傷害，游船倒是滿有趣，駐船歌手很會唱 因為我們早上多玩了一個越野車，所以我們大概下午 1 點才抵達游船的入口，實際吃午餐的時間為下午 1 點 ~ 下午 2 點半，建議中間可以帶一些小零食以防你餓了 聖母大教堂 Baclayon church 教堂壁畫很酷！台灣滿少看到這類的景點，推 歃血為盟紀念碑 Blood compact 5 分鐘景點，普偏廢，趕時間可跳過 大概下午 4 點回到旅館，一樣看你玩的速度，Jay 會全程開車陪同 晚上一樣是自由活動，我們盡情的享受在 Henann 中XD Day 6 # 詳細資訊 當天重點行程 買伴手禮、搭飛機回台 當天住宿 x 備註 x 早上 9:30 旅館接人，前往薄荷島港口 Tagbilaran Port 車程約 40 分鐘，約莫 10:10 抵達港口 這個車一樣是請 Jay 幫忙訂的 早上 10:40 的船回宿霧市區 約莫中午 12:40 抵達宿霧市區 船票可以事前先訂，船班公司是 OceanJet，可以直接用 Klook 代訂，但是記得船票要印紙本出來，登船要看 下船後我們直接搭計程車去 SM City Cebu 買伴手禮 裡面很大，要什麼有什麼，不用怕買不到 搭計程車記得說魔法關鍵字 \u0026ldquo;By Meter\u0026rdquo;（跳錶計價的意思），終於不用再被當盤子靴 下午 4 點抵達宿霧機場，搭乘 星宇航空 週二航班，宿霧（下午 6:55 起飛） -\u0026gt; 桃園機場（晚上 9:45 降落）的班機 總結 # 以上就是我們這一次宿霧的 6 天 5 夜行程安排，祝大家都能盡興享受海島的陽光沙灘海🏝😎\n","date":"2023-04-27","objectID":"d5bf1c6c98a641bd761f7ad7bd5101dd","title":"2023 宿霧 6 天 5 夜自由行分享（逆時針走法）","url":"https://kucw.io/blog/2023/4/cebu-plan/"},{"categories":["Other tech"],"content":"你是否曾經覺得，明明已經工作了 2、3 年，但是學的東西感覺都不是特別扎實？好像自己平常都只是東學一點、西學一點，程式出錯了就上網查解法，但出去面試被面試官問到技術問題時，你明明記得你看過的，卻不知道為什麼就是答不上來技術細節\n造就這一切的原因，其實都可以歸類成：你沒有建立過自己的知識體系\n好記性不如爛筆頭 # 俗話說「好記性不如爛筆頭」，這句話充分的強調了記筆記的重要性，更何況我們生活在這個知識爆炸的時代，你就算擁有再好的記憶能力，也沒辦法保證能將每一點的知識點都記得牢固\n而且說實在的，要能夠閉著眼睛默寫一段程式出來真的是滿難的，而且其實沒什麼意義，往後你會接觸到更多程式語言、更多框架，所以基本上是不可能把每一行程式全部背下來的\n因此平常比較用不到的知識點，其實不需要特別去記住，只要記在你的筆記裡就行，一但要用上時，只要去你的筆記中查詢，就可以快速找到你曾經學習過的知識，將它應用到你現在遇到的問題上了\n不過有的人可能會說：那這樣跟上網查解法有什麼不同？這個不同之處還是滿大的\n首先網路上的文章參差不齊，你不一定馬上就能找到你需要的解法，就算現在有 ChatGPT 可以輔助使用好了，但是要把關鍵字下的讓 ChatGPT 看得懂也是一門學問\n另外，因為這些文章中所提到的知識點，也沒有被你真正的放進你自己的知識體系，所以當你下次遇到同樣的問題時，你很有可能又忘記怎麼解了，所以你又得重新再次上網查詢解法，被同樣的問題重複絆倒許多次\n所以為什麼經常有大神會鼓勵大家要多寫技術 blog，其實也是相同的道理，你有寫 blog 就表示你有技術輸出，要寫出一篇技術文章，你就得去深入整理你對那個知識點的理解，而透過這樣的方式，無形中就是在為你自己建立知識體系\n因此當你下次又遇到同樣的問題的時候，你就會有印象「對！我曾經遇到過這個問題！」，所以你就可以回頭查看當初所寫的那篇文章，快速的回想起來要怎麼解決這個問題了\n記筆記的工具有哪些？ # 假設你看到這裡，已經認真決定要開始透過寫筆記，去建立自己的知識體系的話，那截至目前為止，記筆記的工具到底有哪些選擇？\n通常第一次筆記的工程師，我會建議選擇最容易取得的平台，也就是 Medium 寫作平台、或是 Notion 這類協作工具\n推薦這兩個平台的原因是因為想盡量降低大家寫作的門檻，因為寫筆記這件事，至少你得先寫起來，再來才是思考哪款筆記工具最好使用，所以在你真的「寫起來」之前，任何屠龍寶刀對你來說都是無用的\n而 Medium 和 Notion 這兩款工具，不僅 UI 介面舒適，並且也沒什麼惱人的廣告，作為第一個上手的記筆記工具還是很適合的\n當你寫筆記越寫越上手、以至於你已經培養了這個習慣之後，接著就可以慢慢找尋適合自己的寫筆記工具了\n工程師我會推薦可以學著使用 Markdown 的格式來記錄筆記，Markdown 是在程式領域裡面滿廣泛使用的一種文字格式，多學習是絕對沒有壞處的，而 Markdown 編輯器我個人最推薦 Typora，雖然需要付一次性買斷的費用，但是我認為非常值得，推薦使用\n總結 # 說了這麼多，最關鍵的因素還是得付出行動，其實有時候自制力差只是行動力不足，就像是想看書的人根本不用上網查：我該怎麼自律才能專注的看書，而是直接拿起書來看就可以了，所以踏出第一步真的沒有這麼複雜\n在變強的道路上總是需要付出時間和精力的，希望大家都可以找到最有效率的方法一起變得更猛💪\n","date":"2023-04-02","objectID":"88d5f52fc52bf3984760e9e39aba41fb","title":"工程師如何累積程式實力？","url":"https://kucw.io/blog/2023/4/rename-iphone-photo-by-date-copy/"},{"categories":["Other tech"],"content":"iPhone airdrop 到 Macbook 上的照片檔名為 IMG_0862.JPG，不利於照片整理，改命名成右邊這種 IMG_20220726_110204.JPG 格式會好整理很多\n想要大量修改圖片檔案名稱為右邊這種格式，可以透過 ExifTool 工具解決\nExifTool 使用教學（Mac 版） # 先到 ExifTool 官網下載安裝檔，並且安裝該 dmg 程式\n打開 Terminal，執行以下指令（最後一個參數值 ~/Downloads/image 為待轉換的照片資料夾，可自行更換路徑）\nexiftool -d \u0026#39;IMG_%Y%m%d_%H%M%S\u0026#39; \u0026#39;-Filename\u0026lt;${DateTimeOriginal}.%e\u0026#39; ~/Downloads/image 執行完成後，照片就會根據創建日期重新命名了，可喜可賀XD\nPS: 注意此指令會直接覆寫檔案檔名，不會備份照片，且此操作無法透過 Ctrl+Z 復原\n","date":"2022-08-05","objectID":"4b1c588264f06e087efb10267f055f4d","title":"重新命名 iPhone 照片檔名為日期時間（Mac版）","url":"https://kucw.io/blog/2022/8/rename-iphone-photo-by-date/"},{"categories":["Other tech"],"content":"想要提升學習效率，不管你是使用什麼工具，只有下面這三點最重要\n系統化的學習 循序漸進 大量練習 系統化的學習，讓你可以在腦中組織這些內容的關係圖，而不是像背單字一樣背一個忘一個\n循序漸進，讓你由淺入深慢慢拓展，沒有人一開始就跳過加減乘除去學微積分的對吧\n大量練習，讓這些知識成為你的肌肉記憶，就像呼吸一樣自然，右手寫左手答\n只要能夠掌握好這三點，不管是學習哪個領域，都可以加速你的學習效率\n什麼樣的學習管道最有效率？ # 要我說，對程式語言這個領域，剛入門的人，我建議是 「直接買付費的線上課程」 來學習\n很多人在初學程式語言的時候，都是先從網路上的免費資源開始學起，因為免費嘛！誰不愛\n但是你仔細觀察過可以發現，網路上的免費資源大部分都是比較碎片化的，因為這些文章，通常只會提到幾個知識點而已，那你這樣東學一點、西學一點，其實是很難打好程式的基礎的\n而線上課程就很好的解決這個問題\n你只要跟著課程的安排好好的上，一般是從最基本的程式語言語法開始教起，然後通常也會教你怎麼使用工具、有哪些快捷鍵可以按、怎麼樣 debug 最有效率\u0026hellip;之類的，這些東西都是真的要實際有實戰經驗的人才有辦法總結的，如果你是靠自己摸索，你可能只會停留在最基本的程式語法而已\n況且能夠開設線上課程、並且累積大量好評的老師，通常都是在各自的領域積累了好幾年的經驗、總結了許多想法，才能夠取得這樣的成績，你如果能跟著這些老師按部就班的學習，一定是比你一個人自己摸索著前進還要有效的多\n還是那句話「時間是最寶貴的資源」，你得把時間拿來創造價值，而不是拿來花在摸索上，所以最好的做法，就是直接買別人整理好的內容來學就對了\n除了線上課程之外，看書這種學習方式其實也是滿好的，因為寫書的作者在寫這本書時，目錄的安排也是循序漸進的從基礎開始教你，這其實就跟線上課程有點像，都是系統性的教你如何學程式語言\n只不過看書的門檻會稍微高一點，因為程式語言這種東西有點繁瑣，書其實沒有辦法真的把每一步過程寫在書上，這樣太瑣碎了，所以書通常是講一些比較抽象的概念，然後就會貼一段程式碼，再搭配上一些註解，讓你自己去體會這一段程式碼為什麼要這樣寫\n而相對比較起來，因為線上課程是影片，所以你就可以看著老師一行一行的把程式打出來，然後在自己的電腦上練習，更容易讓自己產生大量練習的機會\n所以書和線上課程，我會偏向選線上課程，用影片的形式更能清楚的呈現程式語言的教學，至於內容上，我倒是覺得沒有太大的差異，兩個都滿棒的\n所以要來排序一下的話，作為入門程式語言的學習方法，我最推薦的學習方式是上線上課程，第二名是看書，最不推的是網路上的文章，至於資策會的程式班雖然效率高，不過你要承擔的離職風險也高，所以這個我就不多做評論\n從現在開始改變 # 最近有人問我，非本科生半路轉職學程式，會不會找不到工作？\n現實是：本科生確實就是比非本科生有優勢，但是有優勢不代表非本科生就沒有機會\n如果宏觀一點來看的話，在台灣，唸到頂的台大資工，也只是能夠在台灣軟體業/半導體業佔盡優勢而已，出了國，比起別人滿手 CMU、MIT 的學歷，台大真的相對來說是還好而已\n但是在美國的 FAANG 大廠，也還是會有台灣工程師在裡面上班\n他們在學歷上有優勢嗎？相對沒有\n但是他們為什麼能錄取？因為想進這間公司，所以就會拼了命的學習\n所以我想說的是，優勢和錄取，不是佔絕對的比重，只要展現足夠的實力，大家都還是有入場券的\n所以別想那麼多啦吼，唸就對了！！！\n履歷就給他投下去，多面試面試練練手感，會更了解自己在市場上的價值～\n","date":"2022-04-30","objectID":"bb82974f07af54cf95dd7d6ffdc9400e","title":"自學程式，如何高效率的學習？","url":"https://kucw.io/blog/2022/4/efficient-learning/"},{"categories":["Spring Boot"],"content":"如果在 application.properties 直接寫上中文，則 Spring Boot 在使用 @Value 讀取時會產生中文亂碼\nname=小明 解決辦法： # 在 application.properties 裡面，將「中文」轉成「Unicode」，即可解決此問題（可使用此網頁進行轉換）\nname=\\u5c0f\\u660e ","date":"2021-07-25","objectID":"8b6f7ef874076648d6e16585b28e307e","title":"SpringBoot - 解決 application.properties 中文亂碼","url":"https://kucw.io/blog/2021/7/spring-chinese-properties/"},{"categories":["Intellij"],"content":"IntelliJ 為 JetBrains 公司旗下的一個產品，因此若要使用 IntelliJ 的折扣碼，則需要同時也創建一個 JetBrains 帳號\n1. 如何使用折扣碼，取得免費的 IntelliJ 訂閱？ # 點擊此連結，進入到 JetBrains 專屬的折扣碼兌換網頁，並填寫以下資訊\n接著會收到一封信，點擊裡面的連結驗證信箱\n接著會跳轉到 JetBrains 官網，去註冊一個 JetBrains 帳號\n填寫完成之後，就可以發現在你的 JetBrains 帳號底下，新增了一筆 IntelliJ IDEA Ultimate 的訂閱，這樣折扣碼就成功的兌換完畢了～\n2. 如何在 IntelliJ 中綁定 JetBrains 帳號？ # 若尚未開啟過 IntelliJ，則可以在第一次啟動時，在 JB Account 的地方，直接填上剛剛註冊的 JetBrains 帳號密碼\n若已使用試用版開啟過 IntelliJ，則可以點選上方的 Help，然後選擇 Register，就可以開啟 IntelliJ 的 license 管理視窗\n接著點擊 Add New license，就可以在這邊填上剛剛註冊的 JetBrains 帳號密碼了\n","date":"2021-04-25","objectID":"6ebeb54c5397f883d2c567a63dab9529","title":"IntelliJ - 折扣碼使用教學","url":"https://kucw.io/blog/2021/4/intellij-coupon/"},{"categories":["Java"],"content":"在了解 Java 8 新增的時間系列之前，我們需要先了解時間相關的知識\n1. 首先是要有時區的概念 # 在台灣的時區是 GMT+8，而在英國的時區為 GMT+0，所以在同一瞬間，在英國看見的時間是 2020/06/29 14:00:00，但在台灣看見的時間卻會是 2020/06/29 22:00:00\n2. 要有 Timestamp 時間戳的概念 # 在電腦的世界裡，有一個東西叫做 Timestamp（時間戳），這個 Timestamp 是一個整數，代表著從 UTC 1970 年 1 月 1 日 0 時 0 分 0 秒 起至現在的總秒數，UTC 代表的是英國格林威治時間，也就是 GMT+0（可以簡單的認為 UTC = GMT+0）\n所以說假設現在你人在英國格林威治，然後你現在看手錶上的時間是 2020/06/29 14:00:00，則這個當下的 Timestamp的值就為 1593439200（代表從 1970/1/1 00:00:00 到現在經過了 1593439200 秒），然後假設同一個瞬間你的朋友在台灣，因為台灣的時區為 GMT+8，所以你朋友在台灣看手錶的時間會是 2020/06/29 22:00:00，但是你朋友當下的 Timestamp 也會是 1593439200\n也就是說，雖然你和你朋友手錶上呈現的時間不一樣，但是你們兩個的 Timestamp 會是一模一樣的，因為 Timestamp 是唯一表示著 UTC 1970/1/1 00:00:00 起至現在的總秒數\n而在Java中，可以使用 System.currentTimeMillis()，取得當前的 Timestamp\n為什麼 Java 中舊版的 Date 不好 ? # 因為 Date 硬是把 時區 和 Timestamp 這兩個概念混合在一起了，這就是為什麼 Date 不好的關係\n通常我們 new 一個 Date object時，都是使用 Date date = new Date()，而這個 Constructor 其實是會去取得當前的 Timestamp，然後把 Timestamp 存放在 Date 內部的 fastTime 變量裡，所以 Date 內部存放的，實際上是 Timestamp 的值\npublic class Date { private transient long fastTime; //存放timestamp的值 public Date() { this(System.currentTimeMillis()); } public Date(long date) { fastTime = date; } } 雖然 Date 內部只存放了 Timestamp 的值，但是 Date 卻在 toString() 時，會去取得當前程式運行的時區，然後再把 Timestamp 換算成當地時區的時間印出來\npublic class MyTest { public static void main(String[] args) { // Date 內部明明是只存放 Timestamp 的值 1593439200，也就是 UTC 2020/06/29 14:00:00 // (因為 Date 的構造方法要輸入 ms 毫秒，所以要把 Timestamp 乘以 1000) Date date = new Date(1593439200L * 1000); // 但是卻會在 toString() 方法裡面再去取得當前程式運行的時區(我的時區是GMT+8) // 然後把 Timestamp 的值轉換成該時區的時間 // 所以這裡會輸出 Mon Jun 29 22:00:00 CST 2020 System.out.println(date); } } 所以 Java 為了改善 Date 混合 時區 和 Timestamp 的問題，在 Java 8 時提出了新的時間系列類，將 Timestamp 和時間分成兩組\nTimestamp組 : Instant 時間組 : LocalDate、LocalTime、LocalDateTime、ZonedDateTime Instant 用法 # 在 Java 8 新增的這一堆時間系列裡面，每個類都有工廠方法可以使用，可以直接用這些工廠方法來產生出一個新的 object\n所以我們就可以直接使用 Instant.of() 去創建一個 instant object\npublic class MyTest { public static void main(String[] args) { // 用當下的 Timestamp 來創建in1 Instant in1 = Instant.now(); // 自定義 Timestamp Instant in2 = Instant.ofEpochSecond(1593439200L); } } LocalDate、LocalTime、LocalDateTime 用法 # LocalDate : 只存日期 (2020/06/29)\n和Date不同，LocalDate內部用了三個Integer變量 year、month、day，分別存放日期的值，徹底將時間和Timestamp的概念區分開來 LocalTime : 只存時間 (14:00:00)\n也是用了三個Integer變量 hour、minutes、second來分別存放時間的值 LocalDateTime : 存了日期和時間 (2020/06/29 14:00:00)\nLocalDateTime內部其實用一個LocalDate變量存放日期，用另一個LocalTime變量存放時間，reuse的極致！ Local 這一系列的時間類型，都不帶有時區的資訊，所以說當你new一個LocalDateTime出來之後，不管你是在台灣運行程式還是在英國運行程式，輸出的值都一樣\npublic class MyTest { public static void main(String[] args) { // LocalDate LocalDate date = LocalDate.of(2020, 6, 29); // 創建一個 2020/06/29的LocalDate LocalDate date2 = LocalDate.parse(\u0026#34;2020-06-29\u0026#34;); // parse 字串成 LocalDate // LocalTime LocalTime time = LocalTime.of(14, 0, 0); // 創建一個 14:00:00 的 LocalTime LocalTime time2 = LocalTime.parse(\u0026#34;14:00:00\u0026#34;); // parse 字串成 LocalTime // LocalDateTime // 創建一個 2020/06/29 14:00:00 的 LocalDateTime LocalDateTime dateTime = LocalDateTime.of(2020, 6, 29, 14, 0, 0); // 或是也可以用 LocalDate 和 LocalTime 組合創建 LocalDateTime dateTime2 = LocalDateTime.of(date, time); // Local 系列可以和同樣也是 Java8 新增的 DateTimeFormatter 一起使用，讓時間 input/output 的更格式化 // Java8 新增的 DateTimeFormatter 和 joda-time 中的","date":"2020-06-30","objectID":"0b355dce319bfa272450b922780f0ea7","title":"Java - Java 8 新增的時間系列用法","url":"https://kucw.io/blog/2020/6/java-date/"},{"categories":["Spring Boot"],"content":"ObjectMapper 是一款非常好用的 json 轉換工具，可以幫助我們完成 json 和 Java 的 Object 的互相轉換\n什麼是 Serialize 和 Deserialize？ # Serialize : 將 Java Object 轉換成 json Deserialize : 將 json 轉換成 Java Object 在 Spring Boot 裡使用 ObjectMapper # ObjectMapper 是由 Jackson library 所提供的一個功能，所以只要在 maven 中加入 spring-boot-starter-web 的 dependency 就可以了\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; Json 和 Java Object、List、Map 的互轉 # 先定義一個 User class\npublic class User { private int id; private String name; // 省略constructor, getter, setter } 使用 ObjectMapper 完成 json 和 Java Object、List、Map 之間的互轉\nimport java.util.*; import com.fasterxml.jackson.core.type.TypeReference; import com.fasterxml.jackson.databind.ObjectMapper; public class MainTest { public static void main(String[] args) throws Exception { ObjectMapper objectMapper = new ObjectMapper(); // User Object 轉 json User user1 = new User(123, \u0026#34;John\u0026#34;); String json = objectMapper.writeValueAsString(user1); // json 轉 User Object User user2 = objectMapper.readValue(json, User.class); // List\u0026lt;User\u0026gt; 轉 json List\u0026lt;User\u0026gt; ulist = new ArrayList\u0026lt;\u0026gt;(); User user4 = new User(123, \u0026#34;John\u0026#34;); ulist.add(user4); String ujson = objectMapper.writeValueAsString(ulist); // json 轉 List\u0026lt;User\u0026gt; List\u0026lt;User\u0026gt; urlist = objectMapper.readValue(ujson, new TypeReference\u0026lt;List\u0026lt;User\u0026gt;\u0026gt;() {}); // Map\u0026lt;String, User\u0026gt; 轉 json HashMap\u0026lt;String, User\u0026gt; umap = new HashMap\u0026lt;\u0026gt;(); User user3 = new User(123, \u0026#34;John\u0026#34;); umap.put(\u0026#34;John\u0026#34;, user3); String mjson2 = objectMapper.writeValueAsString(umap); // json 轉 Map\u0026lt;String, User\u0026gt; Map\u0026lt;String, User\u0026gt; urMap = objectMapper.readValue(mjson2, new TypeReference\u0026lt;HashMap\u0026lt;String, User\u0026gt;\u0026gt;() {}); } } 如果想了解更多 Spring Boot 的用法，也歡迎參考我開設的線上課程 Java 工程師必備！Spring Boot 零基礎入門 （輸入折扣碼「HH202601KU」即可享 85 折優惠）。\n","date":"2020-06-12","objectID":"e2fcd66ccc91620642cafbcdbc233365","title":"SpringBoot - 使用 ObjectMapper 完成 json 和 Java Object 互相轉換","url":"https://kucw.io/blog/2020/6/java-jackson/"},{"categories":["Java"],"content":"Lombok 是一個 Java library，可以透過簡單的寫法自動生成 Java 的 code，像是 setter、getter、logger\u0026hellip;等，目的在消除冗長的 code 和提高開發效率\n例如當你在 Class 上加上了一個 @Getter 和 @Setter 之後，Lombok 就會自動幫你產生 getter 和 setter 出來，所以你就不用再自己去寫這些煩人的程式啦！\n之所以加個 @Getter 就可以幫我們自動生成所有變數的 getter，是因為 Lombok 參與了 Java 在 compile 階段生成 .class 檔的過程，Lombok 會幫我們自動寫一堆 getter，然後塞進 .class 檔，所以真正被編譯出來的 User.class 檔案，是包含完整的 getter 的\n所以簡單的說，Lombok 可以算是一種語法糖，只是在幫我們增進開發效率而已，實際上所產生出來的.class檔仍然是完全正常的！\n安裝 Lombok # 要在 project 中使用 Lombok，除了要在 maven 中加入 Lombok dependency，還要安裝 Intellij 的 Lombok 插件\n1. 加入 maven dependency # \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.projectlombok\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;lombok\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.18.18\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 2. 在 Intellij 中安裝 Lombok 插件 # 補充：我使用的 Intellij 版本是 2019.3.3，可能會因為版本差異導致安裝方式有改變\n先點選左上角 Intellij IDEA -\u0026gt; Preferences\n然後點擊左邊的 Plugins，再點擊上面的 Marketplace tab，然後就可以在搜尋欄中輸入lombok，並且找到 Lombok 插件並安裝它\n補充：為什麼需要特地安裝 Intellij 的 Lombok 插件？ # 其實在 maven 加入 Lombok dependency 之後，使用 mvn clean package 就可以正常 build 過，在 Intellij 中點擊綠色按鈕也可以運行程式\n之所以還要特地安裝 Intellij 的 Lombok 插件，是因為如果不安裝 Lombok 插件的話，Intellij 就會沒辦法自動提示出 Lombok 產生的方法，所以就會發生你的 code 一片紅，但是運行卻可以通過的奇妙現象\n像是下面這段 code 中，因為對 Intellij 來說，code 裡並不存在 setter，所以沒辦法自動提示 setId()、setName() 等方法，但是又因為我們在 maven 中有加入 Lombok dependency，所以點擊第 13 行的綠色箭頭運行程式的話，是可以正常運行成功的\n所以 Lombok 算是侵入性很高的一個 library，只要團隊中有一個人用 Lombok 開發，那麼所有的人都必須得安裝 Lombok 插件才行，這樣才不會發生在 Intellij 中一打開 project 時，整片都是痛苦的紅字\nLombok 用法介紹 # Lombok 官網提供了許多好用的註解，但是「勁酒雖好，可不能貪杯」，你用了越多 Lombok 的進階用法，會讓整個團隊的學習曲線上升，反而會造成反效果，所以在此處只解釋最常見、並且最重要的註解使用方式，其他較少見的用法就不會涵蓋在此文章中\n此篇文章會介紹的 Lombok 方法為：\n@Getter/@Setter @ToString @EqualsAndHashCode @NoArgsConstructor、@AllArgsConstructor、@RequiredArgsConstructor @Data（最常用） @Value @Builder（常用） @Slf4j 1. @Getter/@Setter # 自動產生 getter/setter\n2. @ToString # 自動 override toString() 方法，會輸出所有變數的值\n3. @EqualsAndHashCode # 自動生成 equals(Object other) 和 hashcode() 方法，包括所有的「非靜態變數」和「非 transient 變數」\n如果某些變數不想要加進判斷，可以透過 exclude 排除（或是也可以反過來，使用 of 指定只要輸出某些字段）\n補充： 為什麼只有一個合在一起的註解 @EqualsAndHashCode，而不是兩個分開的註解 @Equals 和 @HashCode？\n因為在 Java 中有規定，當兩個 object equals 時，他們的 hashcode 一定要相同，反之，當 hashcode 相同時，object 不一定 equals。所以 equals 和 hashcode 要一起 implement，免得發生違反 Java 規定的情形發生\n4. @NoArgsConstructor、@AllArgsConstructor、@RequiredArgsConstructor # 這三個很像，都是在自動生成該 Class 的 constructor，差別只是在「生成的 constructor 的參數不一樣」而已\n@NoArgsConstructor : 生成一個沒有參數的 constructor\n@AllArgsConstructor : 生成一個包含所有參數的 constructor\n補充： 這裡要注意一個 Java 中的實作重點，當我們沒有指定 constructor 時，Java compiler 會幫我們自動生成一個沒有任何參數的 constructor 給該 Class，但是如果我們自己寫了 constructor 之後，Java 就不會自動幫我們補上那個無參數的 constructor 了！\n然而很多地方（像是 Spring Data JPA），都會要求每個 Class 一定要有一個無參數的 constructor，所以你在加上 @AllArgsConstructor 時，一定要記得補上 @NoArgsConstrcutor，不然就會出現各種意外的報錯，一定要記得！！！\n@AllArgsConstructor @NoArgsConstructor public class User { private Integer id; private String name; } @RequiredArgsConstructor : 生成一個包含「特定參數」的 constructor，特定參數指的是「那些有加上 final 修飾詞的變數們」\n補充一下，如果所有的變數都是正常的（即是都沒有用 final 修飾的話），那就會生成一個沒有任何參數的 constructor\n5. @Data # 懶人包，只要加了 @Data，等於同時加了以下註解：\n@Getter/@Setter @ToString @EqualsAndHashCode @RequiredArgsConstructor @Data 是使用頻率最高的 Lombok 用法，通常 @Data 會加在一個值可以被更新的 Object 上，像是日常使用的 DTO 們、或是 JPA 裡的 Entity 們，就很適合加上 @Data，也就是 @Data for mutabl","date":"2020-03-04","objectID":"4f394bcf6c466343c47b256aab455986","title":"Java - 五分鐘學會 Lombok 用法","url":"https://kucw.io/blog/2020/3/java-lombok/"},{"categories":["Spring Boot"],"content":"Mockito就是一種 Java mock 框架，他主要是用來做 mock 測試的，他可以模擬任何 Spring 管理的 bean、模擬方法的返回值、模擬拋出異常\u0026hellip;等，在了解 Mockito 的具體用法之前，得先了解什麼是 mock 測試\n1. 什麼是 mock 測試？ # mock 測試就是在測試過程中，創建一個假的對象，避免你為了測試一個方法，卻要自行構建整個 bean 的 dependency chain\n像是以下這張圖，類 A 需要調用類 B 和類 C，而類 B 和類 C 又需要調用其他類如 D、E、F 等，假設類 D 是一個外部服務，那就會很難測，因為你的返回結果會直接的受外部服務影響，導致你的單元測試可能今天會過、但明天就過不了了\n而當我們引入 mock 測試時，就可以創建一個假的對象，替換掉真實的 bean B 和 C，這樣在調用B、C的方法時，實際上就會去調用這個假的 mock 對象的方法，而我們就可以自己設定這個 mock 對象的參數和期望結果，讓我們可以專注在測試當前的類 A，而不會受到其他的外部服務影響，這樣測試效率就能提高很多\n2. Mockito 簡介 # 說完了 mock 測試的概念，接下來我們進入到今天的主題，Mockito\nMockito 是一種 Java mock 框架，他主要就是用來做 mock 測試的，他可以模擬任何 Spring 管理的 bean、模擬方法的返回值、模擬拋出異常\u0026hellip;等，他同時也會記錄調用這些模擬方法的參數、調用順序，從而可以校驗出這個 mock 對象是否有被正確的順序調用，以及按照期望的參數被調用\n像是 Mockito 可以在單元測試中模擬一個 service 返回的數據，而不會真正去調用該 service，這就是上面提到的 mock 測試精神，也就是通過模擬一個假的 service 對象，來快速的測試當前我想要測試的類\n目前在 Java 中主流的 mock 測試工具有 Mockito、JMock、EasyMock..等，而 SpringBoot 目前內建的是 Mockito 框架\n題外話說一下，Mockito 是命名自一種調酒莫吉托（Mojito），外國人也愛玩諧音梗。。。\n3. 在 SpringBoot 單元測試中使用 Mockito # 首先在 pom.xml 下新增 spring-boot-starter-test 依賴，該依賴內就有包含了 JUnit、Mockito\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-test\u0026lt;/artifactId\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; 先寫好一個 UserService，他裡面有兩個方法 getUserById() 和 insertUser()，而他們會分別去再去調用 UserDao 這個 bean的 getUserById() 和 insertUser() 方法\n@Component public class UserService { @Autowired private UserDao userDao; public User getUserById(Integer id) { return userDao.getUserById(id); } public Integer insertUser(User user) { return userDao.insertUser(user); } } User model 的定義如下\npublic class User { private Integer id; private String name; //省略 getter/setter } 如果這時候我們先不使用 Mockito 模擬一個假的 userDao bean，而是真的去 call 一個正常的 Spring bean 的 userDao 的話，測試類寫法如下。其實就是很普通的注入 userService bean，然後去調用他的方法，而他會再去 call userDao 取得 DB 的 data，然後我們再對返回結果做 assert 檢查\n@RunWith(SpringRunner.class) @SpringBootTest public class UserServiceTest { //先普通的注入一個userService bean @Autowired private UserService userService; @Test public void getUserById() throws Exception { //普通的使用userService，他裡面會再去call userDao取得DB的data User user = userService.getUserById(1); //檢查結果 Assert.assertNotNull(user); Assert.assertEquals(user.getId(), new Integer(1)); Assert.assertEquals(user.getName(), \u0026#34;John\u0026#34;); } } 但是如果 userDao 還沒寫好，又想先測 userService 的話，就需要使用 Mockito 去模擬一個假的 userDao 出來\n使用方法是在 userDao 上加上一個 @MockBean 注解，當 userDao 被加上這個注解之後，表示 Mockito 會幫我們創建一個假的 mock 對象，替換掉 Spring 中已存在的那個真實的 userDao bean，也就是說，注入進 userService 的 userDao bean，已經被我們替換成假的 mock 對象了，所以當我們再次調用 userService 的方法時，會去調用的實際上是 mock userDao bean 的方法，而不是真實的 userDao bean\n當我們創建了一個假的 userDao 後，我們需要為這個 mock userDao 自定義方法的返回值，這裡有一個公式用法，下面這段 code 的意思為，當調用了某個 mock 對象的方法時，就回傳我們想要的自定義結果\nMockito.when( 對象.方法名() ).thenReturn( 自定義結果 ) 使用 Mockito 模擬 bean 的單元測試具體實例如下\n@RunWith(SpringRunner.class) @SpringBootTest public class UserServiceTest { @Autowired private UserService userService; @MockBean private UserDao userDao; @Test public void getUserById() throws Exception { // 定義當調用mock userDao的getUserById()方法，並且參數為3時，就返回id為200、name為I\u0026#39;m mock3的user對象 Mockito.when(userDao.getUserById(3)).thenReturn(new User(200, \u0026#34;I\u0026#39;m mock 3\u0026#34;)); // 返回的會是名字為I\u0026#39;m mock 3的us","date":"2020-02-20","objectID":"53cbcd3e355d6042f045630039ff2319","title":"SpringBoot - 單元測試工具 Mockito","url":"https://kucw.io/blog/2020/2/spring-unit-test-mockito/"},{"categories":["Intellij"],"content":" 1. 什麼是 Debug 模式？ # 還記得以前不會使用 IntelliJ 的 debug 功能時，想要看某個 Variable 的值，都是在那行 code 的下面一行加上 System.out.println()，然後運行程式，把值 print 出來，如果要看另一個 Variable，我就再加一行 System.out.println()，所以到後來我的 code 就會長的像下圖這樣\npublic User getMaleUser() { List\u0026lt;User\u0026gt; userList = userDao.getUserList(); System.out.println(userList); // print userList，看一下userList裡面的內容長怎樣 // 從userList中取出男生，然後回傳 User resultUser; for (User user : userList) { if (user.getGender() == \u0026#34;男\u0026#34;) { resultUser = user; } } System.out.println(resultUser); // 再print resultUser，確認一下回傳的user到底是哪一個 return resultUser; } 可想而知，這樣做的開發效率是非常差的，每多看一個 variable 就要多增加一行 System.out.println()，而且每次改了之後，都要重新運行程式，讓程式再 print 出一次數據，我想想都覺得痛苦，難道 IntelliJ 就沒有一個能夠快速反應出現在這個 variable 的值是什麼的功能嗎？\n事實上，IntelliJ 是有提供的！當我們在運行程式時，改成使用 Debug 模式 運行就可以了！\n2. IntelliJ 的 Debug 模式 # 使用 IntelliJ 的 Debug 模式來運行程式的好處\n可以一行行的運行 code 可以馬上知道運行中的 variable 的值，甚至去改變它的值，從此不用再使用System.out.println()去 print variable 了 在 IntelliJ 的 Debug 模式中，有幾個比較重要的功能面板如下\n開啟 Debug 模式的開關，通常在寫 code 時都會改用 Debug 模式來跑程式，已經很少使用旁邊的 Run 模式了 設置 break point，在左邊行號欄單擊左鍵就可以設置 break point，再點一下則可以取消此 break point，能夠設置 break point 是 Debug 模式和 Run 模式最大的區別，而設置 break point 可以幫助我們一行行的運行 code，這也是為什麼推薦使用 Debug 模式而不是使用 Run 模式 Debug 按鈕，debug 的主要功能就對應著這幾個按鈕 Service 按紐，和 break point 有關係，主要搭配著 3. Debug 按鈕 一起使用 Variables，可以查看當前 break point 之前的 variable 的值 3. Debug 基本用法 # IntelliJ 的 Debug 模式基本用法主要對應著上述 3 和 4 的兩組按鈕\nDebug 按鈕，從左到右共 8 個按鈕 # Show Execution Point : 如果你在看其它行或其它頁面，點擊這個按鈕可跳轉到當前代碼執行的地方 Step Over : 一行一行的往下執行 code，如果這一行裡面有 call 其他方法的話，不會進入那些方法 Step Into : 如果當前行有 call 其他方法，可以進入該方法內部，一般用於進入自定義方法內，不會進入 library 的方法 Force Step Into : 強制進入方法內部，能進入任何方法，查看底層 source code 的時候可以用這個進入 library 的方法 Step Out : 退出方法，從進入的方法內退出到方法調用處，此時方法已執行完畢，只是還沒有完成賦值 Drop Frame : 回退 break point，很少用到 Run to Cursor : 運行到目前滑鼠點擊的位置，你可以將滑鼠點擊到你需要查看的那一行，然後使用這個功能，code 就會運行至那一行，而不需要在那一行上打 break point（前提是已經進入了 Debug 模式，就是已經停在某個 break point 上了） Evaluate Expression : 計算表達式，後面第五部分詳細說明 Service 按鈕，從上到下共 7 個按鈕 # Rerun : 重新運行程式，他會關閉程式後再重新啓動一次，不過很少用到，通常都會直接關掉，再手動開啟一次 Update \u0026rsquo;tech\u0026rsquo; application : 更新程式，就是執行當初定義的 update 選項，當 Debug 模式啟動後，再次點擊 debug 按鈕也會跳出此選項 Resume Program : 繼續執行程序，例如在第 20 行和 25 行有兩個 break point，而當前運行至第 20 行，按一下，則運行到下一個 break point（即第 25 行），再按一下，則運行完整個流程，因爲後面已經沒有 break point 了 Pause Program : 暫停程式，很少用，不是很重要 Stop : 連續按兩下關閉程式，有時候你會發現關閉程式再啓動時，說 port 被佔用，這是因爲沒完全關閉程式的原因 View Breakpoints : 查看所有 break point，後面第七部分詳細說明 Mute Breakpoints : 將所有 break point 變爲灰色並使它們失效，按 Resume Program 那個鍵（也就是第三個按鍵）可以直接運行完程式（因為所有打的 break point 都被設置為無效了），再次點擊這個 Mute Breakpoints 按鍵可以使所有無效 break point 變爲紅色有效 4. Debug 模式下的 variable 查看 # 在 Debug 過程中，跟蹤查看 variable 的值是非常必要的，有幾個方式可以查看當前 variable 的值\n參數所在行後面會顯示當前 variable 的值 滑鼠停到參數上，會顯示當前 variable 的資訊，點擊打開可以看到該 variable 的詳情 在下方的 Variables 窗口查看，這裡會顯示當前方法的所有 variable 的詳情 5. 計算表達式 Evaluate Expression # 在前面第三部分有提到一個計算表達式 Evaluation Expression 按鈕，可以使用這個按鈕在 debug 過程中計算某個表達式的值，或是直接改變某個 variable 的值，而不用再去重新改 code 然後再重啟程式\n假設在 Debug 模式下，想要快速比較當前 list.get(0).equals(\u0026quot;first\u0026quot;) 的結果，可以不用改 code，直接在計算表達式裡面運算，讓 IntelliJ 快速幫助我們計算出這個函式會回傳的值，非常方便，像是下面的 3. Result 部分，得到的就是使用計算表達式運行 list.get(0).equals(\u0026quot;first\u0026quot;) 的結果\n或是說想要更改 variable 的值的話，也可以透過計算表達式來改變，像是下面這個例子，對 code 來說，list 裡只會有 first、second 兩個字串，但是因為我們在計算表達式裡使用了 li","date":"2020-02-15","objectID":"dbbfa835138e137d396db1f7f0eeef2a","title":"IntelliJ - Debug 的使用方法","url":"https://kucw.io/blog/2020/2/intellij-how-to-debug/"},{"categories":["Intellij"],"content":"如果你想要 debug 某個 run 在 server 上的 SpringBoot 或是 Spring project 時，必須先配置好 remote debug，才能夠在本地打 break point，然後透過 remote debug 傳到 server 上，去對遠端 server 上的 project debug\n首先先運行起來在 server 上的 project # 如果是 SpringBoot project，需要在執行 build 出來的 jar 檔時，帶上 jvm 啟動參數\njava -agentlib:jdwp=transport=dt_socket,address=18090,server=y,suspend=n -jar myservice-0.0.1-SNAPSHOT.jar 如果是傳統的 Spring + tomcat war 檔 project，則是在 tomcat/bin/catalina.sh裡，加入 JAVA_OPTS 設定 jvm 啟動參數\n#!/bin/sh JAVA_OPTS=\u0026#34;-agentlib:jdwp=transport=dt_socket,address=18090,server=y,suspend=n\u0026#34; 接著在自己的電腦上開啟 tunnel # 如果自己的電腦是 Windows # 先下載 putty，下載完成之後打開他，然後點選 Tunnels\n在 Source port 填上本機的 port，這裡填 1993，但你可以挑一個自己喜歡的 port\n在 Destination上 填上 server ip 和 18090，其中 18090 要跟你剛剛在 server 上運行的參數 address 的值一樣\n填完之後按 Add，上面 Forwarded ports 就會出現你的設定值\n接著按左邊的 session 回到主頁面，在 Host Name 填上 server 的 ip\n最後再按右下角 Open 連線，就可以在 Windows 上開啟 tunnel 了\n如果自己的電腦是 Mac/Linux # Mac/Linux 開啟 tunnel 的方式比較簡單，只要運行以下指令就可以了\nssh -X -N -L 1993:your-server-ip:18090 your-server-ip 其中 18090 要跟你剛剛在 server 上運行的參數 address 的值一樣，而那個 1993 則是本機的 port，你挑一個自己喜歡的就可以了\n設定 IntelliJ # 首先先在 IntelliJ 上新增一個 Remote configuration\n在 host 的地方填入 localhost，而 port 的地方填入你剛剛開的那個本機 port，我剛剛在本機開的是 1993 port，所以我這裡就填 1993，填好按 OK 保存\n接著就可以運行剛剛設置好的 remote configuration 來進行 remote debug 了！\n如果連線有成功，IntelliJ 下方會顯示 Connected to the target VM...，這時候就可以打 break point 來對 server 上的 project debug 了\n","date":"2020-01-15","objectID":"e3643fcd360c677566425decfd24f191","title":"IntelliJ - Remote Debug","url":"https://kucw.io/blog/2020/1/intellij-remote-debug/"},{"categories":["Spring Boot"],"content":" 本文只講解 OAuth 2.0 的實作，有關 OAuth 1.0a 實作，可參考我的另一篇文章 使用 SpringBoot 實作 OAuth 1.0a 綁定 Twitter\n如果你想要在你的網站上取得某位 user 在 Github 上的資料，那麼就要使用 OAuth 2.0 將你的網站和 Github 做綁定，本文介紹如何使用 Spring Boot 來實現 Github OAuth 2.0 綁定\n首先，先進到 Github 的個人設定的 settings 頁面，點擊 Developer settings\n點擊 OAuth Apps，創建一個 OAuth App，這一步就是你的網站和 Github 的協商\n填入相關資料\n當 user 在 Github 按下授權按鈕之後，Github 會將 user 302 導到你指定的 Authorization callback URL，在此處就是 http://localhost:8080/callback，然後順便把 code 也傳給你 點擊創建之後，就會看到 Github 發給你的 OAuth 2.0 用的 Client Id 和 Client Secret 了\n接下來就是實現和 Github 綁定的 SpringBoot code，demo code 放在這裡\nGithub OAuth2 官方文件 : https://developer.github.com/apps/building-oauth-apps/authorizing-oauth-apps/\n假設你已經在 Github 上按下授權按鈕，然後你想要解綁的話，進到 Github 的 setting 頁面，點擊 Application，就可以看到剛剛綁的 oauth-test，在此處就可以刪掉你剛剛綁定的 token 了\n","date":"2019-12-31","objectID":"16b98e019ff016901add0131734d9875","title":"使用 SpringBoot 實作 OAuth 2.0 綁定 Github","url":"https://kucw.io/blog/2019/12/spring-oauth2-bind-github/"},{"categories":["Spring Boot"],"content":" 本文只講解 OAuth 1.0a 的實作，有關 OAuth 2.0 實作，可參考我的另一篇文章 使用 SpringBoot 實作 OAuth 2.0 綁定 Github\n如果你想要在你的網站上取得某位 user 在 Twitter 上的資料，那麼就要使用 OAuth 1.0a 將你的網站和 Twitter 做綁定，本文將介紹如何使用 Spring Boot 來實現 Twitter OAuth 1.0a 綁定\n首先先進到 Twitter developer 網站，將你的 Twitter 帳號申請為 developer 帳號，申請通過之後會收到 Twitter 寄來的 email，點擊 confirm 按鈕會進入到 Twitter developer dashboard get-started\n點擊 Create an app 創建一個 oauth app，這一步是你的網站和 Twitter 的協商\n填入相關資料，需要填寫 app name、Application description、website url、callback Url\n注意此處的 callback Url 要和到時後申請 request token 帶的 callback Url 一致，不然會被 Twitter 擋下來 另外也要注意他的 website url 強制需要 https 和 有域名 兩個條件，所以這時候就要使用 ngrok 來幫我們轉發 在這裡吐嘈 Twitter 一下，為什麼不管是申請個 Twitter 開發者帳號還是申請 Oauth app，都要寫一堆理由..\n填完相關資料點擊 create 後，就成功在 Twiiter 創建 Oauth app了\n點擊 Keys and tokens tab，就可以看到 Twitter 發給我們的 consumer key 和 secret 了\nTwitter 還算貼心，可以直接在開發者頁面一鍵新增 access token，幫你省去綁定的功夫，讓你可以快速使用這個 access token 去 call 他的 api 當然這個 access token 只會提供你自己的 Twitter 帳號的 access token，如果要實現所有人都可以綁定的話，還是需要自己寫 oauth 1.0a 綁定 code，這個 access token 只是讓你能夠快速測試而已 接下來就是實現和 Twitter 綁定的 SpringBoot code，demo code 放在這裡\nTwitter OAuth1.0a 官方文件 : https://developer.twitter.com/en/docs/basics/authentication/oauth-1-0a/obtaining-user-access-tokens\n","date":"2019-12-30","objectID":"3f1ce910313303c57791cf287f37cd9a","title":"使用 SpringBoot 實作 OAuth 1.0a 綁定 Twitter","url":"https://kucw.io/blog/2019/12/spring-oauth1a-bind-twitter/"},{"categories":["Other tech"],"content":"安裝環境 : CentOS Linux release 7.7.1908 (Core)\nsudo yum install python36-pip python3-devel gcc-c++ sudo pip3 install apache-superset superset db upgrade flask fab create-admin superset load_examples superset run -p 8088 ","date":"2019-12-20","objectID":"97299365eb45a8e5c7368181e33045af","title":"Superset 安裝教學","url":"https://kucw.io/blog/2019/12/superset-install/"},{"categories":["Elastic Search"],"content":"在 ElasticSearch 中，提供了兩種用來表示地理位置的方式，分別是 geo_point 和 geo_shape\n用緯度、經度表示的座標點使用 geo_point 字段類型(較常用)，geo_point 允許你找到距離另一個座標點一定範圍內的座標點、計算出兩點之間的距離來排序或進行相關性打分、或者聚合到顯示在地圖上的一個網格 另一種是使用 GeoJSON 格式定義的複雜地理形狀，使用geo_shape字段類型 geo_point 經緯度座標格式 # 在 mapping 定義時將字段類型定義為 geo_point\nPUT mytest { \u0026#34;mappings\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;name\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34; }, \u0026#34;my_location\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;geo_point\u0026#34; } } } } 目前有6種經緯度座標格式可以插入一個座標點到 Elasticsearch中，此處只介紹幾種常用的，全部支持的格式請參考 官方文檔\n使用對象\nPOST mytest/_doc { \u0026#34;name\u0026#34;: \u0026#34;Pala Pizza as an object\u0026#34;, \u0026#34;my_location\u0026#34;: { \u0026#34;lat\u0026#34;: 40.722, \u0026#34;lon\u0026#34;: -73.989 } } 使用數組 location : [ lon, lat ]\nPOST mytest/_doc { \u0026#34;name\u0026#34;: \u0026#34;Pala Pizza as an array\u0026#34;, \u0026#34;my_location\u0026#34;: [-73.989, 40.722] } 使用字符串 location : \u0026ldquo;lat, lon\u0026rdquo;\nPOST mytest/_doc { \u0026#34;name\u0026#34;: \u0026#34;Pala Pizza as a string\u0026#34;, \u0026#34;my_location\u0026#34;: \u0026#34;40.722, -73.989\u0026#34; } 使用Geohash\nPOST mytest/_doc { \u0026#34;name\u0026#34;: \u0026#34;Pala Pizza as a geohash\u0026#34;, \u0026#34;my_location\u0026#34;: \u0026#34;drm3btev3e86\u0026#34; } 通過地理座標點進行過濾 # 目前針對 geo_point 的查詢，ElasticSearch 提供 3 種地理座標點相關的過濾器，可以用來選中或者排除文檔\ngeo_bounding_box (矩形過濾) : 找出落在指定矩形框中的點，效率最高 geo_distance (圓形過濾) : 找出與指定位置在給定距離內的點 geo_polygon (自定義多邊型過濾) : 找出落在指定多邊形中的點 (注意這個過濾器使用代價很大) geo_bounding_box 矩形過濾 # 指定一個矩形的頂部、底部、左邊界、右邊界，然後過濾器只需判斷座標的經度是否在左右邊界之間，緯度是否在上下邊界之間就可以判斷這個座標點是否在矩形範圍內\n可以選擇使用 top_left + bottom_right 或是 top_right + bottom_left 或是 top + bottom + left + right\n具體實例 : 找出那些位在 lat 40.7~40.8，且lon -73 ~ -74的座標點 # GET mytest/_search { \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34;: { \u0026#34;filter\u0026#34;: { \u0026#34;geo_bounding_box\u0026#34;: { \u0026#34;my_location\u0026#34;: { \u0026#34;top_left\u0026#34;: { \u0026#34;lat\u0026#34;: 40.8, \u0026#34;lon\u0026#34;: -74.0 }, \u0026#34;bottom_right\u0026#34;: { \u0026#34;lat\u0026#34;: 40.7, \u0026#34;lon\u0026#34;: -73.0 } } } } } } } geo_distance 圓形過濾 # 從給定的位置爲圓心畫一個圓，找出那些地理座標落在其中的文檔，distance支持的單位 : km、m、cm、mm\u0026hellip;\n圓形過濾計算代價比矩形過濾貴，爲了優化性能，ES 會先畫一個矩形框來圍住整個圓形，這樣就可以用矩形過濾先排除掉一些完全不可能的文檔，然後再對落在矩形內的座標點用地理距離計算方式處理\n在使用圓形過濾時，需要思考是否真的要這麼精確的距離過濾？通常使用矩形模型 bounding box是更更高效的方式，並且往往也能滿足應用需求，假設user想找1km內的餐廳，是否不行找了一個1.2km的餐廳給他？這200m真的差距有這麼大嗎？需要根據實際使用情況做選擇\n為了提高圓形過濾的性能，在計算兩點間的距離時，有多種犧牲性能換取精度的算法\narc : 最慢但最精確的計算方式 (默認的計算方式)，這種方式把世界當作球體來處理，不過這種方式的精度還是有極限，因爲這個世界並不是完全的球體 plane : plane的計算方式把地球當成是平坦的，這種方式快一些但是精度略遜，在赤道附近的位置精度最好，而靠近兩極則變差 具體實例 : 給定一個位置 (40.715, -73.988)，找出距離他1km以內的所有點 # GET mytest/_search { \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34;: { \u0026#34;filter\u0026#34;: { \u0026#34;geo_distance\u0026#34;: { \u0026#34;distance\u0026#34;: \u0026#34;1km\u0026#34;, \u0026#34;distance_type\u0026#34;: \u0026#34;arc\u0026#34;, \u0026#34;my_location\u0026#34;: { \u0026#34;lat\u0026#34;: 40.715, \u0026#34;lon\u0026#34;: -73.988 } } } } } } geo_polygon 自定義多邊型過濾 # geo_polygon 可以自定義一個多邊形，然後判斷這個座標點是否在該多邊形內\n在使用 geo_polygon 時，需要使用 points 數組自定義多邊形，需要把該多邊形的所有點列出來在此數組裡，順序不影響\n具體實例 : 找出那些位在指定多邊形內的座標點 # GET mytest/_search { \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34; : { \u0026#34;filter\u0026#34; : { \u0026#34;geo_polygon\u0026#34; : { \u0026#34;my_location\u0026#34; : { \u0026#34;points\u0026#34; : [ {\u0026#34;lat\u0026#34; : 40, \u0026#34;lon\u0026#34; : -70}, {\u0026#34;lat\u0026#34; : 40, \u0026#34;lon\u0026#34; : -80}, {\u0026#34;lat\u0026#34; : 50, \u0026#34;lon\u0026#34; : -70}, {\u0026#34;lat\u0026#34; : 50, \u0026#34;lon\u0026#34; : -80} ] } } } } } } 按照距離大小進行排序 # 請求 # 注意，會需要在請求時決定距離的單位的原因是因為，這些用於排序的距離的值，會設置在每個返回的結果的sort元素中，方便我們取得他們實際上距離那個點","date":"2019-12-07","objectID":"585c17c0f875ad313182d1f3baa03609","title":"ElasticSearch - 地理座標點 geo_point","url":"https://kucw.io/blog/2019/12/elasticsearch-geo-point/"},{"categories":["Life"],"content":"最近突如其來的想說來減過肥吧，然後突然想到許多健身的人為了讓肌肉更突出，通常在一定時間的重訓後，就會開始為期三個月的減脂肪餐（就是很常見的雞肉餐）\n所以我突發奇想，要是減肥和減脂，他們的原理都是要減去人體內多餘的脂肪的話，那我走減脂那一套吃法，是不是會減的比較輕鬆又快樂？可以一直吃肉，然後又可以瘦下來，怎麼想都比蔬菜水果好減吧！\n詢問了我一個重訓多年的朋友之後，他給我的建議如下\n第一步：決定目標和手段 # 首先，你想減肥，具體有想要搭配重訓長肌肉嗎？還是只是想要減掉肥肉？\n要知道，減脂和減重是不同概念\n如果只是想要減掉肥肉，多做有氧（跑步游泳騎車之類的），就可以有能量消耗。然後不用特別吃肉，只要控制整體熱量 \u0026lt; 支出，兩個月就可以瘦個三五公斤\n減脂要吃肉是為了要維持肌肉量（搭配大量重量訓練），因為減重（包含減掉脂肪＋肌肉）的時候肌肉量一定會掉，但是減脂我們盡量只減脂肪，和少量肌肉（減脂還是會掉肌肉）\n所以如果你沒有想要搭配重量訓練（維持肌肉量），那你直接有熱量赤字就好了，不管是減脂還是減重，熱量赤字都是需要的\n第二步：如何達到熱量赤字？ # 什麼是熱量赤字？\n只要 每天的熱量消耗量 \u0026gt; 每天的熱量攝取量，就是熱量赤字 # 假設你每天消耗（運動＋能量消耗＋基礎代謝）2000大卡，那你就只能吃 1500 ~ 1700 大卡，才能達到熱量赤字\n通常每 7700 大卡熱量赤字會少一公斤，所以假如你一天少吃 400 大卡，你 7700 / 400 = 19.25 天，你就可以少一公斤。所以看看你要想少幾公斤，想要多少時間內減重，再去分配\n這也是為什麼要做有氧運動，就是為了要增加自己的 \u0026ldquo;每日消耗\u0026rdquo;\n前面說到 每日消耗 = 運動消耗＋消化食物消耗的熱量＋基礎代謝（呼吸之類的），所以如果你運動一天多500大卡消耗，你就一天多減500大卡\n可是運動會餓，所以可能又會想吃東西，不過減肥、減脂的人就是要控制自己不能吃太多\n然後要怎麼算自己一天吃 1500 大卡呢？就是要自己煮，或是找有營養標示的早、午、晚餐。所以有在重訓要減脂的人才會都自己煮，這樣才抓的到每日的吸收量是多少\n減脂的話要調配三大基礎營養素的比例：碳水化合物、脂肪、蛋白質。這三種的攝取量會依照你重訓的天數、強度、組數、每天或每月做不同變化\n結論 # 如果你只是想減肥，那就 \u0026ldquo;多做有氧＋每天熱量赤字\u0026rdquo; 就 ok 了\n如果你要減脂\u0026hellip;再跟我說\n","date":"2019-12-03","objectID":"ad134e3239e12813ace867d5f30bf277","title":"減肥和減脂有區別嗎？","url":"https://kucw.io/blog/2019/12/how-to-lose-weight/"},{"categories":["Java"],"content":"Stopwatch 是 Guava 提供，可以用來測量程式運行時間的工具（Guava 是 Google 開發的 Java library，是一個非常好用的工具包）\n常用方法 # Stopwatch.creatStarted() : 創建一個碼表，並且開始計時 stop() : 碼表停止計時 elapsed(TimeUnit unit) : 取得從開始到結束的時間 具體實例 # public class Main { public static void main(String[] args) { Stopwatch stopwatch = Stopwatch.createStarted(); doSomething(); stopwatch.stop(); long millis = stopwatch.elapsed(TimeUnit.MILLISECONDS); System.out.println(\u0026#34;time: \u0026#34; + millis + \u0026#34; ms\u0026#34;); } } ","date":"2019-11-18","objectID":"860a297a1e38020f3224599e6970bb92","title":"Java - 測量程式執行時間","url":"https://kucw.io/blog/2019/11/java-time-measurment/"},{"categories":["Java"],"content":"GraalVM 是 Oracle 發佈的下世代 jvm，2019.05 才發佈了第一個 release 版本，分別有 Community 版和 Enterprise 版\nGraalVM 三大特點 # High-performance modern Java : 使用 GraalVM 執行 Java 程式可以變得更快 Polyglot : 可以在 Java 裡面同時使用多種語言，像是 JavaScript、R\u0026hellip; Instant startup, low footprint : 直接把 Java program compile 成 machine code，執行起來體積更小、啟動更快 High-performance modern Java # High-performance modern Java 使用到了 Graal compiler 技術，Graal compiler 是一個 JIT compiler，並且是使用 Java 撰寫的，目的是拿來替換掉原本 HotSpot VM 的C2 compiler\n為了讓 Graal compiler 可以更彈性的被更新（總不能每發布一次 Graal compiler 更新就要重新 compile 整個 java），Oracle 加上了一層JVM Compiler Interface，簡稱 JVMCI，把原本那些應該由 C2 執行的請求抽象化成 interface，解耦 C1 compiler 和 Graal compiler 的連結，讓 Graal 可以更輕易的被更新\n雖然 Graal 是使用 java 寫的，難免會讓人聯想到性能會比不上 C2 compiler，但是在各種實驗之後，得到的數據顯示對於 Java program，Graal 和 C2 compiler 的能力幾乎不相上下（在已經預熱完畢的前提下），而對於 Scala program，Graal 更是達到 10% 以上的優化，這也是為什麼 Twitter 大規模的使用 GraalVM 替換掉原本的 HotspotVM\n不過在啟動時，GraalVM 會比 HotspotVM 還慢，原因是必須先將 Graal 編譯成 machine code，這個是無可避免的，只是當預熱完畢時，Graal 和 C2 compiler 的性能不相上下，並且根據 Graal 的版本不斷更新，這個數據只可能會更好\nPolyglot # GraalVM 最一開始被發明出來，就是為了讓 Java 可以在一次 runtime 中同時使用多種語言，從官網稱呼 GraalVM 為 High-performance polyglot VM，也可以發現 Oracle 對 GraalVM 定位是一個多語言 jvm\n為了實現 Polyglot，GraalVM 引入了一層 Truffle framework，只要實現了該語言的 interpreter，就可以在 Java program 中使用該語言\n目前官方支援的語言僅有 Python、R、JavaScript，後續會陸續增加\n具體實例\npublic class Main { public static void main(String[] args) { System.out.println(\u0026#34;Hello World from Java!\u0026#34;); Context context = Context.newBuilder().allowAllAccess(true).build(); context.eval(\u0026#34;js\u0026#34;, \u0026#34;print(\u0026#39;Hello World from JavaScript!\u0026#39;);\u0026#34;); context.eval(\u0026#34;python\u0026#34;, \u0026#34;print(\u0026#39;Hello World from Python!\u0026#39;)\u0026#34;); context.eval(\u0026#34;ruby\u0026#34;, \u0026#34;puts \u0026#39;Hello World from Ruby!\u0026#39;\u0026#34;); } } Hello World from Java! Hello World from JavaScript! Hello World from Python! Hello World from Ruby! Instant startup, low footprint # GraalVM 還有最後一項技術，就是 native image，他是在 compile time時，就將 Java program 直接 compiler 成 binary 的 machine code，讓這個程式可以像一般二進制的檔案被運行\nNative images compiled with GraalVM ahead-of-time improve the startup time and reduce the memory footprint of JVM-based applications.\nNative-image 帶來的好處是可以更快速的啟動一個 java program，以往如果要啟動 java 程式，需要先啟動 jvm 再載入 java code，然後再即時的 compile bytecode to machine code，非常耗時和耗 memory，而如果使用 native-image，可以取得一個更小更快速的鏡像，適合用在 cloud deploy\nnative image 之所以可以快速啟動，是因為他做了 Ahead-of-time compile，在 compile time 時，會把所有相關的東西，包含一個 Substrate VM，一起 compile 成 machine code，這個 SubstrateVM 是 GraalVM 才有的東西，他只包含最基本的 thread scheduling、垃圾回收，盡可能的縮小必要的 jvm 體積\n雖然 native image 感覺很猛，但是他也有不可抹滅的缺點，就是使用 native image 的程式，throughput 會下降，原因是因為 java 程式很大一部分的優化都在 JIT compiler 中\n還有另一個缺點是，native image 並沒有辦法動態的加載類（因為所有東西必須要在 compile time 就決定好），所以也沒辦法使用反射等相關機制，不過對於這個問題，GraalVM 也有提出相對應的解法，就是在 compile 時，把所有可能的類全部 compile 進來，所以反射機制還是可以支持的，不然的話，整個 Spring framework 就不能使用 native image 了\n目前 Spring 5 也打算開始支持 GraalVM native-image 的開箱即用設定，可以看到 serverless 的 java program 可能是之後的趨勢\n補充一下，serverless 就是指 Fuction as a Service，他的目的是希望 program 不用一直 run 著，當有請求來的時候，我快速啟動這個 program，然後請求走我就 shutdown 這個 program，不讓 program 一直啟動著，而是有需要的時候才開啟他，也就是說，FaaS 就是讓這個 program 像是 function 一樣，用完即走，因此 native-image 的快速啟動非常符合FaaS的需求\n安裝 GraalVM # 上官網下載 GraalVM community，如果電腦是 mac","date":"2019-10-09","objectID":"decafc112fb06a3d9050e870184fac34","title":"GraalVM 介紹 + 安裝教學","url":"https://kucw.io/blog/2019/10/java-graalvm/"},{"categories":["Java"],"content":" Iterator 是所有 Collection 類（List、Set\u0026hellip;.）們都可以使用的迭代器，而 ListIterator 則是專門為 List 類所設計的迭代器\nIterator 只支持 hasNext()、next()、remove() 三種操作，而 ListIterator 除了原本的 3 種之外，還支持了更多操作\n//Iterator接口 public interface Iterator\u0026lt;E\u0026gt; { boolean hasNext(); E next(); void remove(); } //ListIterator接口 public interface ListIterator\u0026lt;E\u0026gt; extends Iterator\u0026lt;E\u0026gt; { //繼承自Iterator的接口 boolean hasNext(); //後面是否有元素 E next(); //游標向後移動，取得後面的元素 void remove(); //刪除最後一個返回的元素 //ListIterator新增的接口 boolean hasPrevious(); //前面是否有元素 E previous(); //游標往前移動，取得前面的元素 int previousIndex(); //取得游標前的index int nextIndex(); //取得游標後的index void set(E e); //將當前元素改設成e void add(E e); //增加一個元素 } Iterator 和 ListIterator 的差別\niterator() 方法在所有集合類中都能使用，但是 listIterator() 只有 List 類能用 Iterator 只能 remove() 元素，而 ListIterator 可以 add()、set()、remove() Iterator 只能使用 next() 順序的向後遍歷，ListIterator 則向前 previous() 和向後 next() 遍歷都可以 還有一個額外的功能，ListIterator 可以使用 nextIndex() 和 previousIndex() 取得當前游標位置的前後 index 位置，Iterator 沒有此功能 如果想在遍歷 List 時邊做刪除，用 Iterator 和 ListIterator 都能辦到，但如果是想在遍歷 List 時 add 元素，則只能使用 ListIterator 去做，因為 Iterator 是不提供此接口的\n要注意的是，邊遍歷 List 邊使用 Iterator 和 ListIterator 的 add()、remove() 時，並不會影響當前 List 輸出結果，雖然他們修改的是同一個 List，但是迭代器故意將 add 和 remove 設計成就算執行了，也不影響當前迭代器的輸出結果\npublic class Main { public static void main(String[] args) { List\u0026lt;Integer\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); list.add(1); list.add(2); list.add(3); ListIterator\u0026lt;Integer\u0026gt; it = list.listIterator(); while (it.hasNext()) { Integer x = it.next(); System.out.println(x); //雖然使用it.add(100)去新增一個元素，使得list實際儲存的是 [1,2,100,3] //但是此處的遍歷仍然只顯示[1,2,3]，這是迭代器故意這樣設計的 if (x == 2) { it.add(100); } } System.out.println(\u0026#34;list: \u0026#34; + list); } } 1 2 3 list: [1, 2, 100, 3] 另外，雖然 ArrayList 和 LinkedList 都支持 ListIterator，但通常只有在使用 LinkedList 時才會搭配 ListIterator\n因為 LinkedList 幾乎所有的時間消耗都是在去找到這個元素在哪，而找到此元素之後，對他進行修改是非常容易的事情（只要改指針就可以了），所以使用 ListIterator 的話，就可以節省下這個查找時間 而對 ArrayList來說，因為他查找的速度很快（底層是數組），因此使用 ListIterator 省下的查找時間非常少，所以對他來說，並沒有迫切的需要使用 ListIterator，使用 add(index, E) 也能達到同樣的效率 因此可以說 ListIterator 根本是為 LinkedList 發明的，ArrayList 只是順道實現而已，ArrayList 去實現只是為了設計成讓 List 接口的類們都能使用 ListIterator 而已 ","date":"2018-12-12","objectID":"fe39ba8e8bffa090a9917af29ecec97f","title":"Java - Iterator 和 ListIterator","url":"https://kucw.io/blog/2018/12/java-iterator-and-listiterator/"},{"categories":["Java"],"content":" 為什麼 Iterator 接口，只有 hasNext()、next()、remove() 方法，而沒有 add(E) 方法 ? 邏輯上來說，迭代器是一個一個去遍歷集合中的元素，而當前 iterator 停下的地方，就是迭代到一半的地方 如果當迭代到一半時調用 iterator.add() 方法，理論上來說，應該是要在當前這個元素 E1 後面新增一個元素 E2，使得下次遍歷此集合時，E2 一定會出現在 E1 後面，也就是 [\u0026hellip;.E1, E2, \u0026hellip;.] 假設 add() 方法是以這個語意為前提的話，那麼迭代器不提供此方法是很合理的，對於有序的集合（像是ArrayList）來說，在此元素後面新增一個元素是一個很簡單的事情，但是對於無序的集合（像是HashSet）來說，不能保證新插入的這個元素 E2 一定會在 E1 後面（因為還得計算 HashCode），如此就違反了 add() 的語意了，這也就是為什麼 Iterator 接口不提供 add() 方法 另一個說法是，在使用迭代器時，通常就是 \u0026ldquo;遍歷\u0026rdquo; 的場景，這種場景下很少會去使用 add() 方法，因此 Iterator 接口沒必要提供這個方法 ","date":"2018-12-06","objectID":"55704ca4817297acb07604b43d8b27fd","title":"Java - 為什麼 Iterator 不提供 add（E）方法 ？","url":"https://kucw.io/blog/2018/12/java-iterator-without-add/"},{"categories":["Java"],"content":" 所有的集合類（List、Set\u0026hellip;）都實現自 Collection 接口，而 Collection 接口又繼承於 Iterable 接口，因此可以說所有的集合類（List、Set\u0026hellip;）都實現了 Iterable 接口\n當某個類實現 Iterable 接口時，我們就能稱這個類是一個 \u0026ldquo;可數\u0026rdquo; 的類，也就是可以使用 iterator() 獲取一個迭代器 Iterator，然後使用這個 Iterator 實例去遍歷這個類，因此所有的 Collection 類都能夠使用迭代器 Iterator 來遍歷\nIterable 接口\npublic interface Iterable\u0026lt;T\u0026gt; { //當某個類實現Iterable接口的話，就能獲取到迭代器iterator，然後就能使用這個iterator去遍歷此類 Iterator\u0026lt;T\u0026gt; iterator(); } Iterator 接口\n如果某個類實現了 Iterable 接口，那麼他也需要創建一個內部類去實現一個 Iterator 類，讓調用 Iterable 接口中的 iterator() 時，能夠獲取到一個 iterator 實例\npublic interface Iterator\u0026lt;E\u0026gt; { //是否有下一個元素 boolean hasNext(); //取得下一個元素 E next(); //刪除最後一個獲取的元素，因此調用remove()前一定得先調用一次next() void remove(); } 至於此 Iterator 接口怎麼實現，就看各個集合實現類如何定義 \u0026ldquo;下一個元素\u0026rdquo;，像是 ArrayList 的下一個元素就是 element[index+1]，而 HashMap 的下一個元素則是 hash table 數組中儲存的下一個 entry\n另外可以想像 Iterator 像是一個游標一樣，一開始停在最前面，然後不停的往後走（只能向後移動），且此游標每次都是停在元素和元素的中間，當調用 next 時，迭代器就越過下一個元素，並返回剛剛越過的那個元素的引用\n使用迭代器 Iterator 遍歷 ArrayList\npublic class Main { public static void main(String[] args) { //ArrayList實現了Collection接口，因此他也實現了Iterable接口，所以他可以使用iterator迭代器來遍歷 List\u0026lt;String\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); list.add(\u0026#34;hello\u0026#34;); list.add(\u0026#34;world\u0026#34;); //調用Iterable接口中的iterator()取得此ArrayList的迭代器實例 Iterator\u0026lt;String\u0026gt; its = list.iterator(); //使用Iterator接口的hasNext()、next()來遍歷此ArrayList集合實現類 while (true) { if (its.hasNext()) { String s = its.next(); System.out.println(s); } else { break; } } } } 而再進一步說，當某個類能使用迭代器 Iterator 來遍歷時，就能使用 java 提供的 foreach 語法糖來遍歷此類（foreach語法糖其實就是簡化的 iterator()）\nforeach 實際上會被編譯器編譯成使用迭代器 iterator() 去遍歷集合，因此能使用 foreach 的，都是得實現 Iterable 接口的集合類 Collection 們，像是 List、Set\n所以 Map 就沒有辦法直接使用 foreach（因為 Map 沒有實現 Iterable 接口），只有他的 map.entrySet()、map.keySet()、map.values() 這種返回一個集合類的方法，才能使用 foreach\npublic class Main { public static void main(String[] args) { List\u0026lt;String\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); list.add(\u0026#34;hello\u0026#34;); list.add(\u0026#34;world\u0026#34;); //原代碼，使用語法糖的foreach for (String s : list) { System.out.println(s); } //實際上會被編譯成使用iterator去遍歷 for (Iterator\u0026lt;String\u0026gt; its = list.iterator(); its.hasNext(); ) { String s = its.next(); System.out.println(s); } } } 為什麼 Iterator 要額外使用內部類去實現，而不是 ArrayList 直接實現此接口 ?\n如果看過 Collection 類的源碼（以ArrayList為例），可以發現 ArrayList 類並不是由 ArrayList 去實現 Iterator 接口，而是 ArrayList 有一個內部類 Itr，專門去實現 Iterator 接口，而 ArrayList 的 iterator() 方法，只是去創建一個內部類 ArrayList.Itr 的實例而已\n//ArrayList不實現Iterator接口，反而是由他的內部類進行實現 public class ArrayList\u0026lt;E\u0026gt; extends AbstractList\u0026lt;E\u0026gt; { //調用list.iterator()可以取得此list的迭代器 public Iterator\u0026lt;E\u0026gt; iterator() { return new Itr(); //實際上就是去創建一個內部類的實例 } //ArrayList中的內部類Itr，專門實現Iterator接口 private class Itr implements Iterator\u0026lt;E\u0026gt; { int cursor; //記錄當前迭代到哪裡 public boolean hasNext() { ... } public E next() { ... } public void remove() { ... } } } 要這樣設計是因為一個集合類可能同時有多個迭代器去遍歷他，而每個迭代器遍歷到集合的哪裡，是每個迭代器自己的事情，彼此不互相干涉，因此才需要額外使用一個內部類去實現迭代器的 Iterator 接口\n如此當需要用到 Iterator 來遍歷集合時，只需要調用 list.iterator()，就能取得一個全新的、不受別人影響的迭代器供自己使用，而迭代器彼此之間也不會互相干涉 至於為什麼要特別使用內部類來實現 Iterator 接口，而不是創建一個 Iterator 公共類來供所有集合一起使用，是因為迭代器需要知道集合的內部結構，他才能知道要怎麼去實現 hasNext()、next()、remove() 方法，而使用內部類才能無條件的取用外部類的所有信息（包含 private 的變量和方法），因此才需要將 Iterator 提取成接口，讓每個集合自己使用內部類去實現 Iterator 接口 為什麼 Iterator 接口，只有 hasNext()","date":"2018-12-05","objectID":"df46f721cab925e1e7bb583bcecc6677","title":"Java - Iterable 接口、迭代器 Iterator","url":"https://kucw.io/blog/2018/12/java-iterator/"},{"categories":["Java"],"content":" 在探討 Java 傳遞參數是 pass by value 還是 pass by reference 之前，需要先了解 Java 中 = 的具體細節\n賦值 = 的用法\n= 的意義是賦值，但是這個賦值用在 基本類型 和 對象類型 上會有非常大的差別\n如果 = 用在基本類型上，因為基本類型儲存了實際的數值，所以在為其賦值時，是直接將值複製一份新的過去 因此假設 a、b 都是基本類型，如果執行了 a=b，那麼就是將 b 的內容直接複製一份新的給 a，之後如果改變了 a 的值，也不會影響到 b 此處的基本類型，泛指 int、long、boolean\u0026hellip;.和其包裝型態 Integer、Long、Boolean\u0026hellip;.，只要是這些類型的變量，都適用基本類型的 = 規則 但如果 = 用在對象類型上，因為在使用對象操作時，實際儲存的其實是對象的引用，所以在為其賦值時，實際上只是把 \u0026ldquo;引用\u0026rdquo; 從一個地方複製到另一個地方 因此假設 c、d 都是對象類型，如果執行了 c=d，那麼 c 和 d 都會指向原本只有 d 指向的那個對象，而原本 c 的那個對象因為沒人引用了，所以會被垃圾回收清理掉 另外，只要是數組，不管你是基本類型 int[] 還是對象類型 Tank[]，一律存的都是引用，所以只要賦值了，也會互相影響 具體實例\nt1、t2是基本類型的 = 效果（不會互相影響）\nt3、t4是對象類型的 = 效果（因為存的是引用，所以會互相影響）\ni5、i6是基本類型的數組的 = 效果（因為存的也是引用，所以也會互相影響）\nclass Tank { int level; } public class Main { public static void main(String[] args) { Tank t1 = new Tank(); Tank t2 = new Tank(); t1.level = 1; t2.level = 2; System.out.println(\u0026#34;t1: \u0026#34; + t1.level + \u0026#34;, t2: \u0026#34; + t2.level); //此處只是基本類型的賦值，所以t1、t2仍舊指到兩個不同對象 t1.level = t2.level; System.out.println(\u0026#34;t1: \u0026#34; + t1.level + \u0026#34;, t2: \u0026#34; + t2.level); t1.level = 100; System.out.println(\u0026#34;t1: \u0026#34; + t1.level + \u0026#34;, t2: \u0026#34; + t2.level); System.out.println(\u0026#34;----\u0026#34;); Tank t3 = new Tank(); Tank t4 = new Tank(); t3.level = 3; t4.level = 4; System.out.println(\u0026#34;t3: \u0026#34; + t3.level + \u0026#34;, t4: \u0026#34; + t4.level); //此處是對象類型的賦值，所以是t3和t4都指到了同一個對象上 //而原本t3那個對象因為沒人引用了，所以會被垃圾回收清理掉 t3 = t4; System.out.println(\u0026#34;t3: \u0026#34; + t3.level + \u0026#34;, t4: \u0026#34; + t4.level); t3.level = 100; System.out.println(\u0026#34;t3: \u0026#34; + t3.level + \u0026#34;, t4: \u0026#34; + t4.level); System.out.println(\u0026#34;----\u0026#34;); int[] i5 = {5}; int[] i6 = {6}; System.out.println(\u0026#34;i5[0]: \u0026#34; + i5[0] + \u0026#34;, i6[0]: \u0026#34; + i6[0]); //因為數组存的是引用，所以i5和i6會指到同一個地方上 i5 = i6; System.out.println(\u0026#34;i5[0]: \u0026#34; + i5[0] + \u0026#34;, i6[0]: \u0026#34; + i6[0]); i5[0] = 200; System.out.println(\u0026#34;i5[0]: \u0026#34; + i5[0] + \u0026#34;, i6[0]: \u0026#34; + i6[0]); } } t1: 1, t2: 2 t1: 2, t2: 2 t1: 100, t2: 2 ---- t3: 3, t4: 4 t3: 4, t4: 4 t3: 100, t4: 100 ---- i5[0]: 5, i6[0]: 6 i5[0]: 6, i6[0]: 6 i5[0]: 200, i6[0]: 200 Pass by value or Pass by reference\n和 = 一樣，只要掌握好基本類型實際儲存的是 \u0026ldquo;值\u0026rdquo;、對象類型儲存的是 \u0026ldquo;引用\u0026rdquo;、數組不論什類型存的都是 \u0026ldquo;引用\u0026rdquo;，就能了解 Java 到底什麼時候是 pass by value，什麼時候是 pass by reference\n基本類型 pass by value，對象類型 pass by reference，而數組因為存的都是引用，所以也是 pass by reference\nclass Tank { int level; } public class Main { public static void main(String[] args) { Tank t1 = new Tank(); Tank t2 = new Tank(); t1.level = 1; System.out.println(\u0026#34;t1.level: \u0026#34; + t1.level); fooInt(t1.level); //基本類型pass by value System.out.println(\u0026#34;t1.level: \u0026#34; + t1.level); t2.level = 2; System.out.println(\u0026#34;t2.level: \u0026#34; + t2.level); fooTank(t2); //對象類型pass by reference System.out.println(\u0026#34;t2.level: \u0026#34; + t2.level); } public static void fooTank(Tank tank){ tank.level = 1000; } public static void fooInt(int level){ level = 5; } } t1.level: 1 t1.level: 1 t2.level: 2 t2.level: 1000 基本類型的List、Set、Map 也是 pass by value，對象類型的 List、Set、Map 是 pass by reference\nclass Tank { int level; } public class Main { public static void main(String[] args) { List\u0026lt;Tank\u0026gt; tankList = new ArrayList\u0026lt;\u0026gt;(); List\u0026lt;Integer\u0026gt; intList = new Arr","date":"2018-09-10","objectID":"53465f549ce0b7aa1d4dfdb5d88bb771","title":"Java - Pass by value or Pass by reference？","url":"https://kucw.io/blog/2018/9/java-pass-param/"},{"categories":["Elastic Search"],"content":" 閱讀本文需要先了解 Elastic Search 的 index 和 analyzer 的相關知識\nElasticSearch - index mapping（5.x以上）\nElasticSearch - 自定義 analysis\n在此之前，ES 所有的查詢都是針對整個詞進行操作，也就是說倒排索引存了 hello 這個詞，一定得輸入 hello 才能找到這個詞，輸入 h 或是 he 都找不到倒排索引中的 hello\n然而在現實情況下，用戶已經漸漸習慣在輸入完查詢內容之前，就能為他們展現搜索結果，這就是所謂的即時搜索（instant search），或是可以稱為 輸入即搜索（search-as-you-type） 雖然 ES 提供了一系列的前綴搜索 match_phrase、prefix、wildcard、regexp，然而這樣的查詢的性能非常差，要知道用戶每多輸入一個新的字母，就意味著要重新進行一次搜索，在實時的 web 系統中，100 ms 可能就會是一個難以忍受的延遲 因此為了加快 輸入即搜索 的查詢效率，可以改使用 edge n-gram 建立索引，如此可以避免使用前綴查詢，在建立索引時就進行優化，使用空間換取時間，讓查詢的速率增快 使用 edge n-gram 建立索引\n假設有一個詞 hello，普通建索引時，就是把這個詞 hello 放入倒排索引\n用戶輸入 h、he時會找不到索引（倒排索引中只有 hello），因此匹配失敗 而對於輸入即搜索這種應用場景，可以使用一種特殊的 n-gram，稱爲 edge n-grams\n所謂的 edge n-gram，就是指它會固定詞語開始的一邊滑動窗口，他的結果取決於 n 的選擇長度\n以單詞 hello 爲例，它的 edge n-gram 的結果如下\nh he hel hell hello 因此可以發現到，在使用 edge n-gram 建索引時，一個單詞會生成好幾個索引，而這些索引一定是重頭開始\n這符合了輸入即搜索的特性，即是用戶打 h、he 能找到倒排中的索引 h、he，而這些索引對應著的數據就是 hello\n具體實例\n建立索引時使用 edge n-gram 的 token 過濾器，為每個經過這個 token 過濾器的詞條們，都生成從頭開始的字符組合\n假設有一個輸入 QUICK! RUN!，分詞器會先將它分詞成兩個詞 quick 和 run，此時這些詞再一一的通過 edge n-gram token 過濾器，產生了 8 個索引 q、qu、qui、quic、quick、r、ru、run，接著存入倒排索引中 如此，任何詞條像是 quick、run，都能生成他們自己的 n-gram 另外要注意，要額外定義一個 search_analyzer 分析器，供查詢使用\n原因是因為我們為了要保證倒排索引中包含各種組合的詞，所以在建索引時才加入了 edge n-gram 過濾器，然而在查詢時，我們只想匹配用戶輸入的完整詞組，像是用戶的輸入 run 或 qu\n因此需要定義兩套分析器，一套是建索引的分析器（包含edge n-gram 過濾器），另一套是查詢使用的正常的分析器\nPUT my_index { \u0026#34;settings\u0026#34;: { \u0026#34;number_of_shards\u0026#34;: 1, \u0026#34;analysis\u0026#34;: { \u0026#34;filter\u0026#34;: { //定義一個edge n-gram的token過濾器 //並設置任何通過這個過濾器的詞條，都會生成一個最小固定值為1，最大固定值為20的n-gram \u0026#34;my_autocomplete_filter\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;edge_ngram\u0026#34;, \u0026#34;min_gram\u0026#34;: 1, \u0026#34;max_gram\u0026#34;: 20 } }, \u0026#34;analyzer\u0026#34;: { //自定義一個分析器，並使用自定義的edge n-gram過濾器 \u0026#34;my_autocomplete_analyzer\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;custom\u0026#34;, \u0026#34;tokenizer\u0026#34;: \u0026#34;standard\u0026#34;, \u0026#34;filter\u0026#34;: [ \u0026#34;lowercase\u0026#34;, \u0026#34;my_autocomplete_filter\u0026#34; ] } } } }, \u0026#34;mapping\u0026#34;: { \u0026#34;my_type\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;name\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;analyzer\u0026#34;: \u0026#34;my_autocomplete_analyzer\u0026#34;, //在索引時用，生成edge n-gram的每個詞 \u0026#34;search_analyzer\u0026#34;: \u0026#34;standard\u0026#34; //查詢用，只搜索用戶輸入的詞 } } } } } 讓非 text 字段也能使用 edge n-gram\n由於 edge n-gram 是一個 token 過濾器，他包含在 analyzer 分析器裡面，因此只有 text 類型的字段才能使用（其他類型的字段不會被分詞，所以不會使用到 analyzer，因此不能用 edge n-gram）\n但是可能會有一種情況是，有些精確值也希望能通過 edge n-gram 生成組合，這時就要搭配使用一個叫做 keyword 的分詞器\n注意，此 keyword 分詞器和 keyword 字段類型是不同的東西 keyword 分詞器主要的功用是，將輸入的詞條，原封不動的 output 出來，不對其內容做任何改變 因此可以利用這個特性，將精確值的字段類型改成 text，但是分詞器使用 keyword，如此就可以避免分詞的效果，又能使用 edge n-gram 具體實例\n將 postcode 這個本來是 keyword 類型的精確值，改成使用 text 類型並搭配 keyword 分詞器\n因此假設有一個輸入 ABC EF，先經過 keyword 分詞器分詞成 ABC EF（和輸入一模一樣），接著再經過 edge n-gram 生成 A、AB、ABC、ABC （有一個空格） 、ABC E、ABC EF\n如果是使用正常的分詞器，生成的 edge n-gram 會是 A、AB、ABC、E、EF，他們是有差別的\nPUT my_index { \u0026#34;settings\u0026#34;: { \u0026#34;analysis\u0026#34;: { \u0026#34;filter\u0026#34;: { \u0026#34;postcode_filter\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;edge_ngram\u0026#34;, \u0026#34;min_gram\u0026#34;: 1, \u0026#34;max_gram\u0026#34;: 8 } }, \u0026#34;analyzer\u0026#34;: { \u0026#34;postcode_index\u0026#34;: { \u0026#34;tokenizer\u0026#34;: \u0026#34;keyword\u0026#34;, \u0026#34;filter\u0026#34;: [ \u0026#34;postcode_filter\u0026#34; ] }, \u0026#34;postcode_search\u0026#34;: { \u0026#34;tokenizer\u0026#34;: \u0026#34;keyword\u0026#34; } } } }, \u0026#34;mapping\u0026#34;: { \u0026#34;m","date":"2018-08-19","objectID":"68949f08a1e67a8e22fff4a059d079f7","title":"ElasticSearch - 輸入即搜索 edge n-gram","url":"https://kucw.io/blog/2018/8/elasticsearch-instant-search/"},{"categories":["Elastic Search"],"content":" ES 的 bulk 語法允許在一個請求中進行多個操作（create、index、update、delete），也就是可以在一次請求裡做很多事情\n也由於這個關係，因此 bulk 的請求體和其他請求的格式會有點不同 bulk 的請求模板\n分成 action 和 metadata 兩部份 action : 必須是以下 4 種選項之一 index(最常用） : 如果文檔不存在就創建他，如果文檔存在就更新他 create : 如果文檔不存在就創建他，但如果文檔存在就返回錯誤 使用時一定要在 metadata 設置 _id 值，他才能去判斷這個文檔是否存在 update : 更新一個文檔，如果文檔不存在就返回錯誤 使用時也要給 _id 值，且後面文檔的格式和其他人不一樣 delete : 刪除一個文檔，如果要刪除的文檔 id 不存在，就返回錯誤 使用時也必須在 metadata 中設置文檔 _id，且後面不能帶一個 doc，因為沒意義，他是用 _id 去刪除文檔的 metadata : 設置這個文檔的 metadata，像是 _id、_index POST mytest/_bulk { action : { metadata } } { doc } { action : { metadata } } { doc } .... 具體實例\nbulk請求\nPOST mytest/_bulk //創建一筆數據 { \u0026#34;create\u0026#34; : { \u0026#34;_id\u0026#34;: 1 } } { \u0026#34;color\u0026#34;: \u0026#34;create black\u0026#34; } //創建一筆數據，因為id=1的文檔已經存在，所以會創建失敗 { \u0026#34;create\u0026#34; : { \u0026#34;_id\u0026#34;: 1 } } { \u0026#34;color\u0026#34;: \u0026#34;create black2\u0026#34; } //索引一筆數據 { \u0026#34;index\u0026#34; : { \u0026#34;_id\u0026#34;: 2 } } { \u0026#34;color\u0026#34;: \u0026#34;index red\u0026#34; } //索引一筆數據，但是index可以創建也可以更新，所以執行成功 { \u0026#34;index\u0026#34; : { \u0026#34;_id\u0026#34;: 2 } } { \u0026#34;color\u0026#34;: \u0026#34;index red2\u0026#34; } //索引一筆數據，不一定要設置id(index又能創建又能更新又不用設id，超好用) { \u0026#34;index\u0026#34;: {} } { \u0026#34;color\u0026#34;: \u0026#34;index blue\u0026#34; } //刪除一筆文檔，注意delete後面不接一個doc { \u0026#34;delete\u0026#34; : { \u0026#34;_id\u0026#34;: \u0026#34;2\u0026#34; } } //找不到此id的文檔，刪除失敗 { \u0026#34;delete\u0026#34; : { \u0026#34;_id\u0026#34;: \u0026#34;2\u0026#34; } } //更新一筆文檔，注意doc格式不太一樣 { \u0026#34;update\u0026#34; : { \u0026#34;_id\u0026#34;: 1 } } { \u0026#34;doc\u0026#34;: { \u0026#34;color\u0026#34;: \u0026#34;update green\u0026#34;} } //更新一筆文檔，但因為此id的文檔不存在，所以更新失敗 { \u0026#34;update\u0026#34; : { \u0026#34;_id\u0026#34;: 100 } } { \u0026#34;doc\u0026#34;: { \u0026#34;color\u0026#34;: \u0026#34;update green2\u0026#34;} } bulk 的返回結果\n因為在 bulk 中，每個 action 的執行結果都是獨立的，所以有幾個 action，就會有幾個返回結果，返回結果如下\n最上面會有一個 errors，表示這一次 bulk 請求中，是否有 action 出錯了 因此寫代碼時可以先檢查 errors 這個值，如果是 false，表示這次 bulk 請求全部通過，就不用再一一去檢查是否有 action 出錯，但如果是 true，則必須去 items 一個一個檢查到底是哪個 action 出錯了 items 是一個 array，裡面則放著每個 action 對應的結果，上面的請求執行了 9 個 action，所以返回結果的 items 就會有 9 個\n返回結果會依照 action 的順序排好，因此 items 的第一個結果就是請求時第一個 action 的執行結果 { \u0026#34;took\u0026#34;: 145, \u0026#34;errors\u0026#34;: true, \u0026#34;items\u0026#34;: [ { \u0026#34;create\u0026#34;: { \u0026#34;_index\u0026#34;: \u0026#34;mytest\u0026#34;, \u0026#34;_type\u0026#34;: \u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;result\u0026#34;: \u0026#34;created\u0026#34;, \u0026#34;status\u0026#34;: 201 } }, { \u0026#34;create\u0026#34;: { \u0026#34;_index\u0026#34;: \u0026#34;mytest\u0026#34;, \u0026#34;_type\u0026#34;: \u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;status\u0026#34;: 409, \u0026#34;error\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;version_conflict_engine_exception\u0026#34;, \u0026#34;reason\u0026#34;: \u0026#34;[1]: version conflict, document already exists (current version [1])\u0026#34;, \u0026#34;index_uuid\u0026#34;: \u0026#34;PfdgdTyiRgaCIM6uKRQAPQ\u0026#34;, \u0026#34;shard\u0026#34;: \u0026#34;0\u0026#34;, \u0026#34;index\u0026#34;: \u0026#34;mytest\u0026#34; } } }, { \u0026#34;index\u0026#34;: { \u0026#34;_index\u0026#34;: \u0026#34;mytest\u0026#34;, \u0026#34;_type\u0026#34;: \u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;2\u0026#34;, \u0026#34;result\u0026#34;: \u0026#34;created\u0026#34;, \u0026#34;status\u0026#34;: 201 } }, { \u0026#34;index\u0026#34;: { \u0026#34;_index\u0026#34;: \u0026#34;mytest\u0026#34;, \u0026#34;_type\u0026#34;: \u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;2\u0026#34;, \u0026#34;result\u0026#34;: \u0026#34;updated\u0026#34;, \u0026#34;status\u0026#34;: 200 } } ... 5 RESULTS REMOVED ... ] } 使用 bulk 要注意的地方\n如果使用 127.0.0.1/_bulk，那麼就是在整個 ES 的範圍中插入數據，因此在 metadata 中要指定插入的 index，優點是可以一次插入多筆數據到不同的索引 而如果使用 127.0.0.1/mytest/_bulk，就不用在 metadata 再次指定要插入的 index，可以想像成是 _bulk API幫我們自動填好了 me","date":"2018-07-30","objectID":"220b7fd894d07bf549b71cc64510972a","title":"ElasticSearch - 批量操作 bulk","url":"https://kucw.io/blog/2018/7/elasticsearch-bulk/"},{"categories":["Intellij"],"content":" 有时候在升级 IntelliJ 時會遇到 Error: java: invalid flag: -version 解決辦法 打開 File -\u0026gt; settings，搜索 Java compiler 此時會發現右下角的每一個 module 裡的 Compilation options 中，都多加了一個 -version 把每個 module 的 -version 都刪除掉，就可以正常運行了 ","date":"2018-07-26","objectID":"f1e1fb9c42bde50826ddb391c8ef572e","title":"IntelliJ - 升級遇到的問題 Error: java: invalid flag: -version","url":"https://kucw.io/blog/2018/7/intellij-update-error/"},{"categories":["Linux"],"content":" tail -f catalina.log : 實時看log，會自動把新增的log直接顯示出來\n在實時日誌上打印顏色，給每個狀態給上不同的顏色，INFO 綠色、WARN 黃色、ERROR 紅色\ntail -f catalina.out | perl -pe \u0026#39;s/(INFO)/\\e[0;32m$1\\e[0m/g,s/(WARN)/\\e[0;33m$1\\e[0m/g,s/(ERROR)/\\e[1;31m$1\\e[0m/g\u0026#39; 只看 ERROR\ntail -f catalina.out | grep \u0026#34;ERROR\u0026#34; --line-buffered | perl -pe \u0026#39;s/(ERROR)/\\e[1;31m$1\\e[0m/g\u0026#39; 在 .bashrc 下加入這一段，可以讓 tail 輸出 log 時有顏色\nalias tail=\u0026#34;_tail_log\u0026#34; _tail_log() { \u0026#34;tail\u0026#34; $@ | perl -pe \u0026#39;s/(INFO)/\\e[0;32m$1\\e[0m/g,s/(WARN)/\\e[0;33m$1\\e[0m/g,s/(ERROR)/\\e[1;31m$1\\e[0m/g\u0026#39; } less : 通常用來翻找舊的日誌\n輸入 F，也可以實時滾動日誌，就像 tail -f 的效果一樣\n在 .bashrc 下加入這一段，可以讓 less 在找 log 時輸出顏色\nhighlight 整條 log\nalias less=\u0026#34;_show_log\u0026#34; _show_log() { awk \u0026#39; /ERROR/ {printf(\u0026#34;\\033[1;31m%s\\033[0m\\n\u0026#34;, $0)} /WARN/ {printf(\u0026#34;\\033[1;33m%s\\033[0m\\n\u0026#34;, $0)} !/(WARN|ERROR)/ {printf(\u0026#34;%s\\n\u0026#34;, $0)} \u0026#39; $1 | \u0026#34;less\u0026#34; -r } 只highlight INFO、WARN、ERROR 這種狀態\nalias less=\u0026#34;_show_log\u0026#34; _show_log() { awk \u0026#39; /ERROR/ {sub(/ERROR/, \u0026#34;\\033[1;31mERROR\\033[0m\u0026#34;)} /WARN/ {sub(/WARN/, \u0026#34;\\033[1;33mWARN\\033[0m\u0026#34;)} /INFO/ {sub(/INFO/, \u0026#34;\\033[0;32mINFO\\033[0m\u0026#34;)} {print} \u0026#39; $1 | \u0026#34;less\u0026#34; -r } multitail : 可同時開啟多視窗看 log，適合用在看部署在很多機器上的項目的 log\n-cS [color_scheme] : 可以選擇輸出的 log 的顏色，推薦使用 goldengate，也可自定義（修改/etc/multitail.conf）\n-s [column number] : 設定看 log 時會分成幾個縱列\nmultitail -s 2 -cS goldengate -l \u0026#39;ssh [ip] \u0026#34;tail -100f /example/logs/catalina.out\u0026#34;\u0026#39; -cS goldengate -l \u0026#39;ssh [ip] \u0026#34;tail -100f /example/logs/catalina.out\u0026#34;\u0026#39; multitail 開始運作後，點擊 b，可以選擇要 scroll 的檔案，點擊 q 退出\n","date":"2018-07-25","objectID":"b6986617d9c476e93be05d004f10a24c","title":"Linux - 查看 Log 的指令 tail、multitail、less","url":"https://kucw.io/blog/2018/7/linux-log-command/"},{"categories":["Elastic Search"],"content":" 聚合概念 aggs # ElasticSearch 除了致力於搜索之外，也提供了聚合實時分析數據的功能 如果把搜索比喻為大海撈針（從海量的文檔中找出符合條件的那一個），那麼聚合就是去分析大海中的針們的特性，像是 在大海里有多少針？ 針的平均長度是多少？ 按照針的製造商來劃分，針的長度中位值是多少？ 每月加入到海中的針有多少？ 這裏面有異常的針麼？ 因此透過聚合，我們可以得到一個數據的概覽，聚合能做的是分析和總結全套的數據，而不是查找單個文檔（這是搜索做的事） 聚合允許我們向數據提出一些複雜的問題，雖然他的功能完全不同於搜索，但他們其實使用了相同的數據結構，這表示聚合的執行速度很快，並且就像搜索一樣幾乎是實時的 並且由於聚合和搜索是使用同樣的數據結構，因此聚合和搜索可以是一起執行的 這表示我們可以在一次 json 請求裡，同時對相同的數據進行 搜索/過濾 + 分析，兩個願望一次滿足 聚合的兩個主要的概念，分別是 桶 和 指標 桶（Buckets）: 滿足特定條件的文檔的集合 當聚合開始被執行，每個文檔會決定符合哪個桶的條件，如果匹配到，文檔將放入相應的桶並接着進行聚合操作 像是一個員工屬於男性桶或者女性桶，日期 2014-10-28 屬於十月桶，也屬於 2014 年桶 桶可以被嵌套在其他桶裏面 像是北京能放在中國桶裡，而中國桶能放在亞洲桶裡 Elasticsearch 提供了很多種類型的桶，像是時間、最受歡迎的詞、年齡區間、地理位置桶等等，不過他們在根本上都是通過同樣的原理進行操作，也就是基於條件來劃分文檔，一個文檔只要符合條件，就可以加入那個桶，因此一個文檔可以同時加入很多桶 指標（Metrics） : 對桶內的文檔進行統計計算 桶能讓我們劃分文檔到有意義的集合， 但是最終我們需要的是對這些桶內的文檔進行一些指標的計算 指標通常是簡單的數學運算（像是min、max、avg、sum），而這些是通過當前桶中的文檔的值來計算的，利用指標能讓你計算像平均薪資、最高出售價格、95 % 的查詢延遲這樣的數據 aggs 聚合的模板 當 query 和 aggs 一起存在時，會先執行 query 的主查詢，主查詢 query 執行完後會搜出一批結果，而這些結果才會被拿去 aggs 拿去做聚合 另外要注意 aggs 後面會先接一層自定義的這個聚合的名字，然後才是接上要使用的聚合桶 如果有些情況不在意查詢結果是什麼，而只在意 aggs 的結果，可以把 size 設為 0，如此可以讓返回的 hits 結果集是 0，加快返回的速度 一個 aggs 裡可以有很多個聚合，每個聚合彼此間都是獨立的，因此可以一個聚合拿來統計數量、一個聚合拿來分析數據、一個聚合拿來計算標準差\u0026hellip;，讓一次搜索就可以把想要做的事情一次做完 像是此例就定義了 3 個聚合，分別是 custom_name1、custom_name2、custom_name3 aggs 可以嵌套在其他的 aggs裡面，而嵌套的桶能作用的文檔集範圍，是外層的桶所輸出的結果集 GET mytest/doc/_search { \u0026#34;query\u0026#34;: { ... }, \u0026#34;size\u0026#34;: 0, \u0026#34;aggs\u0026#34;: { \u0026#34;custom_name1\u0026#34;: { //aggs後面接著的是一個自定義的name \u0026#34;桶\u0026#34;: { ... } //再來才是接桶 }, \u0026#34;custom_name2\u0026#34;: { //一個aggs裡可以有很多聚合 \u0026#34;桶\u0026#34;: { ... } }, \u0026#34;custom_name3\u0026#34;: { \u0026#34;桶\u0026#34;: { ..... }, \u0026#34;aggs\u0026#34;: { //aggs可以嵌套在別的aggs裡面 \u0026#34;in_name\u0026#34;: { //記得使用aggs需要先自定義一個name \u0026#34;桶\u0026#34;: { ... } //in_name的桶作用的文檔是custom_name3的桶的結果 } } } } } 結果 { \u0026#34;hits\u0026#34;: { \u0026#34;total\u0026#34;: 8, \u0026#34;max_score\u0026#34;: 0, \u0026#34;hits\u0026#34;: [] //因為size設為0，所以沒有查詢結果返回 }, \u0026#34;aggregations\u0026#34;: { \u0026#34;custom_name1\u0026#34;: { ... }, \u0026#34;custom_name2\u0026#34;: { ... }, \u0026#34;custom_name3\u0026#34;: { ... , \u0026#34;in_name\u0026#34;: { .... } } } } terms桶 # 功能 : 針對某個 field 的值進行分組，field 有幾種值就分成幾組 terms 桶在進行分組時，會爲此 field 中的每種值創建一個新的桶 要注意此 \u0026ldquo;terms桶\u0026rdquo; 和平常用在主查詢 query 中的 \u0026ldquo;查找terms\u0026rdquo; 是不同的東西 具體實例 首先插入幾筆數據，其中 color 是一個 keyword 類型 { \u0026#34;color\u0026#34;: \u0026#34;red\u0026#34; } { \u0026#34;color\u0026#34;: \u0026#34;green\u0026#34; } { \u0026#34;color\u0026#34;: [\u0026#34;red\u0026#34;, \u0026#34;blue\u0026#34;] } 執行 terms 桶聚合 GET mytest/doc/_search { \u0026#34;query\u0026#34;: { \u0026#34;match_all\u0026#34;: {} }, \u0026#34;size\u0026#34;: 0, \u0026#34;aggs\u0026#34;: { \u0026#34;my_name\u0026#34;: { \u0026#34;terms\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;color\u0026#34;, //使用color來進行分組 } } } } 結果 因為 color 總共有 3 種值，red、blue、green，所以 terms 桶為他們產生了 3 個 bucket，並計算了每個 bucket 中符合的文檔有哪些 bucket 和 bucket 間是獨立的，也就是說一個文檔可以同時符合好幾個 bucket，像是 {\u0026quot;color\u0026quot;: [\u0026quot;red\u0026quot;, \u0026quot;blue\u0026quot;]} 就同時符合了 red 和 blue bucket \u0026#34;aggregations\u0026#34;: { \u0026#34;my_name\u0026#34;: { \u0026#34;doc_count_error_upper_bound\u0026#34;: 0, \u0026#34;sum_other_doc_count\u0026#34;: 0, \u0026#34;buckets\u0026#34;: [ //terms桶產生的buckets數組，裡面每個json對象都是一個bucket { \u0026#34;key\u0026#34;: \u0026#34;blue\u0026#34;, \u0026#34;doc_count\u0026#34;: 1 }, { \u0026#34;key\u0026#34;: \u0026#34;red\u0026#34;, //表示color為red的文檔有2個，此例中就是 {\u0026#34;color\u0026#34;: \u0026#34;red\u0026#34;} 和 {\u0026#34;color\u0026#34;: [\u0026#34;red\u0026#34;, \u0026#34;blue\u0026#34;]}這兩個文檔 \u0026#34;doc_count\u0026#34;: 2 }, { \u0026#34;key\u0026#34;: \u0026#34;green\u0026#34;, \u0026#34","date":"2018-07-23","objectID":"78294bb6c4280181d28a2712ad9dd904","title":"ElasticSearch - 聚合 aggs","url":"https://kucw.io/blog/2018/7/elasticsearch-aggs/"},{"categories":["Java"],"content":" ThreadLocal 是線程的局部變量， 是每一個線程所單獨持有的，其他線程不能對其進行訪問\nThreadLocal 支持泛型，也就是支持 value 是可以設置類型的，像是 ThreadLocal\u0026lt;Date\u0026gt; 就是設置 value 為 Date 類型 每個線程會有自己的一份 ThreadLocalMap 變量，去儲存這個線程自己想存放的 ThreadLocal 變量們，他內部儲存的是一個鍵值對 Map，其中 key 是某個 ThreadLocal，value 就是這個線程自己 set 的值，所以對於一個線程來說，一個 ThreadLocal 只能存一個值，而一個線程可以存放好多個 ThreadLocal 因此當調用 ThreadLocal tl 的 tl.get() 方法時，其實就是先去取得此線程的 ThreadLocalMap，然後再去查找這個 Map 中的 key 為 tl 的那個 Entry 的 value 值 ThreadLocal 常用的方法\nset(x) : 設置此線程的想要放的值是多少 get() : 取得此線程當初存放的值，如果沒有存放過則返回 null remove() : 刪除此線程的鍵值對，也就是如果先執行 remove 再執行 get，會返回 null ThreadLocal 通常用在 SimpleDateFormat，或是 SpringMVC 上\n因為 SimpleDateFormat 不是線程安全的，因此雖然可以每次要使用的時候重新 new 一個，但是這樣做會很浪費資源，所以如果使用 ThreadLocal 在每個線程裡都存放一個此線程專用的 SimpleDateFormat，就可以避免一直 new 的資源浪費，又確保線程安全 因為 SpringMVC 會對每個請求分配一個線程，可以在攔截器將此線程的用戶信息（ip、名字\u0026hellip;）使用 ThreadLocal 儲存，這樣在後續要用到用戶信息的地方時，就可以去 ThreadLocal 中取得，而且因為 ThreadLocal 可以隔離線程，因此每條請求對應的線程的用戶信息不會互相干擾 ThreadLocal 可能造成的內存洩漏\n在Java裡，每個線程都有自己的 ThreadLocalMap，裡面存著這個線程自己私有的 ThreadLocal 們，而 ThreadLocalMap 的 key 為 ThreadLocal 實例，value 為私有對象 T，即是透過 set() 設置的值\npublic class Thread implements Runnable { //Thread類裡的threadlocals存放此線程的專有的ThreadLocalMap ThreadLocal.ThreadLocalMap threadLocals = null; } public class ThreadLocal\u0026lt;T\u0026gt; { //根據線程，取得那個線程自己的ThreadLocalMap ThreadLocalMap getMap(Thread t) { return t.threadLocals; } static class ThreadLocalMap { //ThreadLocalMap的key是使用 \u0026#34;弱引用\u0026#34; 的ThreadLocal static class Entry extends WeakReference\u0026lt;ThreadLocal\u0026gt; { Object value; //ThreadLocalMap中的key就是ThreadLocal，value就是設置的值 Entry(ThreadLocal k, Object v) { super(k); value = v; } } } } 可以創建許多個 ThreadLocal 對象，對每個 ThreadLocal 都設置不同的值\n像是以下的例子，在 main 線程中的 ThreadLocalMap，就有兩個 key-value 的映射，分別是 userIdThreadLocal -\u0026gt; 100、userNameThreadLocal -\u0026gt; hello\npublic class Main { public static void main(String[] args){ ThreadLocal\u0026lt;Integer\u0026gt; userIdThreadLocal = new ThreadLocal\u0026lt;\u0026gt;(); ThreadLocal\u0026lt;String\u0026gt; userNameThreacLocal = new ThreadLocal\u0026lt;\u0026gt;(); userId.set(100); userName.set(\u0026#34;hello\u0026#34;); } } 之所以 ThreadLocal 會發生內存洩漏，原因是因為只要線程活著，這個線程的 ThreadLocalMap 就會一直活著，而當初透過 ThreadLocal set() 的值，也就會在 ThreadLocalMap 中一直存在這個鍵值對不消失，所以該 ThreadLocal 和該 value 的內存地址始終都有這個 ThreadLocalMap 在引用著，導致 GC 無法回收他，所以才會發生內存洩漏\n為了解決這個問題，java 做了一個小優化，也就是存放在 ThreadLocalMap 中的 ThreadLocal，會使用 弱引用 來儲存，也就是說，如果一個 ThreadLocal 內存地址沒有外部強引用來引用他，只有這條 ThreadLocalMap 的弱引用來引用他時，那麼當系統 GC 時，這些 ThreadLocal 就會被回收（因為是弱引用），如此一來，ThreadLocalMap 中就會出現 key 為 null 的 Entry 們\n下圖中，實線表示強引用，虛線表示弱引用 這個弱引用優化只能使得 ThreadLocal 被正確回收，但是這些 key 為 null 的 Entry 們仍然會存在在 ThreadLocalMap 裡，因此 value 仍然無法被回收\n所以 java 又做了一個優化，就是在 ThreadLocal 執行 get()、set()、remove() 方法時，都會將該線程 ThreadLocalMap 裡所有 key = null 的 value 也設置為 null，手動幫助 GC\nThreadLocal k = e.get(); if (k == null) { e.value = null; // Help the GC } 但是根本上的解決辦法，還是在當前線程使用完這個 ThreadLocal 時，就即時的 remove() 掉該 value，也就是使得 ThreadLocalMap 中不要存在這個鍵值對，這樣才能確保 GC 能正確回收\n具體實例\n每個線程都可以在 ThreadLocal 中放自己的值，且不會干擾到其他線程的值\nclass Tools { public static ThreadLocal threadLocal = new ThreadLocal(); } class MyThread extends Thread { @Override public void run() { if (Tools.threadLocal.get() == null) { Tools.threadLocal.set(Thread.currentThread().getName() + \u0026#34;, \u0026#34; + Math.random()); } System.out.printl","date":"2018-07-16","objectID":"60c8acce13b54ab636e60a38252bb630","title":"Java - ThreadLocal 類的使用","url":"https://kucw.io/blog/2018/7/java-thread-local/"},{"categories":["Spring Boot"],"content":" Spring 中，使用注解 @Autowired 進行注入好，還是使用 xml 配置進行注入好？ 先講結論，使用注解 @Autowired 注入比較好 當時 Spring 開發的初衷是為了解決類與類之間的強耦合 new，所以當時提出了 xml 配置注入bean的方法，就是讓代碼只關注我需要什麼 service，但此 service 是由哪個實現類提供的我並不關心 使用 xml 的好處就是，實現類更換的時候並不需要去改動代碼，只要去改動 xml 配置，將注入的 bean 改成另一個實現類就可以了，如此可以達到類與類之間的松耦合 但是到了 Spring3.0 之後，他們開始提出了使用 @Autowired 注解來進行 bean 的注入 有的人可能會覺得，如果使用 @Autowired、@Qualifier 來注入，那麼假設我要改注入實現類的話，得去改 java 代碼中的 @Qualifier，那這樣還是得改代碼，那這樣使用 Spring 注入和使用 new，又有什麼差別？是不是還是使用 xml 比較好？ 事實上，使用注解確實會有這個問題沒錯，不過經過長時間的項目經驗下來，你會發現，我們其實很少會去改注入的實現類的（天天改服務還要不要命?） 而注解提供的好處卻是不少，像是簡化 xml 配置的冗長、使用注解比較直觀且容易、並且是類型安全的（compiler 可以掃描注解，判斷注入的類型是否正確，但他掃描不了 xml 文件) 因此就算使用注解 @Autowired 去改變注入的實現類比 xml 更困難，但他其他大量的優點足以掩蓋過這個缺點，這也是為什麼 Spring 覺得使用注解配置比使用 xml 配置更好的理由 所以到目前為止（Spring4.0），雖然 Spring 官方本身沒有明說拋棄 xml 配置，不過事實上 Spring 已經轉往注解配置方向前進了，SpringBoot 就是最好的例子 SpringBoot 中只有一個 properties 文件負責配置一些不可避免的設定，像是數據庫連接、mvc 模板配置\u0026hellip;.，除此之外沒有任何一個 xml 文件來定義 bean，全部都是使用注解來配置 注解 vs xml 優缺點比較 注解 優點 : 簡化配置、使用起來直觀且容易，提升開發效率、類型安全 缺點 : 改變實現類比 xml 困難 xml 優點 : 類與類間的松耦合，容易擴展、更換、對象間的關係一目了然 缺點 : 配置冗長，且還要額外多維護一份配置，類型不安全，compiler 無法幫忙校驗，運行期才會發現錯誤 ","date":"2018-07-09","objectID":"c13e8bdfb4e480a692a5adaf81b2c82c","title":"Spring Boot - 注解 vs XML 哪個好？","url":"https://kucw.io/blog/2018/7/spring-annotation-vs-xml/"},{"categories":["Elastic Search"],"content":" 閱讀本文需要先了解 function_score 的相關知識，請看 ElasticSearch - function_score 簡介\n很多變量都可以影響用戶對於酒店的選擇，像是用戶可能希望酒店離市中心近一點，但是如果價格足夠便宜，也願意為了省錢，妥協選擇一個更遠的住處\n如果我們只是使用一個 filter 排除所有市中心方圓 100 米以外的酒店，再用一個 filter 排除每晚價格超過 100 元的酒店，這種作法太過強硬，可能有一間房在 500 米，但是超級便宜一晚只要 10 元，用戶可能會因此願意妥協住這間房 為了解決這個問題，因此 function_score 查詢提供了一組 衰減函數（decay functions）， 讓我們有能力在兩個滑動標準（如地點和價格）之間權衡 function_score 支持的衰減函數有三種，分別是 linear、exp 和 gauss\nlinear、exp、gauss 三種衰減函數的差別只在於衰減曲線的形狀，在 DSL 的語法上的用法完全一樣 linear : 線性函數是條直線，一旦直線與橫軸 0 相交，所有其他值的評分都是 0 exp : 指數函數是先劇烈衰減然後變緩 guass（最常用） : 高斯函數則是鐘形的，他的衰減速率是先緩慢，然後變快，最後又放緩 衰減函數們（linear、exp、gauss）支持的參數 origin : 中心點，或是字段可能的最佳值，落在原點（origin）上的文檔評分 _score 為滿分 1.0，支持數值、時間 以及 \u0026ldquo;經緯度地理座標點\u0026rdquo;（最常用）的字段 offset : 從 origin 為中心，為他設置一個偏移量 offset 覆蓋一個範圍，在此範圍內所有的評分 _score 也都是和 origin 一樣滿分 1.0 scale : 衰減率，即是一個文檔從 origin 下落時，_score 改變的速度 decay : 從 origin 衰減到 scale 所得的評分_score，默認為 0.5（一般不需要改變，這個參數使用默認的就好了） 以上面的圖為例 所有曲線（linear、exp、gauss）的 origin 都是 40，offset 是 5，因此範圍在 40-5 \u0026lt;= value \u0026lt;= 40+5 的文檔的評分 _score 都是滿分 1.0 而在此範圍之外，評分會開始衰減，衰減率由 scale 值（此處是5）和 decay 值（此處是默認值0.5）決定，在 origin +/- (offset + scale) 處的評分是 decay 值，也就是在 30、50 的評分處是 0.5 分 也就是說，在 origin + offset + scale 或是 origin - offset - scale 的點上，得到的分數僅有 decay 分 具體實例一\n先準備數據和索引，在 ES 插入三筆數據，其中 language 是 keyword 類型，like 是 integer 類型（代表點贊量）\n{ \u0026#34;language\u0026#34;: \u0026#34;java\u0026#34;, \u0026#34;like\u0026#34;: 5 } { \u0026#34;language\u0026#34;: \u0026#34;python\u0026#34;, \u0026#34;like\u0026#34;: 10 } { \u0026#34;language\u0026#34;: \u0026#34;go\u0026#34;, \u0026#34;like\u0026#34;: 15 } 以 like = 15 為中心，使用 gauss 函數\nGET mytest/doc/_search { \u0026#34;query\u0026#34;: { \u0026#34;function_score\u0026#34;: { \u0026#34;query\u0026#34;: { \u0026#34;match_all\u0026#34;: {} }, \u0026#34;functions\u0026#34;: [ { \u0026#34;gauss\u0026#34;: { \u0026#34;like\u0026#34;: { \u0026#34;origin\u0026#34;: \u0026#34;15\u0026#34;, //如果不設置offset，offset默認為0 \u0026#34;scale\u0026#34;: \u0026#34;5\u0026#34;, \u0026#34;decay\u0026#34;: \u0026#34;0.2\u0026#34; } } } ] } } } \u0026#34;hits\u0026#34;: [ { \u0026#34;_score\u0026#34;: 1, \u0026#34;_source\u0026#34;: { \u0026#34;language\u0026#34;: \u0026#34;go\u0026#34;, \u0026#34;like\u0026#34;: 15 } }, { //因為改變了decay=0.2，所以當位於 origin-offset-scale=10 的位置時，分數為decay，就是0.2 \u0026#34;_score\u0026#34;: 0.2, \u0026#34;_source\u0026#34;: { \u0026#34;language\u0026#34;: \u0026#34;python\u0026#34;, \u0026#34;like\u0026#34;: 10 } }, { \u0026#34;_score\u0026#34;: 0.0016, \u0026#34;_source\u0026#34;: { \u0026#34;language\u0026#34;: \u0026#34;java\u0026#34;, \u0026#34;like\u0026#34;: 5 } } ] 具體實例二\n假設有一個用戶希望租一個離市中心近一點的酒店，且每晚不超過 100 元的酒店，而且與距離相比，我們的用戶對價格更敏感，那麼使用衰減函數 gauss 查詢如下 其中把 price 語句的 origin 點設為 50 是有原因的，由於價格的特性一定是越低越好，所以 0 ~ 100 元的所有價格的酒店都應該認為是比較好的，而 100 元以上的酒店就慢慢衰減 如果我們將 price 的 origin 點設置成100，那麼價格低於 100 元的酒店的評分反而會變低，這不是我們期望的結果，與其這樣不如將 origin 和 offset 同時設成 50，只讓 price 大於 100 元時評分才會變低 雖然這樣設置也會使得 price 小於 0 元的酒店評分降低沒錯，不過現實生活中價格不會有負數，因此就算 price \u0026lt; 0 的評分會下降，也不會對我們的搜索結果造成影響（酒店的價格一定都是正的） 換句話說，其實只要把 origin + offset 的值設為 100，origin 或 offset 是什麼樣的值都無所謂，只要能確保酒店價格在 100 元以上的酒店會衰減就好了 GET mytest/doc/_search { \u0026#34;query\u0026#34;: { \u0026#34;function_score\u0026#34;: { \u0026#34;query\u0026#34;: { \u0026#34;match_all\u0026#34;: {} } \u0026#34;functions\u0026#34;: [ //第一個gauss加強函數，決定距離的衰減率 { \u0026#34;gauss\u0026#34;: { \u0026#34;location\u0026#34;: { \u0026#34;origin\u0026#34;: { //origin點設成市中心的經緯度座標 \u0026#34;lat\u0026#34;: 51.5, \u0026#34;lon\u0026#34;: 0.12 }, \u0026#34;offset\u0026#34;: \u0026#34;2km\u0026#34;, //距離中心點2km以內都是滿分1.0，2km外開始衰減 \u0026#34;scale\u0026#34;: \u0026#34;3km\u0026#34; //衰減率 } } }, //第二個gauss加強函數，決定價格的衰減率 //因為用戶對價格更敏感，所以給了這個gauss加強函數2倍的權重 { \u0026#34;gauss\u0026#34;: { \u0026#34;price\u0026#34;: { \u0026#34;origi","date":"2018-07-08","objectID":"a05f5941b38bf3fb5a3c5fa29c6fc461","title":"ElasticSearch - function_score（衰減函數 linear、exp、gauss 具體實例）","url":"https://kucw.io/blog/2018/7/elasticsearch-function_score-gauss/"},{"categories":["Elastic Search"],"content":" 閱讀本文需要先了解 function_score 的相關知識，請看 ElasticSearch - function_score 簡介\n在正常的查詢下，有相同評分的 score 的文檔會每次都會以相同次序出現，但是爲了提高展現率，在此引入一些隨機性可能會是個好主意，這能保證有相同評分的文檔都能有均等相似的展現機率\n但是，在隨機的同時，除了想讓不同的用戶看到不同的隨機次序之外，但也希望如果是同一用戶翻頁瀏覽時，結果的相對次序能始終保持一致，這種行爲被稱爲 一致隨機（consistently random） 因此 random_score 加強函數除了能隨機得到一個 0 ~ 1 的分數，也會使用一個 seed 值，來保障生成隨機的順序，當 seed 值相同時，生成的隨機結果是一致的 先準備數據和索引，在 ES 插入三筆數據，其中 language 是 keyword 類型，like 是 integer 類型（代表點贊量）\n{ \u0026#34;language\u0026#34;: \u0026#34;java\u0026#34;, \u0026#34;like\u0026#34;: 5 } { \u0026#34;language\u0026#34;: \u0026#34;python\u0026#34;, \u0026#34;like\u0026#34;: 5 } { \u0026#34;language\u0026#34;: \u0026#34;go\u0026#34;, \u0026#34;like\u0026#34;: 10 } 使用 random_score 生成隨機排序\n注意在 functions 裡，只有 weight 加強函數加了 filter，也就是說只有 like 數小於等於 5 的文檔，才會被 weight 加強函數加強\n而 random_score 加強函數沒有加 filter，表示所有的文檔都會被 random_score 隨機排序一遍\nGET mytest/doc/_search { \u0026#34;query\u0026#34;: { \u0026#34;function_score\u0026#34;: { \u0026#34;query\u0026#34;: { \u0026#34;match_all\u0026#34;: {} }, \u0026#34;functions\u0026#34;: [ { \u0026#34;filter\u0026#34;: { \u0026#34;range\u0026#34;: { \u0026#34;like\u0026#34;: { \u0026#34;lte\u0026#34;: 5 } } }, \u0026#34;weight\u0026#34;: 2 }, { \u0026#34;random_score\u0026#34;: { \u0026#34;seed\u0026#34;: 100 } } ] } } } 當 random_score 的 seed 設為 100，其結果為\n\u0026#34;hits\u0026#34;: [ { \u0026#34;_score\u0026#34;: 1.2912227, \u0026#34;_source\u0026#34;: { \u0026#34;language\u0026#34;: \u0026#34;python\u0026#34;, \u0026#34;like\u0026#34;: 5 } }, { \u0026#34;_score\u0026#34;: 1.1301208, \u0026#34;_source\u0026#34;: { \u0026#34;language\u0026#34;: \u0026#34;java\u0026#34;, \u0026#34;like\u0026#34;: 5 } }, { \u0026#34;_score\u0026#34;: 0.9083528, \u0026#34;_source\u0026#34;: { \u0026#34;language\u0026#34;: \u0026#34;go\u0026#34;, \u0026#34;like\u0026#34;: 10 } } ] 當 random_score 的 seed 設為 200，其結果為\n\u0026#34;hits\u0026#34;: [ { \u0026#34;_score\u0026#34;: 1.2040303, \u0026#34;_source\u0026#34;: { \u0026#34;language\u0026#34;: \u0026#34;java\u0026#34;, \u0026#34;like\u0026#34;: 5 } }, { \u0026#34;_score\u0026#34;: 0.5595852, \u0026#34;_source\u0026#34;: { \u0026#34;language\u0026#34;: \u0026#34;go\u0026#34;, \u0026#34;like\u0026#34;: 10 } }, { \u0026#34;_score\u0026#34;: 0.10916698, \u0026#34;_source\u0026#34;: { \u0026#34;language\u0026#34;: \u0026#34;python\u0026#34;, \u0026#34;like\u0026#34;: 5 } } ] ","date":"2018-07-07","objectID":"20bb3a32640b2e5c56acc6a6bf67126d","title":"ElasticSearch - function_score（random_score 具體實例）","url":"https://kucw.io/blog/2018/7/elasticsearch-function_score-random_score/"},{"categories":["Elastic Search"],"content":" 閱讀本文需要先了解 function_score 的相關知識，請看 ElasticSearch - function_score 簡介\n一樣先準備數據和索引，在 ES 插入三筆數據，其中 language 是 keyword 類型，like 是 integer 類型（代表點贊量）\n{ \u0026#34;language\u0026#34;: \u0026#34;java\u0026#34;, \u0026#34;like\u0026#34;: 5 } { \u0026#34;language\u0026#34;: \u0026#34;python\u0026#34;, \u0026#34;like\u0026#34;: 5 } { \u0026#34;language\u0026#34;: \u0026#34;go\u0026#34;, \u0026#34;like\u0026#34;: 10 } functions 是一個數組，裡面放著的是將要被使用的加強函數列表，我們在裡面使用了 3 個 filter 去過濾數據，並且每個 filter 都設置了一個加強函數，並且還使用了一個會應用到所有文檔的 field_value_factor 加強函數\n可以為列表裡的每個加強函數都指定一個 filter，這樣做的話，只有在文檔滿足此 filter 的要求，此 filter 的加強函數才會應用到文擋上，也可以不指定 filter，這樣的話此加強函數就會應用到全部的文擋上\n一個文檔可以一次滿足多條加強函數和多個 filter，如果一次滿足多個，那麼就會產生多個加強 score\n因此 ES 會先使用 score_mode 定義的方式來合併這些加強 score 們，得到一個總加強 score，得到總加強 score之後，才會再使用 boost_mode 定義的方式去和 old_score 做合併\nGET mytest/doc/_search { \u0026#34;query\u0026#34;: { \u0026#34;function_score\u0026#34;: { \u0026#34;query\u0026#34;: { \u0026#34;match_all\u0026#34;: {} //match_all查出來的所有文檔的_score都是1 }, \u0026#34;functions\u0026#34;: [ //第一個filter(使用weight加強函數)，如果language是java，加強score就是2 { \u0026#34;filter\u0026#34;: { \u0026#34;term\u0026#34;: { \u0026#34;language\u0026#34;: \u0026#34;java\u0026#34; } }, \u0026#34;weight\u0026#34;: 2 }, //第二個filter(使用weight加強函數)，如果language是go，加強score就是3 { \u0026#34;filter\u0026#34;: { \u0026#34;term\u0026#34;: { \u0026#34;language\u0026#34;: \u0026#34;go\u0026#34; } }, \u0026#34;weight\u0026#34;: 3 }, //第三個filter(使用weight加強函數)，如果like數大於等於10，加強score就是5 { \u0026#34;filter\u0026#34;: { \u0026#34;range\u0026#34;: { \u0026#34;like\u0026#34;: { \u0026#34;gte\u0026#34;: 10 } } }, \u0026#34;weight\u0026#34;: 5 }, //field_value_factor加強函數，會應用到所有文檔上，加強score就是like值 { \u0026#34;field_value_factor\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;like\u0026#34; } } ], \u0026#34;score_mode\u0026#34;: \u0026#34;multiply\u0026#34;, //設置functions裡面的加強score們怎麼合併成一個總加強score \u0026#34;boost_mode\u0026#34;: \u0026#34;multiply\u0026#34; //設置old_score怎麼和總加強score合併 } } } \u0026#34;hits\u0026#34;: [ { //go同時滿足filter2、filter3 //且還有一個加強函數field_value_factor產生的加強 //因此加強score為3, 5, 10，總加強score為3*5*10=150 \u0026#34;_score\u0026#34;: 150, \u0026#34;_source\u0026#34;: { \u0026#34;language\u0026#34;: \u0026#34;go\u0026#34;, \u0026#34;like\u0026#34;: 10 } }, { //java只滿足filter1 //但是因為還有field_value_facotr產生的加強score //因此加強score為2, 5，總加強score為2*5=10 \u0026#34;_score\u0026#34;: 10, \u0026#34;_source\u0026#34;: { \u0026#34;language\u0026#34;: \u0026#34;java\u0026#34;, \u0026#34;like\u0026#34;: 5 } }, { //python不滿足任何filter //因此加強score只有field_value_factor的like值 //就是5 \u0026#34;_score\u0026#34;: 5, \u0026#34;_source\u0026#34;: { \u0026#34;language\u0026#34;: \u0026#34;python\u0026#34;, \u0026#34;like\u0026#34;: 5 } } ] 其實 weight 加強函數也是可以不和 filter 搭配，自己單獨使用的，只是這樣做沒啥意義，因為只是會給全部的文檔都增加一個固定值而已\n不過就 DSL 語法上來說，他也像其他加強函數一樣，是可以直接使用而不用加 filter 的\nGET mytest/doc/_search { \u0026#34;query\u0026#34;: { \u0026#34;function_score\u0026#34;: { \u0026#34;query\u0026#34;: { \u0026#34;match_all\u0026#34;: {} } }, functions: [ { \u0026#34;weight\u0026#34;: 3 } ] } } \u0026#34;hits\u0026#34;: [ { \u0026#34;_score\u0026#34;: 3, \u0026#34;_source\u0026#34;: { \u0026#34;language\u0026#34;: \u0026#34;go\u0026#34;, \u0026#34;like\u0026#34;: 10 } }, { \u0026#34;_score\u0026#34;: 3, \u0026#34;_source\u0026#34;: { \u0026#34;language\u0026#34;: \u0026#34;python\u0026#34;, \u0026#34;like\u0026#34;: 5 } }, { \u0026#34;_score\u0026#34;: 3, \u0026#34;_source\u0026#34;: { \u0026#34;language\u0026#34;: \u0026#34;java\u0026#34;, \u0026#34;like\u0026#34;: 5 } } ] weight 加強函數也可以用來調整每個語句的貢獻度，權重 weight 的默認值是 1.0，當設置了 weight，這個 weight 值會先和自己那個 {} 裡的每個句子的評分相乘，之後再通過 score_mode 和其他加強函數合併\n下面的查詢，公式為 new_score = old_score * [ (like值 * weight1) + weight2 ] 公式解析 : weight1 先加強 like 值（只能使用乘法），接著再透過 score_mode 定義的方法（sum）和另一個加強函數 weight2 合併，得到一個總加強 score，最後再使用 boost_mode 定義的方法（默認是 multiply）和 old_score 做合併，得到 new_score\nGET mytest/doc/_search { \u0026#34","date":"2018-07-06","objectID":"da4e2b503c1484ed0a654df41c72baa4","title":"ElasticSearch - function_score（weight 具體實例）","url":"https://kucw.io/blog/2018/7/elasticsearch-function_score-weight/"},{"categories":["Elastic Search"],"content":" 閱讀本文需要先了解 function_score 的相關知識，請看 ElasticSearch - function_score 簡介\n首先準備數據和索引，在ES插入三筆數據，其中 title 是 text 類型，like 是 integer 類型（代表點贊量）\n{ \u0026#34;title\u0026#34;: \u0026#34;ES 入門\u0026#34;, \u0026#34;like\u0026#34;: 2 } { \u0026#34;title\u0026#34;: \u0026#34;ES 進階\u0026#34;, \u0026#34;like\u0026#34;: 5 } { \u0026#34;title\u0026#34;: \u0026#34;ES 最高難度\u0026#34;, \u0026#34;like\u0026#34;: 10 } 先使用一般的 query，查看普通的查詢的評分會是如何\nGET mytest/doc/_search { \u0026#34;query\u0026#34;: { \u0026#34;match\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;ES\u0026#34; } } } \u0026#34;hits\u0026#34;: [ { \u0026#34;_score\u0026#34;: 0.2876821, \u0026#34;_source\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;ES 入門\u0026#34;, \u0026#34;like\u0026#34;: 2 } }, { \u0026#34;_score\u0026#34;: 0.20309238, \u0026#34;_source\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;ES 進階\u0026#34;, \u0026#34;like\u0026#34;: 5 } }, { \u0026#34;_score\u0026#34;: 0.16540512, \u0026#34;_source\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;ES 最高難度\u0026#34;, \u0026#34;like\u0026#34;: 10 } } ] 使用 function_score 的 field_value_factor 改變 _score，將 old_score 乘上 like 的值\n本來 \u0026ldquo;ES 最高難度\u0026rdquo; 的 score 是0.16540512，經過 field_value_factor 的改變，乘上了那個文檔中的like值（10）之後，新的 score 變為 1.6540513\nGET mytest/doc/_search { \u0026#34;query\u0026#34;: { \u0026#34;function_score\u0026#34;: { \u0026#34;query\u0026#34;: { \u0026#34;match\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;ES\u0026#34; } }, \u0026#34;field_value_factor\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;like\u0026#34; } } } } \u0026#34;hits\u0026#34;: [ { \u0026#34;_score\u0026#34;: 1.6540513, //原本是0.16540512 \u0026#34;_source\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;ES 最高難度\u0026#34;, \u0026#34;like\u0026#34;: 10 } }, { \u0026#34;_score\u0026#34;: 1.0154619, //原本是0.20309238 \u0026#34;_source\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;ES 進階\u0026#34;, \u0026#34;like\u0026#34;: 5 } }, { \u0026#34;_score\u0026#34;: 0.5753642, //原本是0.2876821 \u0026#34;_source\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;ES 入門\u0026#34;, \u0026#34;like\u0026#34;: 2 } } ] 加上 max_boost，限制 field_value_factor 的最大加強 score\n可以看到 ES 入門的加強 score 是2，在 max_boost 限制裡，所以不受影響\n而 ES 進階和 ES 最高難度的 field_value_factor 函數產生的加強 score 因為超過 max_boost 的限制，所以被設為 3\nGET mytest/doc/_search { \u0026#34;query\u0026#34;: { \u0026#34;function_score\u0026#34;: { \u0026#34;query\u0026#34;: { \u0026#34;match\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;ES\u0026#34; } }, \u0026#34;field_value_factor\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;like\u0026#34; }, \u0026#34;max_boost\u0026#34;: 3 } } } \u0026#34;hits\u0026#34;: [ { \u0026#34;_score\u0026#34;: 0.6092771, //原本是0.20309238 \u0026#34;_source\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;ES 進階\u0026#34;, \u0026#34;like\u0026#34;: 5 } }, { \u0026#34;_score\u0026#34;: 0.5753642, //原本是0.2876821 \u0026#34;_source\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;ES 入門\u0026#34;, \u0026#34;like\u0026#34;: 2 } }, { \u0026#34;_score\u0026#34;: 0.49621537, //原本是0.16540512 \u0026#34;_source\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;ES 最高難度\u0026#34;, \u0026#34;like\u0026#34;: 10 } } ] 有時候線性的計算 new_score = old_score * like值 的效果並不是那麼好，field_value_factor 中還支持 modifier、factor 參數，可以改變 like 值對 old_score 的影響\nmodifier 參數支持的值\nnone : new_score = old_score * like值 默認狀態就是 none，線性 log1p : new_score = old_score * log(1 + like值) 最常用，可以讓 like 值字段的評分曲線更平滑 log2p : new_score = old_score * log(2 + like值) ln : new_score = old_score * ln(like值) ln1p : new_score = old_score * ln(1 + like值) ln2p : new_score = old_score * ln(2 + like值) square : 計算平方 sqrt : 計算平方根 reciprocal : 計算倒數 factor 參數\nfactor 作為一個調節用的參數，沒有 modifier 那麼強大會改變整個曲線，他僅改變一些常量值，設置 factor \u0026gt; 1 會提昇效果，factor \u0026lt; 1 會降低效果 假設 modifier 是 log1p，那麼加入了 factor 的公式就是 new_score = old_score * log(1 + factor * like值) 對剛剛的例子加上 modifier、factor\nGET mytest/doc/_search { \u0026#34;query\u0026#34;: { \u0026#34;function_score\u0026#34;: { \u0026#34;query\u0026#34;: { \u0026#34;match\u0026#34;: { \u0026#3","date":"2018-07-05","objectID":"a484ab21c7f671c6c54ed0326066f0a3","title":"ElasticSearch - function_score（field_value_factor 具體實例）","url":"https://kucw.io/blog/2018/7/elasticsearch-function_score-field_value_factor/"},{"categories":["Elastic Search"],"content":" function_score 內容較多，此篇主要是介紹 function_score 的基本概念\n具體實例請參考以下連接\nElasticSearch - function_score（field_value_factor 具體實例）\nElasticSearch - function_score（weight 具體實例）\nElasticSearch - function_score（random_score 具體實例）\nElasticSearch - function_score（衰減函數 linear、exp、gauss 具體實例）\n在使用 ES 進行全文搜索時，搜索結果默認會以文檔的相關度進行排序，而這個 \u0026ldquo;文檔的相關度\u0026rdquo;，是可以透過 function_score 自己定義的，也就是說我們可以透過使用 function_score，來控制 \u0026ldquo;怎麼樣的文檔相關度更高\u0026rdquo; 這件事\nfunction_score 是專門用於處理文檔 _score 的 DSL，它允許爲每個主查詢 query 匹配的文檔應用加強函數， 以達到改變原始查詢評分 score 的目的 function_score 會在主查詢 query 結束後對每一個匹配的文檔進行一系列的重打分操作，能夠對多個字段一起進行綜合評估，且能夠使用 filter 將結果劃分爲多個子集（每個特性一個filter），並爲每個子集使用不同的加強函數 function_score 提供了幾種加強 _score 計算的函數\nweight : 設置一個簡單而不被規範化的權重提升值 weight 加強函數 和 boost 參數 類似，可以用於任何查詢，不過有一點差別是 weight 不會被 Lucene normalize 成難以理解的浮點數，而是直接被應用（boost 會被 normalize） 例如當 weight 爲 2 時，最終結果爲 new_score = old_score * 2 field_value_factor : 將某個字段的值乘上 old_score 像是將 字段 shareCount 或是 字段 likeCount 作爲考慮因素，new_score = old_score * 那個文檔的 likeCount 的值 random_score : 爲每個用戶都使用一個不同的隨機評分對結果排序，但對某一具體用戶來說，看到的順序始終是一致的 衰減函數 (linear、exp、guass) : 以某個字段的值為基準，距離某個值越近得分越高 script_score : 當需求超出以上範圍時，可以用自定義腳本完全控制評分計算，不過因為還要額外維護腳本不好維護，因此盡量使用 ES 提供的評分函數，需求真的無法滿足再使用 script_score function_scroe其他輔助的參數\nboost_mode : 決定 old_score 和 加強score 如何合併 multiply（默認） : new_score = old_score * 加強score sum : new_score = old_score + 加強score min : old_score 和 加強 score 取較小值，new_score = min(old_score, 加強score) max : old_score 和 加強 score 取較大值，new_score = max(old_score, 加強score) replace : 加強 score 直接替換掉 old_score，new_score = 加強score score_mode : 決定 functions 裡面的加強 score 們怎麼合併，會先合併加強 score 們成一個總加強 score，再使用總加強 score 去和 old_score 做合併，換言之就是會先執行 score_mode，再執行 boost_mode multiply（默認） sum avg first : 使用首個函數（可以有filter，也可以沒有）的結果作為最終結果 max min max_boost : 限制加強函數的最大效果，就是限制加強 score 最大能多少，但要注意不會限制 old_score 如果加強 score 超過了 max_boost 限制的值，會把加強 score 的值設成 max_boost 的值 假設加強 score 是5，而 max_boost 是2，因為加強 score 超出了 max_boost 的限制，所以 max_boost 就會把加強 score 改為2 簡單的說，就是 加強score = min(加強score, max_boost) function_score 查詢模板\n如果要使用 function_score 改變分數，要使用 function_score 查詢\n簡單的說，就是在一個 function_score 內部的 query 的全文搜索得到的 _score 基礎上，給他加上其他字段的評分標準，就能夠得到把 \u0026ldquo;全文搜索 + 其他字段\u0026rdquo; 綜合起來評分的效果\n單個加強函數的查詢模板\nGET mytest/doc/_search { \u0026#34;query\u0026#34;: { \u0026#34;function_score\u0026#34;: { //主查詢，查詢完後這裡自己會有一個評分，就是 old_score \u0026#34;query\u0026#34;: {.....}, //在 old_score 的基礎上，給他加強其他字段的評分 //這裡會產生一個加強 score，如果只有一個加強 function 時，直接將加強函數名寫在 query 下面就可以了 \u0026#34;field_value_factor\u0026#34;: {...}, //指定用哪種方式結合 old_score 和加強 score 成為 new_score \u0026#34;boost_mode\u0026#34;: \u0026#34;multiply\u0026#34;, //限制加強 score 的最高分，但是不會限制 old_score \u0026#34;max_boost\u0026#34;: 1.5 } } } 多個加強函數的查詢模板\n如果有多個加強函數，那就要使用functions來包含這些加強函數們，functions是一個數組，裡面放著的是將要被使用的加強函數列表\n可以為functions裡的加強函數指定一個filter，這樣做的話，只有在文檔滿足此filter的要求，此filter的加強函數才會應用到文擋上，也可以不指定filter，這樣的話此加強函數就會應用到全部的文擋上\n一個文檔可以一次滿足多條加強函數和多個filter，如果一次滿足多個，那麼就會產生多個加強score，因此ES會使用score_mode定義的方式來合併這些加強score們，得到一個總加強score，得到總加強score之後，才會再使用boost_mode定義的方式去和old_score做合併\n像是下面的例子，field_value_factor和gauss這兩個加強函數會應用到所有文檔上，而weight只會應用到滿足filter的文檔上，假設有個文檔滿足了filter的條件，那他就會得到3個加強score，這3個加強score會使用sum的方式合併成一個總加強score，然後才和old_score使用multiply的方式合併\nGET mytest/doc/_search { \u0026#34;query\u0026#34;: { \u0026#34;function_score\u0026#34;: { //主查詢，查詢完後這裡自己會有一個評分，就是 ol","date":"2018-07-04","objectID":"888dbbd2d9809b99f59dc306c461355b","title":"ElasticSearch - function_score 簡介","url":"https://kucw.io/blog/2018/7/elasticsearch-function_score/"},{"categories":["Elastic Search"],"content":" ES 為了避免深分頁，不允許使用分頁（from \u0026amp; size）查詢 10000 條以後的數據，因此如果要查詢第 10000 條以後的數據，要使用 ES 提供的 scroll 游標 來查詢\n原因是因為假設取的頁數較大時（深分頁），如請求第 20 頁，ES 不得不取出所有分片上的第 1 頁到第 20 頁的所有文檔，並做排序，最終再取出 from 後的 size 條結果作爲最終的返回值 假設你有 16 個分片，則需要在 coordinate node 彙總到 shards * (from + size) 條記錄，即需要 16 * (20 + 10) 記錄後做一次全局排序 所以，當索引非常非常大(千萬或億)，是無法使用 from + size 做深分頁的，分頁越深則越容易 Out Of Memory，即使你運氣很好沒有發生 Out Of Memory，也會非常消耗 CPU 和內存資源 因此 ES 使用 index.max_result_window:10000 作爲保護措施 ，即默認 from + size 不能超過 10000，雖然這個參數可以動態修改，也可以在配置文件配置，但是最好不要這麼做，應該改用 ES 提供的 scroll 方法來取得數據 scroll 游標原理\n可以把 scroll 理解爲關係型數據庫裏的 cursor，因此，scroll 並不適合用來做實時搜索，而更適用於後台批處理任務，比如群發 scroll 具體分爲初始化和遍歷兩步 初始化時將所有符合搜索條件的搜索結果緩存起來，可以想象成快照 在遍歷時，從這個快照裏取數據 也就是說，在初始化後對索引插入、刪除、更新數據都不會影響遍歷結果 游標可以增加性能的原因，是因為如果做深分頁，每次搜索都必須重新排序，非常浪費，使用 scroll 就是一次把要用的數據都排完了，分批取出，因此比使用 from + size 還好 具體實例\n初始化\n請求\n注意要在URL中的search後加上 scroll=1m，不能寫在 request body 中，其中 1m 表示這個游標要保持開啟 1 分鐘\n可以指定 size 大小，就是每次回傳幾筆數據，當回傳到沒有數據時，仍會返回 200 成功，只是 hits 裡的 hits 會是空 list\n在初始化時除了回傳 _scroll_id，也會回傳前 100 筆（假設 size = 100）的數據\nrequest body 和一般搜索一樣，因此可以說在初始化的過程中，除了加上 scroll 設置游標開啟時間之外，其他的都跟一般的搜尋沒有兩樣（要設置查詢條件，也會回傳前 size 筆的數據）\nGET my_index/_search?scroll=1m { \u0026#34;query\u0026#34;:{ \u0026#34;range\u0026#34;:{ \u0026#34;createTime\u0026#34;: { \u0026#34;gte\u0026#34;: 1522229999999 } } }, \u0026#34;size\u0026#34;: 1000 } 返回結果\n{ \u0026#34;_scroll_id\u0026#34;: \u0026#34;DnF1ZXJ5VGhlbkZldGNoBQAAAAAAfv5-FjNOamF0Mk1aUUhpUnU5ZWNMaHJocWcAAAAAAH7-gBYzTmphdDJNWlFIaVJ1OWVjTGhyaHFnAAAAAAB-_n8WM05qYXQyTVpRSGlSdTllY0xocmhxZwAAAAAAdsJxFmVkZTBJalJWUmp5UmI3V0FYc2lQbVEAAAAAAHbCcBZlZGUwSWpSVlJqeVJiN1dBWHNpUG1R\u0026#34;, \u0026#34;took\u0026#34;: 2, \u0026#34;timed_out\u0026#34;: false, \u0026#34;_shards\u0026#34;: { \u0026#34;total\u0026#34;: 5, \u0026#34;successful\u0026#34;: 5, \u0026#34;skipped\u0026#34;: 0, \u0026#34;failed\u0026#34;: 0 }, \u0026#34;hits\u0026#34;: { \u0026#34;total\u0026#34;: 84, \u0026#34;max_score\u0026#34;: 1, \u0026#34;hits\u0026#34;: [ { \u0026#34;_index\u0026#34;: \u0026#34;video1522821719\u0026#34;, \u0026#34;_type\u0026#34;: \u0026#34;doc\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;84056\u0026#34;, \u0026#34;_score\u0026#34;: 1, \u0026#34;_source\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;三个院子\u0026#34;, \u0026#34;createTime\u0026#34;: 1522239744000 } } ....99 data ] } } 遍歷數據\n請求\n使用初始化返回的 _scroll_id 來進行請求，每一次請求都會繼續返回初始化中未讀完數據，並且會返回一個 _scroll_id，這個 _scroll_id 可能會改變，因此每一次請求應該帶上上一次請求返回的 _scroll_id\n要注意返回的是 _scroll_id，但是放在請求裡的是 scroll_id，兩者拼寫上有不同\n且每次發送 scroll 請求時，都要再重新刷新這個 scroll 的開啟時間，以防不小心超時導致數據取得不完整\nGET _search/scroll?scroll=1m { \u0026#34;scroll_id\u0026#34;: \u0026#34;DnF1ZXJ5VGhlbkZldGNoBQAAAAAAdsMqFmVkZTBJalJWUmp5UmI3V0FYc2lQbVEAAAAAAHbDKRZlZGUwSWpSVlJqeVJiN1dBWHNpUG1RAAAAAABpX2sWclBEekhiRVpSRktHWXFudnVaQ3dIQQAAAAAAaV9qFnJQRHpIYkVaUkZLR1lxbnZ1WkN3SEEAAAAAAGlfaRZyUER6SGJFWlJGS0dZcW52dVpDd0hB\u0026#34; } 返回結果\n如果沒有數據了，就會回傳空的 hits，可以用這個判斷是否遍歷完成了數據\n{ \u0026#34;_scroll_id\u0026#34;: \u0026#34;DnF1ZXJ5VGhlbkZldGNoBQAAAAAAdsMqFmVkZTBJalJWUmp5UmI3V0FYc2lQbVEAAAAAAHbDKRZlZGUwSWpSVlJqeVJiN1dBWHNpUG1RAAAAAABpX2sWclBEekhiRVpSRktHWXFudnVaQ3dIQQAAAAAAaV9qFnJQRHpIYkVaUkZLR1lxbnZ1WkN3SEEAAAAAAGlfaRZyUER6SGJFWlJGS0dZcW52dVpDd0hB\u0026#34;, \u0026#34;took\u0026#34;: 2, \u0026#34;timed_out\u0026#34;: false, \u0026#34;_shards\u0026#34;: { \u0026#34;total\u0026#34;: 5, \u0026#34;successful\u0026#34;: 5, \u0026#34;skipped\u0026#34;: 0, \u0026#34;failed\u0026#34;: 0 }, \u0026#34;hits\u0026#34;: { \u0026#34;total\u0026#34;: 84, \u0026#34;max_score\u0026#34;: null, \u0026#34;hits\u0026#34;: [] } } 優化scroll查詢\n在一般場景下，scroll 通常用來取得需要排序過後的大筆數據，但是有時候數據之間的排序性對我們而言是沒有關係的，只要所有數據都能取出來就好，這時能夠對 scroll 進行優化\n初始化\n使用 _doc","date":"2018-06-26","objectID":"52ac56105de41a22c86f3aa0e662d094","title":"ElasticSearch - 解決 ES 的深分頁問題（游標 scroll）","url":"https://kucw.io/blog/2018/6/elasticsearch-scroll/"},{"categories":["Elastic Search"],"content":" 由於在 ES 中，所有單個文檔的增刪改都是原子性的操作，因此將相關的實體數據都儲存在同一個文檔是很好的，且由於所有信息都在一個文檔中，因此當我們查詢時就沒有必要像 mysql 一樣去關聯很多張表，只要搜一遍文檔就可以查出所有需要的數據，查詢效率非常高\n因此除了基本數據類型之外，ES 也支持使用複雜的數據類型，像是數組、內部對象，而要使用內部對象的話，需要使用 nested 來定義索引，使文檔內可以包含一個內部對象\n為什麼不用 object 而要使用 nested 來定義索引的原因是，object 類型會使得內部對象的關聯性丟失\n這是因為 Lucene 底層其實沒有內部對象的概念，所以 ES 會利用簡單的列表儲存字段名和值，將 object 類型的對象層次攤平，再傳給 Lucene\n假設 user 類型是 object，當插入一筆新的數據時，ES 會將他轉換為下面的內部文檔，其中可以看見 alice 和 white 的關聯性丟失了\nPUT mytest/doc/1 { \u0026#34;group\u0026#34;: \u0026#34;fans\u0026#34;, \u0026#34;user\u0026#34;: [ { \u0026#34;first\u0026#34;: \u0026#34;John\u0026#34;, \u0026#34;last\u0026#34;: \u0026#34;Smith\u0026#34; }, { \u0026#34;first\u0026#34;: \u0026#34;Alice\u0026#34;, \u0026#34;last\u0026#34;: \u0026#34;White\u0026#34; } ] } 轉換後的內部文檔 { \u0026#34;group\u0026#34;: \u0026#34;fans\u0026#34;, \u0026#34;user.first\u0026#34;: [ \u0026#34;alice\u0026#34;, \u0026#34;john\u0026#34; ], \u0026#34;user.last\u0026#34;: [ \u0026#34;smith\u0026#34;, \u0026#34;white\u0026#34; ] } 理論上從插入的數據來看，應該搜索 \u0026ldquo;first 為 Alice 且 last 為 White\u0026rdquo; 時，這個文檔才算符合條件被搜出來，其他的條件都不算符合，但是因為 ES 把 object 類型的對象攤平了，所以實際上如果搜索 \u0026ldquo;first 為 Alice 且 last 為 Smith\u0026rdquo;，這個文檔也會當作符合的文檔被搜出來，但這樣就違反我們的意願了，我們希望內部對象自己的關聯性還是存在的\n因此在使用內部對象時，要改使用 nested 類型來取代 object 類型 (因為 nested 類型不會被攤平，下面說明)\nnested 類型就是為了解決 object 類型在對象數組上丟失關聯性的問題的，如果將字段設置為 nested 類型，那個每一個嵌套對象都會被索引為一個 \u0026ldquo;隱藏的獨立文檔\u0026rdquo;\n其本質上就是將數組中的每個對象作為分離出來的隱藏文檔進行索引，因此這也意味著每個嵌套對象可以獨立於其他對象被查詢\n假設將上面的例子的 user 改為 nested 類型，經過 ES 轉換後的文檔如下\n//嵌套文檔1 { \u0026#34;user.first\u0026#34;: [ \u0026#34;alice\u0026#34; ], \u0026#34;user.last\u0026#34;: [ \u0026#34;white\u0026#34; ] } //嵌套文檔2 { \u0026#34;user.first\u0026#34;: [ \u0026#34;john\u0026#34; ], \u0026#34;user.last\u0026#34;: [ \u0026#34;smith\u0026#34; ] } //根文檔，或者也可以稱為父文檔 { \u0026#34;group\u0026#34;: \u0026#34;fans\u0026#34; } 在獨立索引每一個嵌套對象後，對象中每個字段的相關性得以保留，因此我們查詢時，也僅返回那些真正符合條件的文檔\n不僅如此，由於嵌套文檔直接儲存在文檔內部，因此查詢時嵌套文檔和根文檔的聯合成本很低，速度和單獨儲存幾乎一樣\n但是要注意，查詢的時候返回的是整個文檔，而不是嵌套文檔本身，並且如果要增刪改一個嵌套對象，必須把整個文檔重新索引才可以\n具體實例\n索引準備\n定義一個 nested 類型的 mapping，user 是一個內部對象，裡面包含了 first、last 和 age，因為 user 設置了 nested 類型，因此 user 對象會被索引在獨立的嵌套文檔中\nPUT mytest { \u0026#34;mappings\u0026#34;: { \u0026#34;doc\u0026#34;: { \u0026#34;properties\u0026#34;: { //group是正常的keyword字段 \u0026#34;group\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34; }, //user是一個nested類型，表示他底下還會包含子對象 \u0026#34;user\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;nested\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;first\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34; }, \u0026#34;last\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34; }, \u0026#34;age\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;integer\u0026#34; } } } } } } } 插入兩筆數據\nPOST mytest/doc { \u0026#34;group\u0026#34;: \u0026#34;fans\u0026#34;, \u0026#34;user\u0026#34;: { \u0026#34;first\u0026#34;: \u0026#34;Taylor\u0026#34;, \u0026#34;last\u0026#34;: \u0026#34;Swift\u0026#34;, \u0026#34;age\u0026#34;: 30 } } POST mytest/doc { \u0026#34;group\u0026#34;: \u0026#34;fans\u0026#34;, \u0026#34;user\u0026#34;: [ { \u0026#34;first\u0026#34;: \u0026#34;Amy\u0026#34;, \u0026#34;last\u0026#34;: \u0026#34;White\u0026#34;, \u0026#34;age\u0026#34;: 18 }, { \u0026#34;first\u0026#34;: \u0026#34;John\u0026#34;, \u0026#34;last\u0026#34;: \u0026#34;Smith\u0026#34;, \u0026#34;age\u0026#34;: 22 } ] } 因此在ES中存在的文檔如下\n\u0026#34;hits\u0026#34;: [ { \u0026#34;_source\u0026#34;: { \u0026#34;group\u0026#34;: \u0026#34;fans\u0026#34;, \u0026#34;user\u0026#34;: { \u0026#34;first\u0026#34;: \u0026#34;Taylor\u0026#34;, \u0026#34;last\u0026#34;: \u0026#34;Swift\u0026#34;, \u0026#34;age\u0026#34;: 30 } } }, { \u0026#34;_source\u0026#34;: { \u0026#34;group\u0026#34;: \u0026#34;fans\u0026#34;, \u0026#34;user\u0026#34;: [ { \u0026#34;first\u0026#34;: \u0026#34;Amy\u0026#34;, \u0026#34;last\u0026#34;: \u0026#34;White\u0026#34;, \u0026#34;age\u0026#34;: 18 }, { \u0026#34;first\u0026#34;: \u0026#34;John\u0026#34;, \u0026#34;last\u0026#34;: \u0026#34;Smith\u0026#34;, \u0026#34;age\u0026#34;: 22 } ] } } ] 嵌套對象查詢 nested\n由於嵌套對象被索引在獨立的隱藏文檔中，因此我們無法直接使用一般的 query 去查詢他，我們必須改使用 \u0026ldquo;nested查詢\u0026r","date":"2018-06-22","objectID":"564da7aa802946689d07487ae1b60f02","title":"ElasticSearch - 嵌套對象 nested","url":"https://kucw.io/blog/2018/6/elasticsearch-nested/"},{"categories":["Elastic Search"],"content":" ES 中的 term 和 match 牽扯到了分詞器、mapping、倒排索引等，如果不熟悉相關知識，請先看 ElasticSearch - index mapping（5.x以上） 這篇文章 term 是直接把 field 拿去查詢倒排索引中確切的 term match 會先對 field 進行分詞操作，然後再去倒排索引中查詢 具體實例 假設有一個字段 nickname，存放的類型是 text，因此當新增一筆文檔時，內容會被分詞器分詞，然後才儲存進倒排索引 假設插入了一筆文檔，其中 \u0026quot;nickname\u0026quot;: \u0026quot;1 hello\u0026quot;，分詞過後變為 1、hello，因此倒排索引中儲存的是兩筆索引 1 和 hello，而不是一筆索引 1 hello 使用 match 做查詢 \u0026quot;match\u0026quot;: \u0026quot;1-hello\u0026quot; : 成功，因為 match 把 1-hello 分詞成 1、hello，而 1 和 hello 都存在在倒排索引中，所以不只能夠查到，_score 還很高 \u0026quot;match\u0026quot;: \u0026quot;1\u0026quot; : 成功，1 被分詞過後還是 1，而 1 存在在倒排索引中 \u0026quot;match\u0026quot;: \u0026quot;hello how r u\u0026quot; : 成功，match 把 hello how r u 分詞成 hello、how、r、u，而 hello 存在在倒排索引中 使用 term 做查詢 \u0026quot;term\u0026quot;: \u0026quot;2222-hello : 失敗，倒排索引只有 1、hello，並沒有 2222-hello \u0026quot;term\u0026quot;: \u0026quot;hello\u0026quot; : 成功，因為倒排索引中有 hello \u0026quot;term\u0026quot;: \u0026quot;1 hello\u0026quot; : 失敗，雖然 1 hello 和我們當時插入的數據一模一樣，但是因為倒排索引在建立索引時把原始的數據分詞了才儲存進索引，裡面存的是 1 和 hello，並沒有存放 1 hello，因此查詢失敗 ","date":"2018-06-20","objectID":"a8dc66b6c959cdc18053669f36564c1d","title":"ElasticSearch - term 和 match 的差別","url":"https://kucw.io/blog/2018/6/elasticsearch-term-match/"},{"categories":["Java"],"content":" Java 基本內置 annotation\n@Override\n@Override用在方法上，表示這個方法重寫了父方法，如toString() 如果父方法沒有這個方法，那麼就無法編譯過 如果實現接口，需要在每個實現方法都加上@Override，說明這是要實現那個接口的方法，而不是自己新創的方法 @Deprecated\n@Deprecated 表示這個方法已經過期，不建議開發者使用 暗示在將來某個不確定的版本，就有可能會被取消掉 @SuppressWarnings\n@SuppressWarnings是抑制警告的意思，這個注解主要的用處就是忽略警告信息\n常見的警告值\ndeprecation : 使用了不贊成使用的類或方法時的警告 unused : 某個變量被定義，但是沒有被使用 path : 在類路徑、源文件路徑等中有不存在的路徑時的警告 具體實例\npublic class Test { //定義了一個不建議使用了方法 @Deprecated public void sayHello() { System.out.println(\u0026#34;Hello\u0026#34;); } //聲明以下的方法，自動忽略deprecation和unused的警告，不要在console上報出warn //以下的方法使用了被Deprecated的方法sayHello //也沒有使用到一個被定義的變量 i //但是因為設置了警告忽略所以不會有warning @SuppressWarnings({\u0026#34;deprecation\u0026#34;, \u0026#34;unused\u0026#34;}) public static void main(String[] args) { int i; Test test = new Test(); test.sayHello(); } } @FunctionallInterface\nJava 1.8新增的注解，用於約定函數式接口\n函數式接口存在的意義，主要是配合Lambda表達式來使用\n如果接口中只允許有一個public的抽象方法，該接口就稱為函數式接口 (不過此接口可以包含多個default方法或是多個static方法) 能夠包含多個default和static方法的原因是因為在使用函數式編程時，為了能夠使用lambda表達式，所以每個接口的實現類只允許實現一個方法 而default方法和static方法不允許實現類實現，所以就不會影響lambda表達式，因此就可以存在在函數式接口裡 //匿名實現類 new Function\u0026lt;Integer, String\u0026gt; 實現了Function接口 List\u0026lt;Integer\u0026gt; intList = Lists.newArrayList(1, 2, 3); List\u0026lt;String\u0026gt; stringList = Lists.transform(intList, new com.google.common.base.Function\u0026lt;Integer, String\u0026gt;() { @Override public String apply(Integer input) { return input + \u0026#34;aa\u0026#34;; } }); //可以轉換成下面的lambda表達式 List\u0026lt;Integer\u0026gt; intList = Lists.newArrayList(1, 2, 3); List\u0026lt;String\u0026gt; stringList = Lists.transform(intList, input -\u0026gt; input + \u0026#34;aa\u0026#34;); 使用 @FunctionallInterface 自定義函數式接口\n//自定義一個函數式接口，並且只有一個public的抽象方法 @FunctionalInterface public interface MyFunction { public String myApply(); } //定義一個類，讓這個類去使用 MyFunction public class Hello { void say(MyFunction myFunction) { System.out.println(myFunction.myApply()); } } public class MainTest { public static void main(String[] args) { Hello hello = new Hello(); //輸出 Hello World hello.say(new MyFunction() { @Override public String myApply() { return \u0026#34;Hello World\u0026#34;; } }); //可以轉換為以下的lambda表達式，同樣輸出 Hello World hello.say(() -\u0026gt; \u0026#34;Hello World\u0026#34;); } } 自定義新的 annotation\n使用元注解(meta annotation)來設定一個注解的作用，可以說他是 \u0026ldquo;自定義注解\u0026rdquo; 的注解\n元注解的種類\n@Target : 表示這個注解可以放在什麼位置上，也就是可以修飾 ElementType.TYPE : 能修飾類、接口、枚舉、注解 ElementType.FIELD : 能修飾字段、枚舉的常量 ElementType.METHOD : 能修飾方法 ElementType.PARAMETER : 能修飾方法參數 ElementType.CONSTRUCTOR : 能修飾構造函數 ElementType.LOCAL_VARIABLE : 能修飾局部變量 ElementType.ANNOTATION_TYPE : 能修飾注解 (元注解就是此種) ElementType.PACKAGE : 能修飾包 @Retention : 表示這個注解的生命週期 可選的值有三種 RetentionPolicy.SOURCE 表示此注解只在源代碼中有效果，不會編譯進class文件 @Override就是這種注解 RetentionPolicy.CLASS 表示此注解除了在源代碼有效果，也會編譯進class文件，但是在運行期是無效果的 @Retention的默認值，即是當沒有指定@Retention的時候，就會是這種類型 RetentionPolicy.RUNTIME 表示此注解從源代碼到運行期一直存在 程序可以透過反射獲取這個注解的信息 @Inherited : 表示該注解有繼承性，即是子類可以拿到繼承父類上的注解信息 @Documetned : 在用javadoc命令生成API文檔後，文檔裡會出現該注解說明 @Repeatable (java1.8新增) 當沒有使用@Repeatable修飾的時候，注解在同一個位置只能出現一次，如果寫重複的兩次就會報錯 但是使用@Repeatable之後，就能夠在同一個地方使用多次 使用@Repeatable的時機通常在想要取得一組資訊時 像是一個User裡面可能有id、name屬性，我們想要以User為單位來取 但是因為注解裡面無法使用自定義對象 所以只能透過@Repeatable這種方法來達成目標 注解參數的數據類型\n支持的類型 所有基本數據類型 (int, float, boolean, byte, double, char, long, short) String類型 Class類型 enum類型 Annotation類型 以上所有類型的數組 不支","date":"2018-06-11","objectID":"324743321e2b73965ca72d956eeb80d0","title":"Java - annotation 的使用","url":"https://kucw.io/blog/2018/6/java-annotation/"},{"categories":["Elastic Search"],"content":" ElasticSearch 的 analysis 實際上是將三個功能封裝在一起，這三個功能按照順序執行，而這三個功能都是能自定義的 字符過濾器 (char_filter) 首先，字符串按順序通過每個字符過濾器，他們的任務是在分詞前整理字符串 一個字符過濾器可以用來去掉HTML，或者將\u0026amp;轉化成and 分詞器 (tokenizer) 其次，字符串被分詞器分爲單個的詞條，一個簡單的分詞器遇到空格和標點的時候，可能會將文本拆分成詞條 Hello how are you?會被ES預設的分詞器standard分成hello、how、are、you Token 過濾器 (filter) 最後，詞條按順序通過每個 token 過濾器，這個過程可能會改變詞條(Quick -\u0026gt; quick)、刪除詞條(a、an、and、the\u0026hellip;)、增加詞條(jump和leap這種同義詞) 自定義 analysis 格式 PUT mytest { \u0026#34;setting\u0026#34;: { \u0026#34;analysis\u0026#34;: { \u0026#34;char_filter\u0026#34;: { 自定義的字符過濾器 }, \u0026#34;tokenizer\u0026#34;: { 自定義的分詞器 }, \u0026#34;filter\u0026#34;: { 自定義的token過濾器 }, \u0026#34;analyzer\u0026#34;: { 自定義的分析器，可以將上面的char_filter、tokenizer、filter用不同的組合拼起來，形成不同的分析器 } } } } 具體實例 PUT mytest { \u0026#34;settings\u0026#34;: { \u0026#34;analysis\u0026#34;: { \u0026#34;char_filter\u0026#34;: { \u0026#34;\u0026amp;_to_and\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;mapping\u0026#34;, \u0026#34;mappings\u0026#34;: [\u0026#34;\u0026amp;=\u0026gt; and \u0026#34;] }, \u0026#34;xxx\u0026#34;: {....}, \u0026#34;yyy\u0026#34;: {....} }, \u0026#34;filter\u0026#34;: { \u0026#34;my_stopwords\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;stop\u0026#34;, \u0026#34;stopwords\u0026#34;: [\u0026#34;the\u0026#34;, \u0026#34;a\u0026#34;] } }, \u0026#34;analyzer\u0026#34;: { //自定義分析器，將想要的char_filter、tokenizer、filter給加載進來 //數組順序很重要，因為是照順序執行，先執行htmp_strip，再執行\u0026amp;_to_and，然後才去執行tokenizer \u0026#34;my_analyzer\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;custom\u0026#34;, \u0026#34;char_filter\u0026#34;: [\u0026#34;htmp_strip\u0026#34;, \u0026#34;\u0026amp;_to_and\u0026#34;], \u0026#34;tokenizer\u0026#34;: \u0026#34;standard\u0026#34;, \u0026#34;filter\u0026#34;: [\u0026#34;lowercase\u0026#34;, \u0026#34;my_stopwords\u0026#34;] } } } }, \u0026#34;mappings\u0026#34;: { \u0026#34;doc\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;nickname\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;analyzer\u0026#34;: \u0026#34;my_analyzer\u0026#34; //使用自定義的分析器 } } } } } 控制分析器 search_analyzer、analyzer 分析器主要有兩種情況會被使用，一種是插入文檔時，將text類型的字段做分詞然後插入倒排索引，第二種就是在查詢時，先對要查詢的text類型的輸入做分詞，再去倒排索引搜索\n如果想要讓 索引 和 查詢 時使用不同的分詞器，ElasticSearch也是能支持的，只需要在字段上加上search_analyzer參數\n在索引時，只會去看字段有沒有定義analyzer，有定義的話就用定義的，沒定義就用ES預設的 在查詢時，會先去看字段有沒有定義search_analyzer，如果沒有定義，就去看有沒有analyzer，再沒有定義，才會去使用ES預設的 具體實例\nPUT mytest { \u0026#34;mappings\u0026#34;: { \u0026#34;doc\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;nickname\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;analyzer\u0026#34;: \u0026#34;standard\u0026#34;, //索引時使用standard分詞器 \u0026#34;search_analyzer\u0026#34;: \u0026#34;simple\u0026#34; //查詢時使用simple分詞器 }, \u0026#34;name\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;analyzer\u0026#34;: \u0026#34;standard\u0026#34; //索引和查詢都使用standard分詞器 } } } } } ","date":"2018-06-09","objectID":"ba5fcbfaafba32a55f95f60c0714df03","title":"ElasticSearch - 自定義 analysis","url":"https://kucw.io/blog/2018/6/elasticsearch-analysis/"},{"categories":["Elastic Search"],"content":" Elasticsearch支持的基本類型\n字符串 : text, keyword text : 存儲數據的時候，會自動分詞，並生成索引 keyword : 存儲數據的時候，不會分詞，而是直接整個詞拿去建索引 整數 : byte, short, integer, long 浮點數 : float, double 布爾型 : boolean 日期 : date 自定義 mapping\nindex : 設置此字段能不能被查詢，就是決定要不要將這個字段放進倒排索引裡\n若 index 設置為 true（默認是 true），則表示這個這個字段會被放進倒排索引裡，如果是 text 就是分詞過後放進索引，如果是 keyword、integer\u0026hellip;就直接整段放進索引裡 若 index 設置為 false，則表示這個字段不放進倒排索引裡，因此不能查詢這個字段（因為他不存在於倒排索引裡） 通常這種被設成 false 的字段，可以想像成是屬於一種附屬的字段，就是不能被 match、term 查詢，但是當該文檔被其他搜索條件搜出來時，他可以附帶的一起被找出來，因為他們同屬於同一個文檔 analyzer : 主要用在 text 類型的字段上，就是設定要使用哪種分詞器來建立索引\n可以使用內建的分詞器，或是使用自定義的分詞器 可以使用 /_analyze 測試分析器具體會將句子分詞成什麼樣子，它能幫助我們理解 Elasticsearch 索引內部發生了什麼\nGET _analyze { \u0026#34;analyzer\u0026#34;: \u0026#34;standard\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;Text to analyze\u0026#34; } 具體實例\nmapping\nPUT mytest { \u0026#34;mappings\u0026#34;: { \u0026#34;doc\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;name\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34;, \u0026#34;index\u0026#34;: false }, \u0026#34;uid\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;integer\u0026#34; }, \u0026#34;nickname\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;analyzer\u0026#34;: \u0026#34;standard\u0026#34; } } } } } 搜索 uid 時，name 會一起被找出來\nGET mytest/_search { \u0026#34;query\u0026#34;: { \u0026#34;term\u0026#34;: { \u0026#34;uid\u0026#34;: 1 } } } { \u0026#34;uid\u0026#34;: 1, \u0026#34;name\u0026#34;: \u0026#34;1-hello\u0026#34;, \u0026#34;nickname\u0026#34;: \u0026#34;1-nickname\u0026#34; } 搜索 name，會報 error\nGET mytest/_search { \u0026#34;query\u0026#34;: { \u0026#34;term\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;1-hello\u0026#34; } } } \u0026#34;error\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;illegal_argument_exception\u0026#34;, \u0026#34;reason\u0026#34;: \u0026#34;Cannot search on field [name] since it is not indexed.\u0026#34; } 更新 mapping\n當首次創建一個 index 的時候，可以指定類型的 mapping，但假設後來想要增加一個新的映射字段，可以使用 /_mapping 把新的字段加進 mapping 映射裡\n可以增加一個新的映射，但是不能修改存在的映射，原因是因為這個映射可能有文檔去用，如果改了映射的類型，可能會導致 index 的數據出錯，因此只能新加字段進去，不能修改 具體實例\n在 mytest 映射中的 doc 類型增加一個新的名爲 tag 的 keyword\nPUT mytest/_mapping/doc { \u0026#34;properties\u0026#34;: { \u0026#34;tag\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34; } } } 在 ES 中更新 mapping（新增一個字段）會產生的問題\n雖然 ES 支持更新映射在 mapping 中新增字段，但是這樣會造成一個問題，就是舊的文檔並不會自動更新產生新的字段\n假設舊文檔有 name、nickname 這兩個字段，並且已經插入了兩筆數據\n{ \u0026#34;name\u0026#34;: \u0026#34;Jackson\u0026#34;, \u0026#34;nickname\u0026#34;: \u0026#34;jack\u0026#34; } { \u0026#34;name\u0026#34;: \u0026#34;Amy\u0026#34;, \u0026#34;nickname\u0026#34;: \u0026#34;a\u0026#34; } 此時插入一個新的字段 sex，並且插入一筆新的數據\n{ \u0026#34;name\u0026#34;: \u0026#34;NewYork\u0026#34;, \u0026#34;nickname\u0026#34;: \u0026#34;new\u0026#34;, \u0026#34;sex\u0026#34;: 1 } 執行 \u0026quot;match_all\u0026quot;: {} 查詢時，結果如下\n由於 Jackson 和 Amy 並沒有 sex 這個字段，所以雖然執行 match_all 搜索時能被搜出來，但是搜索 \u0026quot;term\u0026quot;: { \u0026quot;sex\u0026quot;: 1 } 的話，就搜索不出來\n{ \u0026#34;name\u0026#34;: \u0026#34;Jackson\u0026#34;, \u0026#34;nickname\u0026#34;: \u0026#34;jack\u0026#34; } { \u0026#34;name\u0026#34;: \u0026#34;Amy\u0026#34;, \u0026#34;nickname\u0026#34;: \u0026#34;a\u0026#34; } { \u0026#34;name\u0026#34;: \u0026#34;NewYork\u0026#34;, \u0026#34;nickname\u0026#34;: \u0026#34;new\u0026#34;, \u0026#34;sex\u0026#34;: 1 } 我們希望的狀況是，增加一個新字段，舊文檔應該也要設置一個預設值，像是 sex=0，而不是整個字段消失，如此在查詢時邏輯才不會有問題\n解決舊文檔沒有新字段這個問題主要有3種方法\n新建一個 index，使用 scroll + bulk insert 將數據從舊的索引批量插入到新索引中\n可以在 java 裡自定義舊文檔預設值的邏輯 新建一個 index，使用 ES 提供的 reindex API 將數據從舊的索引 reindex 到新索引\n需要使用 ES 的腳本 script，在 reindex 的請求裡定義舊文檔預設值的邏輯\nPOST _reindex { \u0026#34;source\u0026#34;: { \u0026#34;index\u0026#34;: \u0026#34;mytest\u0026#34; }, \u0026#34;dest\u0026#34;: { \u0026#34;index\u0026#34;: \u0026#34;mytest2\u0026#34; }, \u0026#34;script\u0026#34;: { \u0026#34;source\u0026#34;: \u0026#34;if (ctx._source.new == null) {ctx._source.new = params.new}\u0026#34;, \u0026#34;params\u0026#34;: { \u0026#34;new\u0026#34;: \u0026#34;good\u0026#34; }, \u0026#34;lang\u0026","date":"2018-06-07","objectID":"742397e1b9a33b03c8681a1369dd22bd","title":"ElasticSearch - index mapping（5.x以上）","url":"https://kucw.io/blog/2018/6/elasticsearch-index-mapping/"},{"categories":["自媒體經營"],"contents":"哈囉，我是古古，這封信是每月一次的自媒體月報，主要分享我經營《古古的後端筆記》個人品牌的幕後秘辛。\n正如標題所提到的，這週開始準備要暫時休刊了🥹，詳情我會在下面說明，上面一樣是先記錄成長人數 \u0026amp; 這兩個月發過的文章。\n2025.5～6 月粉絲追蹤數、電子報訂閱人數 # 這兩個月的粉絲成長人數如下：\n這兩個月撰寫的電子報主題、文章 # 這邊記錄了我這兩個月撰寫了哪些電子報和文章，大家如果對於其中的內容有興趣的話，也可以前往查看：\nDocker 常用指令介紹 + 第一個 Docker 程式 為 Spring Boot 生成 Docker image（Multi-stage build） 終身免費的 VM 服務！Google Cloud 免費方案分享 近況更新 # 正如標題所提到的，我最近下了一個艱難的決定，就是要暫時休刊《古古的後端筆記》電子報了🥹，目前預計會暫時休刊一年（嗚嗚QQ），後續如果有機會復刊的話，也會再發信通知大家我回來了～。\n那麼，也來聊一下為什麼想要暫時休刊吧！\n之所以會做這個決定，主要原因還是因為我最近又換了新工作，而因為新工作有部分會涵蓋到 Frontend 的開發，因此同時要「上手新工作的內容」+「產出後端學習筆記」這兩件事，感覺有點負荷不過來了😭。\n所以最終左思右想，想說既然當初決定回來工作了，那就還是把工作擺第一優先吧！先把自己的本職做好，有多餘的時間再投入到自媒體上和大家分享內容。這也是為什麼休刊時間暫時會定一年的關係，希望在上手工作內容之後，還能夠有機會回來和大家一起每週學習後端新知。\n不過我真的要吐嘈一下，我覺得自媒體和工作這兩件事真的是死循環欸\u0026hellip;.，要工作後才能有更多自媒體內容可以分享，但是開始工作後又會壓縮到自媒體寫稿的時間，能夠長期兼顧這兩項的真的是神人，請接受我的 respect 🙏。\n總之，很感謝大家這段時間的陪伴🥹🥹🥹，如果之後有機會復刊的話（或是不定期發刊），也都會直接發送到大家的信箱的～另外私訊的部分還是可以歡迎隨時私訊我！Threads 上和 Facebook 上我也偶爾會出沒的，如果有捕捉到我歡迎隨時跟我閒聊XD。\n另外這次電子報的暫停不是自媒體的終點！！我把它當成一個蓄積更多能量的機會，等到在工作中有更多的體悟、有更多實戰的經驗，說不定到時候寫出來的文章也可以更有深度。\n我還是很期待新工作的挑戰的💪，一起變強！\n","permalink":"https://kucw.io/blog/as-a-content-creator/monthly-report-202505-06/","tags":null,"title":"軟體工程師的自媒體之路 - 2025.5～6 月報（暫時休刊）"},{"categories":["其他技術分享"],"contents":"在技術分享的過程中，我發現很多人想要入門練習 VM、或是想要找一個免費的雲端主機來部署程式，但是卻不知道要去哪裡找這種資源。\n而剛好我已經用 Google Cloud 的免費服務很久了，使用體感還滿不錯的！！所以這篇文章就來跟大家分享一下，要如何免費使用 Google Cloud 所提供的 VM 服務，免費部署你所寫的程式。\n目錄 什麼是 Google Cloud 的終身免費方案？ 如何創建免費的 Compute Engine？ 如何登入進 Compute Engine 的 VM 裡？ 如何將程式上傳到此 VM 中？ Google Cloud 的終身免費方案總結 結語 什麼是 Google Cloud 的終身免費方案？ # 其實各大雲端服務廠商如 GCP（Google Cloud Platform）、AWS（Amazon Web Service）、阿里雲\u0026hellip;等等，通常都會提供 12 個月的免費方案，目的是讓你在這一年期間試玩雲端上的服務，進一步轉化成他們的付費用戶。\n不過我們今天要用的不是這個！而是真・永久免費方案，即是 Google Cloud 提供的 Free Tier 方案，其中就有一項是針對 Compute Engine 的規範，提供我們每個月可以使用：\n一個 e2-micro 的 VM（地點必須選擇 us-west1、us-central1、us-east1） 30 GB 的標準硬碟 HDD 對外網路量 1GB 所以簡單來說，只要我們在創建 VM 時，選擇最小的 e2-micro 來創建，並且乖乖的將 VM 創建在美國內部、而且不使用高速的 SSD 硬碟，這樣就可以永久免費享用那台 VM 的服務。\n以我個人的使用經驗來說，我曾經用這台 VM 開發過 LINE Bot、Discord Bot 的程式，除了要連線進去 VM 會有一點卡頓感之外，在程式運作期間的 response time 其實都滿快的！！\n所以如果是要做為 VM 的開發練習、部署 side project 的雲端主機、部署個人網站\u0026hellip;等等，e2-micro 應該都還滿夠用，但如果要做更大型的開發可能就不太適合這樣（但想想也是啦，畢竟是很初階的 VM，能夠使用就要感謝了XD，如果要做大型的開發還是得乖乖付費）。\n如何創建免費的 Compute Engine？ # 補充：經實測，現在要綁定信用卡才能使用 Compute Engine 的服務，如果大家要繼續往下操作的話，會需要先準備好一張信用卡 \u0026amp; 個人資訊，如果暫時不想提供的話，那就先看看這篇文章，了解一下流程就好～。\n了解了 Google Cloud 所提供的免費資源額度之後，接下來我們就實際到 Google Cloud 中，來創建一個免費的 Compute Engine（即是 VM 服務）出來吧！\n首先要先打開 https://console.cloud.google.com/ 進到 Google Cloud 的控制台，接著點擊左上角的「選取專案」，然後選擇「新增專案」。\n接著專案名稱可以隨意填，好了之後就按下「建立」，這樣子就可以在 Google Cloud 中建立一個專案，後續就可以在裡面使用 Compute Engine 的服務創建 VM。\n創建好專案之後，接著要再點擊一次上面的「選取專案」，然後選擇剛剛所創建出來的 Project。\n接著展開左邊的側邊欄，然後選擇「Compute Engine」裡面的「VM 執行個體」。\n此時會打開 Compute Engine API 的啟用畫面，就點擊「啟用」，然後等他跑一下。\n補充：如果你是第一次使用 Google Cloud 的服務的話，這裡就會顯示「必須啟用計費功能」，然後會把你導去綁定信用卡 \u0026amp; 強制啟用 300 美元的試用\u0026hellip;.，我自己是已經有綁過信用卡 + 用過 300 美元的試用，所以現在不會再問我了，但第一次使用可能會需要填滿多資料 + 滿多步驟，這裡大家可以自由斟酌是否要填寫相關的資訊給 Google（不過如果不填寫的話後面也沒辦法做就是了😂）。\n等他跑完之後，理論上大家就會被跳轉到下面這個「VM 執行個體」的頁面，如果沒有被跳轉過來的話，也可以跟前面的步驟一樣，先展開左邊的側邊欄，然後選擇「Compute Engine」裡面的「VM 執行個體」，就一樣可以進到這個畫面。\n接著點擊上方的「建立執行個體」，就可以開始創建一個 VM。\n然後重點來了！！！接下來的每個步驟都要小心選擇，如果沒有好好選的話，可能就會不小心選用到高價的服務，月底帳單就要哭了🥹。\n首先 instance 的名稱可以隨意填，這就是到時候被創建出來的 VM 的名稱，區域只能選擇「us-west1、us-central1、us-east1」其中一個，建議選擇 us-west1 的地區，這在美國西岸，離台灣比較近，網路延遲會小一點。\n接著往下拉一點，然後將「機型」調整為 e2-micro，這一步非常重要！！！VM 的機型可以說是影響價格最大的關鍵因素，所以一定要選 e2-micro（微型）才對！！\n接著點擊左側的「OS 和儲存空間」，然後選擇「變更」，將我們要使用的硬碟類型變更一下。\n這裡一定要把「開機硬碟類型」改成「標準永久磁碟」（其實就是俗稱的 HDD 傳統硬碟），另外大小雖然 Google Cloud 上限是提供到 30 GB，不過經個人實測其實填 20 GB 就很夠用了。\n所以調整完硬碟之後的最終狀態會是下面這樣，\n接著再點擊左側的「網路」，然後勾選「允許 HTTP 流量」和「允許 HTTPS 流量」，他會自動在下面的網路標記添加標籤，這部分不用特別動他，讓他自動添加即可。\n接著往下拉一點，然後點擊「網路介面」中的「default」。\n並且在「網路服務級別」的地方改成勾選「標準級（us-west1）」，改好之後記得按完成。\n2025.7.15 更新：大家抱歉\u0026hellip;我沒發現到 Google Cloud 的 UI 有改版過，所以漏加了下面的設定，因此可能會導致大家莫名其妙被收了 6 元台幣😭。建議大家將之前的 VM 砍掉，重新創建一個新的，避免後續再次被 Google Cloud 收費🙏。\n改好上述的設定之後，還需要點擊左側的「資料保護」，然後選擇「無備份」，這樣子才不會啟動 Google Cloud 的備份流程（之前被多收的 6 元台幣就是這個備份快照所導致的）。\n接著再點擊左側的「觀測能力」，然後取消勾選「Ops Agent」，取消 Google Cloud 的監測系統，避免被收取額外費用。\n這樣到這邊就全部設定完畢了！因此接下來就可以按下建立，創建出這個 VM 出來了。\n此時在右邊的預估每月費用中，費用會顯示 6.91 美元左右，這個不用怕，他到時在月底帳單會自己折抵，所以月底帳單收到的費用會是 0 元，如果後續有發現被超收的情況的話，一定要趕快找 Google 申訴！\n建議也可以比對一下紅框處是否只有「2vCPU + 1GB memory」和「20GB 標準永久硬碟」這兩行，如果有其他多出來的設定都是錯誤的，之前我就是犯了這個錯\u0026hellip;。\n如何登入進 Compute Engine 的 VM 裡？ # 等他跑一段時間創建好 VM 之後，這時候就可以看到該 VM 的內部 IP、外部 IP，以及其他的相關資訊。\n如果想要登入進那台 VM 玩耍的話，只要點擊右邊的 SSH，這時 Google Cloud 就會開啟一個新的視窗，創建一個新的 SSH 連線給我們。\n因此只要在新視窗中點擊「Authorize」：\n就可以直接透過此視窗開啟 SSH 連線，登入到 VM 內部了！因此後續大家就可以在這個 VM 裡面執行任何你想要練習的指令、或是運行你的程式了！（在此視窗中輸入指令時會有一個微妙的卡頓感，這是正常的現象，因為此 VM 建立在美國西岸，所以多多少少會有一點網路延遲）\n如何將程式上傳到此 VM 中？ # 雖然在這個 SSH 的視窗中有提供「上傳檔案」的功能，不過我通常都是會先把程式上傳到 GitHub（會順便將該 repo 設定成 private 不公開），接著在此 VM 中直接透過 Git 來下載，這樣子不僅所有改動都可以儲存在 GitHub 上，而且也不用去研究檔案傳輸的問題，個人覺得非常讚！\n至於在運行程式時，可能會遇到某某套件不存在的情況，這就是要靠自己去 debug 以及安裝相關的環境了。\n其實我還是滿推薦大家可以實際的創一台 VM 來玩的啦，只有當你真的靠自己去完成某些環境的設定之後，你才會發現原來可以這樣做，才會知道原來底層的 Linux 系統還有這麼多東西可以玩。\n畢竟我們身為後端工程師，平常都只專注在寫程式上，其實很多時候對 Linux 系統的熟練度沒有那麼高，所以透過下班時間創建一個 VM 來玩，自己從中解決問題、練習尋找問題的解法，也是一個精進自己非常棒的方式！\nGoogle Cloud 的終身免費方案總結 # 所以總結上述的介紹，就可以成功的在 Google Cloud 中創建一個永久免費的 VM 出來了～讚！\n如果大家後續想要重新起一台 VM 的話，就只要刪除舊有的 VM，然後照著一樣的步驟重新創建 VM 即可。不過要特別注意同時間只能有一台 e2-micro 的 VM，如果同時間有兩台的話，就超出 Google Cloud 的免費額度了！因此這部分在使用上也是要小心一下。\n另外除了 Compute Engine 之外，Google Cloud 的 Free Tier 也有提供許多免費額度給其他服務，如 App Engine、Cloud Run\u0026hellip;等等，如果大家有興趣的話，也可以再研究其他的服務～。\n結語 # 這篇文章我們先介紹了什麼是 Google Cloud 的終身免費方案，並且也實際到 Google Cloud 中創建一個免費的 VM，希望可以幫助大家熟悉創建 VM 的流程。\n如果你對後端技術有興趣的話，也歡迎免費訂閱《古古的後端筆記》電子報，每週二為你送上一篇後端技術分享，那我們就下一篇文章見啦！\n補充：我開設的 Spring Boot 零基礎入門、Spring Security 零基礎入門、GitHub 免費架站術 已在 Hahow 平台上架啦！輸入折扣碼「HH202601KU」即可享 85 折優惠。\n","permalink":"https://kucw.io/blog/gcp-free-tier/","tags":null,"title":"終身免費的 VM 服務！Google Cloud 免費方案分享"},{"categories":["Spring Boot"],"contents":"本文介紹要如何使用 Dockerfile 的 Multi-stage build 寫法，為 Spring Boot 生成更精簡的 Docker image。\n目錄 什麼是 Multi-stage build？ 在 Spring Boot 中使用 Multi-stage build 來生成 image 如何知道要把 src 複製到 /root/src 底下？ 結語 什麼是 Multi-stage build？ # 在生成 docker image 時，通常會透過撰寫 Dockerfile 來生成，而 Dockerfile 有兩種寫法可以用，一種就是用基本的 Dockerfile 寫法，另一種則是更進階的 Multi-stage build 寫法。\n針對這種需要編譯的程式語言（ex: Java、C++），用 Multi-stage build 會更好，因為 Multi-stage build 的概念是「依序 build 多個 image，但是只取最終的 image 來生成」。\n所以就可以先在前面的 Build stage 中先編譯 Spring Boot 檔案，此時在這個 image 裡面會有許多跟「執行」無關的檔案，像是 src、pom.xml、target 資料夾中的一堆編譯檔\u0026hellip;等等，這些檔案其實跟執行無關，跟執行真正有關的就只有 .jar 檔而已。\n而在 Build stage 執行完之後，就可以馬上把這個 .jar 檔拉到 Package stage 裡面，並且最終只生成 Package stage 的 image 出來，這樣子中間那些編譯檔就不用也被包進 image 裡面，徒增 image 大小了，讚！！\n另外補充一下，其實 Build、Package 這些名稱完全就是自己想叫什麼就叫什麼，沒有任何規範，只是一個概念而已，實際上可以有多個 stage，並且每個 stage 的名字可以自由取名。\n在 Spring Boot 中使用 Multi-stage build 來生成 image # 要在 Spring Boot 使用 Dockerfile 來 build image 的話，首先要先在 Spring Boot 的資料夾底下創建一個 Dockerfile （注意是要放在和 src 平行的層級，不是放在 src 裡面）。\n然後就可以在 Dockerfile 中撰寫 Multi-stage build 的程式：\n# -- build stage -- # 在 build 階段可以挑選 maven:3.9.0-eclipse-temurin-17 當作基底 image，他裡面已經預裝好 Maven 和 Java 17，讚！（所以挑 image 真的也是一門藝術，挑到對的 image 就可以省去很多自己安裝的步驟） # 記得最後面一定要加 AS xxx，這樣才能使用 Multi-stage build 的功能 FROM maven:3.9.0-eclipse-temurin-17 AS build # 拉取必要的 source code 和 pom.xml 進到 image 裡面（即是把 src 底下的所有程式複製到 image 的 /root/src 中，把 pom.xml 複製到 image 的 /root 裡） # 至於如何知道要放在 /root 下而不是放在 /usr 下，下面會講 COPY src /root/src COPY pom.xml /root # cd 到 /root 資料夾裡面，並且執行 mvn build Spring Boot WORKDIR /root RUN mvn clean package -Dmaven.test.skip=true # -- package stage -- # 因為在執行階段其實只需要 jre 就好，不需要整個 jdk 都拉進來，所以這裡採用的是 eclipse-temurin:17-jre，可以讓 image size 變得更小，選 image 的藝術 again FROM eclipse-temurin:17-jre # 偷 build 階段生成好的 .jar 檔進到此 image 裡面，所以就是複製 build 階段的 /root/target/*.jar 過來，並且將他改名成 app.jar COPY --from=build /root/target/*.jar app.jar # 聲明要開啟 8080 port EXPOSE 8080 # 指定運行此 package image 的指令 CMD [\u0026#34;java\u0026#34;, \u0026#34;-jar\u0026#34;, \u0026#34;app.jar\u0026#34;] 寫好之後就可以在 Spring Boot 中開啟 terminal，然後執行 docker build -t my/springboot:1.0.0 .，表示要運行當前的 Dockerfile，生成此 Spring Boot 程式的 image 出來（注意此處只會生成最終的 package image 出來，前面的 build image 就會被丟掉了）。\n此時就會在本機中生成一個 my/springboot:1.0.0 的 image 出來，接著只要執行 docker run -p 8080:8080 my/springboot:1.0.0，就可以用 docker 執行 Spring Boot 程式了，讚！\n如何知道要把 src 複製到 /root/src 底下？ # 在撰寫 Dockefile image 時，最常見的困擾就是「不知道要把檔案複製到哪裡去」。\n舉例來說，像是在上面的 build 階段時，就必須要把 Spring Boot 的 src 複製到 build image 中的 /root/src 底下，然後要把 pom.xml 複製到 /root 底下：\n# 使用 maven:3.9.0-eclipse-temurin-17 當做基底 image FROM maven:3.9.0-eclipse-temurin-17 # 複製 src 底下的程式到 image 的 /root/src 中，複製 pom.xml 複製到 image 的 /root 中 COPY src /root/src COPY pom.xml /root 之所以會知道要複製到這些位置，除了靠經驗傳承之外，其實也可以透過爬 Docker Hub 上的 image 介紹得知。\n以 maven:eclipse-temurin 為例，在 maven image 中的第 27、28 行就有定義 ARG USER_HOME_DIR=/root 和 ENV MAVEN_CONFIG=/root/.m2，所以其實這個 image 預設的 user home 就是 /root，而不是 /usr，因此才會把 src 程式複製到 /root 底下。\n所以如果想要客製化自己的 settings.xml 的話，那就要把 setting.xml 複製到 /root/.m2/setting.xml 的位置，這樣才會真的生效！\n因此在用任何 image 時，建議也可以來 Docker Hub 中查看 image 的介紹，可以更透徹的了解這個 image 中的系統結構。\n結語 # 這篇文章我們介紹了如何使用 Dockerfile 去生成 Spring Boot 的 image，並且採用了 Multi-image build 的技術，減少最終生成的 image 大小。\n如果你對後端技術有興趣的話，也歡迎免費訂閱《古古的後端筆記》電子報，每週二為你送上一篇後端技術分享，那我們就下一篇文章見啦！\n補充：我開設的 Spring Boot 零基礎入門、Spring Security 零基礎入門、GitHub 免費架站術 已在 Hahow 平台上架啦！輸入折扣碼「HH202601KU」即可享 85 折優惠。\n","permalink":"https://kucw.io/blog/springboot-docker-image/","tags":null,"title":"為 Spring Boot 生成 Docker image（Multi-stage build）"},{"categories":["其他技術分享"],"contents":"初入門 Docker 時，可能會對 Docker 中有哪些指令感到眼花撩亂，這篇文章會介紹如何運行你的第一個 Docker 程式，並且介紹 Docker 的常用指令有哪些。\n如果只想查看 Docker 常用指令的介紹，可以直接點擊 Docker 常用指令 跳轉到下方。\n目錄 Docker 中的 Image、Container、Registry 的用途 運行第一個 Docker Container 安裝 Docker Desktop 下載 Docker Image Docker 常用指令介紹 pull 指令（下載 image） run 指令（創建並運行 container） start/stop 指令（運行/結束 container） ps -a 指令（查看所有 container 的運行狀態） exec 指令（對正在運行的 container 下達指令） logs 指令（查看該 container 輸出的 log） inspect 指令（查看該 container 的詳細資訊） rm 指令、rmi 指令、images 指令 Docker 常用指令總結 結語 Docker 中的 Image、Container、Registry 的用途 # 在 Docker 中，Image、Container、Registry 是很常出現的三個名詞：\n1. Image（映像檔）\n大家可以把 image 想像成是任何一段程式（或是一個 .jar 檔），所以當我們作為 Developer 寫完程式之後，就可以將這段程式封存成一個 image，並且打上一個 tag 的編號 x.x.x（這個效果就等同於 Maven 的版號）。\n2. Container（容器）\nContainer 的概念類似於「買一台新電腦，然後在裡面運行 image 裡的程式」，在 Docker 中可以運行許多個 Container，每一個 Container 都是一個獨立的環境。\n3. Registry（倉庫）\n可以把 Registry 想像成一個雲端倉庫，裡面會存放所有 image 們（概念等同於 Maven 需要有一個地方存放 .jar 檔），所以不管是要 push image 上去、還是要 pull image 下來，都是在跟 Registry 倉庫溝通。\nDocker 官方的 Registry 叫做 Docker Hub，預設就是會從這個地方下載 image 下來，或是公司內部也很常見會建置私人的 Registry，存放公司內部的 image 們。\n運行第一個 Docker Container # 安裝 Docker Desktop # 要在電腦上運行 Docker 的話，首先要先安裝 Docker Desktop 這個軟體，因此大家可以先進到 Docker 官網，然後根據自己的電腦系統下載對應的 Docker Desktop（建議大家也可以順便辦一下 Docker 的帳號，等一下可以登入進 Docker Desktop 中）。\n下載好 Docker Desktop 之後，接著就可以在 terminal 中輸入指令，從 Registry（倉庫）中拉取想要的 image 下來，並且使用該 image 生成 container 來運行。\n補充：安裝好 Docker Desktop 之後，記得要執行他才可以，他一定要在背景運行著，這樣等等我們輸入的指令才會生效。\n所以如果等等在執行下面的 docker 指令時看到 Cannot connect to the Docker daemon at unix:///Users/kujudy/.docker/run/docker.sock. Is the docker daemon running? 的錯誤，就表示你忘記執行 Docker Desktop 軟體了。\n下載 Docker Image # 在 Docker 官方的 Registry Docker Hub 中，裡面提供了各式各樣的 image 供大家下載。\n舉例來說，在 Docker Hub 中有一個 image 叫做 hello-world（沒錯就叫這個名字），此時點擊他右邊的 Copy 就可以複製拉取這個 image 的指令。\n只要在 terminal 中貼上這段指令（或是自己手動輸入 docker pull hello-world），就可以下載 hello-world 這個 image 下來。\n此時如果回到剛剛安裝的 Docker Desktop 查看一下的話，就可以看到在 Images 中出現了 hello-world 這個 image 了，這就表示我們下載了 hello-world 這個 image 映像檔到我們的電腦中。\n而要運行這個 image 的話，只需要在 terminal 中再輸入 docker run hello-world，就可以用 hello-world image 去生成一個 container 出來，並且 Docker 就會去執行這個 container 中的程式，因此最終就會輸出如下的資訊在 console 上。\n這個 image 比較簡單，就只是輸出文字在 console 上而已，其他的 image 有各式各樣的功能可以使用，基本上熱門的服務如 nginx、redis…等，都有 image 可以用。\n順便一提，此時如果回到 Docker Desktop 上查看的話，就可以看到在 Containers 區中多了一個容器出來，他上面就會寫這個 container 的 id 是多少（即是 f10ff7cdfb54）、以及這個 container 是從哪個 image 生成出來的（即是 hello-world image）。\n所以其實安裝了 Docker Desktop 之後，我們就能透過 Docker Desktop 的好用介面，一目瞭然現在到底下載了哪些 image、以及有哪些 container 是正在運行著的，算是方便我們管理這樣（不過這些功能也完全可以用 terminal 指令來查看，就看大家喜歡哪一種）。\nDocker 常用指令介紹 # 成功運行起第一個 Docker 程式之後，接下來也來介紹一下 Docker 中常用的指令有哪些。\npull 指令（下載 image） # docker pull [image name]:[image tag]：從 Registry 中下載 image 到本機電腦。\n如果想要從遠端倉庫中下載某個 image 時，就要用 docker pull 來下載，像是 docker pull nginx 就可以下載 nginx 這個 image 下來。\n另外在下載 image 時，也可以特別指定要下載的 image 是哪個版本（版本在 docker 中稱為 tag）。\n舉例來說，在下載 nginx 時就可以輸入 docker pull nginx:1.28，表示要下載 tag 為 1.28 的 nginx image 下來，這裡的 1.28 就等同於是版本號。\n如果沒有指定版本的話，預設就是下載 latest 這個 tag 下來（表示當前的最新版），所以 docker pull nginx 和 docker pull nginx:latest 是完全一樣的。\n# 這兩個下載的 image 一模一樣 docker pull nginx docker pull nginx:latest 不過在實務上，建議大家在下載和使用 image 時，一定要特別指定要使用的是哪個 tag，不要用無腦用 latest 最新版，這樣很容易會遇到版本升級導致的問題…這是特別要注意的地方！！\nrun 指令（創建並運行 container） # docker run [OPTIONS] [image name]:[image tag] [執行指令]：使用 image 創建一個新的 container，並且運行該 container。\nrun 可以說是 docker 中最重要的指令之一，他會為 image 生成一個 container，並且運行該 container。\n所以像是前面在運行 docker run hello-world 時，就是使用 hello-world image 生成一個 container 出來，並且去運行該 container，所以這也是為什麼在運行完 docker run hello-world 之後，在 Docker Desktop 中的 Containers 區會出現一個新的 container，這就是被 run 指令所創建出來的 container。\n順便一提，如果執行 docker run hello-world 時 hello-world image 還沒被下載下來，那麼 Docker 就會先去倉庫中下載該 image，並且載完之後直接運行該 container，等於是同時做 pull + run 兩件事就對了，所以如果平常懶得執行 pull 指令的話，直接使用 run 指令也是可以的！\n另外在使用 run 去運行 container 時，有一點要特別注意，就是使用 run 所生成的 container ，他在運行完畢之後並不會被刪掉！！！ 所以 container 實際上是會繼續佔用硬碟空間的（只是他的狀態是 exit 而已）。\n所以假設你在 terminal 中運行了 docker run hello-world 5 次，其實是會創建 5 個 container 出來的！！！因為每 run 一次都是會重新創建一個新的 container 出來，並且每一個 container 之間是完全獨立的，等於是你買了 5 台電腦來執行 hello-world 程式的概念。\n所以如果不想要一直創建新的 container 出來的話，就可以改成使用 docker start [container id] 指令，去重複運行已經存在的 container，不要每次都用 run 新創建一個 container 出來（start 指令下面會介紹）。\n補充：因為 run 是 docker 中很重要的指令，所以導致 run 指令有太多參數擴展可以用了，這篇文章沒辦法全部涵蓋進來🥹，後續有更多研究我再來寫一篇文章，專門介紹 run 的各種用法。\nstart/stop 指令（運行/結束 container） # docker start/stop [container id]：運行/結束某個 container。\n因為 run 指令是「創建並運行 container」，所以配套的 start/stop 指令，就只是去「運行/結束 container」而已，並不會執行「創建 container」的部分。\n所以舉例來說，假設我們前面已經用 docker run hello-world 創建一個新的 container 出來之後，這時如果想要再次運行該 container 的話，就可以使用 docker start f10ff7cdfb54，再次去運行 container。\n但當然啦，因為 start/stop 的用途只是「運行/結束 container」而已，所以一定要先使用 run，先把 container 創建出來之後，start/stop 這兩個指令才有用，如果連 container 都還沒創建出來的話，那個 start/stop 是完全派不上用場的。\nps -a 指令（查看所有 container 的運行狀態） # docker ps -a：查看所有 container 的運行狀態。\n這也是超常用的重要指令之一，可以查看所有 container 的運行狀態（包含 container id、運行時間…等重要資訊）。\n另外這指令一定要加 -a 才能顯示全部的 container，不加的話只能看到當前運行的 container 們而已，沒辦法看到停止運行的 container。\nexec 指令（對正在運行的 container 下達指令） # docker exec [OPTIONS] [container id] [執行指令]：對正在運行的 container 下達指令。\nexec 算是也滿常用的指令之一，通常是在初期開發時比較常用，因為 exec 是可以針對「正在運行的 container 下達指令」，甚至可以「登入到這個 container 裡面」，去查看運行時的 log、或是程式位置是否有擺對地方…等等。\n像是執行 docker exec -it [container id] /bin/bash 的話，就可以登入到該 container 裡面，直接查看該 container 中的運行情況。\n舉例來說，在我們執行了 docker run -d nginx 之後，這時候 nginx 就會在背景運行，此時如果想要登入進去看裡面的內容的話，就可以執行 docker exec -it 32512d06d1ccf /bin/bash（32512d06d1ccf 是 nginx container 的 id），這樣子就可以登入到這個 nginx container 裡面了。\n補充：一開始可能會對 exec 指令感到有點疑惑，建議不用太糾結，只要先把他當成一個「能夠登入進 container 中」的指令即可。\nlogs 指令（查看該 container 輸出的 log） # docker logs [container id]：查看該 container 輸出的 log。\n這也是好用的指令！！可以直接在外面呈現 container 中的 log 出來，不用登入進去 container 才看得到，讚！！（唯一要注意的是這個指令是 logs，有 s，不是 log）\n常用的配套參數：\ndocker logs -f [container id]：持續列出最新的 log docker logs -f --tail 10 [container id]：持續列出最新的 log，並且只顯示最後 10 筆 inspect 指令（查看該 container 的詳細資訊） # docker inspect [container id]：查看該 container 的詳細資訊。\n如果想要查看這個 container 的詳細資訊（ex: 環境變數、網路設定），那麼就可以靠 inspect 指令來取得。\n不過這指令輸出的資訊有點太詳細了，初學可能會看不太懂，建議後續有需要更深入了解 Docker 時再來學習即可。\nrm 指令、rmi 指令、images 指令 # rm、rmi、images 這三個指令的用途，現在透過 Docker Desktop 的 UI 就能夠直接操作了，所以初學不用特別背，除非是沒有 Docker Desktop 介面可以用的環境（ex: 遠端的 server，需要 ssh 進去才能使用），才需要手動打以下的指令。\ndocker rm [container id]：刪除某個 container docker rmi [image id]：刪除某個 image（根據 image id） docker rmi [image name]:[image tag]：刪除某個 image（根據 image name 和 tag） docker images：查看目前已下載了哪些 image # 刪除某個 container docker rm 1f2a828ffadf2 # 刪除某個 image docker rmi f1f77a0f96b7 docker rmi nginx:1.28 # 查看目前已下載了哪些 image docker images 以下也列出好用的 docker 組合技（感謝網路上的大神分享），我覺得 stop 和 rm 所有 container 在開發階段還滿好用的，推薦給大家～。\n# 停止所有 container docker stop $(docker ps -a -q) # 刪除所有 container docker rm $(docker ps -a -q) # 刪除所有 image docker rmi $(docker images -a -q) Docker 常用指令總結 # 所以總結 Docker 的常用指令的話，可以統整成以下的用法：\n# pull: 從倉庫中拉取 image 下來 docker pull hello-world docker pull hello-world:1.28 # run: 創建並運行 container（run 有許多參數可擴展，此處先略過沒介紹） docker run hello-world:1.28 # start: 運行 container（以下的 f10ff7cdfb54 皆為 container id） docker start f10ff7cdfb54 # stop: 結束 container docker stop f10ff7cdfb54 # ps -a: 查看所有 container 的運行狀態 docker ps -a # exec: 對正在運行的 container 下達指令 docker exec -it f10ff7cdfb54 /bin/bash # 登入進該 container # logs: 查看該 container 輸出的 log docker logs f10ff7cdfb54 docker logs -f f10ff7cdfb54 # 持續列出最新的 log docker logs -f --tail 10 f10ff7cdfb54 # 持續列出最新的 log，並且只顯示最後 10 筆 # inspect: 查看該 container 的詳細資訊 docker inspect f10ff7cdfb54 # rm: 刪除某個 container docker rm f10ff7cdfb54 # rmi: 刪除某個 image docker rmi 1c48965c5eed # 根據 image id 刪除 docker rmi hello-world:1.28 # 根據 image name 和 tag 刪除 # images: 查看目前已下載了哪些 image docker images 因此大家就可以透過上述的 Docker 指令，在你的電腦中操作 container 和 image 了～，讚！！\n結語 # 這篇文章我們先介紹了 Docker 中的 Image、Container、Registry 的用途，接著運行了第一個 Docker 程式，並且也介紹了 Docker 中的常用指令，希望可以幫助大家對 Docker 指令有更多的了解。\n如果你對後端技術有興趣的話，也歡迎免費訂閱《古古的後端筆記》電子報，每週二為你送上一篇後端技術分享，那我們就下一篇文章見啦！\n補充：我開設的 Spring Boot 零基礎入門、Spring Security 零基礎入門、GitHub 免費架站術 已在 Hahow 平台上架啦！輸入折扣碼「HH202601KU」即可享 85 折優惠。\n","permalink":"https://kucw.io/blog/docker-command/","tags":null,"title":"Docker 常用指令介紹 + 第一個 Docker 程式"},{"categories":["自媒體經營"],"contents":"哈囉，我是古古，這篇文章是每月一次的自媒體月報，主要分享我經營《古古的後端筆記》個人品牌的幕後秘辛，如果你也對於「自媒體創業」有興趣的話，歡迎繼續閱讀本文～\n補充：如果想了解《古古的後端筆記》電子報的起源，也可以先查看創刊號的文章。\n2025.3～4 月粉絲追蹤數、電子報訂閱人數 # 這兩個月的粉絲成長人數如下：\n2025/2/25 人數 2025/4/29 人數 3 月份總成長人數 4 月份總成長人數 Facebook 粉專追蹤數 4607 4674 +37 +30 電子報訂閱人數 3079 3348 +155 +114 Threads 粉絲追蹤數 8135 8732 +391 +206 IG 粉絲追蹤數 688 747 +34 +25 本月撰寫的電子報主題、文章 # 這邊記錄了我這兩個月撰寫了哪些電子報和文章，大家如果對於其中的內容有興趣的話，也可以前往查看：\nCron 是什麼？定時任務的語法怎麼寫？ CDN 是什麼？一次搞懂 CDN 的用途和三大好處 Elasticsearch 是什麼？認識地表最強的全文搜尋工具！ Elasticsearch 進階用法，如何透過 function_score 自定義排序結果？ 近況更新 # 雖然自媒體月報已經有點快被我拿來當成個人生活的抒發😂，但是還是有一個消息想跟大家更新一下，就是我已經找到工作啦～\n其實更準確的說是我已經入職一陣子了，只是想說剛好趁著月報的機會和大家更新一下近況這樣，很感謝大家一路以來的關心，不管是 FB 私訊還是電子報的回信我都有收到，也特別感謝中間有幫忙牽線分享面試機會的古粉們🥹（揪甘心），一路上遇到很多貴人相助，心中只有萬分感謝😭（但拜偷別私訊我問我在哪上班，暫時不方便透露🥹）。\n是說我本來有打算和大家分享這次找工作被問到的問題有哪些，但是考慮到各種因素最後還是作罷（怕牽扯到法律問題的話會有點麻煩，所以只能跟大家說聲抱歉了\u0026hellip;.）。\n然後也跟大家分享一下這份新工作吸引我的地方在哪吧！這份新工作的內容其實會有點偏 DevOps（還沒看 CI/CD 那篇電子報的快去看🤣），有很多機會可以碰 Docker + Kubernetes 的場合，覺得很有挑戰性，是以前完全沒有機會碰到的領域！而且 DevOps 的角色定義也很吸引我，可以當 Developer 和 Operations 的橋樑感覺很酷XD。\n另外我同時也在想，如果我多懂一點 Operations 的東西，將來是不是就可以將一些簡單常用的技巧分享給電子報的大家（也就是 Developer），看能不能提供一些「站在 Developer 角度必學的 Operations 知識」，讓 Developer 和 Operations 之間的隔閡不要再那麼大之類的？不知道XD，可能還需要更多時間來思考一下這個方向。\n總之，這份後端電子報仍舊會持續下去的！！未來的內容主要還是會圍繞在後端的主題上，頂多偶爾會講一點點 Operations 的東西而已，不會真的寫很硬的 Operations 知識，我還是希望能藉由這份電子報，和大家一起精進系統設計的相關技術💪。\n新的一年挑戰新的事物，Sharing is Learning，無限進步🚀！！\n2025.3～4 月報總結 # 以上就是這兩個月的自媒體月報了！如果有什麼想了解的也歡迎隨時回信給我，每一封信我都會看的，那我們就下個月再見啦！\n","permalink":"https://kucw.io/blog/as-a-content-creator/monthly-report-202503-04/","tags":null,"title":"軟體工程師的自媒體之路 - 2025.3～4 月報"},{"categories":["其他技術分享"],"contents":"大家在工作上可能常常會聽到 CI/CD、持續集成、持續部署\u0026hellip;等等的名詞，但是卻不清楚這些名詞背後所代表的意義是什麼，因此這篇文章我們就來介紹一下，到底什麼是 CI/CD，以及他們之間的區別吧！\n目錄 什麼是 CI/CD？ CI（持續集成） CD（持續交付） 補充：Continuous Delivery 和 Continuous Deployment 的差別 CI/CD 總結 補充：什麼是 DevOps？ 結語 什麼是 CI/CD？ # 所謂的 CI/CD，他其實要拆分成兩個名詞來看，分別是 CI 和 CD：\nCI（Continuous Integration，持續集成） CD（Continuous Delivery，持續交付） 所以雖然 CI 和 CD 長得很像，但是他們實際上所負責的是完全不同的流程！所以接下來我們就分別來看一下，CI 到底是負責什麼部分、而 CD 又是負責哪些部分。\nCI（持續集成） # 所謂的 CI，就是指「計畫需求、實作程式、建置程式、測試程式」這四個步驟的統稱，而 CI 的終極目標，就是要讓這四件事可以被「自動化」執行，重點在「自動化」。\n舉例來說，不管你是前端工程師、後端工程師、還是 Android/iOS 工程師，只要你的工作內容是「寫程式完成客戶的需求」（客戶可以是企業用戶，也可以是一般使用者），那麼你就是屬於開發者（Developer），而 Developer 的日常任務，其實就是大家常常在做的釐清需求、寫程式、測試程式而已。\n所以 CI 並不是一個什麼新的流程，他只是希望可以把 Developer 日常的工作整合在一起，讓大家在「釐清需求 → 寫程式 → build code → 測試程式」這段路可以做得更順暢一點而已。\n因此在 CI 的流程中：\n首先會先從 plan（計畫）開始，也就是先釐清需求為何 釐清好需求之後，接著就進到 code 的環節，開始去實作程式 等到程式實作完之後，這時候就可以進到 build 環節來 build code（建置程式），通常前端會用 webpack 來 build code、後端則是用 Maven 和或是 Gradle 來 build build 完程式之後就會進到 test 環節，此時就可以運行單元測試、或是運行自動化測試，確保我們所 build 出來的 code 是能正常運行的 因此大家也可以觀察一下，當你 push code 到你們公司的 GitHub、GitLab、BitBucket 等…雲端時，常常就會觸發一些 job 去 build code、去執行單元測試，而這些自動化執行的 job，其實都是 CI 的一環！！\n也因為有了這些自動化 build code、自動化執行單元測試的 job，所以我們作為 Developer 不僅可以省去反覆手動操作的時間，也可以確保我們所撰寫的程式是已經被驗證過的，不會 merge 一份有問題的程式回 master branch。\n所以到這裡，CI 的任務就完成了，因此簡單來說，CI 只要好好守護 Developer 們能夠把程式 build 完、把測試程式 run 完，CI 就功成身退了，接下來就是要進到 CD 的戰場了！\nCD（持續交付） # 在我們進入 CD 的介紹前，大家可以先回想一下，你作為 Developer（前後端均可），是否還記得當你的 Pull Request 被 merge 之後，到底發生了什麼事嗎？如果你沒辦法很明確的說出後續每一個步驟在幹嘛，其實是非常正常的，因為「部署程式」這件事情，在職責上確實不歸 Developer 管。\n一般在分工比較細的大公司來說，會將工程師區分成兩種人：Developer（開發工程師）和 Operations（維運工程師），其中 Developer 就是負責寫程式，達成 PM 的需求，而 Operations 則是負責部署程式，將 Developer 寫的程式部署到 server 上，讓使用者可以真的用到這個程式。\n所以所謂的 CD，就是指 Operations 中的「發佈程式、部署程式、維運程式、監控程式運行狀態」這四個步驟的統稱，而 CD 的終極目標，一樣是要讓這四件事可以被「自動化」運行（這裡的自動化有一點微妙的差別，等等會介紹）。\n因此在 CD 的流程中：\n首先會從 release 開始，也就是當 Developer 的程式被 merge 之後，維運工程師就可以開始來處理發版的部分 發佈完成之後，接著就會進到 deploy 的環節，將這份程式部署到 server 上 deploy 完成之後會進到 operate 環節，管理程式是否有正常運行 最終則是 monitor 環節，持續監控程式的運行狀態，時時刻刻確保服務在線，不會中斷 所以在 CD 的流程中，可以看到幾乎全部都是在做部署程式、維護 server 的相關操作，而這裡擴展下去就可以講非常非常廣了。\n舉例來說，如果今天 server 選擇部署在 AWS 上，那麼如何更好的管理和運用 AWS 上的服務，就是 CD 要處理的部分，如果今天換成使用另一個雲端服務 GCP，那麼 CD 又會需要跟著改。\n又或是說，假設今天是使用 Docker + Kubernetes 來部署程式，那麼如何打包 image、如何設定環境變數、如何使用 Kubernetes 調度 pod…等等，這些也是 CD 要處理的部分。\n因此 CD 在玩法上可以說是更加的多樣化，追求的已經不僅僅是「把程式弄到 server 上去 run」這麼簡單而已，而是要追求「又快、又好擴展、又安全、又省錢」這種巔峰造極的境界了。\n也因為如此，近幾年的部署流程其實也是各種飛速發展，其中最熱門的大概就是 Docker + Kubernetes 這類的容器化部署了，大家如果對這方面有興趣的話，可以參考我之前寫的 Docker 介紹，或是搜尋網路上各位大大們的 Docker 教學。\n反正總而言之，CD 的任務就是要守護 Operations（維運工程師），讓維運工程師可以用最有效率的方式去部署和管理 server，同時也努力幫老闆省下最多的成本就對了！\n補充：Continuous Delivery 和 Continuous Deployment 的差別 # 了解了 CD 的概念之後，這裡也補充一下前面提到的「有點微妙的自動化」的部分。\n在 CD 中，又可以細分成 Continuous Delivery（持續交付）和 Continuous Deployment（持續部署），他們兩個之間的差別就在於「部署到 production 正式環境這一步，是否需要人工手動操作」。\nContinuous Delivery（持續交付）：部署到 production 環境需要人工手動操作 Continuous Deployment（持續部署）：全自動化，不需人工介入 像是在前面的 CI 和 CD 的介紹中，一直有提到 CI 和 CD 的終極目標是「自動化」執行，但是會不會自動化過了頭，反而導致我們所交付的程式有問題呢？\n舉例來說，假設當你所寫的程式被 merge 回 master branch 之後，假設就這樣自動化一路部署到 production 環境，中間完全沒有任何人再對他進行壓力測試、或是沒有進行服務的整合測試，可能就會出現意料之外的問題。\n還有一個問題是，有時候功能的發佈是會需要搭配商業策略的，譬如說 iOS 的新功能常常會在 iPhone 發表會上宣布，這就是一種為了商業策略而延遲發版的行為。\n因此一般在實務上，Continuous Delivery（持續交付）會是比較常見的做法（即是部署到 production 環境時需要人工手動操作），並且在 CI/CD 流程中的 CD，在正式的定義上也是指 Continuous Delivery（持續交付）的意思。\nCI/CD 總結 # 所以總結上述的介紹，所謂的 CI/CD 其實是指 CI 和 CD 這兩個不同的流程：\nCI（持續集成）：為「計畫需求、實作程式、建置程式、測試程式」這四個步驟的統稱， 目標是將這些步驟自動化運行，守護 Developer（開發工程師）直到把程式 merge 進 master branch CD（持續交付）：為「發佈程式、部署程式、維運程式、監控程式運行狀態」這四個步驟的統稱， 目標是將這些步驟自動化運行（部署到 production 環境除外），守護 Operations（維運工程師）部署和管理 server 所以透過 CI 和 CD 的輔助，Developer 和 Operations 就可以在各自的流程中加快效率，進而達到「持續寫程式 → 持續集成程式 → 持續發版 → 持續交付 → 持續監控程式運行狀態 → 回頭繼續寫程式」的完美循環了！！！\nPS: 注意看上面這張圖，遠看他其實就是一個無限大的符號 ∞，表示 CI/CD 是一個能夠無限運行下去的完美循環。\n補充：什麼是 DevOps？ # 了解了 CI/CD 的概念之後，最後我們再來加碼補充一下什麼是 DevOps 吧！\n其實 DevOps 這個職位是在 CI/CD 出現之後才興起的職缺，因為在 CI/CD 的流程中，Developer（開發工程師）和 Operations（維運工程師）是需要非常緊密的合作，才能夠達到最高的效率的。\n舉例來說，如果 Operations 在後期的部署階段需要使用 Docker + Kubernetes 來部署，那麼 Developer 在前期就需要將程式盡可能地縮小，配合容器化的概念來實作程式，因此即使後面的部署流程和 Developer 沒有關係，但是 Developer 在開發上仍舊會被 Operations 影響，需要互相配合。\n而 Operations 其實也是會反過來被 Developer 影響，像是如果 Developer 亂切服務、每個專案的設置都不一樣…等等，這些也是會造成 Operations 在後期的部署和管理上的困難。\n因此這時候，就有人提出了一個想法：如果我們雇用一個超超超級強的人，他又懂 Developer 又懂 Operations，既會寫 code 又會部署，這樣他是不是就可以一人分飾兩角，在寫 code 時就預先避免掉後期部署可能會造成的影響、並且在後期部署時也不要反向影響 code 的架構，這樣不就天下太平了嗎？\n沒錯，就是因為這個想法，所以 DevOps 這個職位就誕生了（DevOps 即是 Developer + Operations 的組合字，左半邊的 CI 是 Dev，右半邊的 CD 是 Ops）。\n所以對於 DevOps 來說，他真的是包山包海，什麼都來一點，左手寫 code 右手部署，DevOps 就是 Developer 團隊和 Operations 團隊的橋樑，由他來串起整個 CI/CD 的全貌。\n不過當然啦，即使上面的願景很好，但實際在工作中每個 DevOps 專精的領域還是會有點不太一樣（有的比較會寫 code、有的比較會部署），目前台灣比較常見的 DevOps 好像都是偏部署的居多，這方面我也還在學習中，如果有更多內容後續再和大家分享～\n結語 # 這篇文章我們先分別介紹了 CI 和 CD 的流程是什麼、以及他們各自要守護的人是誰，並且也補充了 DevOps 職位的存在意義，希望可以讓大家對 CI/CD 有更多的認識。\n如果你對後端技術有興趣的話，也歡迎免費訂閱《古古的後端筆記》電子報，每週二為你送上一篇後端技術分享，那我們就下一篇文章見啦！\n補充：我開設的 Spring Boot 零基礎入門、Spring Security 零基礎入門、GitHub 免費架站術 已在 Hahow 平台上架啦！輸入折扣碼「HH202601KU」即可享 85 折優惠。\n","permalink":"https://kucw.io/blog/cicd-intro/","tags":null,"title":"CI/CD 是什麼？他們之間的差別在哪裡？"},{"categories":["Elastic Search"],"contents":"Elasticsearch 除了可以用來實作一般的全文搜尋之外，如果想要實作「推薦排序」，針對多個維度綜合比較，Elasticsearch 也是支援這類的用法的！\n因此這篇文章我們就來介紹一下，要如何透過 Elasticsearch 中的 function_score，來實作自定義排序的結果吧！\n補充：如果對 Elasticsearch 不太熟悉，也可以先回頭參考 Elasticsearch 的基本介紹 Elasticsearch 是什麼？認識地表最強的全文搜尋工具！。\n目錄 回顧：什麼是 Elasticsearch？ 例子：美食地圖實作 Elasticsearch 中的推薦排序實作（使用 function_score） Elasticsearch 中的 function_score 總結 結語 回顧：什麼是 Elasticsearch？ # 所謂的 Elasticsearch，他是一個強大的「全文搜尋」（Full-Text Search）工具，讓我們可以從大量的數據中，快速找到想要的資料在哪裡。\n也因為 Elasticsearch 的專長是「全文搜尋」，所以一般通常會將他用來「架設搜尋引擎」，因此像是旅遊攻略、評論、社群貼文、電商產品….等等諸如此類的查詢，背後都很適合使用 Elasticsearch 來實作！\n不過，當大家將 Elasticsearch 應用在旅遊攻略、評論、社群貼文…等等的功能實作時，這時候就會遇到一個非常重要的問題，那就是「什麼樣內容的文章應該排在最前面？」，因此「如何調整文章的排序結果」，這就是這週我們要來探討的主題了！\n例子：美食地圖實作 # 想像一下，假設現在你要實作一個美食地圖的查詢功能，在這個美食地圖中，要提供使用者「距離搜尋」、「關鍵字搜尋」、「依照評價排序」…等相關功能，具體大家可以想像成 Google Map 中的搜尋餐廳或是 Uber Eats 中的尋找餐廳的類似功能。\n假設現在使用者查詢了「小籠包」這個關鍵字，並且想要根據「評價由大到小」來排序的話，那這個在 Elasticsearch 中很好實作，就是直接使用 order 來排序就好（邏輯類似於 SQL 中的 ORDER BY）。\n又或是使用者查詢了「小籠包」這個關鍵字，並且想要查詢他「方圓 2 公里以內」的所有小籠包餐廳，那這個在 Elasticsearch 中也很好實作，即是使用 geo_point 格式來查詢即可（詳細用法可以參考 Elasticsearch 官網，這裡先不詳細展開介紹）。\n但是！！問題來了！！！假設今天使用者選擇了「推薦排序」，那麼作為後端的我們，到底應該是把「評價較優」的店家放在前面，還是要把「距離較近」的店家放在前面呢？這真的是個好問題對吧，畢竟誰都想要排在比較前面的位置，這樣子曝光度會比較高，生意也會比其他店家更好。\n所以這時 Elasticsearch 就開始思考，有沒有辦法提供一個「多維度的評分機制」，讓我們可以根據多個維度，來決定這個店家的總分為何呢？ 答案是有的！我們可以透過 Elasticsearch 中的 function_score，對多個維度的值進行權重加總，最終計算出每一個店家的總分，因此就可以實作出「推薦排序」的功能了！\nElasticsearch 中的推薦排序實作（使用 function_score） # 補充：以下內容較為複雜，建議大家對 function_score 有個概念即可，等到後續真正用到時再回來查相關實作細節。\n在 Elasticsearch 中，有一個特別的地方，就是他會針對「每一個文件給出一個 _score 的分數」，這個 _score 就是指「該文件的匹配程度」，因此簡單來說，_score 的值越高的文件，他在搜尋的結果就會被排在越前面，這個就是 Elasticsearch 的運作機制。\n所以如果我們想要實作一個「多維度的評分機制」，根據店家距離、評價數、價格…等等的多個維度去決定一個店家的總分，那麼就是要透過 function_score 的用法，手動的去改變 Elasticsearch 的 _score 的計算方式，這樣子最終的排序結果，才會是我們期望的「推薦排序」。\n舉例來說，一個基本的 function_score 模板如下圖所示：\nGET /_search { \u0026#34;query\u0026#34;: { \u0026#34;function_score\u0026#34;: { // 主查詢，查詢完後這裡自己會有一個評分，就是 old_score \u0026#34;query\u0026#34;: {.....}, // 這裡可以寫上多個加強函數 // 每一個加強函數會產生一個 boost_score（加強 score），因此有多個 functions 就會有多個 boost_score \u0026#34;functions\u0026#34;: [ { \u0026#34;field_value_factor\u0026#34;: ... }, { \u0026#34;gauss\u0026#34;: ... }, { \u0026#34;filter\u0026#34;: {...}, \u0026#34;weight\u0026#34;: ... } ], // 決定多個 boost_score 們要怎麼合併成一個 total_boost_score \u0026#34;score_mode\u0026#34;: \u0026#34;sum\u0026#34;, // 決定 total_boost_score 怎麼和原始的 old_score 合併 \u0026#34;boost_mode\u0026#34;: \u0026#34;sum\u0026#34; } } } 如果拆解一下這個模板的話，基本上就是在 functions 的地方，可以去添加各種不同維度的評分，最終再透過 score_mode 和 boost_mode，將這些不同維度的評分給加總（或是相乘）起來，最終得到每一個店家的總分。\n所以以上面的美食地圖的功能為例，我們就可以在主 query 中寫上「小籠包」的查詢，並且在 functions 裡面，寫上我們想要根據「評價數」和「距離」分別去評分，最終再透過 score_mode 和 boost_mode，將這些分數全部加總起來，就是這個店家的最終得分 _score 了。\n因此透過 function_score 的用法，我們就可以成功的在 Elasticsearch 中實作出「推薦排序」的功能，進而去針對多個維度，去進行綜合性的比較了！\n補充：如果大家想了解更多 function_score 的具體實作，也可以參考我之前寫的 function_score 系列文章。\nElasticsearch 中的 function_score 總結 # 所以總結上述的介紹的話，如果將來我們想要在 Elasticsearch 中實作「推薦排序」這類較為複雜的排序，需要同時針對多個維度的方向來排序時，那麼就可以透過 function_score 的用法，手動的改變 Elasticsearch 中的 _score 的評分機制，最終得到我們想要的排序結果。\n並且因為 Elasticsearch 的 function_score 是可以一直往上加的，所以不管是要一個維度、還是要 N 個維度，都可以根據當下的需求來擴展，因此擴展性可以說是非常的高！\n不過，也因為 function_score 改變的是「排序的結果」，所以這個其實沒有絕對的對錯，畢竟青菜蘿蔔各有所好，你認為好吃的店家，其他人可能不覺得好吃，所以要如何調出一個「完美的 function_score 參數」，反而才是最困難的部分。\n另外也隨著 AI 的興起，使得「推薦排序」的實作不一定要透過 Elasticsearch 來實作，而是可以考慮改成 AI 的演算法來實時運算，透過 AI 取得當下最推薦的排序。但老實說 AI 這部分我還沒有太多的研究，所以可能沒辦法分享相關的資訊給大家。\n所以總結來說的話，Elasticsearch 的 function_score 目前是處在一個有那麼一點點尷尬的位置，不過他雖然效果有限，但是至少在過渡期是可以拿來擋一下的，畢竟要引入 AI、要實作更厲害的推薦排序演算法，可能就意味著更多的錢錢投入，在成本的考量之下，或許 function_score 還能算是一個高 cp 值的替代方案吧XD。\n結語 # 這篇文章我們深入了解了 Elasticsearch 的進階用法，了解要如何使用 function_score 實作多維度的推薦排序，如果大家知道什麼更神的推薦排序的演算法實作，也歡迎在底下留言分享～。\n如果你對後端技術有興趣的話，也歡迎免費訂閱《古古的後端筆記》電子報，每週二為你送上一篇後端技術分享，那我們就下一篇文章見啦！\n補充：我開設的 Spring Boot 零基礎入門、Spring Security 零基礎入門、GitHub 免費架站術 已在 Hahow 平台上架啦！輸入折扣碼「HH202601KU」即可享 85 折優惠。\n","permalink":"https://kucw.io/blog/elasticsearch-function-score-intro/","tags":null,"title":"Elasticsearch 進階用法，如何透過 function_score 自定義排序結果？"},{"categories":["Elastic Search"],"contents":"Elasticsearch 可以說是長年霸佔「全文搜尋」排行榜的第一名，不管是在使用者的產品開發上、還是在內部的 log 系統中，也都常常能看見 Elasticsearch 的身影，因此這篇文章我們就來介紹一下，Elasticsearch 到底是什麼吧！\n目錄 什麼是 Elasticsearch？ 在以前的 SQL 資料庫時代 使用 Elasticsearch 之後 什麼是反向索引（Inverted Index）？ Elasticsearch 介紹 Elasticsearch 總結 補充：反向索引的實戰經驗分享 結語 什麼是 Elasticsearch？ # 首先 Elasticsearch 其實是由兩個單字 Elastic 和 Search 所組成，因此念法上就會唸成 Elastic Search，只不過官方的產品名稱是全部縮寫在一起而已。\n而 Elasticsearch 本身是一個強大的「全文搜尋」（Full-Text Search）工具，也就是一個「能夠讓你自己架設搜尋引擎」的工具。所以簡單的說，Elasticsearch 的目標就是「讓使用者能夠快速的從一堆數據中，找到他想要的資料在哪裡」，也就是搜尋引擎最重要的作用了。\n不過在我們開始介紹 Elasticsearch 到底是強在哪裡之前，我們可以先回頭來看一下，在 Elasticsearch 還沒有誕生之前，我們是如何使用 SQL 資料庫來實作「查詢」的功能的。\n在以前的 SQL 資料庫時代 # 想像一下，假設現在你要開發一個「評論」的網站，因此在你的資料庫中，就會有一張 review 的 table，裡面記錄了每一筆評論的詳細內容：\nreview_id review_text（評論內容） 1 I jumped out the brown fox 2 hello how are you 那麼問題來了，假設現在使用者輸入了 brown，要你查詢出帶有 brown 的評論，這時候你要怎麼實作？\n最直覺的做法，就是使用「SQL 的模糊搜尋 LIKE %」，從這些評論中找出到底哪些評論中包含 brown 這個單字，因此通常就會寫出類似於下方的 SQL 語法，去資料庫中查詢所有評論。\nSELECT * FROM review WHERE review_text LIKE \u0026#34;%brown%\u0026#34; 雖然上述的作法能夠查詢出帶有 brown 單字的評論，但是這個查詢的效率實在是太差了！因為模糊搜尋沒辦法使用 index 來加速查詢效率，只能呆呆的一筆一筆數據去比對，因此縱使這個方法勉勉強強能夠解決查詢的問題，但是卻解的不夠漂亮。\n所以為了更好的解決這個問題，Elasticsearch 就被發明出來了！\n使用 Elasticsearch 之後 # 在 Elasticsearch 中，一樣是會先對每一筆 review 評論建立一筆數據（在 Elasticsearch 中稱為「文件」），並且因為 Elasticsearch 是屬於 NoSQL 資料庫，所以會使用 JSON 格式來儲存該文件。\n[ { \u0026#34;review_id\u0026#34;: 1, \u0026#34;review_text\u0026#34;: \u0026#34;I jumped out the brown fox\u0026#34; }, { \u0026#34;review_id\u0026#34;: 2, \u0026#34;review_text\u0026#34;: \u0026#34;hello how are you\u0026#34; } ] 其實到這邊其實都跟上面的 SQL 資料庫一模一樣，只是 Elasticsearch 換個方式用 JSON 儲存而已，到目前為止沒有任何的差別。\n不過！！重點來了！！Elasticsearch 之所以能夠快速的查詢出「帶有 brown」的評論，就是因為 Elasticsearch 在插入一筆文件時，會預先對該文件建立「反向索引」（Inverted Index），因此之後就可以借助「反向索引」的力量，快速的找出相關評論。\n什麼是反向索引（Inverted Index）？ # 舉例來說，當 Elasticsearch 插入一筆數據 hello how are you 時，他除了正常的插入一筆文件之外，他同時也會將 hello how are you 拆分成許多不同的小單字，譬如說會拆分成 hello、how、are、you 這四個字，並且 Elasticsearch 會將這些單字「對應」到該筆評論數據上。\n因此後續當使用者查詢 hello 或是查詢 are 時，Elasticsearch 就可以去檢查反向索引，如果有任何一個命中的話（譬如說命中 hello 這個反向索引），那麼就可以根據反向索引，去找出該索引指向的真實的數據（也就是 hello how are you 這個評論），這樣子就可以快速的在大量的資料中，去找到我們想要的數據了！\n也因為在整個 Elasticsearch 的世界中，他不僅要儲存每一筆真實的評論數據之外，Elasticsearch 同時也需要為每一筆評論數據生成對應的反向索引，因此佔用的數據空間會比一般的 SQL 資料庫還要多，不過這其實也是演算法中典型的「用空間換取時間」的概念，即是先對數據進行預處理，將數據處理成好查詢的方式，等到未來需要時就可以馬上查詢，就可以達到「降低查詢時間」的終極目標了！\nElasticsearch 介紹 # 了解了 Elasticsearch 中最最最核心的「反向索引」的概念之後，我們再回頭來看 Elasticsearch 的介紹時，就可以比較看得懂了。\n所謂的 Elasticsearch，他是一個強大的「全文搜尋」（Full-Text Search）工具，目標是讓我們可以從大量的數據中，快速找到想要的資料在哪裡。而 Elasticsearch 之所以可以做到這件事，就是因為他使用了「反向索引」（Inverted Index）的設計，先對數據進行預處理，因此才能夠在查詢時達到比傳統 SQL 資料庫更高的效率。\n也因為 Elasticsearch 的專長是「全文搜尋」，所以一般通常會將他用來「架設搜尋引擎」，因此像是旅遊攻略、評論、社群貼文、電商產品\u0026hellip;等等諸如此類的查詢，背後都很適合使用 Elasticsearch 來實作！\n圖片來源： Elasticsearch 官網 而除了一般的功能開發之外，Elasticsearch 也很常拿來用在內部系統中，最常見的就是用來「收集所有系統的 log」，這樣子 DevOps 或是後端工程師就可以搭配 Kibana、Grafana 之類的 UI 介面，從 Elasticsearch 中直接查詢 log 的資料，就不用再登入每一台 server 中去找 log 了！\nElasticsearch 總結 # 所以總結來說，只要牽扯到「全文搜尋」，基本上就是 Elasticsearch 的天下（當然 FAANG 大廠自行研發的搜尋引擎除外，他們的數據量真的太大，應該不是用 ES），並且內部的 log 系統通常也都是用 ELK 三兄弟來建置，所以了解一下 Elasticsearch 的用法絕對是很吃香的！\n大家如果對 Elasticsearch 有興趣的話，後續也可以參考 Elastic 官網的文件教學，或是我很久很久以前也有寫過一些 Elasticsearch 的文章，大家有興趣的話也可以參考看看～（不過這些文章年代有點久遠，可能很多東西已經不適用了，後續有時間我再來把這部分重寫一下）。\n補充：反向索引的實戰經驗分享 # 最後再跟大家補充一個我經歷過的 Elasticsearch 反向索引的真實故事…\n前面有提到，「反向索引」就是會預先把真實的數據 hello how are you 拆分成一個一個的小單字 hello、how、are、you，並且 Elasticsearch 會將這些單字「對應」到該筆數據上，而這個「拆分單字」的過程，稱為「分詞」（或是「斷詞」），而就是這個「分詞」，搞的我非常痛苦啊🥹…\n首先 Elasticsearch 中的分詞預設都是以英文為主，所以 hello how are you 就可以根據空白鍵很簡單的進行拆分，但是如果你的 input 是中文的話，那就是災難的開始惹！！！\n舉例來說，假設你的 input 是 我想吃小籠包，那麼 Elasticsearch 預設會拆分成 我、想、吃、小、籠、包 這 6 個字，這就會造成一個現象，就是當使用者查詢「LV 包包」時，因為 包 命中了…所以可能就會出現 我想吃小籠包 的神奇回覆….🥹（使用者會覺得合理嗎？好問題）。\n即使使用 Elasticsearch 內建的 CJK（中日韓）分詞器，最終產生的效果也不太好：\nPOST _analyze { \u0026#34;analyzer\u0026#34;: \u0026#34;cjk\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;我想吃小籠包\u0026#34; } 拆分成 [我想, 想吃, 吃小, 小籠, 籠包] 也因為 Elasticsearch 對中文的支援真的太慘烈了，所以 GitHub 上甚至有一個 16.9k star 的專案 analysis-ik，專門就是在做中文分詞，用了這個之後才分得比較合理（拍謝我有點搞不懂 Elasticsearch 現在怎麼裝 plugin，沒辦法實際測試，但應該就是會分詞出 小籠包 這個單字）。\n所以大家如果後續想要拿 Elasticsearch 來實作中文的全文搜尋的話，建議一定要安裝這個 analysis-ik 的 plugin，對中文的分詞才會有比較明顯的改善（在此也感謝開源社區的大大們的貢獻🙏）。\n結語 # 這篇文章我們先介紹了什麼是全文搜尋（Full-Text Search），並且也透過 SQL 資料庫所面臨的困境，介紹 Elasticsearch 實際要解決的問題是什麼，希望可以幫助大家了解 Elasticsearch 的運作邏輯，搞懂反向索引（Inverted Index）的核心概念是什麼。\n如果你對後端技術有興趣的話，也歡迎免費訂閱《古古的後端筆記》電子報，每週二為你送上一篇後端技術分享，那我們就下一篇文章見啦！\n補充：我開設的 Spring Boot 零基礎入門、Spring Security 零基礎入門、GitHub 免費架站術 已在 Hahow 平台上架啦！輸入折扣碼「HH202601KU」即可享 85 折優惠。\n","permalink":"https://kucw.io/blog/elasticsearch-intro/","tags":null,"title":"Elasticsearch 是什麼？認識地表最強的全文搜尋工具！"},{"categories":["其他技術分享"],"contents":"在網路全球化的趨勢下，CDN 現今已經是一個很重要的技術了，但是 CDN 的用途到底是什麼？以及使用 CDN 的好處有哪些？這篇文章我們就來詳細了解一下吧！\n目錄 什麼是 CDN（內容傳遞網路）？ 海底電纜的故事 海底電纜的限制 CDN 如何解決網路傳輸的限制？ 補充：使用 CDN 的注意事項 使用 CDN 的三大好處 1. 降低網路延遲、降低頻寬成本 2. 提升網站可靠性、平衡流量 3. 防禦資安 DDoS 攻擊 CDN 總結 結語 什麼是 CDN（內容傳遞網路）？ # 所謂的 CDN，他的全稱是 Content Delivery Network，中文翻譯為「內容傳遞網路」，而 CDN 的用途，就是 「將靜態資源（ex: 圖片、影片、JavaScript 套件）部署到全球化的節點上，讓當地的居民可以更快速的取得到這些內容」。\n不過，在了解 CDN 所帶來的好處之前，大家要先對「海底電纜」有一點基本的認識，因此下面我們就先來介紹一下什麼是海底電纜，再回頭來說明 CDN 所帶來的好處有哪些。\n海底電纜的故事 # 大家有沒有曾經好奇過，為什麼我們人明明站在台灣，但是卻能夠看到美國網友所上傳的影片或梗圖呢？這確實是透過「網路」來傳遞沒錯，但是這個「網路」，他到底是如何從美國發送到台灣的？是透過衛星嗎？還是透過高壓電？還是說是透過微波通訊來傳遞？？\n特別像是台灣這種海島來說，我們四周都是海，感覺要拉高壓電也不太可能，全部透過衛星來傳遞成本也太高了，因此所謂的「海底電纜」，就是台灣主要的對外網路連線方式。\n大家可以把「海底電纜」想像成是中華電信在台灣四周海域中所鋪設的光纖，每一條光纖會長得像是下面這樣，也就是因為有鋪設這些海底電纜，因此我們的網路訊號才可以傳遞出去，外部的網路訊號也才可以傳遞進來。\n圖片來源： Inside the Extreme Life of Divers Repairing Billion $ Underwater Cables 而其實不光是中華電信，很多大型企業如 Google、Amazon\u0026hellip;等，也都會鋪設自己的海底電纜！像是 Google 一直以來都有海底電纜的鋪設計畫，下圖就是 Google 目前為止所鋪設的海底電纜。\n圖片來源： Google Cloud 據點 而 Google 自己鋪電纜的好處是可以拉一條專線給 Google 自己的服務使用，確保未來不會因為各種因素（ex: 地緣政治）導致全球化的網路失效。\n所以在現今的網路時代下，我們人處在台灣卻可以刷著 YouTube、Instagram，觀看其他國家的人所上傳的影片，背後就是因為有海底電纜在進行網路數據的傳輸。\n海底電纜的限制 # 而說到這裡，就不得不提一下海底電纜的一些物理限制了。\n因為海底電纜畢竟還是屬於光纖網路，因此 「兩者距離越長，傳輸的時間就要越久」，這個完全是物理上的限制，現今沒有更好的方式可以解決。\n所以換句話說，即使台灣和美國之間有一條海底電纜，能夠把彼此的網路串接在一起，但是彼此傳輸的時間仍舊需要很久，可能你人在台北，傳一張圖片給高雄的朋友只要 1 秒，但是傳給海的另一邊的美國朋友卻需要 20 秒，這個就是海底電纜的網路傳輸限制，專業術語稱為 「latency（延遲）」。\n因此簡單的說的話，物理距離越遠，你們之間的網路 latency 就會越高，因此就算全球化的海底電纜能夠將你我連接在一起，但是這個使用者體驗其實是不太好的。\n所以為了解決這個問題，CDN 就出現了！！\nCDN 如何解決網路傳輸的限制？ # 基於上述的限制，現在我們知道 「物理距離越遠，傳輸的時間就要越久」，那麼，我們是不是只要把圖片放在離使用者近一點的地方，這樣子使用者就可以更快的拿到那張圖片了？沒錯！！這個就是 CDN 的核心邏輯，也就是 「將靜態資源（ex: 圖片、影片、JavaScript 套件）部署到 全球化 的節點上，讓 當地的居民 可以更快速的取得到這些內容」。\n舉例來說，當 Netflix 製作完一部新的影集之後，他除了把這個影集上傳到美國的主 server 之外（稱為 Origin Server），他還可以把這部影集也上傳到其他地區的 server（稱為 Edge Server），譬如說日本、台灣、新加坡、澳洲…等。\n因此到時候，使用者就可以「就近」挑選離他最近的 Edge Server，並且可以直接從該 Edge Server 中串流一模一樣的影集觀看，因此就可以達到「降低網路傳輸時間」的好處了！\n所以透過 CDN，Netflix 就可以在世界各地提供高品質、無延遲的影片觀看服務了！\n補充：使用 CDN 的注意事項 # 不過在這邊要再特別提醒一下，只有「靜態資源」（ex: 圖片、影片、JavaScript 套件\u0026hellip;等檔案）才能夠放在 CDN 上，借助 CDN 的力量擴散到全世界，因此像是後端程式的動態處理，這些是沒辦法放到 CDN 上面的，只能夠自己在雲端中部署。\n所以基本上在後端開發中，最常見的部署到 CDN 上的就是影片和圖片，其他像是前端的 JS 等相關檔案，因為後端不太會接觸到，所以比較少需要處理這部分。\n使用 CDN 的三大好處 # 了解了 CDN 的用途和限制之後，接下來我們也可以來看一下使用 CDN 的三大好處。\n使用 CDN 有三大好處，分別是：\n降低網路延遲、降低頻寬成本 提升網站可靠性、平衡流量 防禦資安 DDoS 攻擊 1. 降低網路延遲、降低頻寬成本 # 使用 CDN 的第一個好處，就是可以降低網路延遲和頻寬成本。\n降低網路延遲其實就是 CDN 當初被發明出來的目的，也就是上面所介紹的內容，透過將靜態資源部署在「全球化」的 Edge Server 上，就可以讓「當地的居民」就近取得到相關內容，降低網路傳輸的延遲，進而提升使用者體驗。\n而且也因為有了 CDN 之後，台灣人就可以就近取得影片，因此 Netflix 就不需要每次都把影片從美國傳到台灣，也就可以降低海底電纜的傳輸頻寬成本了。\n2. 提升網站可靠性、平衡流量 # 使用 CDN 的另一個好處，就是可以提升網站的可靠性、以及平衡相關的流量。\n舉例來說，假設 Netflix 在台灣的 CDN 節點掛掉了，那就可以趕快把台灣的流量轉移到附近地區（ex: 日本、香港、新加坡），確保台灣的 Netflix 用戶能夠繼續觀看劇集（雖然這不可避免地會多增加一些網路延遲，但是總比完全不能看好）。\n除此之外，即使台灣的 CDN 節點沒掛掉，Netflix 也可以根據台灣的尖峰流量，動態的調整香港的 CDN 來協助分攤，因為有的時候可能台灣某一陣子很瘋某個劇，流量就會大量上升，因此這時候就可以讓附近的 CDN 一起幫忙分擔流量，降低台灣 CDN 節點的負擔。\n3. 防禦資安 DDoS 攻擊 # 使用 CDN 的第三個好處，是可以防禦資安相關的 DDoS 攻擊。\n不過這部分我其實還不太熟，因此只能先貼相關的連結給大家參考（Cloudflare 官方的 CDN SSL/TLS | CDN security）。\n其實資安的部分算是使用 CDN 的附加好處啦，因為這跟 CDN 最一開始要解決的問題不太一樣，算是大家先因為「降低網路延遲」的原因用了 CDN 之後，才發現 CDN 在資安的表現上也很讚這樣，因此目前也常常會透過 CDN，來避免相關的資安攻擊。\n更新：以下是來自 Kuma 大大使用 CDN 防禦 DDoS 的實務經驗分享！大家有興趣也可以追蹤他的 YouTube 頻道：Kuma 老師的軟體工程教室。\nDDoS 我可以粗淺的補充一下，以前我前公司被打爆勒索過。\n如果你把 domain name 直接指到你的伺服器，當網路上的惡意人士要攻擊你的服務，只要一直大量發垃圾請求過來，你的機器與網路忙著處理這些垃圾請求就飽了，自然服務就斷了。\nCDN 提供的防禦原理說到底就是頻寬夠寬，我們讓整套機器躲到 CDN 後面去，外界只能透過 CDN 存取我們提供的資料，沒有人知道我們機房實際位址在哪。這時惡意人士要來 DDoS ，他首先要面對 CDN 自帶的超大量頻寬。\n要知道要發攻擊別人的封包也是要錢的。像 Cloudflare 這種大公司的防禦頻寬，一般人的財力根本打不下來。既然花了錢又打不下來，那本益比一算，我當然就選擇打別人去了。\n說到底就是口袋深不深跟拳頭粗不粗的問題。\nCDN 總結 # 所以總結上面的介紹，所謂的 CDN，他的全稱是 Content Delivery Network，中文翻譯為「內容傳遞網路」，而 CDN 的用途，就是 「將靜態資源（ex: 圖片、影片、JavaScript 套件）部署到全球化的節點上，讓當地居民可以更快速的取得到這些內容」。\n而在使用了 CDN 之後，可以有三大好處：\n降低網路延遲、降低頻寬成本 提升網站可靠性、平衡流量 防禦資安 DDoS 攻擊 也因為 CDN 可以說是在現今全球化的浪潮下，必備的技術和服務，因此了解 CDN 實際要解決的問題、以及他的來龍去脈，可以更好的理解 CDN 的設計邏輯。\n如果大家對於 CDN 有興趣的話，後續也可以參考 ByteByteGo 錄製的這支影片 What Is A CDN? How Does It Work?（英文），裡面不只有提到本文的內容，還有補充 CDN 是如何「就近」尋找附近的節點的技術，大家有興趣也可以再研究一下～\n結語 # 這篇文章我們先介紹了什麼是海底電纜，也介紹了 CDN 實際上要解決的問題是什麼，最後也補充了使用 CDN 的三大好處，希望可以幫助大家對 CDN 有一個比較全面的了解。\n如果你對後端技術有興趣的話，也歡迎免費訂閱《古古的後端筆記》電子報，每週二為你送上一篇後端技術分享，那我們就下一篇文章見啦！\n補充：我開設的 Spring Boot 零基礎入門、Spring Security 零基礎入門、GitHub 免費架站術 已在 Hahow 平台上架啦！輸入折扣碼「HH202601KU」即可享 85 折優惠。\n","permalink":"https://kucw.io/blog/cdn/","tags":null,"title":"CDN 是什麼？一次搞懂 CDN 的用途和三大好處"},{"categories":["其他技術分享"],"contents":"只要是後端開發，多多少少都會有一些撰寫定時任務的需求，像是每天晚上 10 點固定處理報表、或是每 30 分鐘處理一批次的任務\u0026hellip;等等，因此這篇文章我們就來介紹一下，這個「定時任務」的語法到底要怎麼寫吧！\n目錄 什麼是 Cron？ Cron 表達式的寫法（5 個 *） 補充：Cron 表達式的進階用法 Cron 總結 補充：Spring Boot 的 Cron 表達式寫法（6 個 *） 結語 什麼是 Cron？ # 所謂的 Cron，其實是 Linux 系統下的一個定時任務管理服務，但是因為 Cron 的表達式實在是太萬用了，所以目前也很廣泛用在 GitHub Actions、Spring Boot 的 @Scheduled\u0026hellip;等框架上。\n舉例來說，只要大家有看過類似的表達式 - cron: \u0026quot;0 21 * * *\u0026quot; 或是 @Scheduled(cron = \u0026quot;0 0 21 * * *\u0026quot;) 的寫法，裡面的一堆莫名其妙的 *，其實就是 Cron 的「定時任務」的寫法！\n因此像是在上面這兩個例子中，\u0026quot;0 21 * * *\u0026quot; 指的其實就是「每天晚上 9 點整執行一次這個任務」的意思。\n不過也因為 Cron 的表達式實在是有點抽象，所以下面我們就來介紹一下 Cron 中的每一個 * 代表的意義，來徹底了解一下如何使用 Cron 寫出我們想要的時間吧！\nCron 表達式的寫法（5 個 *） # 在 Cron 中，最傳統且常見的表達式為「5 個 *」，不過因為 Spring Boot 本身的設計不太一樣，所以 Spring Boot 會採用「6 個 *」 的方式來撰寫（因此大家如果不是寫 Java/Spring Boot 的話，就只要看上半部分的 Cron 傳統寫法就好，但如果是寫 Java/Spring Boot 的話，建議也要把下面的補充部分看完）。\n而如果要寫出 Cron 的傳統表達式（5 個 * 的版本），首先必須要先寫出 5 個 *，並且每個 * 之間要用一個空白鍵隔開，所以最基本的 Cron 表達式就會像是下面這個樣子：\n* * * * * 而這 5 個 *，他們所站的每一個「位置」，就會代表不同的意思，譬如說左邊數過來第一個 * 是表示「分鐘」的意思，左邊數過來第二個 * 是表示「小時」的意思…以此類推，因此這 5 個 * 的實際意義，可以用下面這張圖來表示：\n所以舉例來說，假設 Cron 表達式為 0 16 * * *，那就是表示「我們指定在每天的 16:00」要執行一次這個任務（因為我們設定了第一個 * 為 0，第二個 * 為 16，所以就是表示我們指定要在分鐘數為 0、並且小時數為 16 的時候執行任務，因此 0 16 * * * 的結果才會是在每天的 16:00 執行任務）。\n再舉一個例子，假設 Cron 的表達式為 23 1 * * *，就是表示我們指定在「每天的凌晨 1 點 23 分」要執行這個任務。\n再再舉一個例子，假設 Cron 的表達式為 59 23 * * *，就是表示我們指定要在「每天的晚上 23:59 分」執行任務。\n所以對於 Cron 表達式而言，只要你將某一個 * 改為一個確切的數字，其實就是指定要在「那個時間點」執行任務，就只是這樣子而已！！Magic！！\n不過另外也補充一下，除了有被修改過的數字，其他維持原樣的 * 則是表示「所有」的意思，所以像是 23 1 * * *，就只有前面的 23 1 的「凌晨 1 點 23 分」是固定的，其他的 * * * 則是表示「所有」，也就是在「所有日期、所有月份、所有星期」底下的「凌晨 1 點 23 分」，都會執行當前這個任務，因此 23 1 * * * 才會被解讀成「每天的凌晨 1 點 23 分」。\n下面再舉更多的例子給大家參考：\nCron 表達式 實際意義 備註 0 21 * * * 在每天的晚上 21:00 執行一次任務 * * * * * 每分鐘都要執行一次任務 0 * * * * 在每個小時的 0 分執行一次任務（ex: 1 點 0 分、2 點 0 分…. 23 點 0 分） 0 0 * * 5 在每週五的 0 點 0 分執行任務 但一般會避免寫 0 點 0 分這種數字，因為 0 點 0 分是一天的開始，所以如果是要進行那種「當天晚上結算的任務」，改成 23:59 會比較好 59 23 * * 0 在每週日的 23 點 59 分執行任務 注意 0 是週日（Sunday），1-6 是週一到週六 30 10 1 * * 在每個月的 1 號的早上 10:30 分執行一次任務 所以透過上面的例子，我們就可以指定「現在是想要在哪一天、哪一個小時、哪一分」，去執行我們想要執行的任務了！\n補充：如果想要自己玩玩看 Cron 表達式，也可以到 Crontab.guru 這個網站玩一下，他不僅有基礎教學，還可以檢測你寫的 Cron 表達式是否正確，因此也很推薦大家在撰寫 Cron 表達式時先丟上來檢查一下，確認沒問題之後再寫進程式裡面。\n補充：Cron 表達式的進階用法 # 不過，Cron 除了有上述的常見用法之外，Cron 其實有更進階的用法，但以下這些用法其實我自己也用的不多，所以建議大家參考就好。\n舉例來說，在上面的 Cron 的基本用法中，當我們寫 30 10 * * * 時，就是要在「每天的 10:30」執行任務，很直覺對吧，但是如果我們寫成 */3 10 * * * 時，就是表示要在「每天的 10 點 0 分、10 點 3 分、10 點 6 分、10 點 9 分\u0026hellip;（不斷加三分鐘）\u0026hellip;、10 點 54 分、10 點 57 分」執行任務。\n除此之外，我們也可以改寫成是 30 10-15 * * *，則是表示要在「每天的 10:30、11:30、12:30、13:30、14:30、15:30」執行任務。\n再或者，我們也可以改寫成是 30 10,23 * * *，表示要在「每天的 10:30 和 23:30」執行任務（這個好用）。\n所以在 Cron 的進階用法中，已經進展到「不只是指定某個特定的時間點了」，而是變成「指定一段時間區間」或是「指定時間的變動方式」了，因此大家如果有比較特殊的需求，就可以研究一下 Cron 的進階用法，寫出最符合你想要的時間表達式。\n這邊也是舉更多的例子給大家參考，或是大家也可以直接到 Crontab.guru 上測試，他也有支援進階的用法。\nCron 表達式 實際意義 0 22 * * 1-5 在週一到週五的每天晚上 22:00 執行任務 23 12-20/2 * * * 在每天的 12:23、14:23、16:23、18:23、20:23 執行任務 30 10,11 * * 0 在每週日的 10:30 和 11:30 執行任務 59 23 1 */2 * 在每個奇數月（1、3、5、7、9、11）的 1 號的 23:59 執行任務 Cron 總結 # 所以總結上面的介紹的話，Cron 原本是 Linux 中的一個定時任務管理工具，但是因為他的表達式實在是太好用，所以現在很廣泛使用的定時任務的表達上面。\n而常見的 Cron 為 5 位數（預設是 5 個 *），每一個位數分別代表了「分鐘」、「小時」、「日期」、「月份」、「星期幾」的含義，因此大家就可以透過修改不同位數的值，用來表達你想要在哪個時間點執行任務了！\n補充：Spring Boot 的 Cron 表達式寫法（6 個 *） # 在 Spring Boot 中，如果我們想要使用 @Scheduled 創建一個定時任務的話，則是要使用 「6 個 *」 來撰寫（注意是 6 個！！6 個！！！！），而這個多出來的一個 *，其實就只是往左擴充一個「秒數」的功能而已。\n所以在 Spring Boot 中的 Cron 表達式，就會是下面這個樣子：\n因此在 Spring Boot 中，要實作 @Scheduled 時，就要先寫出 6 個 *，然後才是根據不同的位置，去指定不同的時間點，而這部分其實就跟上面的 Cron 表達式一模一樣，所以只要 5 個 * 的版本有學好，6 個 * 版本就只是往左多擴充一個「秒數」部分而已！\n所以像是我們可以寫 @Scheduled(cron = \u0026quot;11 59 23 * * *\u0026quot;)，就是表示要在「每天的 23 點 59 分 11 秒（23:59:11）」執行任務，而當我們寫 @Scheduled(cron = \u0026quot;* 0 10 * * *\u0026quot;) 時，則是要在「每天的 10:00:00、10:00:01、10:00:02\u0026hellip;（不斷加一秒鐘）\u0026hellip;、10:00:58、10:00:59」執行任務。\n也因為 Spring Boot 所使用的 Cron 表達式是 6 位數，因此在實作 Spring Boot 時，就要特別注意 Cron 的最左邊是「秒數」，所以千萬不要直接複製網路上常見的 Cron（5 位數）到 Spring Boot，Spring Boot 會毀滅的🥹（最常見的作法就是把最左邊那一位補 0，表示要固定在 0 秒運行，這樣就和 5 位數的 Cron 表達式運行的時機點一樣了）。\n結語 # 這篇文章我們介紹了 Cron 的表達式的寫法，並且也補充了 Spring Boot 中的 Cron 的寫法，希望讓大家對於 Cron 有更多的了解。\n如果你對後端技術有興趣的話，也歡迎免費訂閱《古古的後端筆記》電子報，每週二為你送上一篇後端技術分享，那我們就下一篇文章見啦！\n補充：我開設的 Spring Boot 零基礎入門、Spring Security 零基礎入門、GitHub 免費架站術 已在 Hahow 平台上架啦！輸入折扣碼「HH202601KU」即可享 85 折優惠。\n","permalink":"https://kucw.io/blog/cron/","tags":null,"title":"Cron 是什麼？定時任務的語法怎麼寫？"},{"categories":["自媒體經營"],"contents":"哈囉，我是古古，這篇文章是每月一次的自媒體月報，主要分享我經營《古古的後端筆記》個人品牌的幕後秘辛，如果你也對於「自媒體創業」有興趣的話，歡迎繼續閱讀本文～\n補充：如果想了解《古古的後端筆記》電子報的起源，也可以先查看創刊號的文章。\n2025.2 月粉絲追蹤數、電子報訂閱人數 # 本月份（2025.2）的粉絲成長人數如下：\n2025/1/28 人數 2025/2/25 人數 2 月份（1 月份）總成長人數 Facebook 粉專追蹤數 4547 4607 +60（+72） 電子報訂閱人數 2872 3079 +207（+392） Threads 粉絲追蹤數 7354 8135 +781（+1358） IG 粉絲追蹤數 600 688 +88（+111） 這個月的數據也是順順成長，雖然數據可能相比上個月有稍微降低，但也是因為我這個月比較忙碌，比較沒辦法很好的兼顧社群的營運，所以才會這樣。\n等到之後比較穩定之後，應該就比較有時間可以跟大家在社群上互動惹！在此之前可能只有在電子報才看得到我😂，大家如果有什麼想跟我說的悄悄話可以直接私訊我 or 回信給我，我看到都會盡量回的🙏。\n本月的自媒體主題：電子報為什麼又開始紅了？ # 這個月剛好有一個自媒體主題很想跟大家分享，所以就借月報的篇幅來寫了，那就是：「電子報為什麼又開始紅了？」。\n最近看到台灣越來越多人開始寫電子報，覺得很讚！其實電子報作為上古時代的行銷產物，曾經有一度是被大家唾棄的，曾經我們對電子報的印象是「促銷信件」，就是那種直接會被你丟到垃圾信件的廣告信，但是現在我們對電子報的印象卻是「吸取知識的管道」，到底為什麼電子報有這麼大的轉變？今天就來討論一下這個話題吧！\n電子報和其他社群媒體有一個最最最不一樣的差別，在於 「曝光度」，也就是俗稱的 「流量」。\n其實在現今的社群媒體中（不管是 Facebook、Threads、YouTube、抖音），當創作者寫完一篇文章之後，其實這篇文章不一定會被我的讀者所看到。\n舉例來說，當我在 Facebook 上發一篇文時，可能只有三分之一的追蹤者能看到這篇文章，其他的追蹤者是「根本連看都沒看到，連想按讚的機會都沒有」，而為什麼會有這個差別？就是 Facebook 的演算法所導致的。\n目前的演算法是當你發一篇文之後，他會先小範圍的散播這篇文章給你的部分追蹤者，假設這些追蹤者的反應很好（譬如說按讚、留言、分享），那麼演算法就會覺得這篇文章是個好文，所以就會再把這篇文章擴散出去，讓更多人能看到這篇文章。\n但如果反過來呢？假設你寫的文章沒什麼人按讚分享，那麼演算法就會覺得這篇文章不好，因此後續就不會推送這篇文章給其他人，因此這篇文章的觀看人數就會非常少，原因就是因為被演算法給掐滅了。\n所以在大社群時代下，只有 Facebook 這種平台是贏家，我們這些小創作者都只是他的囊中之物而已，今天 Facebook 心情好，他就會將你的文章推送給更多人，假設今天他心情不好，你寫的任何寶藏文章都沒人看得到，這就是演算法的機制，也就是 「曝光度」 的概念。\n那麼，要打破這個機制，有沒有其他解決方案呢？有的，那就是電子報！！\n電子報有一個特性，就是 「創作者可以直接把他寫的文章交到你手上」，舉例來說，只要我有你的信箱，我寫的每一封電子報，都可以確保這封信一定會進到你的信箱裡面。\n所以對於電子報而言，再也沒有「曝光度」的問題了，只要我肯寫，只要你肯讀，創作者和讀者之間一定可以維持某種聯繫，再也不會發生「我寫了，但是你沒收到」的幽靈情況出現。\n並且電子報還有一個附加價值，就是 「隱私性」，舉例來說，假設我在 Facebook 上公開發一篇文，可能你對於電子報中的某個議題很感興趣，但是又不好意思在下面留言，私訊好像又有點麻煩，所以就作罷。\n但是電子報可以直接透過「回信」的方式，就可以直接讓讀者有一個窗口和創作者對話，並且這個過程是完全隱私的！！！只有讀者和創作者彼此知道信件內容而已，因此寫起來可以更隨心所欲一點，不用擔心會被第三者看到。\n所以基於上述的種種好處，電子報就從以往的促銷信件時代，轉換成了大知識時代，將來可能會有越來越多創作者同時經營「電子報 + 社群平台」（我現在就是這樣），除了持續在 Facebook 等社群平台打造影響力之外，同時也確保喜歡我的內容的讀者真的可以收到我創作的內容，不然寫了那麼久的文章，結果最終被 Facebook 吃掉，沒辦法傳遞給想閱讀的讀者手上，還是會有點難過的🥹。\n希望後續台灣也會有越來越多的創作者使用電子報進行創作，讓這些精彩的內容可以被看見，而不是埋沒在社群平台的底下。\n本月撰寫的電子報主題、文章 # 這邊記錄了我這個月撰寫了哪些電子報和文章，大家如果對於其中的內容有興趣的話，也可以前往查看：\nDNS 是什麼？在瀏覽器中輸入 URL 會發生什麼事？ Polling 和 Webhook 是什麼？如何更有效的串接第三方系統？ Http 中的 GET 和 POST 的差別在哪裡？ 2025.2 月報總結 # 呼～這個月大概是這樣吧！電子報的部分因為覺得很有共鳴所以打的有點長😂，希望你們會喜歡這類內容。\n那我們就下個月再見啦！\n","permalink":"https://kucw.io/blog/as-a-content-creator/monthly-report-202502/","tags":null,"title":"軟體工程師的自媒體之路 - 2025.2 月報"},{"categories":["其他技術分享"],"contents":"在軟體開發中，Http 可以說是大家最常打交道的一個協議了，因此這篇文章就會來介紹一下 Http 中的 GET 和 POST 的差別。\n目錄 什麼是 Http Method？ GET 介紹 POST 介紹 GET 和 POST 總結 補充：GET 和 POST 的更多細節比較 結語 什麼是 Http Method？ # 所謂的 Http Method，就是在發送一個 API 時，所使用的請求方式。\n較常見的 Http Method 有以下四種：\nGET POST PUT DELETE 其中 GET 和 POST 是使用上最常見的兩種請求方法，所以接下來我們就來比較一下，GET 和 POST 之間的差別在哪裡吧！\nGET 介紹 # GET 是最常使用的 Http Method，大家可以把 GET 想像成是 「明信片」 的概念，也就是 「當你使用 GET 來請求時，你所傳遞的參數就會被別人看見」。\n舉例來說，在使用 GET 來請求時，我們就要將請求參數添加在 url 的最後面。因此在下面的例子中，我們就必須要將參數 id=123\u0026amp;name=Judy 添加在 url 的最後面（黃色區塊所示），這樣子才能夠成功傳遞參數給後端。\n所以在使用 GET 方法來請求時，所有的請求參數都是「公開的」，因此任何人都能查看參數的值，所以 GET 就像是「明信片」一樣，信中的內容可以被所有人查看。\n也因為使用 GET 來請求的所有參數都會被看見，因此如果你的請求參數是比較敏感的資訊（ex: 身分證字號、手機號碼），那就不建議使用 GET 方式來請求，因為這些數據會暴露在 url 中給其他人看到，可能就會導致數據的洩漏。\n甚至瀏覽器也會 cache GET 請求的 url，以記錄你曾經訪問過哪些網頁，因此使用 GET 來請求真的是走過路過都會留下痕跡，因此敏感數據絕對不可以使用 GET 來傳遞！！\n因此如果想要更隱私的傳遞參數，就可以使用下面的 POST 來實作。\nPOST 介紹 # 不同於 GET 是公開所有的請求參數，POST 就是相反過來，POST 會隱藏所有的請求參數，因此任何人都沒辦法取得其中的請求參數，所以 POST 也可以說是「信封」的概念，所有的內容都會好好的被封裝在信封內，不會隨意向外部展示。\n舉例來說，在使用 POST 來請求時，我們就要改成將請求參數添加在 request body 中，並且通常會使用 JSON 格式來添加數據。因此在下面的例子中，我們就會將 JSON 參數 {\u0026quot;id\u0026quot;: 123, \u0026quot;name\u0026quot;: \u0026quot;Judy\u0026quot;} 添加在 request body 中（藍色區塊所示），這樣子就能夠隱私的將參數傳遞給後端了。\n所以在使用 POST 方法來請求時，所有的請求參數都是「隱私的」，只有收件者（後端）都能查看，其他人是完全看不到的，因此就像是「信封」一樣，信中的內容會對其他人隱藏，只有收件者後端可以查看。\n也因為使用 POST 來請求時，所有的參數都會被隱藏起來，不被其他人所看見，因此像是比較敏感的資訊（ex: 身分證字號、手機號碼），就很適合使用 POST 來請求，確保敏感數據不會洩漏。\n補充：雖然 POST 是信封的概念，會將所有請求參數隱藏起來，但是駭客仍舊是可以透過其他招數來偷看裡面的內容，因此就算是 POST 來請求還是會有風險，所以仍舊需要做其他的資安加強（ex: Https），才能確保數據不會被駭客給偷走。\nGET 和 POST 總結 # 所以總結上面的介紹的話，就可以將 GET 和 POST 做一個比較：\nGET： 明信片的概念，將參數放在 url 中傳遞，並且所有參數都是「公開的」，任何人都能看見。 POST： 信封的概念，將參數放在 request body 中傳遞，並且會將所有參數「隱藏起來」，其他人都看不見。 所以大家以後就可以根據自己目前的 API 的需求，選擇最適合的請求方式了！\n補充：GET 和 POST 的更多細節比較 # 如果大家想了解更多關於 GET 和 POST 的技術細節，也可以參考下方的表格整理（資料來源：前后端数据交互(八)——请求方法 GET 和 POST 区别）。\nGET POST 上一頁、重新整理網頁 無影響 數據會重新被提交 收藏 可收藏至瀏覽器中的「我的最愛」 不可收藏 cache 能被瀏覽器、後端 cache 不能被 cache 歷史 參數會保存在瀏覽器的歷史中 參數不會保存在瀏覽器歷史中 安全性 較差，因為請求參數添加在 URL 中 較安全，因為參數不會被保存在瀏覽器的歷史中、也不會隨著 URL 被記錄在 log 裡 數據長度 有限制，因為 URL 的最大長度是有規範的（最大 2048 個字符） 無限制 使用情境 一般網頁讀取 表單提交、新增數據 結語 # 這篇文章我們先介紹了 GET 和 POST 的用法，並且也比較了他們之間的差別，其實就是一個是「明信片」、另一個是「信封」而已～\n如果還想了解更多關於 Http、API 設計的相關知識，也可以參考過往的文章：\n一文搞懂 Http Status Code，詳細解析 200、301、401、403、500、503 RESTful API 設計指南，3 個必備條件缺一不可！ 如果你對後端技術有興趣的話，也歡迎免費訂閱《古古的後端筆記》電子報，每週二為你送上一篇後端技術分享，那我們就下一篇文章見啦！\n補充：我開設的 Spring Boot 零基礎入門、Spring Security 零基礎入門、GitHub 免費架站術 已在 Hahow 平台上架啦！輸入折扣碼「HH202601KU」即可享 85 折優惠。\n","permalink":"https://kucw.io/blog/http-get-post/","tags":null,"title":"Http 中的 GET 和 POST 的差別在哪裡？"},{"categories":["其他技術分享"],"contents":"一般在實作後端系統時，如果想要去串接外部的第三方系統，這時候就會有兩種串接方式：Polling 和 Webhook，所以這篇文章我們就來了解一下 Polling 和 Webhook 之間的差別吧！\n目錄 什麼是 Polling？什麼是 Webhook？ 串接股票中心的故事 使用 Polling 來串接 使用 Webhook 來串接 Polling 和 Webhook 總結 補充：在 Webhook 的實作中，股票中心是如何通知我們的後端程式？ 結語 什麼是 Polling？什麼是 Webhook？ # 在串接第三方的系統時，我們可以使用兩種方式來串接，分別是 Polling 和 Webhook，而他們兩個在實作上其實是完全相反的兩種方式：\nPolling（輪詢）： 由「我們的後端程式」主動且瘋狂的去問「第三方系統」，詢問當前數據的值為何。 Webhook： 當數據有變動時，由「第三方系統」主動通知「我們的後端程式」，告訴我們數據已經變化了。 這個乍聽之下會覺得有點抽象，所以下面就透過一個例子，來介紹一下 Polling 和 Webhook 的差別。\n串接股票中心的故事 # 假設你現在想要實作一個後端的系統，當你偵測到某隻股票的價格低於某個點時（譬如說台積電股價跌破 1000 元），這時候你就要在後端系統中儲存當下的時間，如果是由你來實作這個後端程式，你會怎麼實作？\n使用 Polling 來串接 # 最直覺的做法，就是在你的後端程式裡面，每秒鐘都去 call 股票中心的 API，瘋狂的去問台積電現在的價格是多少，因此假設在 12:01 分時台積電的價格跌到 960 元，你就可以在你的系統中記錄當前的這筆時間。\n上面這種「不斷的去詢問股票中心 Server 當前的股價為何」的行為，就稱為是 Polling（輪詢）。\n但是上面這個做法有一個缺點，就是你 「每一秒」 都得要 call 一次股票中心的 API，才能知道當下的台積電股價，又因為一天有 86400 秒，所以你的後端程式一天就得要 call 股票中心的 API 86400 次，就會造成很大量的 API call，加重股票中心 server 的負擔。\n並且上面的做法除了會使得 API call 的數量飆升之外，其實在這些 API call 中，也不是每一次的 API 都很有用處。因為我們真正想要的功能，是「當台積電跌破 1000 元以下時，記錄當下的時間」，所以當台積電現在是 1100、1200、1300 元時，這些 API call 的返回值對我們都是沒有意義的，就只有跌破 1000 元的那個時間點，才是我們真正關注的部分。\n所以為了解決 Polling 的問題，Webhook 就出現了！\n使用 Webhook 來串接 # 在剛剛的 Polling 中，主動方是「我們實作的後端程式」，也就是由我們主動發起 API call，一直不斷地瘋狂去煩股票中心，問他現在台積電的股價是多少。\n而在 Webhook 中，則是會反過來，主動方變成是「股票中心」，也就是當台積電跌破 1000 元時，股票中心就會主動 call 我們的 API，通知我們台積電跌破 1000 元了！！\n所以在 Webhook 的設計中，主動方會變成是「股票中心」，只有當股票中心發現台積電跌破我們預期的值時，才發送通知給我們，在其他時間時，股票中心則是會什麼事都不做，完全不會 call 我們的 API，大大的減少了 API call 的次數。\n因此透過 Webhook 的設計，就可以將 API call 的次數降到最低，只有在台積電的股價跌破 1000 元時才會 call 一次我們的 API，比起前面的 Polling 的設計要 call 86400 次少多了！！因此在一般在實作上，通常會建議採用 Webhook 的設計，這樣子可以讓兩邊的 Server 負擔都不會那麼大，減少浪費的 API call 次數。\nPolling 和 Webhook 總結 # 所以總結上面的介紹的話，當我們在串接第三方的系統時，就可以使用兩種方式來串接，分別是：\nPolling（輪詢）： 由「我們的後端程式」主動且瘋狂的去問「第三方系統」，詢問當前數據的值為何。 Webhook： 當數據有變動時，由「第三方系統」主動通知「我們的後端程式」，告訴我們數據已經變化了。 因此下次大家在串接第三方系統時，就可以看一下他們的系統是否有支援 Webhook 的設計，如果有的話，就可以使用 Webhook 的方式來串接，這樣子就不用再瘋狂的一直去重複大量的 API call 了！\n補充：在 Webhook 的實作中，股票中心是如何通知我們的後端程式？ # 了解了 Polling 和 Webhook 的差異之後，這裡也順便補充一下 Webhook 的實作。\n因為 Webhook 的核心設計理念是「由股票中心變成主動方」，因此當台積電股價跌破 1000 元時，股票中心需要主動通知我們的後端程式，告訴我們台積電目前的股價。\n所以為了讓「股票中心有能力通知我們的後端程式」，需要實作兩個步驟：\n1. 我們需要先在我們自己的後端程式中，先新增一個新的 API\n首先我們需要在我們的後端程式裡面，先新增一個 API 出來（假設叫做 /myapi），至於這個 API 的請求參數有哪些、以及這個 API 的請求方法（ex: GET、POST）為何，通常第三方系統都會有詳細的定義，到時可以查詢一下第三方系統的相關文件。\n@RestController public class MyController { @RequestMapping(\u0026#34;/myapi\u0026#34;) public void myApi(@RequestParam String stockName, @RequestParam Integer price) { // 記錄當前股價和時間 } } 2. 到第三方系統中，在 Webhook 處填上你的 /myapi 的 API\n創建好 API 之後，接著可以登入到第三方系統，然後通常就會有一個填寫 Endpoint URL 的地方（如下圖所示），讓你將你剛剛所創建的 /myapi 的 API 給填上來（這邊因系統不同而有不同的介面，甚至有的第三方系統沒有 UI 介面，要自己去跟他們的工程師對接）。\n只要完成了上述的步驟之後，未來當你預期的事件發生時（ex: 台積電跌破 1000 元），這時候第三方系統就會 call 你所填上的 API（也就是 https://example.com/myapi）。\n所以換句話說的話，當你的 /myapi 被 call 時，就表示台積電跌破 1000 元了，因此你就可以在這個 /myapi 的程式中，去實作你想要實作的功能（如記錄當前的股價和時間…等等），這樣子就可以和第三方系統成功使用 Webhook 串接在一起了！\n結語 # 這篇文章我們先分別介紹了 Polling 和 Webhook 是什麼，並且也比較了他們之間的差別，Polling 和 Webhook 可以說是在串接第三方系統時很常見的兩種方式，雖然目前比較流行的是 Webhook 的作法，但是多了解一下 Polling 的設計理念也是很可以的～\n如果你對後端技術有興趣的話，也歡迎免費訂閱《古古的後端筆記》電子報，每週二為你送上一篇後端技術分享，那我們就下一篇文章見啦！\n補充：我開設的 Spring Boot 零基礎入門、Spring Security 零基礎入門、GitHub 免費架站術 已在 Hahow 平台上架啦！輸入折扣碼「HH202601KU」即可享 85 折優惠。\n","permalink":"https://kucw.io/blog/polling-webhook/","tags":null,"title":"Polling 和 Webhook 是什麼？如何更有效的串接第三方系統？"},{"categories":["其他技術分享"],"contents":"相信大家在準備面試時，常常會遇到一題是「在瀏覽器中輸入 URL 會發生什麼事？」，而這背後其實就和 DNS 息息相關。\n因此這篇文章我們就來介紹一下，到底在瀏覽器中按下 URL 會發生什麼事，以及其背後的 DNS 原理吧！\n目錄 什麼是 DNS？ 在沒有 DNS 的年代 DNS 的雛形 現今 DNS 的全貌 DNS 總結 結語 什麼是 DNS？ # 所謂的 DNS，全稱是 Domain Name System（好像沒有中文翻譯），DNS 的用途在於「查詢某個域名的 IP 位置為何」，這個聽起來可能有點抽象，所以接下來我們就透過例子來了解一下 DNS 的用途到底是什麼。\n在沒有 DNS 的年代 # 首先回到最最最古老的年代，其實當我們運行一台 Server 起來時，這台 Server 擁有的只有 IP 位置而已，譬如說某一台 Server 就會運行在 142.250.196.206 這個 IP 上面，因此當前端想要 call 後端的 api 時，前端就是要 call http://142.250.196.206:80/api ，就可以訪問這台 Server 上所運行的後端程式了。\n所以到這裡要先掌握一個重點，就是 「前後端之間溝通，只需要知道對方的 IP 位置即可」，只要知道對方的 IP 位置，前端就可以直接去 call 該 IP 上所運行的 Server，去請求後端的數據了。\nDNS 的雛形 # 不過，雖然對於前後端來說，他們彼此之只要知道對方的 IP 就可以進行溝通，但是對於使用者而言，要記住這麼長一串的 IP 地址可是很累人的啊！！譬如上方所提到的 IP 例子 142.250.196.206，要記住這麼長一串 IP 位置是很痛苦的。\n但是如果我們能把這個 IP 位置，轉換成「一個簡單好記的英文單字」，這樣子是不是會更方便記憶？譬如說我們將 142.250.196.206 轉換為 google.com，google.com 總是比一串數字來的好記多了對吧！！也因為如此，DNS 就被發明出來了！！！\n大家可以把 DNS 想像成是一張很大很大的 table，他裡面會儲存 域名:IP位置 的一一對應，所以以上面的例子來說，就可以在 DNS 這張 table 中插入一筆 google.com 和 142.250.196.206 的對應關係。\n域名 IP google.com 142.250.196.206 \u0026hellip; \u0026hellip; 因此這時當使用者在瀏覽器中輸入 http://google.com/api 時，就會依序執行以下的步驟：\n使用者在瀏覽器中輸入 http://google.com/api 網址 瀏覽器詢問 DNS：「google.com 的 IP 位置是多少？」 DNS 查詢他的 table 中有沒有記錄 google.com 所對應的 IP 的值，因為 table 中有記錄（即是 142.250.196.206），所以 DNS 就會回覆瀏覽器：「google.com 的 IP 為 142.250.196.206」 瀏覽器知道 IP 位置之後，改成去請求 http://142.250.196.206/api，成功連線到後端 Server，因此就可以成功的去 call 後端的 api 了 後端返回 api 的數據 所以在其實在這整個前後端的溝通中，DNS 所負責的任務就只是「查詢一下 google.com 這個域名的 IP 位置為何」而已，比想像中單純對吧！DNS 至始至終都只是在記錄「域名和 IP 之間的對應關係」而已，只要掌握好這個核心邏輯就可以了！！\n補充：實際上 142.250.196.206 其實就是 Google 在台灣的一組 IP 地址，如果在瀏覽器中輸入 142.250.196.206 的話，就會跳轉到 https://www.google.com/ 上，大家有興趣也可以玩一下～。\n現今 DNS 的全貌 # 不過，雖然 DNS 所負責的任務就只是「查詢一下 google.com 這個域名的 IP 位置為何」而已，但是當這個域名數量變的很多很多很～～～多的時候，DNS 也逼不得已得進化一下，設計成更能符合當前量級需求的架構。\n因此在現今的 DNS 架構中，不會僅使用一張 table 來記錄所有的 域名:IP 的對應關係，而是會分成：\nRoot Name Server（根域名） TLD Name Server（頂級域名） Authoritative Name Server（權威域名） 這三層來依序將「域名」解析成「IP」。\n舉例來說，假設今天的域名是 www.googe.com，那 DNS 內部就會先拿著 www.google.com 去問 Root Server 這個該去找誰解析成 IP，Root Server 會先檢查這個域名的結尾（也就是 .com），因此就會叫 DNS 拿去找第二層的 .com TLD Name Server。\n而當 DNS 去問第二層的 .com TLD Name Server www.googe.com 的 IP 為何時，第二層的 .com TLD Name Server 就會去解析主域名（也就是 google.com），然後叫 DNS 拿著去找第三層的 google.com Name server。\n而當 DNS 終於抵達第三層的 google.com Name Server 時，DNS 就會一樣會問他 www.google.com 的 IP 為何，這時候第三層的 google.com Name Server 就會找出他的真實 IP 為何（也就是 142.250.196.206），然後將他回傳給 DNS。\n到這裡為止，DNS 內部才是真正的找出 www.google.com 所對應的 IP 地址為 142.250.196.206，因此就可以將這個 IP 地址回傳給瀏覽器，讓瀏覽器去請求這個 IP 地址了！\n不過即使 DNS 的內部架構變的稍微複雜一點，但是 DNS 實際上要做的事情仍舊是不變的！也就是「查詢一下 google.com 這個域名的 IP 位置為何」而已，因此如果覺得上面的 DNS 架構太複雜的話，暫時忘記他也是可以的，只要記得 DNS 的目的是「查詢域名的 IP 位置為何」就好，細節可以等真的要用到的時候再回來參考即可。\nDNS 總結 # 所以總結一下上面的介紹的話，所謂的 DNS，全稱是 Domain Name System，並且 DNS 的用途在於「查詢某個域名的 IP 位置為何」。\n而在 DNS 的內部架構中，為了提升查詢的效率以及提高能同時乘載的查詢量，所以 DNS 內部會分成三層（Root、TLD、Authoritative），根據域名的結尾不同，去分配到不同的 DNS Server 上，盡可能的分散每一台 DNS Server 所需要負責的查詢數量，讓這些 DNS Server 能夠承載目前世界上所有人的 IP 查詢。\n也因為 DNS 的用途在於「查詢某個域名的 IP 位置為何」，因此當使用者在瀏覽器中輸入某個 URL 時，實際上瀏覽器在背後就會偷偷先去詢問 DNS：「這個域名的 IP 為何？」，等到問到 IP 位置之後，瀏覽器才會實際去 call 該 IP 上所運行的後端服務，因此下次再有人問你「在瀏覽器中輸入 URL 會發生什麼事」時，你就可以大膽的回覆他「DNS 會先去\u0026hellip;」的答案了！\n補充：其實在瀏覽器拿到 Server 的 IP 位置之後，還會需要和 Server 建立 TCP/IP 的連線，等到建立完連線之後才能真正的 call API 取得數據，不過老實說 TCP/IP 的協議又更底層了，感覺只有網路通訊相關的工程師才需要了解這部分，如果大家有興趣的話可以再自行上網查詢相關介紹。\n結語 # 這篇文章我們介紹了 DNS 是什麼，並且也介紹了「在瀏覽器中輸入 URL 時」的運作流程，希望可以透過這篇文章，讓大家對 DNS 有更多的了解。\n如果你對後端技術有興趣的話，也歡迎免費訂閱《古古的後端筆記》電子報，每週二為你送上一篇後端技術分享，那我們就下一篇文章見啦！\n補充：我開設的 Spring Boot 零基礎入門、Spring Security 零基礎入門、GitHub 免費架站術 已在 Hahow 平台上架啦！輸入折扣碼「HH202601KU」即可享 85 折優惠。\n","permalink":"https://kucw.io/blog/dns/","tags":null,"title":"DNS 是什麼？在瀏覽器中輸入 URL 會發生什麼事？"},{"categories":["自媒體經營"],"contents":"哈囉，我是古古，這篇文章是每月一次的自媒體月報，主要分享我經營《古古的後端筆記》個人品牌的幕後秘辛，如果你也對於「自媒體創業」有興趣的話，歡迎繼續閱讀本文～\n補充：如果想了解《古古的後端筆記》電子報的起源，也可以先查看創刊號的文章。\n2025.1 月粉絲追蹤數、電子報訂閱人數 # 本月份（2025.1）的粉絲成長人數如下：\n2024/12/31 人數 2025/1/28 人數 1 月份（去年 12 月份）總成長人數 Facebook 粉專追蹤數 4475 4547 +72（+86） 電子報訂閱人數 2480 2872 +392（+404） Threads 粉絲追蹤數 5996 7354 +1358（+1430） IG 粉絲追蹤數 489 600 +111（+136） 這個月一樣是各項指標持續成長中（感謝大家的支持🙏） ，不過我最近其實想要回頭找工程師的工作了，所以想說剛好藉著這個自媒體月報的篇幅，也想跟大家分享一下「為什麼我做了自媒體之後，仍舊想要回頭找工程師的工作」。\n為什麼我做了自媒體之後，仍舊想要回頭找工程師的工作？ # 會想要回頭找工程師的工作，主要原因應該還是因為我在 2024 年的自媒體一年中過的不是很好，覺得「全職自媒體」這個行業可能不太適合我，自媒體可以是我的一個事業，但是沒辦法完全是我的主業這樣。\n可能是因為剛好我走的這條路是「技術自媒體」，我自己也很喜歡分享知識、教課，如果我自己沒有真的在第一線的程式上打拼的話，感覺自己好像會離技術越來越遠，並且也不確定自己目前分享的東西業界到底還有沒有在用、是不是其實分享了沒用的知識…等等，諸如此類的焦慮會很常浮現在我心中🥹。\n我想要變強，不想要原地踏步，但是有很多經驗是必須在第一線實戰中累積的，不管是解決問題的能力、團隊合作的能力、甚至是通靈客戶的能力（懂的都懂），這些都是得真實的和別人相處之後，才有辦法累積的實力，相較來說，「自媒體」終究只有「自己」，一個人的能力還是有極限的。\n不過我不是要放棄自媒體了唷！！我覺得自媒體作為一個副業來說還是很讚的👍，至少有一個管道可以分享最近學到的知識、可以抒發心情、可以認識到很多不同的大大們、可以幫助到需要幫助的人，這份工作對我而言真的很有意義。\n我希望將來可以在工作中越變越強，並且在變強之後，也想帶著大家一起變強，2025 年給自己的期許是「Sharing is Learning!」，我會努力做到的！\n所以如果總結一下的話，我會想要從「自媒體」回去做「工程師」，有以下幾點：\n「自媒體」會離業界越來越遠，不確定自己所知是否仍是業界主流，容易感到焦慮 「自媒體」是很自由沒錯，但是長期的精神壓力會很重（壓力來自於不確定感和不安感），不確定未來方向要往哪裡走、下一個客戶在哪裡 當「工程師」的好處有：可以磨練自己的技術、團隊合作能力、客戶通靈能力，並且可以參與大型的專案開發，累積系統架構的設計能力 同時兼顧「自媒體 + 工程師」感覺是目前最棒的選擇，但是要兼顧兩者真的很累（曾經兼過，那陣子都沒睡飽過），不知道是否能找出更平衡的兼顧方式 （2025 來找找看吧！） 目前的想法大概是這樣，想把目前的心情記錄下來，不僅給自己做一個記錄，也一起分享給大家～\n但我覺得人的每一個階段都會喜歡不一樣的東西啦，所以我也是有可能工作個 3、5 年之後，就又辭職跑去全職做自媒體了🤣，未來的事情誰知道呢？人生在世一場，如果能夠在每一個時間點，都做出不愧於自己的決定，應該就能盡量不留下遺憾了吧。\n希望 2025 年，我們都可以做出自己最想要的那個決定！\n本月撰寫的電子報主題、文章 # 這邊記錄了我這個月撰寫了哪些電子報和文章，大家如果對於其中的內容有興趣的話，也可以前往查看：\n電腦中的 RAM（記憶體）的用途是什麼？他和硬碟的差別在哪裡？ 如何成為資深工程師？心態最重要 Event Sourcing 是什麼？他和 CRUD 的差別在哪裡？ GPU 是什麼？為什麼 GPU 對 AI 的發展很重要？ 2025.1 月報總結 # 最近這幾個月都在忙著學習技術，比較沒有多餘的心力看自媒體的書了🥹，近期的目標應該會優先擺在找工作上，後續如果有比較多求職心得時，也再來跟大家分享求職的過程～\n那我們就下個月的月報再見啦！\n","permalink":"https://kucw.io/blog/as-a-content-creator/monthly-report-202501/","tags":null,"title":"軟體工程師的自媒體之路 - 2025.1 月報"},{"categories":["其他技術分享"],"contents":"在 AI 的浪潮下，GPU 可以說是一間公司的算力的體現，但是 GPU 到底是什麼？為什麼他對 AI 的發展這麼重要呢？所以這篇文章我們就來介紹一下，到底什麼是 GPU 吧！\n目錄 什麼是 GPU？ 影像處理簡介 GPU 和影像處理的關聯 為什麼 GPU 在 AI 時代這麼重要？ 補充：為什麼提升「訓練模型」的速度這麼重要？ GPU 總結 結語 什麼是 GPU？ # 所謂的 GPU，全稱是 Graphics Processing Unit，中文翻譯為「圖形處理器」，所以顧名思義，其實 GPU 最一開始的用途，就是拿來「處理影像圖形」用的。 只不過因為 GPU 的「平行處理」的特性實在太好用，所以後來才被拿來挖礦、甚至發展 AI。\n所以在了解 GPU 為什麼對 AI 很重要之前，首先一定要先了解 GPU 的用途為何，了解 GPU 是怎麼做到「平行處理」的概念的，才能夠了解為什麼 GPU 對於 AI 的發展這麼重要。\n影像處理簡介 # 其實 GPU 最一開始的用途就是拿來「處理圖形」的，而在了解 GPU 的用途之前，我們必須要先了解一下目前電腦螢幕裡面是如何構成的，才能知道 GPU 的用途為何。\n舉例來說，在每一台電腦螢幕中，其實都是由好幾個微小的像素（pixel）所組成，而每一個像素你可以想像成就是一個小格子。\n所以像是現在主打的 4K 螢幕（3840×2160），就是指這台螢幕的長度有 3840 個像素，而高度則是有 2160 個像素，因此在整台螢幕上面，就是有 3840 x 2160 = 829 萬個像素（pixel）存在。\n所以我們平常在使用螢幕時，不管是觀看 YouTube 影片、寫程式、打遊戲…等等，電腦就要分別計算「每一格 pixel 當前應該要呈現什麼顏色」，而當所有的 pixel 都計算好自己應該長什麼顏色之後，最終就會呈現一張完整的圖片了。\n如果大家有生成過點陣圖、或是有玩過 Minecraft 的話，其實就是背後用的就是「像素」的概念，像是下圖就是一個 pixel 實際呈現的結果，當每一格 pixel 都計算出他的顏色之後，最終呈現給我們人眼看的結果，就是最右邊的「寶劍」了！\n所以在影像處理的世界中，「每一格 pixel 都是獨立的，自己控制自己要呈現什麼顏色」，而當這些 pixel 們計算好自己要呈現什麼顏色之後，最終合成再整個合在一起看，就是對我們人類有意義的圖片了～\n所以其實對於 pixel 而言，他其實根本不知道現在是要呈現什麼圖片😂，他的任務就是乖乖計算自己要什麼顏色，剩下的怎麼解讀就交給人類自己去判定。\nGPU 和影像處理的關聯 # 所以透過上面的介紹，現在我們知道「一張圖片之所以能夠呈現出來，靠的就是 pixel 們自己在背後默默的運算」，而這其實就是 GPU 被發明出來的契機！\n在 GPU 還沒被發明出來之前，如果我們用傳統 CPU 的去計算 pixel 的值的話，那就是得寫個 for loop，然後每一次 loop 就去計算每一格 pixel 的值。\n圖片來源： 【OpenGL 篇】为什么游戏总要编译着色器？ 但是使用 CPU 這樣子 for loop 一格一格計算實在是太慢了，所以為了加快計算的過程，GPU 就被發明出來了！！\n在 GPU 裡面，有超超超超超級多個核心存在，每一個核心都可以執行一個簡單的計算，所以對於 GPU 而言，他就可以為每一個 pixel 都分配一個核心，然後 「在同一時間，所有核心都去計算他所分配到的 pixel 的值」，所以 GPU 就可以一口氣計算出所有 pixel 的顏色，因此就可以得到最終的結果了。\n圖片來源： 【OpenGL 篇】为什么游戏总要编译着色器？ 所以 GPU 之所以強大的地方，就在於「平行處理」，每一個 GPU 核心都有強大計算的能力，只要你告訴他要計算的是哪一格 pixel、以及要處理的數據有哪些，GPU 就可以為那一格 pixel 分配一個核心，專門去計算這個 pixel 的最終顏色，又因為 GPU 中的核心數量非常多，因此就可以達到「同時計算所有 pixel」的效果了～\n所以對於 GPU 來說，「平行處理」就是他的最強大的武器，而這也是 GPU 為什麼會在 AI 世界大放異彩的特質！\n為什麼 GPU 在 AI 時代這麼重要？ # 首先在 AI 時代中，所有的模型都是「訓練」出來的，而在訓練模型的過程中，使用 GPU 的「平行處理」就可以加快訓練的過程。\n「訓練」的概念有點像是在教導小孩子一樣，每一個模型一開始都是一個天真無邪的孩子，並且每個孩子的特長和天賦都不同，而我們工程師所做的，就是拿著「同樣的對話範例」去給這個孩子看，試試看這個孩子最終會長成什麼樣子。\n像是你可以拿下面這兩段對話，去訓練 X 模型，所以這時候 X 模型就會去「旁觀」這兩段對話，並且自己去理解這段對話（就像是小時候我們看著父母的言行一樣，就是從旁觀中去學習，所以身教大於言教啊！）。\nA：你好 B：哈囉你好，你吃飽了沒？ A：你好 B：心情不好，滾 而當你使用上面這兩段對話「訓練」完 X 模型之後，這時候當你跟 X 模型說「你好」時，他可能會回你：\n你：你好 X 模型：滾 或是 你：你好 X 模型：哈囉滾 因此在「訓練」模型的過程中，其實我們作為工程師，也是不知道 X 模型最終到底會回覆什麼的，一定得等到訓練完成之後，我們才能夠透過一問一答的測試的方式，去檢查 X 模型的回覆是否如我們預期。\n所以在 AI 的時代中，所有的模型其實都是通過「訓練」出來的，並且上面這種給 X 模型參考旁觀對話的過程，也稱為「訓練模型」。\n而 GPU 之所以在 AI 的發展中很重要，就是因為 「使用 GPU 的平行處理，就可以加快訓練的過程」。\n舉例來說，如果我們使用傳統 CPU 來訓練 X 模型的話，那就像是教育小孩一樣，一次只能夠教導一個科目，等到這個科目完成之後，才教導下一個科目。\n而如果我們使用 GPU 來訓練 X 模型的話，那就像是教育一個超級天才一樣，你可以一口氣教超級多科目，這個天才會用他的超級 GPU 腦袋，為每一個科目都分配一個核心，並且同時處理這些科目（就像前面的處理 pixel 一樣）。\n所以只要我們使用了 GPU，就可以「大幅提升訓練模型的速度」，因此就可以快速將 X 模型訓練完畢，進而檢查他的訓練成果了。\n補充：為什麼提升「訓練模型」的速度這麼重要？ # 這裡可能會有人有疑問，就是「為什麼提升訓練模型的速度這麼重要？」，就讓我緩緩道來我個人的訓練模型的經驗，跟大家分享一下我 train model 的血淚史\u0026hellip;.🥹（以下「訓練模型」會簡稱為 train model）。\n以前我在唸研究所的時候有稍微旁聽過 Machine Learning 的課（機器學習，算類 AI 吧），那時候有個作業要自己去 train 一個 model 出來，我當時就是調調調參數，然後按下 Enter 鍵放下去讓他跑，接著我就沒事幹了只能苦苦等著他跑完🥹。\n想當然第一次跑出來的結果一定是很爛，需要重 train，所以這時候我又只能重新調一下參數，然後再按下 Enter 鍵，重新用新參數去 train model，然後我就又只能再苦苦等一天\u0026hellip;.。\n所以 train model 真的是會花很多時間都在空等….，就像是你寫了一段程式，然後要等一天後你才能 debug 一樣，只有煎熬可言（而且進度也會進展的很慢），所以這也是為什麼 GPU 真的很重要。\n只要有一個好的 GPU，就可以讓 train model 的時間從 3 天降成 30 分鐘（是有點誇張的比喻，但大概是這個概念），同樣是 30 天的開發週期，有一個好 GPU 的工程師就是可以有比較多次 train model 的機會（也就是有比較多次失敗的機會），而爛 GPU 的工程師就只能試幾次而已，剩下時間都在空等而已。\n所以這也是為什麼 GPU 對於 AI 發展這麼重要的原因，只要能夠盡可能的降低 train model 的空等時間，就可以 debug 更多次，技術也會發展得更快一點。\n因此 GPU 的平行處理，可以說是加速 AI 發展的強大催化劑，有了 GPU 之後，原本需要 1 年才能進步的技術，可能縮短為 3 個月就能做到，所以 GPU 可以說是兵家必爭之地，擁有足夠的 GPU 資源，才能夠確保 AI 技術有能力往下發展。\nGPU 總結 # 所以最後做個總結的話，所謂的 GPU，他的全稱是 Graphics Processing Unit，中文翻譯為「圖形處理器」。\nGPU 有一個強大的特性，就是「平行處理」，因此 GPU 就能夠藉由他內部的眾多核心，同時去處理許多的任務，加速程式的運行。\n也因為 GPU 的平行處理的特性，因此 GPU 最一開始的用途，是拿來「處理影像」的，所以像是追求高畫質的遊戲玩家，就需要挑選好一點的 GPU，才能夠得到更好的畫質、更逼真的特效體驗。\n而隨著 AI 浪潮的崛起，大家也發現 GPU 很適合用在「訓練模型」上面，只要透過 GPU 的平行處理的特性，就可以加速訓練模型的速度，因此研究人員就可以更快的知道當次訓練模型的結果，進而提早投入到下一次的訓練中了！\n結語 # 這篇文章介紹了 GPU 是什麼，並且也介紹了為什麼 GPU 對 AI 的發展很重要，希望可以透過這篇文章，幫助大家了解 GPU 的底層邏輯是什麼，也能大概了解為什麼 NVIDIA 是現在最火熱的公司了（因為他就是專門生產高階 GPU 的公司，大家要用高階 GPU 只能跟他買）。\n如果你對後端技術有興趣的話，也歡迎免費訂閱《古古的後端筆記》電子報，每週二為你送上一篇後端技術分享，那我們就下一篇文章見啦！\n補充：我開設的 Spring Boot 零基礎入門、Spring Security 零基礎入門、GitHub 免費架站術 已在 Hahow 平台上架啦！輸入折扣碼「HH202601KU」即可享 85 折優惠。\n","permalink":"https://kucw.io/blog/gpu-ai/","tags":null,"title":"GPU 是什麼？為什麼 GPU 對 AI 的發展很重要？"},{"categories":["其他技術分享"],"contents":"Event Sourcing 的設計理念可以說是和一般常見的 CRUD 完全不同，我一開始聽到的時候也驚嘆「啊？？竟然還能這樣？？」，所以這篇文章我們就來了解一下，到底什麼是 Event Sourcing 吧！\n目錄 什麼是 Event Sourcing？ Event Sourcing 和傳統 CRUD 的差別在哪裡？ Event Sourcing 的優化 Event Sourcing 的優勢 Event Sourcing 總結 補充：Event Sourcing 和 DDD 補充 2：Event-Driven Design 是什麼？ 結語 什麼是 Event Sourcing？ # 所謂的 Event Sourcing，中文硬翻的話是「事件溯源」，重點在於「事件」這兩個字。\n而 Event Sourcing 的概念，其實就只是 「將每一筆發生的 Event（事件）都記錄下來」 而已，比想像中單純！\n舉例來說，如果大家去銀行存款/提款的話，銀行一定會記錄「你在某某時間存了多少錢」，因此當你後續去畫簿子（或是查看交易記錄時），就可以看到自己「每一筆存款/提款的時間、以及金額的大小」，而這種「把每一個 Event 都記錄下來」的設計方式，就稱為是 Event Sourcing。\n也因為在 Event Sourcing 中，我們所儲存的是「每一個 Event 的記錄」，而不是儲存「最終的餘額結果」，所以假設使用者想要知道他現在到底有多少存款的話，那我們就只能手動的一筆一筆 event 加總，也就是「把事件全部重頭執行一遍」，最終就可以得到他的最終餘額。\n所以像是在上面的例子中，我們就需要加總這 3 筆 event，也就是「存款 500」、「存款 1000」、「提款 200」，因此使用者最終的餘額就是 500 + 1000 - 200 = 1300。\n因此 Event Sourcing 說穿了，就只是將 「每一筆發生的 Event 忠實的記錄下來」 的架構模式而已！\nEvent Sourcing 和傳統 CRUD 的差別在哪裡？ # 大概了解了 Event Sourcing 的概念之後，我們也可以來比較一下 Event Sourcing 和傳統 CRUD 的差別在哪裡。\n由於 Event Sourcing 的特徵是「將每一個發生的 Event 都記錄下來」，因此在資料庫中我們所儲存的，是每一個 Event 發生的時間。優點是可以知道每一個 Event 的具體發生的時間，缺點則是沒辦法馬上知道最終的總額是多少，需要一筆一筆將 Event 全部加總之後，才能夠得到結果。\n而傳統 CRUD 則不一樣，傳統的 CRUD 是「直接將最終的結果儲存下來」，因此當使用者存錢時，CRUD 就是直接去修改使用者的當前餘額，將他修改成最終的數字。因此 CRUD 的優點是可以快速地知道當前餘額是多少，但是缺點是不知道使用者中間到底交易過幾次。\n也由於 Event Sourcing 和 CRUD 在本質上的不同，因此一般來說，通常是「對每一個 Event 都要詳細記錄的情境」才需要使用 Event Sourcing 來設計，像是金融業銀行、股票買賣、Audit Log\u0026hellip;等等，這種要細到每筆帳都要清算的情況，就很適合用 Event Sourcing 來實作。\n而如果沒有這種需求的話，其實用 CRUD 就真的很夠用了，因為一般來說大家在意的不是那個過程，而是最終的結果，所以這也是為什麼 CRUD 目前還是後端設計主流，就是因為 CRUD 可以應付大部分的真實場景。\n所以作為一個後端工程師，能夠熟練掌握最基本的 CRUD 能力還是非常重要的，基本功不能丟啊！\nEvent Sourcing 的優化 # 呈上面所說，因為 Event Sourcing 就是瘋狂的把每一筆發生過的 Event 給記錄下來，所以每次要得到最終結果的時候，都得要重新一筆一筆的把 Event 給加總，才能夠得到最終結果，但其實在實作上，是有一些手段可以加速的。\n像是我們可以在每天加總該天的 Event，最後生成一個當天的最終結果給使用者看，所以像是股票買賣記錄，就可以在當天晚上結算，先得到一個結果（術語稱為 snapshot），這樣後續就不用再重頭一筆一筆加總 Event 了，只要從今天的結果繼續往下加總明天的 Event 就好。\nEvent Sourcing 的優勢 # 補充：本段內容擷取自 高速大量業務的應用架構關鍵\n另外 Event Sourcing 也有一個超級強大的優勢，就是能夠 「提高後端系統的吞吐量」。\n因為 Event Sourcing 是瘋狂把每一筆 Event 記錄下來就好，所以他就不需要執行 SELECT SQL 語法，先查到要更新的是哪一筆數據，再進行更新，Event Sourcing 就只要直接無腦把 Event 數據 INSERT 到資料庫就好，因此資料庫就可以特意挑選那種擅長寫入的資料庫了！\nEvent Sourcing 總結 # 所以總結上面的介紹，所謂的 Event Sourcing，就是 「將每一筆發生的 Event 都記錄下來」，因此將來不管是要查詢使用者的哪一筆操作有問題、還是要回溯到當下的狀況，都可以用我們所儲存的 Event 數據來回溯。\n而 Event Sourcing 和 CRUD 最大的差別，就在於：\nEvent Sourcing 是「儲存每一筆 Event」。 CRUD 是「儲存數據的最終結果」。 因此大家就可以根據自己的情境，選擇最適合你的架構了～\n補充：Event Sourcing 和 DDD # 其實只要講到 Event Sourcing，就一定會提到跟他很有關係的 DDD。\n所謂的 DDD，全稱是 Domain-Driven Design（領域驅動設計），概念大概是將程式劃分成好幾個領域，每一個領域需要搭配一個領域專家，並且會有一個聚合根（Aggregate），負責該領域的所有事件和數據處理。\n上面這段文字看起來很難對不對？嗯其實我也覺得很難😂，感覺文字分開看我都懂，合在一起看就不太懂🥹。\n由於 DDD 我也只有略懂而已，所以大家如果有興趣的話，也可以再上網查詢「CQRS、Aggregate」\u0026hellip;等關鍵字，這邊就不班門弄斧了🙏。\n補充 2：Event-Driven Design 是什麼？ # 其實了解了 Event Sourcing 的目的是「儲存每一筆 Event 的記錄」之後，要了解另一個名詞 Event-Driven Design 就很容易了～\n所謂的 Event-Driven Design，中文翻譯為「事件驅動設計」，概念大概就是 「當某事件發生時，我們要執行什麼功能」。\n舉例來說，假設我們架設了一組 RabbitMQ，你就可以說「當某個 Queue 出現 message 時，我們就要更新資料庫」，而這其實就是一個 Event-Driven Design，也就是「當某個事件出現時，我們就執行什麼程式」這樣。\n另外如果大家有寫過前端的程式的話，其實整個前端的架構都是 Event-Driven Design，像是「當使用者點擊某個 Button，我就要執行某段程式」，或是「當使用者滑動視窗時，我要改變 Dom 的狀態」\u0026hellip;等等，整個前端其實就是超級大的 Event-Driven Design 架構。\n也因為 Event-Driven Design 的使用情境很廣泛（不僅前端廣泛使用，後端其實也會用到），所以建議大家要了解一下他的概念會比較好～。\n結語 # 這篇文章我們介紹了 Event Sourcing 是什麼，並且也比較了 Event Sourcing 和傳統 CRUD 的差別，最後也補充了一下 DDD 和 Event-Driven Design 的概念，希望可以幫助大家了解 「Event（事件）」 到底是在玩什麼花樣。\n如果你對後端技術有興趣的話，也歡迎免費訂閱《古古的後端筆記》電子報，每週二為你送上一篇後端技術分享，那我們就下一篇文章見啦！\n補充：我開設的 Spring Boot 零基礎入門、Spring Security 零基礎入門、GitHub 免費架站術 已在 Hahow 平台上架啦！輸入折扣碼「HH202601KU」即可享 85 折優惠。\n","permalink":"https://kucw.io/blog/event-sourcing/","tags":null,"title":"Event Sourcing 是什麼？他和 CRUD 的差別在哪裡？"},{"categories":["職涯相關"],"contents":"其實所謂的「資深工程師」，他並不是一個突然從天而降的改變，而是一個緩慢的、融入到你工作中的微小變化。\n可能是你今天多幫同事解決了一個 bug 可能是你今天又多學到了一些技術 可能是你以前每一個微小的功能所累積下來的穩定表現，讓主管願意相信你，將更重要的任務交給你 所以要成為資深工程師，並不是突然神蹟降臨，將你頭上的稱號從「初階工程師」升級成「資深工程師」這樣。\n而是會融入在每一天的工作生活中，你慢慢的變強，慢慢的累積周遭同事、主管對你的信任，慢慢的成為人們口中的英雄，這時候你突然回首一看，才發現自己其實已經變成資深工程師了。\n通常到這個時候主管就會約你 1-1，將你的職稱升到資深工程師，確保「你的職稱」和「你所具備的能力」是相符的，這時候就恭喜你～正式成為資深工程師啦🎉🎉\n所以不用急、不用太焦慮，只要慢慢的累積技術實力，不斷變強，每一次提交 commit 時都當成是出 bug 會嚴重到被電到飛高高的那種，戰戰兢兢的前進，慢慢的就會到達你想要的高度了～祝大家職場順遂！\nPS: 其實我覺得「成為資深工程師」和「談戀愛」很像😂，都是那種累積許多微小的改變，最終慢慢的喜歡上一個人這樣（可能我不是那種突然來個浪漫大餐、盛大告白就會心動的類型XD）。\n每一次的 commit 提交，就像是在觀察曖昧對象的每一個舉動一樣：\n可能是 coding style 不好（沒有整理儀容） 可能是架構設計的有問題（金錢觀、感情觀的落差） 可能是單元測試沒寫好出 bug（訂位餐廳但是沒有 double check 所以訂錯時間） 每一個小舉動，都影響著我是否對這個人有加分或扣分（當然對方也是用同樣的標準在審視我），最終當這個人的分數突破 100 分之後，就可以在一起了（就可以升遷了），大概是這種感覺吧XDD\n補充：我開設的 Spring Boot 零基礎入門、Spring Security 零基礎入門、GitHub 免費架站術 已在 Hahow 平台上架啦！輸入折扣碼「HH202601KU」即可享 85 折優惠。\n","permalink":"https://kucw.io/blog/how-to-become-senior-developer/","tags":null,"title":"如何成為資深工程師？心態最重要"},{"categories":["其他技術分享"],"contents":"RAM 可以說是組裝電腦的必備元件，也是電腦運行程式的基礎，所以這篇文章我們就來介紹一下，電腦中的 RAM 到底是什麼吧！\n目錄 RAM（記憶體）簡介 RAM 的用途 RAM 和硬碟的差別 RAM 總結 補充：「重開機治百病」是什麼原理？ 結語 RAM（記憶體）簡介 # 所謂的 RAM，他的全稱是「Random Access Memory」，台灣通常翻譯為「記憶體」、大陸則是翻譯為「內存」，不過不管是記憶體還是內存，他們指的都是電腦中的 RAM。\n大家平常最接近 RAM 的情境，通常會是在買手機 or 買電腦的時候，像是在買電腦時，常常會聽到賣家宣傳：「這台電腦的記憶體有 16GB」或是「你要不要擴充記憶體到 16GB？」，這個記憶體所指的，實際上就是 RAM。\n像是下圖中就是一條常見的 RAM：（平常有在組桌機的人可能有摸過，但如果你是買筆電的話，就很少有機會能看到 RAM，因為廠商在生產筆電時，就已經把他嵌進筆電裡面了）\n那麼 RAM 到底可以幹嘛呢？RAM 真的是容量越大越好嗎？（當然越大也越貴），下面就介紹 RAM 實際的用途為何。\nRAM 的用途 # 不知道大家在寫程式時，有沒有曾經思考過：「這個程式到底是怎麼運行在電腦上的？」，譬如說，當我們在程式中使用一個變數時，這個變數的空間到底哪裡來的？實際上這些變數就是存放在 RAM 裡面。\n舉例來說，有一台電腦，他的 RAM 有 25 個空格：\n假設此時有一個 A 程式，他裡面宣告了 5 個變數（假設一個變數佔用一格），所以當這台電腦執行 A 程式時，A 程式就會去 RAM 中佔用 5 格（沒錯就是佔地為王），因此 RAM 就只會剩下 20 格可以給其他人用。\n假設這個時候，這台電腦又想去執行 B 程式，而剛好 B 程式裡面宣告了 15 個變數，因此 B 程式就會佔走 RAM 中的 15 格，因此 RAM 只剩下 5 格可以使用。\n而如果這個時候，這台電腦又想去運行 C 程式，但因為 C 程式裡面宣告了 20 個變數，因此 C 程式需要 RAM 中的 20 格才能成功運行起來。但是因為目前 RAM 中僅存的空格只剩 5 格（其他的被 A 程式和 B 程式佔走了），因此 RAM 就沒有足夠的空間能夠運行 C 程式，所以此時就沒辦法運行 C 程式。\n但如果這時候你還是很想運行 C 程式的話，那該怎麼辦呢？答案很簡單，你只要關掉 A 程式或是 B 程式，將 RAM 的空間釋放出來，就可以運行 C 程式了。\n舉例來說，因為 C 程式需要 20 格，所以在這個情境下，就需要關掉 B 程式，將 B 程式的 15 格釋放出來，這樣子才有足夠的空間運行 C 程式。\n所以這也是為什麼常常當我們 Google 分頁開太多時、或是 VS Code + IntelliJ + 其他 IDE 雙開時，電腦會開始有點卡卡的，這就是因為每一個分頁、每一個程式，他們實際上都在搶 RAM 的地盤啊！！！\n當 RAM 剩餘的空間不夠時，電腦就會開始卡卡的，所以這也是為什麼在買電腦的時候，一定會建議大家要把 RAM 從 8GB 升到 16GB，因為當你的 RAM 有 16GB 時，就表示你的 RAM 的空地比較大，因此就可以 「同時容納更多的程式」，重點在「同時」。\n所以換句話說，只要 RAM 越大，你就可以越瀟灑的運行更多的程式，再也不用擔心 RAM 的空間不夠用了，讚讚讚！！\nRAM 和硬碟的差別 # 了解了 RAM 的用途之後，接著我們可以看一下 RAM 的特性，以及 RAM 和硬碟的差別。\nRAM 有一個很重要的特性，就是「當電腦關機之後，RAM 中的所有數據就會全部被刪掉，無法救回」，所以像是我們在程式中所宣告的變數，因為變數是儲存在 RAM 裡面，所以如果沒有及時的把變數中的值儲存到資料庫的話，那麼當這台電腦關機時，該變數的值也就會跟著被刪掉了，因此即使你重新開機，也無法找回當初的變數的值。\n所以為了能夠有一個地方能「永久保存數據」，因此這時候就是「硬碟」派上用場的時候了！\n其實硬碟大家日常生活中應該用的滿多的了，像是我們可以在 Windows 的 C 槽中創建一個檔案、或是在 Macbook 中創建一個檔案，這些檔案所儲存的位置，其實都是儲存在硬碟上。\n而硬碟的特性，就是「即使電腦關機，裡面的數據仍舊會保存下來」，因此硬碟在電腦中所扮演的角色，就是一個永久的儲存空間，只要是關機後仍然想保留下來的數據，一定要儲存在硬碟中，這樣才不會隨著電腦關機而消失。\n因此電腦就是透過 RAM 和硬碟的搭配，來完成程式的執行和數據的儲存了！\nRAM 總結 # 所以總結上面的介紹，RAM 的全稱是「Random Access Memory」，中文翻譯為「記憶體」或是「內存」，並且 RAM 的用途是「用來儲存程式執行過程中的變數」，也就是提供足夠的空間讓程式能夠順利運行。\n而 RAM 和硬碟的差別就在於：\nRAM： 當電腦關機之後，RAM 中的所有數據就會全部被刪掉，無法救回。 硬碟： 即使電腦關機，裡面的數據仍舊會保存下來。 因此大家如果想要將程式中的計算結果永久儲存下來的話，記得一定要寫進硬碟裡面（不管是寫進檔案裡也好、還是寫進資料庫也好，就是要寫進硬碟就是了），不然的話那些數據就會隨著電腦關機，一起跟著消失了！\n補充：「重開機治百病」是什麼原理？ # 當大家了解 RAM 的概念之後，其實就可以理解「重開機治百病」的背後原理到底是什麼了🤣。\n不知道大家有沒有遇到過，不管遇到什麼問題，好像只要重新開機一下，就可以解決他，很有可能就是因為 RAM 出問題了。\n在前面有提到，RAM 的用途是「儲存程式執行過程中的變數」，而因為每個程式各自都會需要宣告一些變數，所以 RAM 需要提供足夠的空地給每一個程式。\n但是重點來了！！假設有某個程式在結束執行時，不好好的歸還他所租借的空地的話，那這樣 RAM 就會越租越少，到最後就會變成無地可租的情況。\n舉例來說，如果有一個 D 程式，他明明租借了 5 塊空格，但是在他程式執行完畢之後，他卻只歸還了 4 格，這樣子 RAM 的總額就會只剩下 24 格（原本是 25 格），進而降低了後續能租出去的空地，因此 RAM 就會越用越少，嚴重一點就會導致無空地可用，因此電腦就會整個卡住，沒辦法運行任何程式。\n如果沒有寫過較底層的程式語言（如 C、C++），可能會覺得「當程式結束了，變數仍舊會佔用空間」這件事情怎麼可能發生，但是事實上，這件事情是真的會發生的🥹。\n一般來說，較高階的程式語言（如 Java、Kotlin、Python、JavaScript、PHP…等），都會自動處理那些沒有用到變數，所以對於寫這些高階程式語言的工程師來說，當我們創建一個變數時，其實我們不需要思考「什麼時候要銷毀它」，我們只要創建它、然後用它來解決程式邏輯就好，根本不需要思考什麼時候要銷毀它，因為高階語言會自動幫我們去銷毀這些變數。\n但是對於 C 和 C++ 這類較底層的語言來說，當你創建一個變數時，你是得要記得去銷毀他的，如果你忘記銷毀的話….那麼你的 RAM 就會一直沒辦法被釋放，因此那格 RAM 就會永遠被佔用，即使你的程式已經停止運作了，那格 RAM 仍舊會一直被佔用。\n那假設那一格 RAM 一直被佔用該怎麼辦？目前只有一種手段可以解決，就是「重新開機」，因為重開機會強制刪除 RAM 中的所有數據，因此該格 RAM 就可以重新被釋放出來，讓其他人租借。\n所以這也是為什麼重開機可以解決許多問題的原因，根本原因就是因為有某個工程師程式沒寫好，老是寫出一些忘記銷毀的變數，使得 RAM 的可用空間越變越小，所以才會導致電腦越跑越慢🥹。\n所以下次當你的電腦又越跑越慢時，先別急著罵電腦廠商，很有可能是海的另一邊的某個工程師寫出了 bug，導致某個變數沒被釋放，所以才會使得你的 RAM 越用越少。既然都是工程師，就別為難彼此了XDD，寫出 bug 是常有的事，大家就默默重開機就好😂。\n補充：當然還有許多因素會影響 RAM 的可用空間啦，不過通常 RAM 真的是會越用越小，所以建議大家可以定時重新開機，就可以強制清空 RAM，讓你的 RAM 能夠重新變回一塊乾淨的空地～\n補充 2：在高階語言中，「自動銷毀變數的機制」稱為「Garbage Collection」，簡稱「GC」，中文翻譯為「垃圾回收」，其中又以 Java 的 GC 做的最為知名，如果大家有興趣的話，也可以再上網搜尋 GC 相關的介紹。\n結語 # 這篇文章我們介紹了 RAM 的用途是什麼、並且也比較了 RAM 和硬碟的差別，希望可以透過這週的電子報，讓大家了解 RAM 的用途是什麼，對於平常開發的電腦有更多的認識。\n如果你對後端技術有興趣的話，也歡迎免費訂閱《古古的後端筆記》電子報，每週二為你送上一篇後端技術分享，那我們就下一篇文章見啦！\n補充：我開設的 Spring Boot 零基礎入門、Spring Security 零基礎入門、GitHub 免費架站術 已在 Hahow 平台上架啦！輸入折扣碼「HH202601KU」即可享 85 折優惠。\n","permalink":"https://kucw.io/blog/ram/","tags":null,"title":"電腦中的 RAM（記憶體）的用途是什麼？他和硬碟的差別在哪裡？"},{"categories":["自媒體經營"],"contents":"哈囉，我是古古，這篇文章是每月一次的自媒體月報，主要分享我經營《古古的後端筆記》個人品牌的幕後秘辛，如果你也對於「自媒體創業」有興趣的話，歡迎繼續閱讀本文～\n補充：如果想了解《古古的後端筆記》電子報的起源，也可以先查看創刊號的文章。\n2024.12 月粉絲追蹤數、電子報訂閱人數 # 本月份（2024.12）的粉絲成長人數如下：\n2024/11/26 人數 2024/12/31 人數 12 月份（11 月份）總成長人數 Facebook 粉專追蹤數 4389 4475 +86（+239） 電子報訂閱人數 2076 2480 +404（+444） Threads 粉絲追蹤數 4566 5996 +1430（+2009） IG 粉絲追蹤數 353 489 +136（+106） 各項指標仍舊成長中！可能目前還在流量成長期，所以我目前也會先朝著「盡量提高曝光度」努力，先讓大家「能看到我」、讓大家知道「我有在分享後端內容」，再由大家自由決定是否想要訂閱電子報。\n本月撰寫的電子報主題、文章 # 這邊記錄了我這個月撰寫了哪些電子報和文章（花了整個月在介紹 JWT😂），大家如果對於其中的內容有興趣的話，也可以前往查看：\nSession 和 JWT 的差別在哪裡？ 密碼學中的 Encode、Encrypt、Hash 的差別在哪裡？ JWT 是什麼？一次搞懂 JWT 的組成和運作原理 JWT 是如何實作「數位簽名」的？揭秘 signature 的面紗 2024 回顧 # 回顧 2024 年，這是我身為自由工作者的整整一年，在這個期間，我做了：\n錄製完成一門線上課程：Spring Security 零基礎入門 出版一本書：Spring Boot 零基礎入門 參加了幾場社群分享 還有就是，創立了這份電子報 老實說身為一個自媒體工作者，我其實是對我的 2024 年有點沮喪的😞，我深刻感受到一人工作在自律上的種種困難，以及很討厭自己的創作產能不是很穩定，心情很常會變得很低落\u0026hellip;（我想再次跟購買過課程的同學說聲抱歉😭，抱歉中間延期了那麼多次才完成所有課程影片\u0026hellip;）。\n有時候我會坐在電腦前面，明明已經想好要寫哪個主題，我也大概知道大綱要怎麼寫、素材要怎麼找，但是就提不起勁，最終就變成坐在電腦前發呆，然後那一天就這樣消失了\u0026hellip;。\n不過，即使 2024 年的我過得不是很好，但我仍舊想要試著改變，希望可以透過不同的形式，找回當初創作的快樂，而這個嘗試之一，就是創立了電子報！\n我也不知道為什麼，可能是寫電子報的負擔沒有錄製課程影片大，也可能是電子報的頻率比較低（一週寫一篇就好），目前電子報也已經寫了 20 期了，真的很感謝大家一路以來的訂閱和支持🙏。\n不過未來我還是會想錄製課程的！還有好多主題想要錄，而且我相信 「軟體的價值在於重複使用」，只要我好好的錄一次影片，這支影片就可以被許多人重複觀看，不斷的重複使用，超級讚！\n因此在 2025 年，我希望可以再錄製一堂線上課程出來，不過目前主題暫時還沒想好，等到確定了會再跟大家說～（只是有了前幾次錄製課程的教訓，這次我會盡力將進度安排得更合理一點的🥹）。\n2025 展望：Sharing is Learning! # 拍謝上面的 2024 年回顧好像有點沈重😂，只是想說既然是自媒體月報，就想要把自己真的經歷過的心情跟大家分享這樣，自由工作者其實真的沒有想像中輕鬆（壓力來自於不確定感和不安感），雖然是能每天睡到自然醒啦，不過長期下來的心情其實是沒辦法太放鬆的，大概就是「長期精神慢性病 + 睡到飽的健康身體」這樣。\n不過 2025 年展望，我們說點輕鬆的！！沒錯我要開始畫餅了🤣（展望就是拿來畫餅的對吧XD）\n在 2025 年，除了上面提到的「想要再錄製一堂線上課程」之外，2025 年我想用一句話來期許，就是 「Sharing is Learning!」（分享就是最好的學習！）。\n在新的 2025 年，我想學更多，也想分享更多！想要把學習到的知識分享給大家，也想要讓自己變得更強！！！\n老實說我不知道我還能寫多久（希望至少寫 3 年啦），但我相信我沒辦法寫一輩子（就算我能寫一輩子，我也沒辦法重現當下學習知識的快樂和成就感）。\n人的成長只有一次，我希望我能慢慢變強，我也希望能夠帶著大家一起變強，與其看著照片牆上一張張專業的攝影牆讚嘆不已，倒不如真的親身一步一步爬上山比較有趣對吧？\n希望 2025 年會是起飛的一年，大家坐穩繫好安全帶，我們一起變強💪！！！\n如果你喜歡這份電子報，歡迎分享給你的朋友、同事，揪他一起訂閱電子報，大家一起變強！\n電子報訂閱連結：https://kucw.io/bio/\n","permalink":"https://kucw.io/blog/as-a-content-creator/monthly-report-202412/","tags":null,"title":"軟體工程師的自媒體之路 - 2024.12 月報"},{"categories":["其他技術分享"],"contents":"因應 Medium 的付費牆、以及 SEO 的政策調整，我發現我在 Medium 上的文章越來越難被搜尋到了🥹。\n有的人可能不知道什麼是 SEO（Search Engine Optimization，搜尋引擎最佳化），簡單的說，你 SEO 做得越好，這篇文章就可以在 Google 搜尋中排名越前面，而在 Google 搜尋中排名越前面，自然點閱率就越高，曝光度就越大（因為大家在找資料的時候，一定都是先點前幾個連結嘛）。\n所以在寫文章時，除了提升自己文章的內容之外，要怎麼樣讓自己的文章可以 「被看見」，也是非常重要的一件事！\n是 Medium 還是 Google 把我文章吃了？ # 鑑於 SEO 實在是太重要了，所以這也是為什麼我會離開 Medium 的主因。\n回想 Medium 剛起家的時候，他憑藉著自身簡約的網站風格、再加上 SEO 的優化政策做得非常好，所以有非常多的作者轉移到 Medium 上寫文章。\n但是近幾年 Medium 對 SEO 優化做了非常多調整，我自己曾在 Medium 上和 GitHub 個人網站上，分別寫了兩篇一模一樣的文章，但是當我用同樣的關鍵字去查詢的時候，GitHub 個人網站的文章可以排在前三名，而 Medium 的文章我翻到第 10 頁了還找不到，差距非常大。\n上圖為我使用同樣的關鍵字「lombok」去查詢的結果，我在自架的 GitHub 個人網站上寫的文章可以進到第 1 頁，但是 Medium 的文章卻連前 10 頁都找不到\nMedium 的文章連結：https://medium.com/@kujudy/java-lombok-cc4a2947ab5a\nGitHub 個人網站的文章連結：https://kucw.io/blog/2020/3/java-lombok\n老實說，當時看到這種情況我真的是哭笑不得，我沒想到 Medium 對 SEO 的影響會大到這麼誇張，如果是差個幾頁就算了，但是在 10 頁之內都找不到自己寫的文章，知道的當下還是有點沮喪的😞。\n有寫過文章的人就知道，產出一篇文章的背後，要花很多時間去研究、安排架構、調整用字遣詞，自己都花很多時間和熱情去寫文章了，但是卻因為這個 Medium 的 SEO 政策的關係，導致自己寫的內容沒辦法被別人看見，只能默默地在網路的世界不斷下沉\u0026hellip;\n想到這裡，就更加讓我下定決心要離開 Medium 了。\n下一站在哪裡？ # 有鑒於曾經在 Medium 上投注了心血，卻沒辦法得到相對應成果的痛苦經驗，所以這次我決定，我不要再受限在任何一個平台上了，因為難保下一個平台不會發生和 Medium 同樣的事情，如果這一次轉換平台，又碰到和 Medium 一樣的問題，那到時候就又只能崩潰的尋找下一個替代方案。\n在花了很多時間在網路上查了各種方法之後，最後我發現了在國外很熱門的 Hugo 架站工具，Hugo 在 GitHub 上有 76.9K 的 Stars，算是非常活躍的社群！\n只要使用這套 Hugo 架站工具，再搭配上 GitHub 提供的免費個人網站域名 GitHub Pages，這樣就可以架設出自己的個人網站了！聽起來好像滿簡單的，所以當時我就花了一些時間去看官方文件，因此就開始了我的自架個人網站之路。\n如何使用 Hugo 在 GitHub 上架設個人網站？ # 如果你本身有工程師背景的話，其實照著 Hugo 官方的文件做，再花一些時間 debug，很快就能在 GitHub 上架出個人網站了。\n但如果你完全沒有寫過任何一行程式的話，那要直接上手 Hugo 的難度還是滿高的，因為在使用 Hugo 的過程中，會有一些必要的背景知識，而這些是官方文件不會教你的。\n在使用 Hugo 架站之前，你必須要知道的幾件事：\n如何使用 brew or choco 去安裝 Hugo？ 如何修改程式碼？（工程師通常都有自己用習慣的編輯器，像我是 VS Code + IntelliJ 雙棲） 如何使用 Git，將程式碼上傳到 GitHub 上？ 如何撰寫 Markdown 文章？ 如果以上這四點你都了解的話，那麼直接看 Hugo 官方文件來架個人網站完全沒問題，但如果你對上面提到的 Git、Markdown 這些專有名詞有障礙的話，建議會需要先上網查一下相關資料，或是參考下面的線上課程。\n工商時間 | 一起在 GitHub 上架設個人網站吧！ # Hahow 線上課程：Github 免費架站術！輕鬆打造個人品牌， 輸入折扣碼「HH202601KU」即可享 85 折優惠\n如果你沒有工程師背景，但也想擺脫各大文章平台的束縛，擁有一個自己的個人網站的話（並且還是免費的！），也許這門線上課程就是你在找的引路人。\n本課程會一步步的從零開始教學，介紹要如何使用 Hugo 以及 Github Pages，架設出屬於你的個人網站，因此當你上完這門課時，你的個人網站也已經完成了！\n架設好自己的個人網站，然後呢？ # 架設出自己的個人網站之後，我才發現可以玩的東西多太多了！\n1. 文章終於可以分類了 # 光這點我覺得就完勝 Medium，我真的很不解為什麼 Medium 不願意提供一個分類的機制給大家使用，難道 Medium 覺得我們寫的文章都很整齊不用分類整理嗎！！！\n2. 可以添加個人經歷頁面，讓網站更豐富 # 以前在 Medium 寫文章時，只能設定一些簡單的自我介紹，但是如果是自架個人網站的話，就可以自由發揮，用圖形化的方式去呈現一些個人經歷，同時也可以去整合自己的其他作品，讓別人進到這個網站，就可以了解你過去所有的經歷、作品集、以及所寫的所有文章。\n不過要達到這個效果，會需要具備一些前端的 Html、Css\u0026hellip;等知識，但是如果很熟悉前端的知識的話，做出來的網站豐富度真的不是 Medium 可以比的，完勝 Medium！\n3. 使用 Google Search Console 查看搜尋成效 # 這個是 Google 提供的很酷的功能，我也是架了個人網站才接觸到這個功能。\n當架設好個人網站之後，可以到 Google Search Console 裡，申請在 Google 搜尋引擎上註冊你的個人網站，只要申請成功之後，這樣其他人就可以透過 Google 搜尋找到你的個人網站了！\n並且申請了入住 Google 搜尋之後，後續你也可以透過 Google Search Console，去查看個人網站的搜尋成效，譬如說我可以查看某段時間內，網頁的 曝光量 / 點擊量 有多少，或是網頁的點擊率是多少。\n如果網頁點擊率低的話，就表示別人在 Google 搜尋結果中看到我的文章，但是卻沒有點進來看內容，那原因可能就是因為我的文章標題下得不夠吸引人，所以我就可以朝這個方向去修改我的文章標題。\n4. 使用 Google Analytics（GA）查看網站成效 # 這個也是 Google 提供的功能，不過 GA 的名氣就比 Google Search Console 大多了，一般前端工程師和行銷的職位都會碰到 GA。\n架設好個人網站之後，可以到 Google Analytics 申請使用 GA 的服務，接著就可以使用 GA 去查看個人網站的流量了。\n5. 使用 Google AdSense 收取廣告費 # Google 真的是佛心來著，不只提供了許多好用的功能給我們使用，現在竟然還可以讓我們靠寫文章來賺錢！！\n大家在瀏覽網站的時候，常常會看到有的網站下面有一個「Google 提供的廣告」對吧？這個就是 Google Adsense 的功能。\nGoogle AdSense 這個功能簡單的說，就是你將個人網站中的一塊地租給 Google，而 Google 會在這裡投放廣告，並且 Google 會根據你的個人網站的瀏覽量和使用者點擊廣告的次數，去計算你應得的分潤。所以假設你寫的文章非常受歡迎，每月的瀏覽量非常高，那麼每個月就可以有一筆被動收入，就是網站放著也能賺錢的概念啦！\n只要個人網站的流量到達一定的標準之後，就可以到 Google AdSense 申請使用這個服務。\n補充：不過我自己是沒有申請過 Google AdSense，一來是因為我覺得 Google 廣告有點惱人，二來是這個分潤的錢也不是非常多，所以目前沒辦法提供 Google AdSense 的數據給大家參考。\n自架個人網站聽起來很強，但真的完全沒有缺點嗎？ # 雖然上面描述了許多自架個人網站的優點，但是不可否認的，使用 GitHub 架設個人網站還是會有一些缺點的。\n首先，架設個人網站需要花費一定的時間，不僅需要上傳程式碼到 GitHub 上，包含後續申請 Google Search Console、以及申請 GA\u0026hellip;等等，都是需要自己手動操作的，所以無法享受 Medium 幫你包到好的服務。\n再來文章功能的方面，個人網站沒辦法使用「追蹤（Follow）」的功能，因此當你寫了新的文章時，想關注你的人無法接收到新文章的通知（除非有額外設定 RSS feed，不過目前一般人也不太會使用這個功能）。另外讀者也無法收藏文章、也無法畫重點，所以就只能夠手動將該文章加到瀏覽器的書籤列裡做保存。\n最後是自架個人網站的話，需要使用 Markdown 來撰寫文章，而這個寫作門檻比較高，一開始接觸 Markdown 的人可能會覺得語法很多有點難背。相對來說，Medium 在這部分就表現得比較好，Medium 在文章的編輯上面非常平易近人，新手一下子就能上手。\n總結：沒有最好的，只有最適合你的 # 所以總結來說，不管是使用 Medium 還是使用 GitHub 自架個人網站，都是有不同的優缺點的，並沒有說哪一個一定是特別好的，這篇文章也只是想分享我自己從 Medium 換到自架 GitHub 個人網站的經驗和心得而已。\n在 Medium 上寫文章是真的比較舒適，什麼都不用管，只要專心產出文章內容就好，但是缺點就是會被平台的演算法限制，而自架個人網站比較自由，且可以統整自己所有的經歷、作品集，但缺點則是無法和讀者產生互動。\n所以還是那句話：「沒有最好的，只有最適合你的」，如果你是深受 SEO 困擾的 Medium 寫手，那麼自架個人網站增強曝光度可能會是更好的選擇，如果你是想嘗試培養寫文章習慣的新手，那麼 Medium 可能是更好的選擇，畢竟 Medium 優秀的文章編輯介面是大家有目共睹，如果一上手就使用比較複雜的 Markdown 語法的話，可能會降低你寫作的意願，凡事總是得先求有再求好。\n不過我也是看過有的人會兩邊都做啦，也就是同時在 Medium 和個人網站上寫一模一樣的文章（我全都要！），這樣做不僅可以利用 Medium 的 Follow 功能維持和讀者的互動，也可以享受自架個人網站帶來的 SEO 效益，唯一的缺點就是要花兩倍的時間去排版吧，因為要分別使用 Medium 和 Markdown 格式去寫兩次文章。\n最後，說了這麼多，我自己還是非常推薦大家可以自架個人網站的，除了可以自己掌控主導權之外，還可以把你的人生全部濃縮記錄到這個個人網站裡面，而且說不定若干年後 Medium 倒了，你在 Medium 上寫的文章就全部付諸流水了，畢竟當初誰也沒想過 Yahoo 或是無名小站會倒閉的對吧！\n補充：如果你對 GitHub 免費架站有興趣、並且想要無痛上手的話，歡迎加入線上課程 Github 免費架站術！輕鬆打造個人品牌，4 小時手把手帶你架出個人網站！（輸入折扣碼「HH202601KU」即可享 85 折優惠）\n","permalink":"https://kucw.io/blog/2021/1/from-medium-to-github/","tags":null,"title":"為了 SEO！我離開了 Medium，改在 GitHub 上自架個人網站"},{"categories":["其他技術分享"],"contents":"在上一篇的 JWT 是什麼？一次搞懂 JWT 的組成和運作原理 文章中，我們有介紹了 JWT 是由三個部分所組成，分別是：header、payload 以及 signature。\n而在 header、payload、signature 這三個部分中，他們各自負責的功能如下：\nheader： 用來設定這個 JWT 的簽名算法、以及此 Token 的類型 payload： 用來儲存使用者的數據，可以根據自己的需求進行客製化 signature： 用來儲存「簽名」的計算結果 因此這篇文章我們就會接著來探討，為什麼 JWT 透過 signature 的部分就可以實作出「數位簽名」的概念，並且也會介紹「數位簽名」到底是有多神奇，可以直接阻擋駭客的竄改。\n本文為 JWT 系列文的最終章，會使用到前面所提到的所有概念（包括 JWT 的組成、非對稱加密、Hash），因此如果你對這些概念還不太熟悉，建議可以先回頭參考前面文章的介紹（建議按照順序閱讀，才會有最佳的閱讀體驗）：\nSession 和 JWT 的差別在哪裡？ 密碼學中的 Encode、Encrypt、Hash 的差別在哪裡？ JWT 是什麼？一次搞懂 JWT 的組成和運作原理 JWT 是如何實作「數位簽名」的？揭秘 signature 的面紗（本文） 目錄 signature（數位簽名）的運作邏輯 前置作業 JWT 的生成 JWT 的驗證 JWT 的數位簽名總結 結語 signature（數位簽名）的運作邏輯 # 前置作業 # 如果要實作 JWT 的數位簽名的機制，最常見的做法是使用 「非對稱加密」 來實作，所以在實作前，後端需要先生成一組「公鑰」和「私鑰」出來，等等就會使用這兩組密鑰來搭配實作「數位簽名」的功能。\n而當後端生成好一對公鑰和私鑰之後，就可以開始來進行 JWT 的生成了！\n補充：在非對稱加密中，公鑰是公開的、可以廣發給所有人，私鑰則是私有的，要自己保管好，絕對不可以洩漏。並且使用公鑰來加密的數據，只能使用私鑰來解密；使用私鑰來加密的數據，只能使用公鑰來解密。\nJWT 的生成 # 在生成 JWT 時，首先後端要先根據自己的商業邏輯，填上 header 和 payload 中的值。\n所以像是在下方的 payload 中，我就填上了 {\u0026quot;sub\u0026quot;:\u0026quot;123\u0026quot;, \u0026quot;name\u0026quot;:\u0026quot;古古\u0026quot;...} 的資訊，用來表示這個 JWT 中所裝的使用者資訊，是名叫「古古」的使用者資訊。\n這裡大家可以根據自己的需求，在 payload 中填上你想要的值，不管你在 payload 中填上什麼值，對後續的 signature 生成都不會有任何影響（只不過在生成 signature 之前，一定要先確定好 payload 中的值要填什麼就是了，一旦 signature 生成之後，就不能改 payload 中的值了）。\n而當寫好 header 和 payload 中的值之後，此時後端需要對 header + payload 的值 Hash 一下（此處使用的是 SHA-256 Hash 演算法），所以此時就會計算出 header + payload 被 Hash 過後的結果，即是 srtp3k。\n接著後端要使用「私鑰」，將這個 hash value srtp3k 加密，因此就會得到一個加密過後的結果 ap9fPl...。\n而當後端產生出 ap9fPl... 這個加密過後的結果之後，後端必須將這個值放在 JWT 中的 signature 的欄位中，因此最後後端傳送出去的 JWT 結果，就會在 signature 的部分填上 ap9fPl... 的加密過後的值。\n所以到這裡，就完成了第一階段的「JWT 的生成」了，因此此時後端就可以將這個 JWT Token 傳送給前端，交由前端保存這個 JWT Token。\nJWT 的驗證 # 而當前端後續拿著這個 JWT 來請求 api 時，我們身為後端，就必須要驗證這個 JWT 的正確性（即是是否有被駭客竄改過），而要驗證 JWT 的正確性，就是去檢查其中的 signature 的值就可以了。\n舉例來說，當前端拿著剛剛的那一個 JWT 來請求 api 時，這時候我們身為後端，必須要先對當下的 header + payload 的區塊進行 Hash，先計算出 header + payload 的 Hash 值，因此此時就會得到一個 Hash 結果（即是下方區塊中的 srtp3k）。\n這時候 JWT 中最精華的地方來了！！！當後端計算出 header + payload 的 Hash value 之後，後端只要使用「公鑰」將 signature 解密，然後比較一下「當初所計算出來 Hash 的值」和「現在所計算出來的 Hash 值」是否一樣，就可以知道此 JWT Token 是否有被竄改過了！\n像是假設駭客偷偷修改 name 的值，將他從 古古 改為 我是駭客 的話，那麼當後端在收到這個 JWT 時，當下所計算出的 header + payload 的值就會是 Fy93HE，而這個值就會和「使用公鑰解密 signature 所得到的原始 Hash 值 srty3k」不一樣，因此 JWT 就會驗證失敗，所以後端就會認為這個 JWT 中的內容有被偷偷修改過，因此就不相信裡面的數據。\n所以總結來說的話，當後端收到 JWT 時，後端只要驗證一下 「當下 header + payload 所計算出來的 Hash 值」 和 「使用公鑰解密 signature 所得到的值」 是否一樣，就可以知道這個 JWT 有沒有被偷偷修改了，這就是「數位簽名」的核心運行邏輯啦！！\n所以大家以後就可以透過 JWT 的數位簽名的特性，將 JWT 直接儲存在前端中，後端就只要在收到 JWT 時驗證一下簽名就好，因此就不需要再儲存大量的數據在後端裡面了！讚！！\nJWT 的數位簽名總結 # 所以總結上面的介紹，JWT 之所以可以透過 signature 的「數位簽名」來避免駭客的竄改，就是因為他使用了「非對稱加密」來實作數位簽名的機制。\n而我們身為後端，在生成 JWT 時，需要使用「私鑰」來加密 header + payload 的數據，並將結果放在 signature 中。\n並且在驗證前端傳過來的 JWT 時，需要使用「公鑰」來解密 signature 得到原始值，並且比較他和「當下 header + payload 所計算出來的 Hash 值」是否一樣，如果一樣的話，才表示 JWT 驗證成功，裡面的數據沒有被駭客所竄改，因此可以相信裡面的數據。\n因此大家就可以透過這個步驟，在你的後端程式中實作 JWT 的相關程式了！\n補充：本文是擷取自我開設的線上課程「資安一把罩！Spring Security 零基礎入門」的內容，如果你想了解更多的資安內容、以及如何應用 Spring Security，歡迎參考課程簡介 （輸入折扣碼「HH202601KU」即可享 85 折優惠）。\n結語 # 這篇文章我們介紹了 JWT 的「數位簽名」的核心運作邏輯是什麼，數位簽名可以說是 JWT 中最重要的特性，就是因為有了數位簽名，才使得我們可以將 JWT 儲存在前端 Client 中，打破了以往只能將數據儲存在後端的設計方式，可以說是超級厲害的發明！！\n如果你對後端技術有興趣的話，也歡迎免費訂閱《古古的後端筆記》電子報，每週二為你送上一篇後端技術分享，那我們就下一篇文章見啦！\n本文為 JWT 系列文的最終章，如果你想回顧前面的介紹，也可以參考前面的文章：\nSession 和 JWT 的差別在哪裡？ 密碼學中的 Encode、Encrypt、Hash 的差別在哪裡？ JWT 是什麼？一次搞懂 JWT 的組成和運作原理 JWT 是如何實作「數位簽名」的？揭秘 signature 的面紗（本文） ","permalink":"https://kucw.io/blog/jwt-signature/","tags":null,"title":"JWT 是如何實作「數位簽名」的？揭秘 signature 的面紗"},{"categories":["其他技術分享"],"contents":"在現今的架構中，JWT 可以說是使用非常廣泛的一項技術，所以這篇文章我們就來介紹一下 JWT 是由哪些部分所組成，以及每個部分所負責的功能為何吧！\n本文為 JWT 系列文之一，建議在閱讀本文前，要先了解 Session 和 JWT 之間的差別、以及 Encode/Decode 的概念，才會比較好上手。如果你對這些概念還不太熟悉，也可以參考前面的文章介紹（建議按照順序閱讀，才會有最佳的閱讀體驗）：\nSession 和 JWT 的差別在哪裡？ 密碼學中的 Encode、Encrypt、Hash 的差別在哪裡？ JWT 是什麼？一次搞懂 JWT 的組成和運作原理（本文） JWT 是如何實作「數位簽名」的？揭秘 signature 的面紗 目錄 回顧：Session 和 JWT 的差別 什麼是 JWT？ JWT 中的 header 部分：存放通用資訊 補充：JWT 中的 Encode 和 Decode JWT 中的 payload 部分：存放使用者的數據 補充 1：payload 中的常用變數 補充 2：不要在 payload 中存放敏感數據 JWT 中的 signature 部分：實作數位簽名 JWT 總結 結語 回顧：Session 和 JWT 的差別 # 在 Session 和 JWT 的差別在哪裡？ 的文章中，我們有介紹到 Session 和 JWT 的差別分別是：\nSession 認證： 將登入的資訊儲存在「後端 Server」上 JWT 認證： 將登入的資訊儲存在「前端 Client」中 所以大家就可以根據自己的需求，選擇到底要使用 Session 來進行認證、還是使用 JWT 進行認證。\n不過在當時的那篇文章中，我們先跳過了「為什麼後端可以無條件相信 JWT 中的內容？」的相關細節，因此這篇文章就會回過頭來介紹這部分，了解 JWT 中的組成有哪些，以及 JWT 的運作原理是什麼，使得後端可以無條件相信 JWT 中所記錄的資訊。\n什麼是 JWT？ # 所謂的 JWT，他的全稱是 JSON Web Token，而他的用途，通常就是用來「傳遞身份認證的數據」。\n在 JWT 中，會由三個部分所組成，分別是：header、payload 以及 signature，並且在每一個部分之間，就會使用一個 . 作為分隔。\n像是在下面的例子中，左邊的 eyJhb.... 這段亂碼，他其實就是一個 JWT Token，所以他就可以根據其中的 . 區分成三個部分，也就是 header、payload 以及 signature。\n所以其實 JWT 格式，他就只是一段亂碼，只是我們可以使用 .，把內部的資訊區隔成三個部分而已。\n而如果我們把下面這段 JWT 的亂碼，貼到 JWT 的官方網站 https://jwt.io/ 中的話：\neyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjMiLCJuYW1lIjoi5Y-k5Y-kIiwiaWF0IjoxNzIxMDAxNjAwfQ.G41XQGNNJ5Tp88U48aXh4n0XtGkpPkQ3xK6j43_61gE309hzyTVyciG5v05aVIvvY9NrApYiQdvwlMMrjRPFVV8xunghtKKFMj3kPx93Ll8Pf6n-tDiL_NZYqcusrgwtb-EDza80hMG5PTu75ogTIfRKr4jC0_FZzLaMix07LaZReoUSionTWTxJlm8qJc0BAFXgsaGNs9oVhCXOg_jJmOfFZBP0tD3q4xaKp9MTtLRTtslAhoAjPczdnPqaWGcaS8OY11RUTvvxijA7W-mPRlmqt0Hd_XForETUFZRdCKsPQIiGjkavycPtdiViVihQKstHlT4afEzYvzWSeK1cnw 就可以看到這個網站就會將此 JWT 分成三個部分，也就是剛剛提到的 header、payload、signature。\n所以在了解 JWT 的運作原理之前，一定要先知道 「JWT 是由 header、payload 和 signature 這三個部分所組成」，每一個部分所負責的功能都不一樣，所以先了解 JWT 的結構是非常重要的！\n而在 JWT 中，每一個部分所負責的功能都不一樣，以下分別介紹他們各自所負責的功能：\nJWT 中的 header 部分：存放通用資訊 # 首先 header 的用途，就是用來存放一些通用的資訊，譬如說可以用來設定這個 JWT 的簽名算法、以及設定這個 JWT 的 Token 類型。\n舉例來說，像是在下方的 header 例子中，裡面的 alg 就是用來設定這個 JWT 的簽名算法，而 typ 則是表示這個 Token 是 JWT 類型。\n{ \u0026#34;alg\u0026#34;: \u0026#34;RS256\u0026#34;, \u0026#34;typ\u0026#34;: \u0026#34;JWT\u0026#34; } 所以在 header 中，主要就是用來設定這個 JWT 的通用資訊。\n補充：JWT 中的 Encode 和 Decode # 而大家如果觀察一下的話也可以發現，在 JWT 的官網中（https://jwt.io/），當我們在左側貼上 JWT 的亂碼之後，在右邊所呈現的會是 Decode（解碼）過後的結果。\n像是以 header 的亂碼 eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9 為例，將他 Decode 之後，就可以得到原始的 JSON 字串 {\u0026quot;alg\u0026quot;:\u0026quot;RS256\u0026quot;,\u0026quot;typ\u0026quot;:\u0026quot;JWT\u0026quot;}。\n所以在 JWT 中，header 的亂碼看似好像有加密，但他實際上是完全沒有加密的！！！JWT 只是使用 Base64 將 JSON 字串給編碼一下而已，完全沒有加密的成分在裡面，因此所有人都有能力 Decode 這段亂碼，取得原始的 JSON 字串。\n補充：不熟悉 Encode 和 Decode 的概念的話，可以回頭參考 密碼學中的 Encode、Encrypt、Hash 的差別在哪裡？ 中的介紹。\nJWT 中的 payload 部分：存放使用者的數據 # 了解了 header 的用途之後，接著我們可以來看一下 payload 的用途。\npayload 的用途，就是用來存放使用者的數據，所以在 payload 中，我們就可以根據自己的需求，自由決定我們想要放什麼資訊在裡面。\n所以像是在下面的 payload 例子中，裡面就存放了 \u0026quot;name\u0026quot;: \u0026quot;古古\u0026quot; 的數據，用來表示這個使用者的名字為「古古」，因此我們就可以根據自己的需求，在 payload 中存放客製化的使用者數據了！\n{ \u0026#34;sub\u0026#34;: \u0026#34;123\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;古古\u0026#34;, \u0026#34;iat\u0026#34;: 1721001600 } 補充 1：payload 中的常用變數 # 在客製化 payload 的數據時，我們也是可以使用 JWT 預先定義好的變數名稱來實作的。\n舉例來說，sub 所代表的就是「使用者的 id 的值」，至於 iat 所代表的就是「這個 JWT Token 的創建時間」，這些都是 JWT 預設的變數名稱，算是使用 JWT 的一個默契。\n所以大家在使用上，除了自己定義變數名稱之外，建議也可以多多利用 JWT 所定義的變數名稱，這樣就可以讓不同工程師所設計出來的 payload 長得差不多，就不用再每次都一個一個詢問「這個變數名稱的含義是什麼？」了。\n除了 sub 和 iat 之外，這裡也補充常見的 JWT 變數名稱：\niss（issuer）：此 JWT 的發行人 sub（subject）：JWT 的使用者（通常是放使用者的 id 的值） aud（audience）：接收此 JWT 的收件人 exp（expiration time）：此 JWT 過期失效的時間 iat（issued at time）：此 JWT 是什麼時候被發布的（即是什麼時候被創建） nbf（not before time）：定義在某個時間以前，此 JWT 都是不可用的 jti（JWT ID）：此 JWT 的唯一身份標誌，當 JWT 用來當作一次性的 Token 的時候，可以避免重放攻擊（即是這個 Token 只能使用一次） 但是老實說這些變數名稱都是用簡寫，真的很難記🥹，所以如果忘記了的話，就再回來查一下就好。\n補充 2：不要在 payload 中存放敏感數據 # 在 payload 中，我們一樣是可以使用 Base64 去 Encode 或是 Decode，得到原始的字串或是編碼過後的亂碼。\n像是在 JWT 的官網中，就會將左側的 paylod 的亂碼 eyJzdWIiOiIxMjMiLCJuYW1lIjoi5Y-k5Y-kIiwiaWF0IjoxNzIxMDAxNjAwfQ，Decode 成右邊的原始 JSON 字串 {\u0026quot;sub\u0026quot;:\u0026quot;123\u0026quot;,\u0026quot;name\u0026quot;:\u0026quot;古古\u0026quot;,\u0026quot;iat\u0026quot;:1721001600}。\n也因為 payload 中的數據僅是使用 Base64 進行編碼而已，所以完全沒有安全性可言！！因此千萬不要將使用者的敏感數據（ex: 身分證字號）放在 JWT 中傳遞，因為 JWT 的 payload 是所有人都可以輕易解碼的。\n所以通常在 payload 中，只會存放使用者的必要的資訊（ex: id 的值），後端到時再去根據這個 id 的值，去資料庫中查詢使用者的敏感數據。\nJWT 中的 signature 部分：實作數位簽名 # 了解了 header 和 payload 的用途之後，最後則是要了解 signature 的部分。\nsignature 的用途，就是用來儲存「簽名」的計算結果，所以後端之所以可以無條件相信 JWT 中的 payload 數據，就是透過 signature 來達成的！\n不過因為 signature 的實作機制比較複雜，因此在下一篇文章 JWT 是如何實作「數位簽名」的？揭秘 signature 的面紗中，才有辦法完整介紹 signature 的精髓。\n因此這裡大家只要先知道：後端之所以可以無條件相信 JWT 中的數據，全部都是 signature 的功勞就可以了！\nJWT 總結 # 了解了上面的所有介紹之後，最後我們也可以來總結一下 JWT 中的內容。\nJWT 的全稱為 JSON Web Token，通常是用來 「傳遞身份認證的數據」，並且 JWT 會由三個部分所組成，分別是：header、payload 以及 signature，每個部分之間使用 . 做分隔。\n而在 header、payload、signature 這三個部分中，他們各自負責的功能如下：\nheader： 用來設定這個 JWT 的簽名算法、以及此 Token 的類型 payload： 用來儲存使用者的數據，可以根據自己的需求進行客製化 signature： 用來儲存「簽名」的計算結果 所以大家以後再看到 JWT 時，就可以用這個格式拆解 JWT，進而取得到其中的數據了！\n補充：本文是擷取自我開設的線上課程「資安一把罩！Spring Security 零基礎入門」的內容，如果你想了解更多的資安內容、以及如何應用 Spring Security，歡迎參考課程簡介 （輸入折扣碼「HH202601KU」即可享 85 折優惠）。\n結語 # 這篇文章我們介紹了 JWT 是由哪些部分所組成，以及每個部分所負責的功能為何，JWT 可以說是目前最流行的認證機制，所以搞懂 JWT 可以說是對工作上非常有幫助的！\n如果你對後端技術有興趣的話，也歡迎免費訂閱《古古的後端筆記》電子報，每週二為你送上一篇後端技術分享，那我們就下一篇文章見啦！\n如果你對 JWT 的其他文章有興趣，也可以直接點擊下列連結跳轉到該文章（建議按照順序閱讀，才會有最佳的閱讀體驗）：\nSession 和 JWT 的差別在哪裡？ 密碼學中的 Encode、Encrypt、Hash 的差別在哪裡？ JWT 是什麼？一次搞懂 JWT 的組成和運作原理（本文） JWT 是如何實作「數位簽名」的？揭秘 signature 的面紗 ","permalink":"https://kucw.io/blog/jwt/","tags":null,"title":"JWT 是什麼？一次搞懂 JWT 的組成和運作原理"},{"categories":["其他技術分享"],"contents":"在密碼學中，Encode、Encrypt、Hash 可以說是三大基礎概念，並且也是後端工程師必備的密碼學知識，因此這篇文章就會詳細來介紹什麼是 Encode、Encrypt、Hash，以及比較他們之間的區別。\n本文為 JWT 系列文之一，如果你對 JWT 的其他文章有興趣，也可以直接點擊下列連結跳轉到該文章（不過建議還是按照順序閱讀，才會有最佳的閱讀體驗）：\nSession 和 JWT 的差別在哪裡？ 密碼學中的 Encode、Encrypt、Hash 的差別在哪裡？（本文） JWT 是什麼？一次搞懂 JWT 的組成和運作原理 JWT 是如何實作「數位簽名」的？揭秘 signature 的面紗 目錄 Encode、Encrypt、Hash 簡介 什麼是 Encode（編碼）？ 什麼是 Encrypt（加密）？ 什麼是對稱加密？ 什麼是非對稱加密？ 什麼是 Hash（雜湊）？ 補充：Hash 真的沒辦法被破解嗎？ 補充 2：我還是很想用 MD5，真的沒辦法了嗎？ Encode、Encrypt、Hash 總結 結語 Encode、Encrypt、Hash 簡介 # 在密碼學中有三大概念，分別是：\nEncode（編碼） Encrypt（加密） Hash（雜湊） 以下分別介紹如何透過這三種不同的方法，去對數據做不同的處理。\n什麼是 Encode（編碼）？ # 所謂的 Encode（編碼），就是「數據可以直接被編碼」，並且中間「不需要」任何的密鑰參與。\n像是在下面的例子中，左邊的原始字串 123，就可以被 Encode（編碼）成右邊的 gg2oGVzdD，而右邊的 gg2oGVzdD，他也是可以直接被 Decode（解碼）回原始的字串 123 的。\n因此在 Encode 和 Decode 的過程中，是不需要任何的密鑰，「所有人」 都可以輕易的 Encode 和 Decode。\n而一般在實務上，最常見的 Encode 演算法為「Base64」，像是在這個 Base64 Encode 的網站中，只要在上面輸入 test123，下面就會出現 Encode 過後的結果 dGVzdDEyMw==。\n而這時如果大家複製一下下方的結果 dGVzdDEyMw==，然後點擊左邊的 Decode 連結（跳轉到 Decode 的頁面），然後將剛剛的結果 dGVzdDEyMw== 貼在上面的話，這時候就可以直接將這個結果 Decode 回原始的字串 test123。\n所以對於 Encode 和 Decode 來說，他們完全不需要密鑰的參與，也可以對數據進行「編碼和解碼」，因此所有人都可以針對某一筆數據進行 Encode 和 Decode。\n也因為如此，大家在使用 Base64 去 Encode 數據時，一定要注意這個數據是沒有被加密過的，所以所有人都有能力將他 Decode 回原始的字串！！一定要小心！！！\n所以下次當你看到有人在網路上隨意散播使用 Base64 Encode 的數據時，你完全可以大膽的將他 Decode，就可以得到原始的字串，因此千萬不要再誤解 Base64 很安全了🥹，他真的就只是一個編碼的工具而已，完全沒有任何加密的成分在裡面！\n補充：Encode 其實嚴格上來說不算加密，因為他只是改變數據的呈現方式，完全沒有加密可言，但口語上有時候還是會把 Encode 歸類成加密，因此才放在這裡一起介紹。\n什麼是 Encrypt（加密）？ # 了解了 Encode 之後，接下來我們可以來看一下 Encrypt 的相關介紹。\n所謂的 Encrypt（加密），就是「將數據加密成密文」，所以透過 Encrypt 加密過後的數據，他可以說是非常安全的。\n而在 Encrypt 的世界中，又可以再細分成兩種加密方式，分別是：\n對稱加密 非對稱加密 所以以下針對這兩種加密方式來介紹。\n什麼是對稱加密？ # 在對稱加密中，只會有「一把」密鑰存在，因此不論是加密還是解密，就統統是用這把密鑰來進行。\n舉例來說，左邊的原始的字串 123，他就可以透過這把密鑰（或是簡稱為這把 key），加密成右邊的 gg2oGVzdD，而右邊的 gg2oGVzdD，他也可以透過這把密鑰，解密回原始的字串 123。\n所以在對稱加密中，就只會存在「一把」密鑰，因此不管你是要加密還是解密，統統就是透過這把密鑰進行。\n也因為在對稱加密中只有一把密鑰存在，所以這把密鑰必須要好好的保護，絕對不可以洩漏，一但密鑰洩漏，駭客就可以透過這把密鑰解密出原始的字串，因此在對稱加密中，保護密鑰是非常重要的任務！\n什麼是非對稱加密？ # 而不同於對稱加密，在非對稱加密中，則是會有「兩把」密鑰存在。\n在這兩把密鑰中，其中一把會叫做「公鑰」（也就是 Public Key），另一把則叫做「私鑰」（也就是 Private Key），因此在非對稱加密中，就是由「公鑰」和「私鑰」共同配合，對數據進行加密和解密。\n所以這兩把密鑰，他們的特性如下：\n公鑰（Public Key）：公開的，可以複製好幾份，廣發給所有人 私鑰（Private Key）：私有的，必須要好好的保護，不可以洩漏 並且在非對稱加密中，有一個很神奇的運作邏輯，也就是：\n由 「公鑰」 所加密的數據，只能夠由 「私鑰」 解密 由 「私鑰」 所加密的數據，只能夠由 「公鑰」 解密 所以換句話說的話，就是 「由其中一把鑰匙所加密的數據，只能夠用另一把鑰匙來解密」，這就是「非對稱加密」的運作方式。\n也由於非對稱加密的神奇特性（其中一把加密的數據，只能用另一把解密），所以在 JWT 中的「數位簽名」，實際上就是用非對稱加密所實作的。甚至不止 JWT，像是區塊鏈中的數位簽名，他背後也是用非對稱加密實作的（不如說只要是扯到「數位簽名」或是「數位簽章」這個概念，底層都是同一套，都是用非對稱加密實作）。\n所以在了解 JWT 的「數位簽名」是如何實作的之前，建議大家一定要先了解「非對稱加密」的運作邏輯（也就是其中一把加密的數據，只能用另一把解密），這樣子後續在了解 JWT 的相關知識時，才能夠知道他底層的運作邏輯為何。\n什麼是 Hash（雜湊）？ # 在了解了 Encrypt 中的「對稱加密」和「非對稱加密」之後，最後我們也可以來看一下 Hash 的相關介紹。\n所謂的 Hash（雜湊），就是「單方面的將數據轉換成亂碼（或稱為 Hash Value，雜湊值）」，並且這個 Hash Value，他是「不能夠」轉換回原始的字串的。\n舉例來說，左邊的原始字串 123，他可以被 Hash 成右邊的亂碼 gg2o861kdn5（又稱為 Hash Value，雜湊值），但是我們卻沒辦法將右邊的亂碼 gg2o861kdn5，轉換回原始的字串 123。\n所以在 Hash 的世界中，所有的數據只要被 Hash 過，就再也沒辦法轉換回原始的數據，就算老天來也沒用，世界上沒有人（包含駭客和你自己）有能力將 Hash Value 轉換回原始的數據。\n補充：Hash 真的沒辦法被破解嗎？ # 從根本的邏輯上，只要一個數據被 Hash 過，那我們是真的沒有辦法將這個數據轉換回原始的字串，但是！！駭客就想到一招破解的方式：「既然我沒辦法將數據轉換回來，那我乾脆提前做一張很大很大的表格，提前記錄 什麼樣的數據 會轉換成 什麼樣的亂碼 不就好了？」\n舉例來說，駭客可以提前計算出 123 這個字串會被 Hash 成 gg2o861kdn5、456 這個字串會被 Hash 成 aaaa777k3nt\u0026hellip;等等的結果。因此當駭客發現某一筆被 Hash 過的值是 aaaa777k3nt 時，駭客就只要回來查詢這張表格，就可以馬上找出 aaaa777k3nt 的原始字串是 456，因此就可以用這張很大的表格，來破解被 Hash 過後的值。\n原始字串 Hash 過的值 123 gg2o861kdn5 456 aaaa777k3nt 因此像是常見的 Hash 演算法「MD5」，駭客就已經透過 「彩虹表（Rainbow Table）」 反向破解出他的所有可能組合了，因此在實務上，建議大家選擇更可靠的 Hash 演算法（像是 BCrypt）來實作，才能夠避免駭客的攻擊。\n補充 2：我還是很想用 MD5，真的沒辦法了嗎？ # 即使 MD5 已經被駭客的「彩虹表」給反向破解了，但實際上我們還是可以透過一個簡單的補強方法，來強化 Hash 的安全性，這個做法就叫做 「加鹽（salting）」。\n所謂的加鹽，就是「偷偷在原始的字串中插入一段亂碼」，然後再把這整個字串拿去 Hash，等於是我們為原始的字串偷加了一點調味料（鹽巴），讓他變得不太一樣。\n舉例來說，我們就可以在原始的字串 123 中，偷偷加上一點鹽巴 ND3dmEyMzQxM，這樣最後 Hash 出來的結果就會不一樣。\n而這種加鹽的做法之所以可以反制駭客，有兩個原因：\n我們可以將中間的「鹽巴」設定成一個很長的字串，只要字串一變長，窮舉法就很難列完所有組合，因此駭客的那張表格就會變得非常非常大，大到駭客難以維護。 即使駭客運氣好仍舊破解出這個字串 12ND3dmEyMzQxM3，但是駭客也不知道「到底哪一個字母是我們偷加的鹽巴」、「哪一個字母是原始的字串」，因此即使駭客看著手上的 12ND3dmEyMzQxM3 字串時，他也不知道其中的 123 才是真實的原始字串。 所以透過「加鹽（salting）」的方式，我們就能夠大大的提升了 Hash 的安全性了！讚！\n補充：現今流行的 Hash 演算法（ex: BCrypt），通常都會自帶加鹽的實作，因此不需要我們再額外手動去為他加鹽，為我們節省許多開發的時間，太讚啦！！\nEncode、Encrypt、Hash 總結 # 所以總和上述的介紹，最後來總結一下 Encode、Encrypt、Hash 這三大概念的話：\nEncode（編碼）：數據可以直接被編碼，並且「不需要」任何的密鑰參與，所有人都可以直接 Encode 和 Decode 數據，非常不安全 Encrypt（加密）：使用密鑰將數據加密成密文，安全性高，又可區分為「對稱加密」和「非對稱加密」 Hash（雜湊）：單方面的將數據轉換成 Hash Value（又稱為雜湊值） 所以透過這張表格，希望能夠讓大家更了解 Encode、Encrypt 和 Hash 他們之間的差別在哪裡，因此大家後續在使用上，就可以根據自己的需求，決定哪一種方式是最適合你的實作方法了。\n補充：本文是擷取自我開設的線上課程「資安一把罩！Spring Security 零基礎入門」的內容，如果你想了解更多的資安內容、以及如何應用 Spring Security，歡迎參考課程簡介 （輸入折扣碼「HH202601KU」即可享 85 折優惠）。\n結語 # 這篇文章我們介紹了 Encode、Encrypt 以及 Hash 的差別，這三大概念可以說是密碼學的基礎，也是後端工程師必備的密碼學知識，因此建議大家一定要好好了解會比較好！\n如果你對後端技術有興趣的話，也歡迎免費訂閱《古古的後端筆記》電子報，每週二為你送上一篇後端技術分享，那我們就下一篇文章見啦！\n本文為 JWT 系列文之一，如果你對 JWT 的其他文章有興趣，也可以直接點擊下列連結跳轉到該文章（建議按照順序閱讀，才會有最佳的閱讀體驗）：\nSession 和 JWT 的差別在哪裡？ 密碼學中的 Encode、Encrypt、Hash 的差別在哪裡？（本文） JWT 是什麼？一次搞懂 JWT 的組成和運作原理 JWT 是如何實作「數位簽名」的？揭秘 signature 的面紗 ","permalink":"https://kucw.io/blog/encode-encrypt-hash-intro/","tags":null,"title":"密碼學中的 Encode、Encrypt、Hash 的差別在哪裡？"},{"categories":["其他技術分享"],"contents":"在現今的架構中，JWT 可以說是使用非常廣泛的一項技術，但是 JWT 到底是什麼？以及他的用途為何？甚至 JWT 和 Session 的差別在哪裡？這些都是在了解 JWT 的過程中，需要具備的知識。\n因此在這個 JWT 系列文中，我會用 4 篇文章介紹 JWT 的前世今生，包含在 JWT 的用途是什麼、他要解決的是什麼問題、以及 JWT 的底層運作邏輯為何。\n所以首先這篇文章，我們就先來介紹 Session 和 JWT 的運作原理為何，以及並且比較他們之間的差別。\n目錄 什麼是 Session 認證？ 什麼是 JWT 認證？ 補充：後端為什麼能無條件相信 JWT？ 小結：Session 和 JWT 的運作邏輯 Session 和 JWT 的優缺點比較 使用 Session 的優點和缺點 使用 JWT 的優點和缺點 到底使用 Session 好，還是使用 JWT 好？ 結語 什麼是 Session 認證？ # Session 和 JWT 可以說是現今主流的兩種登入認證機制，不過在開始比較 Session 和 JWT 的差別之前，首先我們要先來介紹一下什麼是 Session 身份認證機制。\n所謂的 Session 認證，就是「將登入的資訊儲存在後端 Server 上」的一項技術，所以換句話說的話，就是後端 Server 會儲存這個使用者的登入資訊，並且回傳一個 Session id 給使用者。\n舉例來說，假設我是一個使用者，我的帳號密碼是 Judy / 123，這時候當我在網站上輸入帳號密碼，並且嘗試登入時，首先後端 Server 會先去驗證我的帳號密碼 Judy / 123 是否曾經註冊過（畢竟得先註冊過才能登入），假設這組帳號密碼存在的話，後端 Server 就會生成一個 Session id（也就是 66EE89C175E），並且將 Session id 存放在資料庫中，然後將 Session id 回傳給前端。\n所以當前端（此處以瀏覽器為例）收到 Session id 的值時，前端就可以將這個 Session id 的值存放在 Cookie 中，等待後續使用。因此到這裡就完成了登入的操作，所以使用者理論上就會被跳轉回首頁，並且已經是成功登入的狀態。\n而當使用者成功登入之後，假設使用者後續想要去 call 其他受保護的 api（ex：查看個人設定），這時候前端就可以在 call api 時，同時也帶上當初後端 Server 發放的 Session id，這樣後端在收到這一次的請求時，就可以去資料庫查詢一下這個 Session id 的值是否存在，如果存在的話，就表示這個使用者已經有成功登入過了，所以就可以允許這一次的 api 通過，進而返回實際的結果給前端。\n所以對於 Session 這種登入機制而言，所有的登入記錄都是儲存在「後端 Server」上，前端所拿到的 Session id 的值，其實就只是一組沒有意義的亂碼，只有後端 Server 才知道這組 Session id 實際上對應到的是哪個使用者的登入資訊。\n因此 Session 這種登入機制，他就是「將登入的資訊儲存在後端 Server 上」的一項技術。\n什麼是 JWT 認證？ # 了解了什麼是 Session 的登入機制之後，接著我們可以來介紹什麼是 JWT 的登入機制。\n所謂的 JWT 認證，就是「將登入的資訊儲存在前端 Client 中」的一項技術，所以換句話說的話，就是會將使用者的登入資訊，直接儲存在前端的 Client 中，因此在後端 Server 中是不會儲存任何一筆登入資訊的！\n這聽起來可能有點神奇，不過 JWT 的運作邏輯是這樣子的：\n和前面一樣的例子，假設我是一個使用者，我的帳號密碼是 Judy / 123，這時候當我在網站上輸入帳號密碼，並且嘗試登入時，首先後端 Server 一樣是會先去驗證我的帳號密碼 Judy / 123 是否曾經註冊過。\n但是這裡重點來了！！假設這組帳號密碼存在的話，後端 Server 就會生成一個 JWT 格式的 Token，並且會直接返回該 Token，而且「不需要」在後端 Server 中儲存這個 Token 的數據。\n所以在 JWT 認證的世界中，後端 Server 是不需要儲存任何一筆 JWT 的數據的！！！後端 Server 要做的事情，就是生成 JWT Token，然後直接回傳就好，就是這麼簡單暴力！！！\n這時候你可能會想：這樣到時候要怎麼驗證這個 JWT Token 是有效的？這時候就是展現 JWT 的神奇地方之處了！！\n當使用者成功登入之後，假設使用者後續要想去 call 其他受保護的 api，這時候前端就可以在 call api 時，同時也帶上當初後端 Server 發放的 JWT Token，而當後端收到這個 Token 時，只要這個 JWT 的簽名驗證成功，後端就會無條件相信 JWT Token 中的內容，也就是 JWT Token 聲稱這個使用者的名字叫做 Judy，那後端就無條件相信這一次來請求的人就叫 Judy；JWT Token 聲稱這個使用者的 id 是 111，後端就無條件相信這個使用者的 id 是 111。\n所以在 JWT 認證的世界中，後端就是這麼的天真可愛，只要 JWT 說什麼，後端就無條件相信他，完全不需要質疑 JWT 的安全性，因此在 JWT 的認證機制中，所有的登入記錄都是儲存在「前端 Client」上，前端所拿到的 JWT Token，就是一個包含所有使用者資訊的 Token，因此只要能夠正確解讀這個 JWT Token，就可以拿到使用者的所有資訊。\n所以 JWT 這種登入機制，他就是「將登入的資訊儲存在前端 Client 上」的一項技術。\n補充：後端為什麼能無條件相信 JWT？ # 第一次接觸 JWT 的人，一定會很疑惑覺得：「到底為什麼後端可以這麼無條件的相信 JWT？」，事實上後端之所以可以無條件相信 JWT 中的內容，是因為 JWT 本身是一個帶有數位簽名的 Token 格式。\n在 JWT 的組成結構中，可以分成 3 個部分，分別是：header、payload、signature。\n舉例來說，下面這一串亂碼：\neyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjMiLCJuYW1lIjoi5Y-k5Y-kIiwiaWF0IjoxNzIxMDAxNjAwfQ.G41XQGNNJ5Tp88U48aXh4n0XtGkpPkQ3xK6j43_61gE309hzyTVyciG5v05aVIvvY9NrApYiQdvwlMMrjRPFVV8xunghtKKFMj3kPx93Ll8Pf6n-tDiL_NZYqcusrgwtb-EDza80hMG5PTu75ogTIfRKr4jC0_FZzLaMix07LaZReoUSionTWTxJlm8qJc0BAFXgsaGNs9oVhCXOg_jJmOfFZBP0tD3q4xaKp9MTtLRTtslAhoAjPczdnPqaWGcaS8OY11RUTvvxijA7W-mPRlmqt0Hd_XForETUFZRdCKsPQIiGjkavycPtdiViVihQKstHlT4afEzYvzWSeK1cnw 就可以被解析成 header、payload、signature 這三個部分（每一個部分之間用一個點 . 隔開）。\nheader：\neyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9 payload：\neyJzdWIiOiIxMjMiLCJuYW1lIjoi5Y-k5Y-kIiwiaWF0IjoxNzIxMDAxNjAwfQ signature：\nG41XQGNNJ5Tp88U48aXh4n0XtGkpPkQ3xK6j43_61gE309hzyTVyciG5v05aVIvvY9NrApYiQdvwlMMrjRPFVV8xunghtKKFMj3kPx93Ll8Pf6n-tDiL_NZYqcusrgwtb-EDza80hMG5PTu75ogTIfRKr4jC0_FZzLaMix07LaZReoUSionTWTxJlm8qJc0BAFXgsaGNs9oVhCXOg_jJmOfFZBP0tD3q4xaKp9MTtLRTtslAhoAjPczdnPqaWGcaS8OY11RUTvvxijA7W-mPRlmqt0Hd_XForETUFZRdCKsPQIiGjkavycPtdiViVihQKstHlT4afEzYvzWSeK1cnw 而當後端在生成一個 JWT 的 Token 時，後端會先將 header 和 payload 的值組合起來，然後用 「hash + 非對稱加密」 的方式，生成一個 signature（簽名）的值出來。\n所以假設駭客偷偷修改了 payload 中的數據，這樣子最終解析出來的 signature 的簽名，就會和原始的簽名值不一樣，因此就可以透過這種 「數位簽名」 的方式，避免被駭客偷偷修改 payload 中的數據了。\n補充：如果覺得上面這段太難的話，建議也可以先跳過 JWT 的詳細內容，只要先知道 JWT 是真的很強，後端可以直接無條件相信他就對了👍。\n小結：Session 和 JWT 的運作邏輯 # 所以先總結一下上面的介紹的話：\nSession 認證就是「將登入的資訊儲存在後端 Server 上」 JWT 認證就是「將登入的資訊儲存在前端 Client 中」 Session 和 JWT 的優缺點比較 # 使用 Session 的優點和缺點 # 因為 Session 的特性是將登入的資訊儲存在後端 Server 上，因此後端 Server 能夠主動刪除使用者的登入資訊（後端只要將資料庫中的 Session id 的數據刪除，該名使用者的登入記錄就會被刪除，因此就能夠實作「將使用者強制登出」的情境）。\n但也因為 Session 的數據是儲存在資料庫中，因此當數量變多時，就會影響資料庫效能，所以當使用者數量到達百萬級之後，Session 認證就會遇到許多擴展上的困難。\n使用 JWT 的優點和缺點 # 因為 JWT 的特性是將登入的資訊儲存在前端 Client 中，所以就算使用者數量到達百萬級別，也不會對後端 Server 造成影響，因此很適合用在大型的微服務架構下、或是 SSO（Single Sign-On，單一登入）的使用情境。\n但也因為 JWT 是將登入的資訊儲存在前端 Client 中，因此後端 Server「沒有能力」主動刪除使用者的登入資訊（因為後端會無條件相信 JWT Token 中的數據，所以後端沒有辦法主動撤銷某個 JWT Token，只能被動的等待該 JWT 自己過期失效）。\n所以如果在使用 JWT 的前提下，仍舊想要實作「黑名單」之類的功能的話，就會需要走 Session 的回頭路，使用資料庫來記錄黑名單的使用者有哪些，就會喪失 JWT 本身的優勢。\n到底使用 Session 好，還是使用 JWT 好？ # 綜觀以上的優缺點比較，其實 Session 和 JWT 真的沒有誰比較好、誰比較壞，他們兩個就像是站在對立面的選擇一樣，Session 的優點就是 JWT 的缺點、Session 的缺點就是 JWT 的優點，一切都要因實際的需求，選擇當下最適合的做法。\n簡單一句話總結的話，就是 Session 和 JWT 的戰爭還未停止😂，甚至有時候也會看到混用他們的情況出現，因此建議大家兩種用法都要會，這樣在面對變動的需求時，才能選擇最適合的方式來解決問題！\n補充：本文是擷取自我開設的線上課程「資安一把罩！Spring Security 零基礎入門」的內容，如果你想了解更多的資安內容、以及如何應用 Spring Security，歡迎參考課程簡介 （輸入折扣碼「HH202601KU」即可享 85 折優惠）。\n結語 # 這篇文章我們介紹了 Session 和 JWT 認證的差別，並且也比較了一下他們的優缺點，在現今 JWT 使用非常廣泛的時代中，多了解一點資安的技術也是絕對不會虧的！\n如果你對後端技術有興趣的話，也歡迎免費訂閱《古古的後端筆記》電子報，每週二為你送上一篇後端技術分享，那我們就下一篇文章見啦！\n如果你對 JWT 的其他文章有興趣，也可以直接點擊下列連結跳轉到該文章（建議按照順序閱讀，才會有最佳的閱讀體驗）：\nSession 和 JWT 的差別在哪裡？（本文） 密碼學中的 Encode、Encrypt、Hash 的差別在哪裡？ JWT 是什麼？一次搞懂 JWT 的組成和運作原理 JWT 是如何實作「數位簽名」的？揭秘 signature 的面紗 ","permalink":"https://kucw.io/blog/session-vs-jwt/","tags":null,"title":"Session 和 JWT 的差別在哪裡？"},{"categories":["自媒體經營"],"contents":"哈囉，我是古古，這篇文章是每月一次的自媒體月報，主要分享我經營《古古的後端筆記》個人品牌的幕後秘辛，如果你也對於「自媒體創業」有興趣的話，歡迎繼續閱讀本文～\n補充：如果想了解《古古的後端筆記》電子報的起源，也可以先查看創刊號的文章。\n2024.11 月粉絲追蹤數、電子報訂閱人數 # 本月份（2024.11）的粉絲成長人數如下：\n2024/10/29 人數 2024/11/26 人數 11 月份總成長人數 Facebook 粉專追蹤數 4150 4389 +239 電子報訂閱人數 1632 2076 +444 Threads 粉絲追蹤數 2557 4566 +2009 IG 粉絲追蹤數 247 353 +106 這個月的各項指標就是順順的成長，沒有特別突出的爆文，比較意外的是 Threads 和 Facebook 竟然黃金交叉了😂。\n但不得不說我最近也都是滑 Threads 比較多，趁著現在 Threads 裡面沒有廣告，滑起來真的很愉快舒暢XDD，推推！（天曉得以前在 Facebook 要被多少篇商周雞湯文、或是各種廣告轟炸）\n本月自媒體活動：我出書了！！ # 這個月我出了人生的第一本書《Spring Boot 零基礎入門》！！！而且也感謝博碩出版社願意支援我「預購送簽名」的活動，完全是圓了我的簽書夢，謝謝博碩🥹。\n出書的寫作心法和幕後花絮，在之前的文章中已經有和大家分享：\niThome 鐵人賽 - 得《優選》獎項的寫作心法 iThome 鐵人賽 - 出書的幕後花絮 所以這邊就不多贅述，就以一張我簽名簽到很開心的照片作為收尾吧🤣！\n如果你也想要出自己的一本書，非常推薦大家可以參加每年 iThome 舉辦的 30 天鐵人賽活動，只要得獎就可以出書（冠軍、優選、佳作皆可出書）。\n老實說就連在我已經開過好幾堂線上課程的前提下，靠自己的力量還是很難出一本書（首先你要有人脈能聯繫上出版社編輯，然後你要說服他們願意讓你出書），所以藉由 iThome 所舉辦的盛事活動，先用得獎來證明自己的文章是值得出書的，後續再直接和出版社對接，真的是素人出書最簡單的方式了～\n本月撰寫的電子報主題、文章 # 這邊記錄了我這個月撰寫了哪些電子報和文章，大家如果對於其中的內容有興趣的話，也可以前往查看：\n資料庫的 ACID、Transaction（交易）介紹 免費仔萬歲！使用 GitHub Actions 實作 CI/CD、網路爬蟲 iThome 鐵人賽 - 出書的幕後花絮 給工程師的求職建議（年資 1-3 年） 雲端服務中的 IaaS、PaaS、FaaS、SaaS 的差別 2024.11 月報總結 # 呼～大概是這樣！這個月其實花了大半部分的精力在出書上，所以沒有太多時間學習自媒體的相關知識，最後也要真的感謝大家的支持🙏，希望你們會喜歡我的簽名🤣。\n下個月應該就比較有空學習自媒體的內容了！我已經囤積了好幾本書想看了🤣，等到有更多心得也會再和大家分享～那我們就下個月的月報再見啦！\n如果你對後端筆記有興趣，也歡迎免費訂閱《古古的後端筆記》電子報，每週二為你送上一篇後端技術分享，一起變強💪\n","permalink":"https://kucw.io/blog/as-a-content-creator/monthly-report-202411/","tags":null,"title":"軟體工程師的自媒體之路 - 2024.11 月報"},{"categories":["其他技術分享"],"contents":"IaaS、PaaS、FaaS、SaaS 這些名詞，是大家一開始在接觸雲端服務時，很容易搞混的名詞，所以這篇文章我們就來介紹一下他們的差別吧！\n目錄 1. 什麼是 IaaS？ IaaS 的優點 IaaS 的缺點 2. 什麼是 PaaS？ PaaS 的優點 PaaS 的缺點 小結：IaaS 和 PaaS 的區別 3. 什麼是 FaaS？ FaaS 的優點 FaaS 的缺點 補充：FaaS 也稱為 Serverless（無伺服器運算） 4. 什麼是 SaaS？ IaaS、PaaS、FaaS、SaaS 總結 結語 1. 什麼是 IaaS？ # IaaS 是 Infrastructure as a Service 的簡寫，中文翻譯為「基礎結構即服務」，IaaS 是指「你能夠使用這個服務來創建 VM」。\n所以假設有一個雲端服務是 IaaS，那就表示他可以讓我們在上面自由的創建 VM，並且我們可以在該 VM 中安裝喜歡的 Java 版本、或是安裝喜歡的 Python 版本，然後我們也可以在這個 VM 裡面自由的運行想運行的程式，完全不受到任何限制！\n所以只要是直接提供一台 VM 給你自由運用的服務，即是屬於 IaaS 的一種，也就是 Infrastructure as a Service。\n舉例來說，像是 AWS 的 EC2、GCP 的 Compute Engine，他們就都是屬於 IaaS 的服務（因為他就是直接提供一台 VM 給我們，讓我們自由去運用）。\nIaaS 的優點 # 因為 IaaS 提供完整的 VM 存取權，所以靈活性非常高，想幹嘛就幹嘛！ IaaS 的缺點 # 因為雲端服務商只會提供一台 VM 給你，所以凡事都得自己來，上到安裝 Java 版本、下到網路防火牆設定，全部都得靠自己完成。 2. 什麼是 PaaS？ # PaaS 是 Platform as a Service 的簡寫，中文翻譯為「平台即服務」，而到了 PaaS 這裡之後，就沒有了 VM 的概念。\n因此假設有一個雲端服務是 PaaS，那麼 他只會要求你上傳你的程式碼，然後他就會像變魔法一樣，直接幫你把這個程式運行起來了，magic！\n所以當你使用了 PaaS 的服務之後，你就再也碰不到 VM 層了（或是非常難），雲端服務商會把你的程式運行在一個「容器 Container」裡面，你只要告訴他你要幾個容器就好，剩下的雲端服務商會全部包辦。\n因此 PaaS 也可以稱為是懶人部署法，你不需要像上面的 IaaS 一樣，自己去搞 VM 然後自己安裝 Java 版本，你要做的，就是寫好程式，上傳，然後剩下的雲端服務商會全部幫你搞定，世界和平！\n舉例來說，像是 AWS 的 Elastic Beanstalk、GCP 的 App Engine、或是 Zeabur、Heroku、Vercel…等等的網站，他們就都是屬於 PaaS 的服務（因此我們就只要直接上傳我們的程式就好，不需要處理任何環境安裝的問題）。\nPaaS 的優點 # 只需要上傳程式碼即可運作，降低維運的人力和時間成本。 PaaS 的缺點 # 靈活度比較低，碰不到實際的 VM 層級，沒辦法直接連線到容器裡面做特別的設定。 通常會限制程式語言，只支援熱門的，太冷門的不支援。 收費較貴（不過貴不是他的缺點，是我的🥹。 小結：IaaS 和 PaaS 的區別 # 所以從上面的 IaaS 和 PaaS 的介紹，大概可以感覺得出來 IaaS 和 PaaS 其實是一個對立的關係。\nIaaS 就是直接丟一個最原始的 VM 給你，你愛蓋什麼就蓋什麼，有點像是給你一塊地你自己自由發揮。\n而 PaaS 則像是一棟蓋好的大樓，裡面的設施非常先進漂亮，你只要提著你的行李箱（程式碼）就可以入住，但缺點就是你不能隨便更動大樓裡面的管線，只能照著他們既定的規則走這樣。\n所以如果你只是要做一個小型的 Project，不想要管環境的安裝問題，那就可以直接採用 PaaS 的服務來部署；而如果你是想要自己掌握所有控制權，想要自己處理防火牆、軟體版本\u0026hellip;等等的控制，或是你想省點錢的話😂，那就可以考慮採用 IaaS 來部署。\n3. 什麼是 FaaS？ # 了解了經典的 IaaS 和 PaaS 的概念之後，接著我們可以來看一下什麼是 FaaS。\nFaaS 是 Function as a Service 的簡寫，中文翻譯為「函式即服務」或是「功能即服務」。\n相較於 IaaS 和 PaaS，FaaS 其實是近十年才被提出來的新概念，所以雖然 FaaS 也是屬於 XaaS 家族的一員，但其實他和上面的 IaaS 和 PaaS 沒什麼關係。\nFaaS 的概念，是 「把程式當成方法來執行」，即是讓程式不用一直運行著，而是當有請求來時，就快速啟動這個程式，然後請求走的時候就 shutdown 這個程式，簡單的說就是不讓程式一直啟動著，而是有需要的時候才開啟他，這就是 FaaS 的概念！\n大家也可以想像一下，一般我們在寫後端程式的時候，通常就是把程式運行起來，然後這個程式就會一直運行著，等著去接收前端的請求，即使沒有前端的請求過來，這個程式仍舊會一直運行著。\n而 FaaS 即是想要提出一個新概念，就是只有當前端發請求過來的時候，才會去運行起這個後端程式去處理前端的請求，當請求執行完畢後，就關掉這個後端程式，不讓他在那邊空轉，把「程式」當成是一個「方法」來運行，即是 FaaS 的概念。\n舉例來說，像是 AWS 的 Lambda、GCP 的 Cloud Functions，他們就都是屬於 FaaS 的服務。\nFaaS 的優點 # 只需要在使用時付費，不需付錢讓程式空轉。 FaaS 的缺點 # 功能要拆分的比較細，每一份程式要保持在處理非常輕量化的小功能，像是處理一張圖片的 resize…等。 和雲端服務綁比較深，萬一將來要下雲會比較麻煩。 補充：FaaS 也稱為 Serverless（無伺服器運算） # 在這裡也補充一下，其實 FaaS 服務還有另一個稱呼，即是 Serverless（無伺服器運算）。\nFaaS 之所以能夠被稱為 Serverless，是因為從定義上來說，我們並沒有長期運行一個 server，而是當前端請求來時，我們才啟動這個 server，並且當前端請求走了之後，這個 server 也被關掉了。所以在定義上，我們「並沒有」長期運行一台 server，傻傻的去等待前端發送請求過來，因此這種部署方式，就稱為是 FaaS，也叫做 Serverless（無伺服器）。\n所以 FaaS 和 Serverless，他們指的其實都是同一件事情，就是把程式當成方法一樣來使用，用完即丟，不會長期運行某份程式這樣。\n補充：其實我一開始有點不能接受 Serverless 的定義😂，因為他就是有運行 server 啊！只是中間的過程很短我們看不見而已！！不過這邊的定義就是這樣，所以建議大家就先接受這個定義吧🥹，FaaS 就是 Serverless，Serverless 就是 FaaS，他們指的是同一件事情。\n4. 什麼是 SaaS？ # 介紹完前面的 IaaS、PaaS、以及 FaaS 之後，最後我們可以來看一下什麼是 SaaS。\nSaaS 是 Software as a Service 的簡寫，中文翻譯為「軟體即服務」。\nSaaS 其實就是泛指 Gmail、Google Drive 這種已經很成熟的軟體，SaaS 跟工程師其實沒有什麼特別的關係，通常只是在提到 IaaS、PaaS 時，會一起拿出來被介紹到。\n舉例來說：\n我們在工作上，可以使用 Jira、Trello 這類的 SaaS 的軟體，幫助我們管理敏捷看版的流程。 我們也可以使用 Outlook、Gmail 這類的 SaaS 軟體，幫助我們收發 email。 在日常生活中，我們也可以使用 Notion、Heptabase 這類的 SaaS 筆記軟體，幫助我們記錄工作上遇到的大小事、或是個人的學習筆記。 所以對於 SaaS 而言，基本上只要是你喊得出名字的軟體服務，大部分都是屬於 SaaS 的服務，所以大家在日常的生活中，其實已經大量使用到 SaaS 的服務了！\nIaaS、PaaS、FaaS、SaaS 總結 # 所以總結一下上面的介紹的話，XaaS 家族就可以被統整成下面這張圖片（其中虛線下方所表示的，就是 AWS、GCP、Azure 所提供的雲端服務應用）。\n圖片來源： What are Cloud Computing Services [IaaS, CaaS, PaaS, FaaS, SaaS] 因此大家在工作上，除了專注在後端的程式開發之外，也可以多多觀察一下你們公司目前是用什麼方式來部署的，雖然部署這部分通常是會交由 DevOps 工程師來執行，但是多懂一點雲端服務的概念總是不會虧的XD。\n畢竟只有當我們全面的了解有哪些工具可以運用時，我們才能夠活用這些工具，用最高的效率達到我們想要的效果！\n結語 # 這篇文章我們介紹了 IaaS、PaaS、FaaS、以及 SaaS 的差別，並且也介紹了市面上有哪些相關的服務可以使用，希望可以讓大家更了解 XaaS 家族中各個名詞的含義。\n如果你對後端技術有興趣的話，也歡迎免費訂閱《古古的後端筆記》電子報，每週二為你送上一篇後端技術分享，那我們就下一篇文章見啦！\n補充：我開設的 Spring Boot 零基礎入門、Spring Security 零基礎入門、GitHub 免費架站術 已在 Hahow 平台上架啦！輸入折扣碼「HH202601KU」即可享 85 折優惠。\n","permalink":"https://kucw.io/blog/iaas-paas-faas-saas-intro/","tags":null,"title":"雲端服務中的 IaaS、PaaS、FaaS、SaaS 的差別在哪裡？"},{"categories":["其他技術分享"],"contents":"哈囉，我是古古！之前有在 iThome 鐵人賽 - 得《優選》獎項的寫作心法 的文章中，和大家分享我得獎的寫作心法，這篇文章則是會分享在 iThome 鐵人賽得獎之後，出書過程中的一些幕後花絮，如果你也對出書感興趣的話，歡迎繼續觀看本文章～\n目錄 這本書《Spring Boot 零基礎入門》在介紹什麼？ 出書的幕後花絮 書稿要用 Word 檔繳交 書稿的中英之間不能有空白鍵 封面文案、封底文案設計 結語 這本書《Spring Boot 零基礎入門》在介紹什麼？ # 首先先介紹一下我所出版的書籍，這本書是改編自 iThome 鐵人賽的得獎文章《Spring Boot 零基礎入門》，當初會想用 Spring Boot 零基礎入門這個主題參賽，就是因為自己剛入門 Spring Boot 時，發現單純透過網路上零散的介紹，很難完整了解 Spring Boot 的運作邏輯是什麼（一開始覺得IoC 好難…🥹），一度覺得很挫折。\n所以希望可以透過這本書，系統性的去整理 Spring Boot 的知識，讓想要入門 Spring Boot 的人有個方向，至少在看完這本書之後，能夠學到：\nSpring IoC、Spring AOP 的概念和用法 Spring MVC 的用法 Spring JDBC 的用法 能夠使用 Spring Boot，開發出一個簡易的後端系統（書中使用圖書館管理系統作為範例） 如果你也對 Spring Boot 有興趣、或是打從心底想要從頭開始學習 Spring Boot，那麼這本書真心推薦給你！\n出書的幕後花絮 # 以下僅列出我在寫書中覺得很意外 or 很新鮮的事，記錄的不是很完全，大家就看個開心就好～\n書稿要用 Word 檔繳交 # 這個應該是在寫書時痛苦指數最高的事情🥹，在出版社真的拿著書稿內容去排版之前，會需要作者先用 Word 檔把全部的內容整理起來（包含各章標題、圖號、程式碼樣式），先給編輯看過一遍之後，編輯才會把 Word 檔交給美編，交由美編後續去排版。\n但是在習慣使用 Markdown、Notion 這類的筆記軟體之後，突然要回頭使用 Word 檔.…真的是只有想哭可言🥲（我從學校畢業之後就沒打開過了）。\n首先 Word 的排版就真的很難搞，再來就是 Mac 上的 Word app 常常會閃退（我不知道是我電腦有問題還是 Word 有問題），反正就是要花很多時間和 Word 戰鬥.…如果大家將來也想要出書的話，建議先跟你家 Word 打好關係，因為你真的會很依賴他🥹。\n給大家看看我的 Word 檔，以及給美編排版過的成果：\n這樣看下來，美編是不是真的很神！！！只要給她醜醜的 Word 檔，她就可以幫你排出好看的排版，出這本書真的不能沒有美編XDD，感謝美編！！！\n書稿的中英之間不能有空白鍵 # 又是一個撰寫書稿的痛苦（出書大概有 80% 的痛苦都是在寫書稿，其他部分相較還好），一般我在寫文章的時候，中英文之間會有空白鍵，但是出版社要我們繳交的書稿，竟然要把中英文間的空白鍵刪掉！！！（好像是因為排版軟體的設定，所以必須要刪掉空白鍵，這樣子弄出來的書稿才會正常）\n反正這部分也是折磨我很久…就算用「取代」功能一鍵把所有空白鍵刪掉，也需要整份稿子重新檢查有沒有缺漏的部分。最可怕的是在改稿的時候，手會不小心習慣在中英之間按下空白鍵，然後事後發現之後又要整個回頭重改🥹，我只能….哭惹😭。\n反正中英不能有空白鍵這件事真的是造成我心理陰影，甚至還想跟編輯說我之後不想再寫書了XDD，但老實說現在回頭看起來也是一次特別的經驗就是了，畢竟是第一次出書，再怎麼樣都是一次新鮮的體驗！\n封面文案、封底文案設計 # 這部分算是我很意外的部分！我沒想到出版社可以讓我們自己想封面和封底設計，其實對於作者來說彈性還滿大的，先給大家看看我的封面和封底設計（沒錯編輯竟然是給我一張這樣的展開圖，我第一次收到有嚇到XDD）：\n其中有關書名、封面的大圖、封面文案、封底文案、作者簡介，這些都是可以讓作者設計的，所以作者可以根據你自己的書，填上你想放的宣傳語。\n舉例來說，下面這些都是我提供給編輯的文案：\n不得不說，真的是當了作者之後，才發現原來一本書的封面、封底設計，都是有意義的！！所以大家下次再走進書店買書時，建議可以仔細研究一下封面上的各種小字，每一行小字其實都是作者精心放上去的內容，絕對沒有那種來湊數的文字存在！\n然後在設計封面和封底文案時，中間也有發生一件很好笑的事，因為我實在是不知道怎麼寫文案比較好，我就跑去附近的諾貝爾書局，然後一本一本翻以前鐵人賽的書是怎麼寫的，邊翻邊拍照，我大概拍了 20 幾本有（還好店員沒有覺得我很奇怪🤣），在書局待了一整個下午就只為了參考其他書是怎麼寫的，現在回想起來，真的是很特別的一次經驗XD。\n結語 # 呼～大概是這樣吧！雖然上面吐嘈了一些寫書稿的痛苦，但是老實說看到自己寫的書上架還是滿有成就感，如果你也對出書有興趣的話，非常推薦參加一年一度的 iThome 鐵人賽，希望大家都可以成功出版你人生的第一本書👍。\n如果你對後端技術有興趣的話，也歡迎免費訂閱《古古的後端筆記》電子報 ，每週二為你送上一篇後端技術分享，那我們就下一篇文章見啦！\n補充：我開設的 Spring Boot 零基礎入門、Spring Security 零基礎入門、GitHub 免費架站術 已在 Hahow 平台上架啦！輸入折扣碼「HH202601KU」即可享 85 折優惠。\n","permalink":"https://kucw.io/blog/ithome-write-a-book/","tags":null,"title":"iThome 鐵人賽 - 出書的幕後花絮"},{"categories":["職涯相關"],"contents":"在面試找工作時，選擇一家心儀的公司絕對是最重要的事，以下分享 2 點找工作的建議給 1-3 年年資的工程師：\n1. 找工作時，發展性 \u0026gt; 錢 # 這個階段其實大家都還是新手，成長性仍舊很高，所以在考慮要不要去某間公司時，要思考的是：「3 年後你離開這間公司時，你有哪些武器可以拿來面試下一間公司」。\n舉例來說，如果 A 公司是 65k（新創），B 公司是 50k（台灣大型企業），那麼你願不願意為了「大企業鍍金」的價值，屈就自己去領 50k 的薪水。這沒有正確答案，就只是個人選擇而已，沒有誰能為你的人生負責，只有自己能為自己負責。\nPS: 但如果真要說，我會建議選擇大公司，畢竟大公司將來要跳新創比較容易，新創要跳大公司會稍微難一點，考量到人生很長，有大公司的經歷還是不錯的。\n2. 學習是下班的重要活動，健身之餘也要健腦 # 有很多人入職之後就疲於工作奔命，沒有留時間給自己繼續精進，其實這是風險很高的事情，因為你沒辦法跟新鮮人拉開差距。\n畢竟你當初可能是努力了一年才成功轉職，如果你不繼續往前走，那麼被其他新鮮人努力一年之後取代，只是遲早的事。\n長江後浪推前浪，身為前浪，真的要避免死在沙灘上😂。\n結語 # 如果你想保持學習的步調，歡迎免費訂閱《古古的後端筆記》電子報，每週二為你送上一篇後端技術分享，大家一起變強💪！\n補充：我開設的 Spring Boot 零基礎入門、Spring Security 零基礎入門、GitHub 免費架站術 已在 Hahow 平台上架啦！輸入折扣碼「HH202601KU」即可享 85 折優惠。\n","permalink":"https://kucw.io/blog/developer-interview-suggestion/","tags":null,"title":"給工程師的求職建議（年資 1-3 年）"},{"categories":["其他技術分享"],"contents":" 目錄 什麼是 GitHub Actions？ GitHub Actions 在 CI/CD 中的用途 實戰：使用 GitHub Actions 架設第一個 CI/CD GitHub Actions 在網路爬蟲中的用途 實戰：使用 GitHub Actions 實作網路爬蟲 GitHub Actions 總結 結語 什麼是 GitHub Actions？ # 所謂的 GitHub Actions，是 GitHub 所提供的一個自動化集成服務，簡單的說的話，就是我們可以自由指定：「當有 commit 被 push 到 GitHub 中的某個 repository 時，我們要 GitHub 做什麼事」。\n舉例來說，我們可以設定成：「當有 commit 被 push 到 mytest 這個 repository 時，我們要求 GitHub 要傳送一則訊息到 Slack 裡面通知大家」，所以當我們添加了這一個 GitHub Action 之後，以後只要有人 push 了任一個 commit 到 mytest 中，GitHub Action 就會被觸發，因此就會傳送一筆訊則到 Slack 群裡面通知大家了。\n所以 GitHub Actions 他最一開始被發明出來的目的，就是為了「程式的自動化集成」，也稱為是「CI/CD」（Continuous Integration/Continuous Deployment）。\nGitHub Actions 在 CI/CD 中的用途 # 如上面所介紹到的，GitHub Actions 本來就是為了「程式的自動化集成」而發明，簡單的說的話，就是我們可以預先設定好「當工程師上傳 code 之後，要 GitHub Actions 做什麼事」，所以這裡就延伸出各式各樣的用法。\n舉例來說，有的團隊會設定成：\n當工程師上傳 code 之後，自動執行單元測試，檢查所有測試是否能夠成功通過 當工程師上傳 code 之後，自動執行 ESLint、SonarCube 這類的檢查，確保程式的品質正常 當工程師上傳 code 之後，自動將該程式部署到 dev 環境 …等等 而上述這些用法，如果要給他們一個統稱的話，就稱為是「CI/CD」，也就是「持續整合/持續部署」 （Continuous Integration/Continuous Deployment），所以當大家在工作中聽到 CI/CD 時，基本上就是在對我們所上傳的程式做一些「後處理」，確保一些無聊的重複工作可以被自動化執行，這就是 CI/CD 的目的！\n實戰：使用 GitHub Actions 架設第一個 CI/CD # 了解了 GitHub Actions 的概念之後，接著我們也可以試著到 GitHub 上設定看看 GitHub Actions，實作第一個 CI/CD 程式。\n老實說要在 GitHub 中設定一個 GitHub Actions 真的比想像中容易🤣，只要在 GitHub repo 中添加一個 .github 資料夾，並且在裡面再創建一個子資料夾 workflows（也就是 .github/workflows），接著就可以在裡面撰寫 GitHub Actions 的設定了！\n所以創建好 .github/workflows 這兩層資料夾之後，接著可以在裡面添加一個 demo-github-action.yml 的檔案，表示這是一個 action（檔案的檔名可以隨意取，要叫做 demo-github-action.yml 或是 xxx.yml 都可以，每一個檔案就是一個 action）。\n此時在 demo-github-action.yml 裡添加下列程式之後：\nname: GitHub Actions Demo run-name: GitHub Actions Demo # 觸發此 action 的時機 on: push: branchs: # 只要有任何一個 commit 被 push，就會觸發此 action \u0026#39;*\u0026#39; workflow_dispatch: # 可以手動執行此 action # 預先定義此 action 要幹嘛 jobs: demo: runs-on: ubuntu-latest steps: - run: echo \u0026#39;執行成功\u0026#39; 只要這樣寫之後，就可以在「任何一個 commit 被 push」以及「手動執行此 action」這兩個時機點，去觸發這一個 GitHub Action。\n因此當有 commit 被 push 上來時，此 action 就會輸出執行成功的結果，如下圖所示：\n所以透過在 .github/workflows 中添加 demo-github-action.yml 的檔案（檔名可以隨意取），我們就可以為這個 GitHub repo 去添加他專屬的 GitHub Actions，因此就可以用 GitHub Actions 不斷的去集成這份程式，實作 CI/CD 的效果了！\n另外大家以後在查看程式時，如果有發現某份程式有 .github/workflows，就表示他有使用 GitHub Actions，所以就不會看不懂這資料夾到底是在幹嘛的了～（在知道有 GitHub Actions 這功能之前，我一直都以為 .github/workflows 只是 GitHub 產生的檔案，沒啥用處，真的是誤會大了🤣）。\n補充：因為篇幅有限，所以沒辦法詳細介紹 GitHub Actions 中每一行程式的用途，如果大家有興趣的話，可以再查詢 GitHub Actions 的用法介紹。\nGitHub Actions 在網路爬蟲中的用途 # 而 GitHub Actions 除了可以用在最經典的 CI/CD 用途上之外，同時 GitHub Actions 其實也是可以拿來實作爬蟲的！\n之所以可以將 GitHub Actions 用來實作爬蟲，是因為 GitHub Actions 被觸發的時機點，除了可以設定成「當任何一個 commit 被 push 時觸發此 action」之外，也可以設定成 「定時觸發此 action」，而就是這個「定時觸發此 action」的功能，讓我們可以拿來活用他，進而實作網路爬蟲。\n實戰：使用 GitHub Actions 實作網路爬蟲 # 如果要使用 GitHub Actions 實作網路爬蟲的話，首先需要先在 mytest 中新增一份爬蟲程式（此處以 crawler.py 為例）。\n接著在 .github/workflows 中創建一個新的 action 檔案 crawler-demo.yml（檔名可以隨意取），並且在 crawler-demo.yml 中添加下列程式：\nname: Crawler Demo Action run-name: Crawler Demo Action # 觸發此 action 的時機 on: schedule: - cron: \u0026#34;55 12 * * *\u0026#34; # UTC 每天下午 12:55 執行此 action（等同於台灣晚上 8:55 執行） workflow_dispatch: # 可以手動執行此 action # 預先定義此 action 要幹嘛 jobs: crawler-demo: runs-on: ubuntu-latest steps: - name: Checkout uses: actions/checkout@v3 - name: Setup Python uses: actions/setup-python@v4.5.0 with: python-version: \u0026#34;3.10\u0026#34; - name: Install Python Dependency run: pip3 install requests - name: Run crawler.py # 前面都是在安裝 Python 環境，這裡才是真的去執行 crawler.py 的程式 run: python crawler.py - name: Commit Data Back To GitHub Repo # 將爬到的數據 commit 回 GitHub repo run: | git config --global user.name \u0026#34;crawler-bot\u0026#34; git config --global user.email \u0026#34;crawler-bot@gmail.com\u0026#34; git add . \u0026amp;\u0026amp; git commit -m \u0026#34;daily crawl\u0026#34; git push origin main 在這一段程式中，首先最上面有一段 cron 的設定，這一段 cron 的設定就是可以將此 GitHub Actions 設定成「定時觸發此 action」，因此如果大家想要實作定時的網路爬蟲的話，就可以利用 GitHub Actions 的功能，定時去執行你想要執行的爬蟲程式。\n而至於下面的 jobs: 之後的這一大串程式，就是在安裝 Python 環境、執行爬蟲程式 crawler.py、並且將爬取到的數據 commit 回此 repo（不用額外找地方存爬到的數據，讚！）。\n因此透過 GitHub Actions 的用法，等於是可以將下面這三件事，全部都靠一個 GitHub repo 來搞定：\n實作 Python 爬蟲程式 crawler.py 定時執行爬蟲程式，爬取數據 儲存數據 所以對於只是想要寫一個小爬蟲的情境來說，用這招真的是在維護上最方便的做法👍，而且 GitHub Actions 在 public repo 上完全免費（在 private repo 每個月 2000 分鐘免費，也很夠用了），真的只能說是佛心來著🥹。\n我自己已經用這功能爬了 2 個月多的數據，完全沒出過狀況，很穩定！推薦大家使用～\n補充：如果某一次 GitHub Actions 執行失敗，GitHub 也會寄信通知你失敗了，所以只要當我收到失敗信，我再進到 GitHub 上看問題出在哪就好，因此就不用擔心哪天有突發狀況導致數據沒爬到的情況出現，感謝 GitHub！\nGitHub Actions 總結 # 所以總結一下上面的介紹的話，GitHub Actions 就是 GitHub 所提供的一個自動化集成服務（CI/CD），也就是讓我們可以自由指定：「當有 commit 被 push 到 GitHub 中的某個 repository 時，我們要 GitHub 做什麼事」。\n而 GitHub Actions 除了支援最常見的 CI/CD 的用法之外，也可以魔改成網路爬蟲的伺服器來使用，利用 GitHub Actions 中的 cron 的定時執行的功能，就可以達到「定時執行爬蟲程式」的效果，進而在固定的時間去爬取數據了！\nGitHub Actions 目前針對 public repo 完全免費（在 private repo 則是每個月 2000 分鐘免費），我目前每天同時跑 4 個爬蟲，用下來的每月用量大概是 480 分鐘，還很綽綽有餘XD，大家如果想要實時查看你的當月使用量，也可以透過 GitHub 中的 Billing and Plans 頁面 查看。\n在 AI 時代，不只玩玩最新潮的 Copilot，推薦有空時也可以回頭挖寶 GitHub 中那些不為人知的神奇服務，感謝 GitHub 提供免費服務讓我們玩（還有讓我們蹭🤣），GitHub 我大哥！！！\n結語 # 這篇文章我們介紹了 GitHub Actions 的用途，並且也介紹了如何使用 GitHub Actions 架設一個簡易的 CI/CD 程式、以及實作網路爬蟲程式。\n如果你對後端技術有興趣的話，也歡迎免費訂閱《古古的後端筆記》電子報，每週二為你送上一篇後端技術分享，那我們就下一篇文章見啦！\n補充：我開設的 Spring Boot 零基礎入門、Spring Security 零基礎入門、GitHub 免費架站術 已在 Hahow 平台上架啦！輸入折扣碼「HH202601KU」即可享 85 折優惠。\n","permalink":"https://kucw.io/blog/github-actions-intro/","tags":null,"title":"免費仔萬歲！使用 GitHub Actions 實作 CI/CD、網路爬蟲"},{"categories":["其他技術分享"],"contents":" 目錄 什麼是資料庫的 ACID？ Transaction（交易）是什麼？ 例子：銀行轉帳 使用 Transaction 解決轉帳的問題 Transaction 和資料庫 ACID 的關聯 資料庫的 ACID 總結 結語 什麼是資料庫的 ACID？ # 在常見的關聯式資料庫中（例如：MySQL、PostgreSQL、MS SQL），都會有 ACID 的特性，而 ACID 即是：\nAtomicity（原子性） Consistency（一致性） Isolation（隔離性） Durability（永久性） 也因為有 ACID 這四個特性，使得 MySQL 這類的資料庫支援 「Transaction（交易）」 的操作，所以接下來我們就直接用一個例子，來了解一下什麼是「Transaction（交易）」，以及了解 ACID 在其中的用途是什麼。\nTransaction（交易）是什麼？ # 在資料庫中，有一種用法叫做 Transaction，而他的中文可以被翻譯成「交易管理」或是「事務管理」。\n而 Transaction 的用途，就可以在「一個 Transaction 裡面，包含多個資料庫的操作，並且這些資料庫的操作，要嘛全部一起成功，要嘛全部一起失敗，也就是 All or Nothing 原則」。\n例子：銀行轉帳 # 舉例來說，假設我們現在要實作一個轉帳的功能，讓 A 可以轉 1000 元給 B，那麼在實作轉帳的功能時，就需要對資料庫進行兩次操作：也就是先將 A 的存款減去 1000 元，再將 B 的存款增加 1000 元，這樣子就可以完成轉帳的實作。\n所以像是在上面的 transfer() 方法中，就是會先去對 A 的帳戶減去 1000 元（A 的存款從 3000 變成 2000），再為 B 的帳戶增加 1000 元（B 的存款從 500 變成 1500），進而完成轉帳的操作。\n不過，在這段 transfer() 的程式中，其實是有一個潛在的問題的。\n舉例來說，我們在執行這段程式時，一開始一樣是先從 A 的帳戶中減去 1000 元（A 的存款從 3000 變 2000），但是！假設這時程式突然出現了錯誤（有可能是程式出現 bug、或是機器故障、機房停電…等因素），導致在扣完 A 的錢之後，程式沒辦法繼續往下運行，再去 B 的帳戶中增加 1000 元。\n因此最終結果就會變成 A 損失了 1000 元、但是 B 卻沒收到 1000 元，導致 1000 元就這樣消失了！這種狀況一定是大家不想看見的。\n所以為了解決這個問題，Transaction 就被發明出來了！\n使用 Transaction 解決轉帳的問題 # 在資料庫中，他支援一種用法叫做 「Transaction（交易）」，當我們使用 Transaction 來管理這整個轉帳的流程之後，那麼「扣掉 A 的錢」以及「增加 B 的錢」這兩件事情，他們就只能夠一起成功，或是一起失敗。\n舉例來說，在 Spring Boot 程式中，我們可以在某個方法上面加上 @Transacional，這樣子就可以宣告「使用一個 Transaction 來管理這個方法」，因此在這個例子中，當我們在 transfer() 方法上面添加 @Transactional 時，就表示我們創建了一個 Transaction，來管理這個 transfer() 方法。\n而當某個方法被 Transaction 來管理時，那麼 「在那個方法中的所有資料庫操作，要嘛全部一起成功、要嘛全部一起失敗，也就是 All or Nothing 原則」。\n因此在這個例子中，首先 A 一樣是會先被減去 1000 元沒錯（所以 A 的存款從 3000 變成 2000），然後這時候一樣，程式遇到了錯誤，因此程式就只能夠被迫中斷，沒辦法繼續往下執行，為 B 的帳戶增加 1000 元。\n但是這個時候，因為我們有在 transfer() 方法上面加上 @Transactional，用一個 Transaction 來管理此方法，因此此時 Transaction 就會復原（也稱為 rollback）前面做過的所有資料庫操作，也就是會將 1000 元還給 A，所以 A 的存款又從 2000 元變回 3000 元，就像是剛剛那個扣除的 SQL 語法從來沒有執行過一樣，A 和 B 的存款都回到最初的樣子，這就是 Transaction 的厲害之處！！\n所以對於轉帳這種「涉及多個資料庫操作」的功能而言，如果我們想要確保轉帳中的所有資料庫操作要嘛一起成功、要嘛一起失敗，這時候就可以使用資料庫所支援的 Transaction 用法，使用 Transaction 來保護這整筆轉帳的交易過程了。\n也因為 Transaction 會確保方法中的所有資料庫操作，要嘛全部一起成功、要嘛全部一起失敗，因此這也稱為是 All or Nothing 原則。\n補充：Transaction 只能確保「同一個資料庫」中的交易會一起成功、一起失敗而已，如果涉及到多個資料庫（像是分散式資料庫），那麼使用 Transaction 的情況會變得複雜得多，大家有興趣的話，可以再上網查詢「分散式交易（Distributed Transactions）」的相關資訊。\nTransaction 和資料庫 ACID 的關聯 # 了解了 Transaction（交易）要解決的問題之後，我們終於可以說回到最一開始的「資料庫的 ACID」的特性了！\n我們在前面有提到，常見的關聯式資料庫中（例如：MySQL、PostgreSQL、MS SQL），都會有 ACID 的特性，而 ACID 即是：\nAtomicity（原子性） Consistency（一致性） Isolation（隔離性） Durability（永久性） 也因為有 ACID 這四個特性，所以 MySQL 這類的資料庫才能支援 Transaction 的操作。所以換句話說的話，假設某個資料庫他不具備 ACID 的特性的話，那他是不能使用 Transaction 的操作的！！！\n舉例來說，假設你使用的資料庫是 NoSQL（例如 MongoDB、Elastic Search），那麼即使你有在 Spring Boot 程式中添加 @Transactional，指定這段方法要使用 Transaction 來管理，但是因為 NoSQL 他不支援 ACID 啊！所以他就不支援 Transaction 的操作🥹。\n因此不管你在程式中加了多少個 @Transactional，那段程式仍舊是沒有受到 Transaction 的交易保護的，所以就算程式運行中出現錯誤，仍舊是沒辦法 rollback 成原始數據的，這是大家在使用 Transaction 時，一定要注意的細節！\n補充：軟體變化瞬息萬變，現在也已經有些 NoSQL 資料庫支援 ACID 的特性、進而支援 Transaction 了，大家在使用之前，建議也可以參考一下你使用的 NoSQL 資料庫介紹。\n而如果我們把 ACID 展開來，一一對應到 Transaction 中的概念的話，就可以發現他真的每一條都是為了 Transaction 來設計的：\n特性 描述 Atomicity（原子性） Transaction 是一個不可被分割的單元 Consistency（一致性） Transaction 執行的前後，必須確保數據的完整性是一致的 Isolation（隔離性） 資料庫同時處理多個 Transaction 時，各個 Transaction 之間不能互相影響 Durability（永久性） Transaction 一旦提交之後，他對資料庫所做的改變永久有效，不會因為系統重啟或錯誤而改變 也因為傳統的 SQL 資料庫滿足了 ACID 的特性，因此我們作為後端工程師，才能夠在程式中使用 @Transational，進而控制某一段程式要使用一個 Transaction 來管理，感謝 ACID！！\n資料庫的 ACID 總結 # 所以透過上面的介紹，現在我們就了解到，資料庫的 ACID 和 Transaction（交易）可以說是息息相關的！\n我們可以使用 Transaction 來包住一段程式，讓裡面的所有資料庫操作要嘛一起成功、要嘛一起失敗，也就是 All or Nothing 原則。\n而 ACID 則代表的是：\n特性 描述 Atomicity（原子性） Transaction 是一個不可被分割的單元 Consistency（一致性） Transaction 執行的前後，必須保持數據的完整性是一致的 Isolation（隔離性） 資料庫同時處理多個 Transaction 時，各個 Transaction 之間不能互相影響 Durability（永久性） Transaction 一旦提交之後，他對資料庫所做的改變永久有效，不會因為系統重啟或錯誤而改變 所以大家如果使用的是傳統的 SQL 資料庫，就可以善加利用 ACID 的特性和 Transaction 的功能，確保你的數據不會因為中途的意外而產生髒資料了～\n結語 # 這篇文章我們有介紹了資料庫的 ACID 特性、並且也介紹了 Transaction 的概念，希望可以讓大家更了解傳統 SQL 資料庫的特性！\n如果你對後端技術有興趣的話，也歡迎免費訂閱《古古的後端筆記》電子報，每週二為你送上一篇後端技術分享，那我們就下一篇文章見啦！\n補充：我開設的 Spring Boot 零基礎入門、Spring Security 零基礎入門、GitHub 免費架站術 已在 Hahow 平台上架啦！輸入折扣碼「HH202601KU」即可享 85 折優惠。\n","permalink":"https://kucw.io/blog/db-acid-transatcion/","tags":null,"title":"資料庫的 ACID、Transaction（交易）介紹"},{"categories":["自媒體經營"],"contents":"哈囉，我是古古，這篇文章是每月一次的自媒體月報，主要分享我經營《古古的後端筆記》個人品牌的幕後秘辛，如果你也對於「自媒體創業」有興趣的話，歡迎繼續閱讀本文～\n補充：如果想了解《古古的後端筆記》電子報的起源，也可以先查看創刊號的文章。\n2024.10 月粉絲追蹤數、電子報訂閱人數 # 本月份（2024.10）的粉絲成長人數如下：（因為剛好前面的數據也都還在，就放上來做個對比）\n2024/9/24 人數 2024/10/29 人數 10 月份總成長人數 Facebook 粉專追蹤數 2687 4150 +1463 電子報訂閱人數 1195 1632 +437 Threads 粉絲追蹤數 535 2557 +2022 IG 粉絲追蹤數 130 247 +117 從這個誇張的線圖可以看到，這個月份真的是被流量眷顧一波🤣，會造成這麼誇張的粉絲數成長，是因為我在 10/24 時有 Po 了一篇「周杰倫演場會搶票系統 - 拓元售票背後的架構」，裡面有提到拓元是架設在 AWS 的環境上，然後網路上各種大神、對架構有興趣的人，就紛紛轉貼這則貼文，然後就變成爆文了😂（當時的貼文在這 Threads 貼文、FB 貼文）。\n不得不說，經過這一次完全體會到什麼叫流量爆炸，人生第一次粉絲數漲那麼快，手機真的一整個晚上都在響通知，謝謝周杰倫🙏（雖然我還是沒搶到你的演唱會門票🥲）。\n不過事後覆盤一下的話，我發現中間還是有很多有趣的演算法運作的！\n首先對於 Facebook 來說，我發現真正要讓文章能擴散出去，是要靠大粉專幫忙分享，像是在這篇貼文中，就是在 科技工作講 Tech Job N Talk 大大先分享了我的貼文之後，後面才引發一連串的流量爆炸（不知道有多少朋友是透過科技工作講知道我的呢？）。\n所以對於 Facebook 而言，如果今天要寫一篇爆文，可能不是得靠你自己的粉絲分享，而是得讓某個大粉專也幫忙分享，這樣子的瞬間流量才會起來，Facebook 才會覺得這篇文章可能是爆文，因此演算法才會把文章推播出去，進而觸及到更多受眾。\n當然目前這都還只是我自己的猜想啦XD，沒有人知道 Facebook 演算法是如何運作的，我能做的事情仍舊沒有變，就是盡力分享我覺得有價值的內容，至於有沒有受演算法青睞….就隨緣吧🤣。\n不過經過這次的周杰倫事件之後，我之後確實會更加注意有沒有時事可以蹭一下（盡量是和後端有關的時事），畢竟偶爾蹭一下時事，還是對破圈漲粉絲滿有幫助的，這樣子對長期經營自媒體來說，可能會是更健康的循環。\n至於 Threads 的話，要讓文章能擴散出去，是靠大家的按讚、回覆、分享。我自己感覺 Threads 目前比較去中心化，文章是依靠「話題性」決定他是不是一篇爆文，像是在 Threads 上常常會滑到追蹤數 100 人以內、但是按讚數一兩千以上的貼文。\n也因為 Threads 是看文章的話題性決定觸及人數，所以老實說要在 Threads 上要寫爆文就更飄渺了😂，因為你沒辦法抱大腿取暖，完全就是看 Threads 心情要不要把你推播出去這樣。\n不過畢竟 Threads 也還在發展階段，演算法應該也是一直持續在改，所以 Threads 我可能要再摸一段時間之後，才能有更多心得可以跟大家分享～\n本月學習內容：詹雨安的創業筆記（Heptabase 創辦人） # 這個月的自媒體學習內容，是我意外在 Medium 上逛到的「詹雨安的創業筆記」，這系列總共有 5 集，我把連結都貼在下面這裡，大家有興趣也可以看一下這些文章：\n創業筆記（一）：休學創業學到的七件事 創業筆記（二）：在美國開公司的大小事 創業筆記（三）：在錄取 Y Combinator 之前 創業筆記（四）：核心指標的成長 創業筆記（五）：種子輪籌資 我自己最喜歡的是 「創業筆記（三）和（四）」，在新創軟體界中，Y Combinator（簡稱 YC）是最知名的孵化器，眾多新創軟體（ex: Zapier、PagerDuty、GitLab、Dropbox、Twitch…等），都是從 YC 出來的，而且每年 YC 也會舉辦 Demo Day，可以說是新創界的盛事，所以能夠入選 YC 的新創團隊，真的都是非常厲害的團隊！\n而 Heptabase，這個筆記軟體的新創團隊，就真的入選了 YC，然後大神還把他準備的過程全部寫出來，真的是滿滿乾貨！！超級推薦！！！\n雖然我自己沒有用 Heptabase，但是這個系列不需要你使用過 Heptabase 也能看（當然如果你看完之後願意付費使用 Heptabase，大神應該會很開心XD），推薦對創業有興趣、或是單純想了解看看 YC 到底在幹嘛的人閱讀這系列的文章。\n以下也節錄我自己最有感觸的幾段話，分享給大家：\n再多的方法論和聰明才智，重要性都比不上創業者自己的信念和決心。（出自創業筆記一） MVP 推出去功能太少、太爛、沒有人用，這些一點都不是問題。每一次更新 MVP 都是一次學習、一次揮棒。揮棒多了才有可能打安打、打全壘打。MVP 從來都不該一次到位，而是要能高速迭代、變得愈來愈好。（出自創業筆記三） 一家新創公司的基本要素 — 產品、客戶、團隊、市場，空有宏大願景，但是缺乏足夠執行力和商業思維的新創公司，九成以上會在第一年就陣亡。（出自創業筆記三） 流量可以用廣告買，但是留存率就完全取決於你的產品實力。（出自創業筆記四） 作為自媒體創業者，真的是對 「流量可以用廣告買，但是留存率就完全取決於你的產品實力」 這句話感到當頭棒喝🥹。\n其實我在創作的過程中，還是很容易會被流量綁架（特別是剛經歷周杰倫的爆文漲粉），但看到這句話之後，就是要常常提醒自己：流量是假象，留存率才是真相，我也想和 Heptabase 一樣，盡力做一個能幫助到大家的產品，以後也會繼續朝著這個目標努力的💪。\n總之這份創業系列文真的很推薦大家閱讀！對創業有興趣的話，真的推薦一看～～\n本月撰寫的電子報主題、文章 # 這邊記錄了我這個月撰寫了哪些電子報和文章，大家如果對於其中的內容有興趣的話，也可以前往查看：\nTDD 是什麼？認識 Test-Driven Development（測試驅動開發） Git 的好用技巧介紹 - Cherry-Pick 和 git reset HEAD^ 工程師如何和 PM 共事？PM 親自來解答！ RabbitMQ 介紹（一）- 什麼是 Message Queue？ RabbitMQ 介紹（二）- RabbitMQ 用法介紹 RabbitMQ 介紹（三）- RabbitMQ 安裝教學 + Web 管理介面導覽 淺談搶票系統 2024.10 月報總結 # 呼～總之這個月的月報大概就是這樣吧！感覺周杰倫真的是印象最深刻的了XDD，啊還有能發現詹雨安的寶藏創業筆記也很讚！！真的是處處有驚喜，到處都可以挖寶🤣。\n最後也是感謝從 Hahow 時代一路追蹤以來的老粉、以及剛加入訂閱的新粉們支持！後續也會盡力分享後端知識、以及經營自媒體的幕後祕辛給大家的，那我們就下個月的月報再見啦～\n如果你對後端筆記有興趣，也歡迎免費訂閱《古古的後端筆記》電子報，每週二為你送上一篇後端技術分享，一起變強💪\n","permalink":"https://kucw.io/blog/as-a-content-creator/monthly-report-202410/","tags":null,"title":"軟體工程師的自媒體之路 - 2024.10 月報"},{"categories":["其他技術分享"],"contents":"搶票系統，一直是後端工程師在面試時的一大難題，而搶票系統又與我們的生活息息相關（例如：周杰倫演唱會搶票、雙 11 搶購），因此這篇文章就會淺談一下搶票系統的設計和遇到的挑戰，帶大家簡易入門搶票系統的實作。\n補充：搶票系統真的是一個很難的題目，我其實也不到真的很懂，所以這篇文章真的只是淺淺談一下，和大家分享目前我所學習過的內容，大家如果有什麼想法也歡迎留言，一起學習成長💪\n目錄 創建一筆訂單的實作 解決商品超賣的問題 補充：系統設計的 Functional Requirement 和 Non-functional Requirement 如何應對高流量？ 補充：拓元的搶票系統架構 結語 創建一筆訂單的實作 # 在我們實作高流量的搶票系統之前，萬事都得從平地開始做起，所以我們就先從最基本的功能開始設計，並且也在設計的過程中，討論搶票系統可能會出現的潛在問題。\n一般來說，在搶票時，不管今天是搶周杰倫的票、搶五月天、或是搶 iPhone…等等，都是要執行 「創建一筆訂單，並且將商品庫存 -1」 的操作，所以如果用程式來實作的話，可以寫成下面這個樣子（此處使用 Spring Boot 程式當作範例）：\n所以到這裡，我們就完成最基本的下訂單的雛形了。不過這個實作其實是有問題的，在一次只有一個人來下訂單時，這段程式可以正常運作，但是只要「多人同時一起來下訂單」，這段程式就會出現「商品超賣」的情形。\n解決商品超賣的問題 # 在上面的實作中，雖然程式看起來很正確沒錯，但是在「多人同時下單」時，也就是「多個 Thread 同時去執行這段程式」時，就會出現商品超賣的問題。\n大家可以想像一下，假設現在資料庫中還有 1 個商品庫存，然後此時有三個人同時執行到了第 11 行的 getProductAmount() 程式的話，那麼這三個人都會覺得：「現在資料庫中還有 1 個商品庫存，太棒了！這最後一個就是我的了！！」，所以這三個人都會繼續往下執行後面的程式，去創建一筆訂單，並且將商品的庫存 -1。\n但是這樣子的行為，就會導致資料庫中的商品庫存被減了 3 次（也就是被賣了 3 次），但是我們實際上只剩下 1 個商品庫存啊！！所以這時候就會導致商品超賣的問題出現，也就是我們賣超過自己擁有的庫存，導致有些消費者付了錢、但是拿不到真正的商品。\n要知道，商品超賣這件事在公關危機上算是非常嚴重的事件，所以為了避免這個問題，我們就必須修改這段程式，也就是 「為他加上一個同步鎖，確保一次只會有一個人執行這段程式」，因此我們就可以將這段程式改寫成下面這樣：\n（Java 中的同步鎖是用 synchronized 來實作，不熟悉 Java 語法的人可以不用管細節沒關係，只要知道這裡是加一個同步鎖就好）\n也因為我們改寫了上面這段程式，在第 11 行的地方加上了一個 synchronized 的同步鎖，因此這個同步鎖一次只會放一個人進去執行第 14～19 行的程式，就可以避免商品超賣的問題了！\n所以到這裡，我們才真的算是完成了「下訂單」的基本功能實作，也就是先確保我們的程式運行是正確的，至少不會產生商品超賣的問題。\n而一般在系統設計的流程中，當我們實作完「基本功能」之後，就可以來探討「怎麼承受住高流量」這類的問題了。\n補充：系統設計的 Functional Requirement 和 Non-functional Requirement # 在實作「能承受高流量的搶票系統」之前，我們先跳出來補充一下系統設計的相關概念。\n系統設計通常分兩塊，一塊是 Functional Requirement（功能性需求）、另一塊是 Non-functional Requirement（非功能性需求）。\n所謂的 Functional Requirement（功能性需求），就是「你是否能夠正確的解決問題」，譬如說你是否能夠實作出一個不會商品超賣的訂單系統、你是否能夠實作出一個 url 的短連結跳轉…等等，所以所謂的 Functional Requirement，就是你先把這個功能真的實作出來這樣。\n而至於 Non-functional Requirement（非功能性需求），則是「你能夠多厲害的解決問題」，譬如說你這個訂單系統，是否能夠承受 1000 人的流量？是否能夠承受 1 萬人的流量？是否能夠承受 100 萬人的流量？或是你這個訂單系統，他的可用性是多少？有沒有辦法確保 99.9999% 的時間不會當機？…等等。\n因此所謂的 Non-functional Requirement，就是在考驗你的系統到底有多強、執行效率有多高、可用性有多好…等。\n所以在進行系統設計時，可以總結成一句話：「先求有，再求好」。\n首先是 「求有」，也就是一定要先確保 Functional Requirement 能正常運作，這種最最最基本的功能一定要先完成，至少要先確保商品不要超賣，討論後面的高流量才有意義。\n等到最基本的 Functional Requirement 實作完畢之後，再來就是 「求好」，也就是處理 Non-functional Requirement 的問題，例如高流量、高性能、高可用，這類的三高問題（沒錯系統設計跟血糖一樣，也有三高問題🥹）。\n當然一般在系統設計中，面試官更關注的是 Non-functional Requirement 的部分，也就是你的系統能夠架設到多厲害這樣，所以 Non-functional Requirement 也可以說是在準備系統設計時，最需要花大量時間準備的地方（因為牽涉範圍又深又廣），不過在實作上，還是會建議大家「先求有，再求好」，沒有一步到位的系統，Don’t Over Design，Facebook 也不是第一天就長成那麼龐大的架構，都是慢慢跟著需求一起變化而來的。\n如何應對高流量？ # 在了解系統設計的概念之後，如果我們回到最一開始的問題的話，現在我們已經把「創建訂單」的功能實作出來了，所以現在我們可以開始探討，要如何提升這個系統，讓他可以應付更高的流量。\n現在在這個架構中，因為我們是使用 synchronized 這個同步鎖，強制讓同時湧進來的許多人被擋在 synchronized 上，一次只允許一個人執行第 14 ～ 19 行的程式，因此雖然可以確保商品不會超賣，但是卻讓使用者會被同步鎖卡太久，導致使用者體驗不好。\n一個較常見的解法，就是改用 Redis 來取代同步鎖，即是將商品庫存的數據改成暫存到 Redis 中，然後 Redis 中可以使用 lua 腳本確保原子性（參考 Bilibili 影片介紹、阿里雲介紹）。\n圖片來源： 阿里雲官方幫助文檔 因此這個優化的概念，就是用 Redis 來取代 Java 內建的同步鎖，進而達到更高的效能。但是具體的實作細節，抱歉我也不是很熟悉、也沒有真的實作過，所以這樣子的作法到底能夠支撐多少流量呢？我可能也沒辦法給大家一個很好的量化數字🥹。\n我目前所學習到的知識，大概就是停在 Redis 這裡而已，後面的部分我也還在探索中，所以目前還沒辦法給大家答案🥹，如果大家有興趣的話，可以在 Bilibili 上面搜尋關鍵字「秒殺系統」，大陸那邊有很多類似的影片介紹可以參考，如果想找英文資源的話，也可以搜尋「How to design a Ticketmaster」，也會有滿多相關的討論可以看一下。\n也希望將來的某一天，我可以重寫這篇主題，重新深入探討搶票系統，到時候如果有學到更多新的知識，也想再重新整理出來分享給大家！\n補充：拓元的搶票系統架構 # 以台灣來說，比較知名的搶票系統為「拓元售票」，如果大家對拓元售票的系統架構感興趣的話，也可以參考 AWS 於 2020 年提供的公開資料（tixCraft 案例研究），拓元就用到了大量的 AWS 功能，來處理高流量的搶票問題。\n圖片來源： AWS 的 tixCraft 案例研究 不過因為這篇案例研究中牽涉到更多複雜的 AWS 架構機制，因此建議大家在了解簡單的搶票系統實作、以及熟悉 AWS 功能的前提下，再去閱讀這篇文章會比較易懂。\n結語 # 這篇文章我們有淺淺的談了一下搶票系統，不得不說這部分我真的還有很多地方可以學習和加強，目前只是先把我所知道的部分、以及網路上的公開資料，一起整理到這篇文章裡面，希望將來的某一天我可以重新回頭來寫這篇文章，把搶票系統給吃得透透的！！\n如果你對後端技術有興趣的話，也歡迎免費訂閱《古古的後端筆記》電子報，每週二為你送上一篇後端技術分享，那我們就下一篇文章見啦！\n補充：我開設的 Spring Boot 零基礎入門、Spring Security 零基礎入門、GitHub 免費架站術 已在 Hahow 平台上架啦！輸入折扣碼「HH202601KU」即可享 85 折優惠。\n","permalink":"https://kucw.io/blog/ticket-system/","tags":null,"title":"淺談搶票系統"},{"categories":["其他技術分享"],"contents":"寫稿中….✍️\n有需要的人可以先參考這個 Github repo 中的 code，感謝！\nhttps://github.com/kucw/spring-boot-demo/tree/master/spring-boot-demo-rabbitmq\n","permalink":"https://kucw.io/blog/rabbitmq4/","tags":null,"title":"RabbitMQ 介紹（四）- 在 Spring Boot 中串接 RabbitMQ"},{"categories":["其他技術分享"],"contents":" 目錄 RabbitMQ 安裝教學 Web 管理介面導覽 查看 Queue 的整體運行情況 查看/新增 Exchange 查看/新增 Queue Admin 管理 結語 RabbitMQ 安裝教學 # 需要先安裝 docker-desktop，可以到 Docker 官網下載\n可以使用 docker 在自己的電腦上快速架設起 RabbitMQ 以及 RabbitMQ 專屬的 Web 管理介面。\n推薦使用 rabbitmq:management 的 docker image，不僅可以幫我們架設起一個 RabbitMQ，還可以順便為我們架設起一個用來管理該 RabbitMQ 的 web 管理介面，非常方便。\n執行以下方法，就可以順利啟動這個 docker image：\ndocker run --name rabbitmq -d -p 15672:15672 -p 5672:5672 \\ -e RABBITMQ_DEFAULT_USER=root -e RABBITMQ_DEFAULT_PASS=admin1234 \\ rabbitmq:management 在上面的方法中，可以自己修改 RABBITMQ_DEFAULT_USER 和 RABBITMQ_DEFAULT_PASS 的參數去自定義帳號密碼，像是此處就是設定帳號為 root、密碼為 admin1234。\n啟動好 docker image 之後，RabbitMQ 使用的 port 預設是 5672，而 RabbitMQ 的 Web 管理介面使用的 port 預設是 15672，因此只要訪問 http://localhost:15672，就會出現 RabbitMQ 的 Web 管理介面，此時就可以在輸入剛剛運行 docker image 所設定的帳號密碼登入進去。\n到這裡 RabbitMQ 就安裝好了，所以就可以使用 SpringBoot 連接上此 RabbitMQ 了。\nWeb 管理介面導覽 # 查看 Queue 的整體運行情況 # 登入之後就會進到 Overview 頁面，在 Overview 頁面可以查看 Queue 的整體狀況以及 cluster node 的 cpu/memory 使用狀態。\n查看/新增 Exchange # 點擊上方的 Exchanges tab 可以進到 Exchanges 頁面，可以查看目前已存在的 Exchange，以及新增一個新的 Exchange。\n點擊其中一個已存在的 Exchange，可以查看該 Exchange 的詳細資訊：\n查看/新增 Queue # 點擊上方的 Queue tab 可以進到 Queue 頁面，可以查看目前已存在的 Queue，也可以新增一個新的 Queue。\n同理，點擊其中一個已存在的 Queue，可以查看該 Queue 的詳細資訊，也可以對該 Queue 進行一系列的操作（這裡和 Exchange 的操作差不多，因此就不重複列出）。\nAdmin 管理 # 點擊上方的 Admin tab 可以進到 Admin 頁面，然後在 Admin 裡點擊右側的 Users tab，可以查看/新增 RabbitMQ 的使用者，也可以查看該使用者允許 access 的 virtual host。\n點擊右側的 Virtual Hosts tab，可以查看/新增 RabbitMQ 的 virtual host。\n補充： 在 RabbitMQ 裡面有一個 virtual host 的概念，可以想像成是分組，也就是一個 virtual host 就是一組。\n當 RabbitMQ 運行時，預設會產生一個 virtual host 叫做 /，然後如果不特別調整的話，所有的 Queue 都是創建在這個 / 的 virtual host 裡面，而 user 預設也是被設定成能存取 /。\n所以如果想要在 RabbitMQ 裡面做分組的權限控管的話，只要多創建幾個 virtual host，user 就可以在不同的 virtual host 下創建 Queue 和 Exchange，不同 virtual host 裡的 Queue 和 Exchange 無法互通，然後也可以去限制說某些 user 只能存取某些 virtual host。\n結語 # 這篇文章我們介紹了如何透過 Docker 安裝 RabbitMQ，並且也介紹了 RabbitMQ 管理介面中的使用方法，了解要如何透過 RabbitMQ 管理介面新增、查看 Queue 和 Exchange 的資訊。\n如果你對 RabbitMQ 的其他文章有興趣，也可以直接點擊下列連結跳轉到該文章：\nRabbitMQ 介紹（一）- 什麼是 Message Queue？ RabbitMQ 介紹（二）- RabbitMQ 用法介紹 RabbitMQ 介紹（三）- RabbitMQ 安裝教學（本文） RabbitMQ 介紹（四）- 在 Spring Boot 中實作 RabbitMQ 如果你對後端技術有興趣的話，也歡迎免費訂閱《古古的後端筆記》電子報，每週二為你送上一篇後端技術分享，那我們就下一篇文章見啦！\n補充：我開設的 Spring Boot 零基礎入門、Spring Security 零基礎入門、GitHub 免費架站術 已在 Hahow 平台上架啦！輸入折扣碼「HH202601KU」即可享 85 折優惠。\n","permalink":"https://kucw.io/blog/rabbitmq3/","tags":null,"title":"RabbitMQ 介紹（三）- RabbitMQ 安裝教學 + Web 管理介面導覽"},{"categories":["其他技術分享"],"contents":" 前期提要：如果不了解什麼是 Message Queue，可以先參考 RabbitMQ 介紹（一）- 什麼是 Message Queue？ 的介紹\n目錄 什麼是 RabbitMQ？ RabbitMQ 中常見的 5 種模式 1. Direct 模式 2. Worker 模式 3. Publish/Subscribe 模式 4. Routing 模式 5. Topics 模式 RabbitMQ 總結 結語 什麼是 RabbitMQ？ # RabbitMQ 是在各企業中最為廣泛使用的 Message Queue，而在 RabbitMQ 的世界中，有三個重要的角色需要了解，分別是：\nProducer（生產者）：負責發送 message 到 Queue Consumer（消費者）：負責從 Queue 中接收 message Queue：暫存 message 的地方 以下圖為例，綠色的「訂單系統」是 Producer，藍色的「數據分析系統」是 Consumer，而橘色的「Message Queue」則是 Queue。\n在 RabbitMQ 的世界，Producer、Consumer、以及 Queue，是最重要的三個名詞，因此先了解這些名詞的意義，可以說是認識 RabbitMQ 的第一步。\nRabbitMQ 中常見的 5 種模式 # 在 RabbitMQ 中，常見的 5 種模式如下（所有模式可參考 RabbitMQ 官網）：\nDirect 模式 Worker 模式 Publish/Subscribe 模式 Routing 模式 Topics 模式 1. Direct 模式 # Direct 是最簡單的模式，也就是只有一個 Producer 負責發送 message 到 Queue 裡，並且也只有一個 Consumer 會從 Queue 中接收 message，接著處理該 message。\n像是以上面的「訂單系統」和「數據分析系統」的例子來說，他們其實就是使用最簡單的 Direct 模式，由「訂單系統」這個 Producer 負責發送 message，並且由「數據分析系統」這個 Consumer 接收 message。\n2. Worker 模式 # Worker 模式和 Direct 模式很像，差別只在 Worker 模式「同時有多個 Consumer」一起去接收 Queue 裡面的 message，進而提升 message 消化的速率。\nWorker 模式是 RabbitMQ 中滿常用的一個模式，假設今天 Queue 突然有很多 message 要處理，就可以多叫幾台 Consumer 來一起消化，因此可以輕易的達成「橫向擴展」，在實作上非常的好用！\n3. Publish/Subscribe 模式 # Publish/Subscribe 模式也是 RabbitMQ 中很常用的一種模式。從這個模式之後，在 Producer 和 Queue 之間，就會多出一個叫做 「Exchange」 的角色。\n所以在 Publish/Subscribe 模式中，Producer 就不會直接把 message 丟到 Queue 裡面了，Producer 反而是會先把 message 丟給 Exchange，然後再交由 Exchange 去決定要把這個 message 丟到哪個 Queue 裡面。\n所以換句話說的話，就是 Producer 再也不會直接和 Queue 溝通了，而是會藉由一個中間人 Exchange 去處理這樣。\n而在 Exchange 中，他有 3 種類型（type）可以選（direct、fanout、topic），所以在下面不同的模式中，就會搭配不同的 Exchange 設定來實作。\n像是在 Publish/Subscribe 的模式中，Exchange 使用的是 fanout 設定，也就是當 Producer 把 message 丟給 Exchange 時，Exchange 會把這個 message 丟到「他綁定的所有 Queue」中。\n舉例來說的話，假設今天 Producer 發送了一個 message 給 Exchange，那麼 Exchange 除了會將這個 message 丟到上面那條 Queue 裡面之外，同時 Exchange 也會 「複製一份 message」，然後將他丟到下面那條 Queue 裡面。\n所以在上下這兩條 Queue 中，裡面都會各自有一份 message 存在！\n因此即使 Producer 只傳送了一個 message 給 Exchange，Exchange 也會透過「複製」的方式，在每一條 Queue 中都添加同樣的 message，這樣子就可以確保所有的 Consumer 都可以接收到這個 message 了！\n也因為 Publish/Subscribe 模式的特性非常好用，因此通常在實作「訂閱」的情境下，就會採用 Publish/Subscribe 模式來實作。\n像是你在 Facebook 上追蹤了某個粉專，只要該粉專發文，你就會收到貼文通知，這就是一種 Publish/Subscribe 的應用，即是「粉專主（Producer）」發送一個貼文給 Exchange，而「每一位粉絲（Consumer）」都可以收到這個貼文的通知。\n而如果以前面提到的例子來說的話，假設今天除了「數據分析系統」想要取得訂單數據之外，其他的系統如「物流系統」、「倉管系統」也都想要取得訂單數據的話，那麼這時就可以採用 Publish/Subscribe 的方式來實作，這樣子「訂單系統（Producer）」一樣是丟出一份訂單數據給 Exchange，而「每一個想要獲得通知的微服務」就都可以從 Queue 中取得到這筆訂單數據了！\n4. Routing 模式 # Routing 模式也是一個用到 Exchange 的模式，他所使用的是 Exchange 的 direct 設定。\n在 Routing 模式中，當 Producer 將 message 丟給 Exchange 時，Producer 同時要在這個 message上面添加一個 routing key，因此 Exchange 就會根據這個 routing key，將 message 丟到指定的 Queue 上（Exchange 和 Queue 之間要用什麼 routing key 綁定，需要先行設置)。\nRouting 模式雖然使用上沒有 Publish/Subscribe 模式來的常用，但是他的重點在於 「可以多重綁定」，也就是同一個 routing key 可以綁到多條 Queue 上，因此就可以拿來實作收集 Log 的 Queue。\n像是在下圖中，我們可以將 info、error、warning 這三個 routing key，綁到記錄一般 Log 的 Queue 上，然後再將 error 這個 routing key，再綁定到另一條記錄 Error Log 的 Queue 上，這樣子就可以實作出一份帶有全部 Log 的 Queue、以及一份只有 Error Log 的 Queue 了。\n不過，雖然使用 Routing 模式可以很容易的實作出上述的收集 Log 的 Queue，但是因為他的重要邏輯都寫在 Exchange 上，所以如果對 RabbitMQ 或是 Exchange 不太熟練的話，就會不知道要去哪裡改這些設定（Exchange 的設定要進到 RabbitMQ 的系統中改）。\n因此在實作上，建議大家是慎用這個模式，除非團隊中的每個人真的都很熟悉 RabbitMQ，不然的話用這個模式可能會導致後期維護不易。\n5. Topics 模式 # Topics 模式算是更進階的 Routing 模式，他的 Exchange 使用的是 topic 設定，不過用法基本上和 Routing 模式一樣，只是 routing key 進階成可以使用模糊綁定而已。\n我自己還沒有在實務上見到過 Topics 模式的用法，所以除非大家有很特殊的需求，才需要考慮使用 Topics 模式，不然一般的情況下，使用前面的模式就可以解決大部分的問題了。\nRabbitMQ 總結 # 所以總結上面的介紹的話，在 RabbitMQ 中，最常見的 5 種模式分別是：\nDirect 模式 Worker 模式（常用） Publish/Subscribe 模式（常用） Routing 模式 Topics 模式 因此大家以後就可以根據自己的需求，決定要使用哪一種模式來實作了！\n結語 # 這篇文章我們先介紹了 RabbitMQ 中的三個重要角色：Producer、Consumer、Queue，並且也介紹了 RabbitMQ 中常見的五種模式，因此大家就可以根據自己的需求，決定要使用哪種模式來實作了。\n如果你對 RabbitMQ 的其他文章有興趣，也可以直接點擊下列連結跳轉到該文章：\nRabbitMQ 介紹（一）- 什麼是 Message Queue？ RabbitMQ 介紹（二）- RabbitMQ 用法介紹（本文） RabbitMQ 介紹（三）- RabbitMQ 安裝教學 RabbitMQ 介紹（四）- 在 Spring Boot 中實作 RabbitMQ 如果你對後端技術有興趣的話，也歡迎免費訂閱《古古的後端筆記》電子報，每週二為你送上一篇後端技術分享，那我們就下一篇文章見啦！\n","permalink":"https://kucw.io/blog/2020/11/rabbitmq/","tags":null,"title":"RabbitMQ 介紹（二）- RabbitMQ 用法介紹"},{"categories":["其他技術分享"],"contents":"RabbitMQ 是目前使用上最廣泛的 Message Queue，但是在了解 RabbitMQ 之前，必須先了解 Message Queue 的概念和特性，才會比較好上手。\n因此此系列文會先從 Message Queue 開始介紹，接著介紹 RabbitMQ 的用法、如何在電腦上安裝 RabbitMQ、以及如何在 Spring Boot 中實作 RabbitMQ。\n如果你對 RabbitMQ 的其他文章有興趣，也可以直接點擊下列連結跳轉到該文章：\nRabbitMQ 介紹（二）- RabbitMQ 用法介紹 RabbitMQ 介紹（三）- RabbitMQ 安裝教學 RabbitMQ 介紹（四）- 在 Spring Boot 中實作 RabbitMQ 而在這篇文章中，我們就會先來介紹什麼是 Message Queue，所以我們就開始吧！\n目錄 什麼是 Message Queue？ 例子：郵差送信 Message Queue 的具體應用場景 Message Queue 的優缺點 Message Queue 的優點 Message Queue 的缺點 結語 什麼是 Message Queue？ # Message Queue 是一種系統設計的技術，大陸是翻譯成「消息隊列」，台灣這邊好像沒有準確的譯名，所以通常大家還是直接用 Message Queue 來稱呼。\n而 Message Queue 的用途，就是「信箱」的概念，因此 Message Queue 就擁有了「非同步處理」以及「功能解耦」的兩大優點。\n上面的描述看起來可能有點抽象，所以我們可以直接透過一個例子，來了解 Message Queue 的概念。\n例子：郵差送信 # 舉例來說，假設你家沒有郵箱的話，那麼今天郵差如果想要送信給你，郵差就只能夠來你家按門鈴時，然後你就得從沙發上爬起來、走到樓下開門、並且當著郵差的面簽收這封信，這樣子你才能夠拿到這封信。\n所以在沒有信箱的時代，你和郵差「必須同一時間」出現在家裡大門口，這樣子郵差才能把信件親手交給你。\n但是，如果我們使用了「信箱」的話，狀況就不一樣了！\n如果你家有安裝信箱的話，那麼郵差想要送信給你時，就只要直接把信投遞到你家的信箱裡面，然後郵差就可以繼續去處理其他事情了，完全不用等你下樓來開門！而你也可以等到之後有空時，再自己下來收這封信。\n因此在有了信箱之後，你和郵差就「不需要同一時間」出現在家裡大門口，而是郵差先把信件投遞到信箱中，並且將這封信暫存在信箱裡，等到你之後有空時再來收信。\n因此「信箱」的概念，就是 Message Queue 的用途，也就是能夠 「暫存消息的傳遞」，進而達到兩個服務之間的非同步處理！\nMessage Queue 的具體應用場景 # 透過上面的例子，先大概了解「Message Queue = 信箱」這個概念之後，接著我們也可以用更具體的真實情境，來介紹 Message Queue 的用途。\n舉例來說，假設現在在電商網站中有兩個微服務：訂單系統、數據分析系統，那麼當使用者下了一筆訂單之後，這時候訂單系統就必須 call 數據分析的 api，將使用者購買了哪些商品傳給數據分析系統，讓他背後去進行大數據分析。\n所以在沒有使用 Message Queue 之前，微服務的架構會像是下面這樣子：\n這個架構也沒有說不好，但是想像一下，假設今天數據分析系統出現問題，導致 call api 請求超時、或是直接出現 500 錯誤，那這樣子就會導致使用者沒辦法成功下訂單：\n但是對於使用者而言，他根本不想要使用數據分析系統！他只是想要下訂單而已，但是卻會因為數據分析系統出現問題，導致使用者被連累著也出現問題。\n所以這個時候，就可以透過引入「Message Queue」這項技術，來解決這個問題！\n假設我們在「訂單系統」和「數據分析系統」之間，添加了一組 Message Queue 的話，那麼步驟就會變成下面這樣：\n使用者下單 訂單系統處理訂單的邏輯 訂單系統將這筆訂單的數據，傳送到 Message Queue 裡面來暫存 回傳下單的結果給使用者 所以當我們使用了 Message Queue 之後，在使用者下訂單的過程中，完全不會受到數據分析系統的干擾，而是可以專心的執行下訂單的操作了。\n而數據分析系統也可以在自己有空時，主動到 Message Queue 中查看是否有尚未處理的訂單數據，如果有的話，就抓取這一筆訂單數據來處理。並且他也可以慢慢的去分析這筆訂單數據，不用為了要搶快、要盡快回覆使用者，而逼迫自己要分析的非常迅速。\n所以透過 Message Queue 的設計，我們就可以將「訂單系統」和「數據分析系統」的功能給拆分開來，讓他們不需要同一時間處理完所有步驟，而是可以分批步驟慢慢執行，進而達到「非同步處理」以及「功能解耦」的效果了！\n所以最終的架構圖就會如下圖所示：\nMessage Queue 的優缺點 # 了解了 Message Queue 的具體使用情境之後，接著我們也可以來探討一下使用 Message Queue 的優缺點。\nMessage Queue 的優點 # 使用 Message Queue 有四大優點：\n非同步處理（Asynchronous Processing） 功能解耦（Decoupling） 易於橫向擴展（Horizontal Scalability） 流量速率限制（Rate Limiting） 其中關於「非同步處理」和「功能解耦」的部分，在上面的例子中已經有介紹到這一塊了。\n而至於「易於橫向擴展」和「流量速率限制」這部分，因為比較複雜，大家有興趣的話，可以再參考 ByteByteGo 的相關介紹。\nMessage Queue 的缺點 # 而至於使用 Message Queue 的缺點，則有：\n系統變得更複雜、增加維護成本（因為我們多添加了一個新功能到微服務架構中，勢必得多花一份心力去維護他） 上游無法知道下游的執行結果為成功 or 失敗 消息可能會丟失、或是會重複傳遞 也因為 Message Queue 在使用上不是萬能的，所以大家在引入 Message Queue 進來之前，一定要仔細思考：「這項技術是否適用於目前的架構？他是否真的能解決目前你遇到的問題？你是否願意多維護一份功能？」，只有當 Message Queue 真的能解決你的問題時，才有引入他的意義。\n而這也是大家想要邁向資深工程師的必經過程，即是有能力評估某一個功能的優缺點，並且決定是否要採用此項技術。\n不過老實說 Message Queue 是真的滿好用的啦🤣，而且也真的很常見，所以多了解一點是絕對不會虧的！\n結語 # 這篇文章我們先介紹了 Message Queue 是什麼、並且也比較了 Message Queue 的優缺點，希望能讓大家對 Message Queue 的用途有更多的了解。\n如果你對 RabbitMQ 的其他文章有興趣，也可以直接點擊下列連結跳轉到該文章：\nRabbitMQ 介紹（二）- RabbitMQ 用法介紹 RabbitMQ 介紹（三）- RabbitMQ 安裝教學 RabbitMQ 介紹（四）- 在 Spring Boot 中實作 RabbitMQ 如果你對後端技術有興趣的話，也歡迎免費訂閱《古古的後端筆記》電子報，每週二為你送上一篇後端技術分享，那我們就下一篇文章見啦！\n補充：我開設的 Spring Boot 零基礎入門、Spring Security 零基礎入門、GitHub 免費架站術 已在 Hahow 平台上架啦！輸入折扣碼「HH202601KU」即可享 85 折優惠。\n","permalink":"https://kucw.io/blog/rabbitmq1/","tags":null,"title":"RabbitMQ 介紹（一）- 什麼是 Message Queue？"},{"categories":["其他技術分享"],"contents":"哈囉大家好，我是古古。身為一個工程師，在工作上多多少少都得和 PM 打交道，可能有的人會好奇 PM 的工作內容是什麼、或是不知道怎麼跟 PM 相處比較好。\n所以這篇文章，我們邀請到了 PM 大大來為我們工程師們解惑一下，分享 PM 的工作內容是什麼、以及工程師如何和 PM 共事，所以我們就開始吧！\n前言 # Hello 我是 Eileen，目前任職於 Hahow 好學校的產品經理，約擔任 PM 經歷 4 年，同時也是 Taiwan Product Managers 臉書社團的管理員，近一年舉辦了許多產品經理及軟體產品從業者的小聚，希望透過這篇文章跟大家分享及交流。\n也容許我在開始前打個預防針，產品經理的日常幾乎沒有正確答案，只有最合適的答案，因此在不同團隊中可能有所差異。本篇文章僅能代表我自身體驗及所觀察到周遭產品經理的經驗！那就讓我們開始吧～\n目錄 前言 1. Project Manager（PJM）和 Product Manager（PDM）的差異 2. PM 的工作範圍到哪裡？如果遇到灰色模糊地帶的事情，如何權責劃分？ 3. PM 都是如何規劃一個專案的發想到執行？有沒有推薦的課程或是文章可以參考？ 4. 想知道 PM 的職責會幫忙拆分 User Story 嗎？ 5. PM 是如何評估專案工時的？ 6. 請問 PM 面對比較陌生的開發專案，例如：要修改很陳舊的專案，接手的工程師都不知道要怎麼抓開發時間，PM 要怎麼抓時程？ 7. RD 後期真的都會轉 PM 嗎？網路上看到不少案例 8. 當 PM 說「他不懂技術」、或是「不要跟他說技術」時，該怎麼辦？ 9. RD 和 PM 之間應該如何和平相處呢？有時候和 PM 溝通都會很無力\u0026hellip; 總結（by 古古） 1. Project Manager（PJM）和 Product Manager（PDM）的差異 # 這題問題是我在擔任 PM 第一年，最常被 PM 前輩問到的 101 問題，「你覺得產品經理跟專案經理有什麼不一樣」？網路上有許多文章說明產品經理與專案經理的差異，以下先列出普遍對於專案經理及產品經理職務上的要求差異。\n產品經理（PDM）：\n主要負責產品的整體策略和方向 關注產品的長期發展和市場需求 決定產品功能和優先順序 與各個部門協調，確保產品符合公司目標和用戶需求 專案經理（PJM）：\n負責具體專案的執行和時程管理，以確保專案按時完成 管理專案資源和團隊協調 控管專案中的風險和問題 簡單而言，產品經理（PDM）專注於「價值交付」，專案經理（PJM）則專注於「專案交付」。\n舉例而言，如果是一個串流影音平台，產品經理可能會負責與營運、業務行銷單位討論預計推出新的影片類型、預計在市場上的定位及策略進而思考對應功能（如互動式影片、離線觀看等），以滿足用戶需求並提升平台競爭力。而專案經理則可能負責管理這些新功能的開發進度，確保各個團隊（如開發、設計、內容）能夠協調一致，按時完成專案。\n雖說如此，在實際的日常中，這兩個職稱的界限可能會有所模糊。許多公司的PM職位可能是複合型的，例如：在多數公司並沒有額外招募專案經理，而是由產品經理身兼專案經理的角色。或雖然職稱掛產品經理，卻實際上被期待作為客戶經理、業務的角色。\n各家 PM 實際要負責的範圍五花八門，我和幾位 PM 朋友也常開玩笑說「工程師不做的事就是 PM 的守備範圍」，因此當在分工有疑惑時，建議大家可以參考自己公司的 PM 的 JD（職缺敘述） 或直接跟自己主管、或 PM 聊聊！\n2. PM 的工作範圍到哪裡？如果遇到灰色模糊地帶的事情，如何權責劃分？ # 延續上題，由於各個產品團隊所包含的成員不同，例如是否擁有 UI designer、UX Researcher、數據分析師、測試工程師等，影響了 PM 所扮演的角色。而當 PM 所需擔任的角色越多，時間固定情況下，可以做到的顆粒度，與勢必有所影響。\n我自己認為 PM 的工作在一個專案中（Epic 或 Story），為了避免認知不同造成誤會或浪費工程資源，至少須確保以下內容有被定義：\n目標定義： 開發這個功能是為了達成什麼目的？我們的專案規模是多大？是 POC 或是一個長期使用的功能？了解目標也可以幫助工程師想到更好的解法及考慮維運性。 功能想像對焦： 不管是流程圖、PRD（規格文件）、wireframe、設計稿、技術開發文件，目的都是用來對齊團隊成員對於功能的想像跟期待，最終期待是所有人能夠具備共識。 驗收條件定義： 驗收的內容包含但不限於：開發是否如設計稿、是否使用者正向流程及負向流程都被考量、Bug 的優先序定義等，甚至如果公司內有多個團隊，本次上線是否對於其他產品或功能造成影響，都是 PM 在功能發布前須考慮的內容。 即使如此我想大家還是有很多疑問，常見的灰色地帶，例如：帶領會議究竟是技術主管還是 PM 負責？PM 到底要不要畫出流程圖？萬一沒有設計稿，工程師要自己做嗎？ 答案是「都可以」（被揍）XD\n在不同的公司、不同團隊甚至同一個團隊的不同專案都有可能有所差異，這一切都要取決於 「團隊所擁有的資源」。例如：我們有一位 App 工程師主管為了讓使用者體驗更好，在沒有設計資源的情況下，主動發起了 Dark mode 的導入，再請設計師做 design review ，反轉了由 PM 主導需求的角色。\n因此，如果遇到灰色地帶時，最好的方式就是在 retro 當中提出，甚至工程團隊也可以發起討論會議，了解彼此的期待及難處。希望能讓大家理解，讓開發順利推動是所有專案成員的責任，大家的付出都會幫助團隊運作更為順暢！\n3. PM 都是如何規劃一個專案的發想到執行？有沒有推薦的課程或是文章可以參考？ # 古古補充：這段比較多專有名詞，如果覺得有點複雜可以先跳過這題\n在目前的公司，我們透過公司層級定義的 OGSM（年度目標）來制定產品部門及組別層級的 OGSM。這包含了目標、策略（如何實現）以及衡量指標（如何確認完成）。\n舉例來說，今年的一個目標是能夠檢驗和衡量使用者的學習成效。經過對國內競品、市場分析、國外領導產業的研究，以及團隊腦力激盪後，我們選擇了透過「測驗」功能來量化學習效果作為策略。考慮到 Hahow 現有的技術架構、使用者和創作者的使用習慣，我們發現要提供「測驗」服務，需要完成 A、B、C 三項任務。為了在目標期限內完成這項策略，我們還定義了這三個專案各自的目標、時程安排，以及可用的工程資源和時間。\n接下來，PM 會根據這些資訊進行更深入的競品調查和使用者研究，以了解「測驗功能」（Epic）需要滿足哪些使用者情境（Story）及其具體流程。這個階段也就是撰寫「產品規格文件」（PRD，Product Requirement Document）的必要環節。由於這個專案預計運用 AI 技術，我們還額外進行了工程 POC 來評估新技術的可行性。確認可行後，我們將任務交給產品設計師進行 Wireframe 和設計稿的繪製，並反覆討論使用者體驗和操作介面。在這個過程中，我們也邀請工程師評估設計流程的開發可行性。\n最後，我們進入 Scrum 流程中的 Pre-refinement、Refinement 和 Planning 會議，將任務交給工程團隊進行 Task 的切分和開發實作。但這還不是終點。為了確保測驗功能上線後能達到目標使用人數並驗證假設，我們還需要規劃數據埋點，以及與行銷團隊討論產品行銷策略。上線後，PM 還需要負責數據分析和後續迭代規劃。\n每一個大型專案上線都像生了一個孩子，從發想到執行的過程總是充滿驚喜（嚇）。也幸好團隊中擁有產品設計師、工程師和測試工程師各自的專業，透過不斷的討論，才能確保產出最佳的解決方案。\n如果想瞭解 PRD 如何撰寫，歡迎參考以下優秀文章：\nPM 文件指南 - 產品經理一定要掌握的 PRD/SPEC 心法與撰寫教學 寫PRD？我教你｜PRD文件是產品經理的聖經 產品經理該怎麼處理灰色地帶、模糊不清或未定義的問題？ 4. 想知道 PM 的職責會幫忙拆分 User Story 嗎？ # PM 在撰寫 PRD 時通常會羅列本次上線須包含哪些 User Story（使用者情境）。\n如同第二題中提到我們近期開了 DOR 定義會議，其中討論了 Story 應包含的內容時，有提及拆分 Story 其實是一門藝術（技術）。在過往經驗中，遇過 Story 拆分過細，導致兩張 story 之間有耦合，工程師在開對應 Task 時會不確定應該關聯於哪張 Story。也有拆分顆粒過大，導致 Story 包含 Task 數量過多，Story 較難在一個 Sprint 內被完成。\n目前我們在開完 Story 之後開卡前都會請工程師夥伴協助檢視是否方便理解及開發，在開發過程中也會動態調整，以確保協作順暢。\n5. PM 是如何評估專案工時的？ # 在我工作的第一年，我無數次好奇資深 PM 們如何估計時程及列出目標，而當時前輩跟我說：「這是個感覺」。當時的我 be like 🤔😦🫠，在經過幾年後，我也必須說這是個玄學（大笑）。\n具備經驗的 PM 通常能夠透過過往團隊消耗點數、本次合作工程師的消化速度、對於專案複雜度的理解，由此推斷出預估花費時間。如果有一個公式的話，大概是：\n藉此可以在專案開始前推斷出預計花費時間。\n在這之中，工程師的估點對 PM 至關重要，即使估的是複雜度，當複雜度高時長短和複雜度低時長長相互平衡配合估點足夠細緻及平均消化點數穩定的情況，就能幫助 PM 更準確的判斷工時。\n在專案開始前，我們目前通常透過工程師 Spike (技術研究)，了解潛在複雜度及工時的合理性，若有明確交付時間，則會因此決定是否要縮小專案規模或拆階段上線。當然專案開發中的動態調整也是時常發生，回扣到第一題，如何掌握且降低專案風險、協調團隊資源，這件事就是「專案管理」的專業！\n6. 請問 PM 面對比較陌生的開發專案，例如：要修改很陳舊的專案，接手的工程師都不知道要怎麼抓開發時間，PM 要怎麼抓時程？ # 看起來時程真是大多數人的痛。不管是在前一份工作或是目前的工作，拆除和重寫了許多「古蹟」，遇過的情況，如原始的 PRD 沒有被維護，開發的人已經離職，只好抱著工程師的腿一起翻 code，重新梳理後發現未爆彈越來越多，上到測試站發現其他地方也要修改，只能說滿紙辛酸淚 (?) 你各位古蹟維護員都辛苦了！\n回到時程的預估，面對陌生的專案，通常不會先對外承諾時程及可行性。作為 PM，我們會至少安排 1–2 個 Sprint 的研究時間，請工程師撰寫技術文件。研究文件中包含了 PM 設想的預期結果、希望確認的內容或滿足條件，以及是要先了解技術架構還是確認可行性。同時，我們也會把「研究任務」納入估點，避免工程師後續開發時間被壓縮。\n研究結束後，通常能確定需要如何動工——是重寫還是修改。在衡量可投入的時間資源及調整範圍後，我們才決定下一步。有時也會發現要花費的功夫和效益不如預期，而決定暫不執行。\n為了避免憾事重演，我強烈建議大家要記得同步討論結果，針對研究結果提供說明文件。未完成的部分也可以標示清楚，幫助後人能順利銜接！\n7. RD 後期真的都會轉 PM 嗎？網路上看到不少案例 # 我認為 RD 會不會轉為 PM 取決於工程師的職涯安排。我遇過工程師轉 PM 或 Technical PM 成功的案例或是因為擔任 RD Manager 或 Product Diretor 而需要擔任部分 PM 工作，也遇過轉職後因為受不了 PM 日常頻繁的 Context Switch 轉回工程師的案例。因此這題沒有固定答案，只有適不適合！\n8. 當 PM 說「他不懂技術」、或是「不要跟他說技術」時，該怎麼辦？ # 關於「PM 要不要懂技術」的主題，網路上有許多文章討論，節錄我很認同其中一篇《產品經理需要懂技術嗎？》的內容：\n將問題拆解後，我們背後真正想問的是：\n若要成為一個及格的產品經理，對技術的了解要有多少？ 產品經理有那麼多種技能要點，技術在這所有技能中有多重要？ 一般來說：PM 對技術的理解，要足夠跟工程師溝通、安排資源、解決問題。\n我的答案也是相同的。PM 通常被公司期待「為達成策略目標而確保專案交付」，因此 PM 需要多了解技術也取決於「做決定時多需要仰賴對技術的理解」。當然擁有的正確知識越多，能夠做出的判斷也越正確，但萬一 PM 擁有的知識不夠正確呢？\n在剛當 PM 時曾與工程師討論這題，工程師夥伴說「如果你知道我們在做什麼當然是最好的，但如果你知道的不是最正確的，我反而會誤會你就是希望我這麼做，最後做出來的是我們都不想要的結果。」因此後來我的做法是告訴工程師我想達成的目的、滿足的情境，由工程師告訴我方案及每個方案所需的 trade-off，再一起做決定。\n我也必須感謝在當 PM 過程中遇到許多願意用白話文解釋工程架構的工程師，讓技術不再遙不可及。讓我也逐漸理解網站的邏輯、在遇到 Bug 時嘗試重現，開啟 inspect 模式試圖看 error code ，而不是一有問題就抓著工程師。也因為經過了前公司面對瞬間流量、 DDOS 經驗、重構經驗後，在設計功能時不自覺得會想考慮維護性、對於潛在風險的應對，試圖降低未來的風險。\n如果你遇到這樣的 PM 不妨試試用白話文或日常的例子解釋工程邏輯，就像把難以下嚥的生紅蘿蔔變美味一樣，像我這樣（遇到太困難的技術就當機）的 PM 會超感謝你的！\n9. RD 和 PM 之間應該如何和平相處呢？有時候和 PM 溝通都會很無力\u0026hellip; # 回顧上面的內容，有許多情境都沒有標準答案，在團隊協作上更是。更多是人與人之間的頻率、溝通技巧等問題，如果有一個解法可能就是「更多的溝通」和「同理心」。\n我相信幾乎沒有人會刻意的想「不和平相處」，想謝謝每位願意看完這篇文章的你，感謝你願意試圖了解 PM ，這是建立同理心的第一步。透過同理心可以降低對於彼此錯誤的期待，例如：時程其實 PM 沒有控制權，業務已經跟客戶談好了，會有違約賠償問題，老闆也答應了對方客戶。\n目前工作中，我固定每半年會約團隊內每位工程師 1 on 1 ，期待能夠了解在過去合作期間能夠互相調整的地方。(即使如此，我仍舊經常感覺到自己做得不夠好就是了XD) 人際相處一直是互相的，通常是兩個人都需要調整，如果真的無法相處就事論事吧！\n總結（by 古古） # 看完了上面這麼長的文章，希望能夠讓大家對於 PM 這個職業有更多的了解！我自己在工作的時候，對 PM 也是又愛又恨🥹。但我必須說 PM 真的是有好 PM 也有壞 PM（就跟工程師有好工程師和壞工程師一樣），在開發過程就是不斷的團隊合作，誰也不是故意來迫害誰的（沒那麼閒吧XD），一切都只是因為角色定位問題而已。\n在我們努力充實自己的硬實力的同時、也要精進自己的軟實力，當到將來有能力能夠跟 PM 獨自打一架時，就表示你已經成為資深工程師了！\n最後這次真的感謝 Eileen 願意熱情支援來解惑🥹，大家對 PM 話題有興趣的話，也可以追蹤Taiwan Product Managers 臉書社團～\n如果你對後端技術有興趣的話，也歡迎免費訂閱《古古的後端筆記》電子報，每週二為你送上一篇後端技術分享，那我們就下一篇文章見啦！\n","permalink":"https://kucw.io/blog/pm-for-developer/","tags":null,"title":"工程師如何和 PM 共事？PM 親自來解答！"},{"categories":["其他技術分享"],"contents":"Git 可以說是工程師使用上最頻繁的技術，這篇文章會分享兩個我覺得 Git 的好用技巧給大家，分別是：\nCherry-Pick： 擷取某個 branch 中的某個 commit git reset HEAD^： 撤銷最新的 commit 所以我們就開始吧！\n目錄 Git 好用技巧之一：Cherry-Pick（擷取某個 branch 中的某個 commit） Git 好用技巧之二：git reset HEAD^（撤銷最新的 commit） 結語 Git 好用技巧之一：Cherry-Pick（擷取某個 branch 中的某個 commit） # 如果說 Git 有什麼隱藏的特殊技能的話，Cherry-Pick 絕對是我心目中的第一名！\nCherry-Pick 的用途，是「擷取某個 branch 中的某個 commit」，這個聽起來是有點抽象，所以下面就透過一個實際的例子來示範 Cherry-Pick 的用法。\n像是目前在 master branch 中，在 resources 資料夾底下只有一個 application.properties 的檔案：\n如果這時候，我們切到 test 這個 branch 上，然後在 resources 底下新增一個 123.txt 的檔案，並且成功 commit 的話，結果就會像下圖一樣，在「步驟 3」的地方新增了一個 123 的 commit 出來。\n這時如果再接著新增一個 456.txt 的檔案，並且也成功 commit 的話，結果就會和下圖一樣，在「步驟 2」的地方新增了一個 456 的 commit 出來。\n所以到目前為止，在 test branch 就新增了兩個 commit：\n一個是 123 的 commit（包含 123.txt 檔案） 另一個則是 456 的 commit（包含 456.txt 檔案） 而 master branch 中則是維持原樣，沒有任何新增的 commit，resources 底下也只有 application.properties 一個檔案。\n這時候，神奇的需求來了！！如果現在有人要你切回到 master branch，並且要求你將 test branch 中的 123.txt 的檔案移植到 master branch 的話，你該怎麼辦？\n在還不會使用 Cherry-Pick 時，第一直覺反應是將 test merge 進 master，並且想辦法把 456 的 commit 刪掉，這樣子就能夠只保留 123 的 commit。\n這種做法雖然也能夠解決問題，但是當 commit 數一多的時候，就會變的很混亂，無法確保自己是否有保留到正確的 commit。\n所以這時候，就是 Cherry-Pick 上場的時候了！\n當我們在 master branch，想要擷取 test branch 中的某個 commit 時，只要在 IDE 上點擊右鍵（在這個例子中，就是對 123 這個 commit 點擊右鍵），然後選擇 Cherry-Pick：\n點擊之後，就可以看到在 master branch 的 resources 資料夾中，就多出了一個 123.txt 的檔案！並且在 master branch 中，也多出了一個新的 commit 123，所以這也就表示，我們就成功的將 test branch 中的 commit，偷到 master branch 中了！\n因此大家以後如果有「擷取別的 branch 中的某個 commit」的需求時，就可以使用 Cherry-Pick 幫助我們非常方便的做到！\n補充：Cherry-Pick 的「偷」的動作不是真的偷過來，而是將 test branch 中的 123 commit 中的內容，複製同樣的一份到 master branch 上，所以 master branch 的 123 commit 和 test branch 中的 123 commit，兩者之間是沒有任何關係的，在 Git 的線圖上，他們會是兩個獨立的 commit。\n雖然 Cherry-Pick 的使用情境看起來真的很少見，但老實說我在實際的工作中真的有用過一兩次，而且那次幫助真的滿大的，超級感謝發明 Cherry-Pick 的人XD。\n那時候我是在某條 branch（ex: TICKET-112）上開發，但是後來因為各種原因所以要棄用這條 branch，換到另一條 branch 開發（ex: TICKET-917），這時候我就在新的 branch 上使用 Cherry-Pick 去拉有用的 commit 過來，真的很好用！！\nCherry-Pick 就是屬於一年不開張、開張吃一年的指令，建議大家可以先把他的情境記下來，等到將來有一天真的也遇見這種神奇的狀況時，再回頭來查看他的使用方法就好～\nGit 好用技巧之二：git reset HEAD^（撤銷最新的 commit） # git reset HEAD^ 是我個人愛用的 Git 指令，他可以用來撤銷最新的 commit，但是不會刪除該 commit 中的內容，所以適合用在「上一個 commit 沒寫好，想要重新 commit」的情境上。\n舉例來說，目前在 test branch 中，有兩個 commit：\n一個是 123 的 commit（包含 123.txt 檔案） 另一個則是 456 的 commit（包含 456.txt 檔案） 如果這時候我發現「啊！我少添加了一個 789.txt 的檔案」，那麼我就可以先執行 git reset HEAD^ 的指令，先將 commit 456 給撤銷（注意此時 456.txt 的檔案仍舊存在，只是變回尚未 commit 的狀態）：\n此時我就可以自由添加想要的程式（ex: 789.txt），然後後續就可以將 456.txt 和 789.txt 一起加到 commit 裡，將他們存放在同一個 commit 中。\n之所以會特別介紹 git reset HEAD^，是因為我在工作上還滿常用這個指令的。根據以往的經驗，我發現將多個相關的檔案儲存在同一個 commit 裡面，這樣後續如果要排查程式的話，放在同一個 commit 中的檔案會比較好查。\n像是在 IntelliJ 這個 IDE 中，點擊「456 + 789」的 commit，就會在右側呈現這一次 commit 中的檔案有哪些，所以就可以透過這個線索，去查詢和他有相關的改動為何。\n所以在實作上，我個人會偏好盡量把相關的程式 commit 在一起，也算是幫助自己後續排查問題時比較好查詢這樣。\n不過老實說 commit 的頻率和檔案數，這個真的就很看大家自己的喜好，所以大家就自由參考，或是說如果有什麼更好的做法，也歡迎在下方留言！\n補充：如果想要在 IntelliJ 中達到 git reset HEAD^ 的效果，可以直接在該 commit 上點擊「Undo Commit」，這樣子就可以得到和 git reset HEAD^ 一樣的「撤銷 Commit」的效果了！\n結語 # 這篇文章我們有分享了 Git 中的好用技巧：Cherry-Pick 和 git reset HEAD^ 給大家，雖然這兩個指令的使用頻率不是很高，但是這兩個都是我自己用過，真心覺得好用的指令～\n如果你對後端技術有興趣的話，也歡迎免費訂閱《古古的後端筆記》電子報，每週二為你送上一篇後端技術分享，那我們就下一篇文章見啦！\n補充：我開設的 Spring Boot 零基礎入門、Spring Security 零基礎入門、GitHub 免費架站術 已在 Hahow 平台上架啦！輸入折扣碼「HH202601KU」即可享 85 折優惠。\n","permalink":"https://kucw.io/blog/git-tip/","tags":null,"title":"Git 的好用技巧介紹 - Cherry-Pick 和 git reset HEAD^"},{"categories":["其他技術分享"],"contents":"對於軟體工程師來說，「撰寫單元測試」已經是一個必須具備的技能，撰寫好的單元測試不僅能夠確保程式運行正確，也能夠降低後期重構、維護的成本，可以說是一舉多得！\n而在單元測試越來越重要的情況下，就誕生了 「TDD（測試驅動開發）」 的開發流程，因此這篇文章我們就來介紹一下，TDD 到底是什麼、以及要如何使用 TDD 來開發程式吧！\n目錄 什麼是 TDD（Test-Driven Development）？ 傳統的開發流程 TDD 的開發流程 步驟 1：只宣告功能的方法名稱，不實作內部程式 步驟 2：撰寫單元測試，並且單元測試運行失敗（紅燈） 步驟 3：實作主功能程式 步驟 4：單元測試運行成功（綠燈） 小結：TDD 開發流程 vs 傳統開發流程 TDD（Test-Driven Development）總結 結語 什麼是 TDD（Test-Driven Development）？ # TDD 的全稱是 Test-Driven Development，中文翻譯為「測試驅動開發」，而 TDD 的核心理念，就是 貫徹「先寫測試、再寫開發」的精神。\n也因為 TDD 的核心理念「先寫測試、再寫開發」比較抽象，所以以下我們就直接透過一個例子，來比較一下「傳統的開發流程」和「使用 TDD 的開發流程」的差別在哪裡。\n傳統的開發流程 # 一般我們在開發程式時，比較常見的流程為：\n接到需求 開始寫程式，實作該功能出來 最後撰寫單元測試，確保功能運行正確 所以在傳統的開發流程中，當我們拿到需求時，基本上就是先動手寫程式，先去實作該功能出來，而等到功能都實作的差不多之後，最後再補足單元測試，確保程式運行正確，這樣子就算完成這個功能的開發了。\n舉例來說的話，假設我們現在要實作一個「計算機的加法功能」，那麼我們就可以先寫出下圖左的程式（以 Java 為例），去實作加法功能出來。\n而當我們實作完左邊的加法功能時，就可以再去撰寫右邊的單元測試，使用單元測試去驗證我們所寫的程式是否正確，因此到最後，我們就實作完「主功能程式」和「單元測試」的程式了。\n所以上述這樣子的做法，就是最常見的傳統開發流程，也就是照著「先寫開發、再寫測試」的步驟，去完成一個功能的開發。\nTDD 的開發流程 # 而在了解了傳統的開發流程之後，接著我們就可以來介紹 TDD 的開發流程是什麼了！\n步驟 1：只宣告功能的方法名稱，不實作內部程式 # 當我們使用 TDD 時，首先第一步，就是 「只宣告功能的方法名稱，但卻不實作他的內部程式」。\n所以舉例來說的話，假設我們想要實作「計算機的加法功能」，那我們第一步，就只能夠先去宣告這個 add() 方法，但是不能夠去實作這個功能內部的程式。\n這一步對於習慣傳統開發流程的工程師來說，其實就是非常反人類的一步了😂，人生從來沒遇過只需要宣告方法名稱、但是不需要實作程式的要求！\n但是沒關係，建議大家就先接受 TDD 就是這樣的流程，所以當我們使用 TDD 時，第一步就是只宣告方法名稱，但是不實作他的內部程式。\n步驟 2：撰寫單元測試，並且單元測試運行失敗（紅燈） # 宣告完方法之後，接著也是很反人類的第二步來了。在第二步中，我們就要 「先根據這個方法的用途，憑空寫出他的單元測試出來」。\n舉例來說的話，因為我們想要實作的是「計算機的加法功能」，所以邏輯上，這個功能應該要能夠正確執行加法的操作才可以。因此我們可以直接在右邊撰寫一個單元測試，並且在這個單元測試中，就去測試 add() 方法的行為是否正確。\n所以在這個單元測試中，當我們去 call add(1, 2) 方法時，就「預期」他的返回結果應該要是 3 才對（因為抽象的邏輯意義上，add() 方法就是要去執行加法操作，所以 1+2 要等於 3 才對），程式如下圖右所示。\n所以在 TDD 的第二步中，我們就會直接根據這個方法的抽象邏輯，直接去撰寫單元測試出來，去「預期」這個方法的行為為何。\n不過當然啦，因為我們目前在 add() 方法中還沒有實作任何一行程式，所以當我們運行這一段單元測試的程式時，單元測試就會運行失敗，因此產生「紅燈」的結果（雖然此時單元測試運行失敗，但是這也是 TDD 的開發流程一環，因此這裡出現紅燈是正常現象）。\n老實說步驟二是大家一開始在接觸 TDD 時，最容易碰壁的一步，因為通常我們在實作程式時，會一不小心就往下鑽研去思考實作細節，但是卻忽略了「這個方法本身的用途」為何。\n因此在使用 TDD 開發程式時，我們就得換個角度來思考，在真正實作程式的細節之前，反而是要先從大方向去規劃每一個方法的用途為何，這樣子後續在實作程式時，才能夠寫出功能拆分完整、職責分明的程式了！\n步驟 3：實作主功能程式 # 在我們經歷了第二步最難熬的一關之後，後續的步驟就比較容易了！\n因為在第二步中，我們已經寫好測試 add() 方法的單元測試了，所以在第三步中，我們就可以回頭去實作 add() 方法中的邏輯，將這個功能真正的實作出來。\n步驟 4：單元測試運行成功（綠燈） # 而在我們實作完 add() 方法中的程式之後，這時候我們再回頭去運行單元測試，理論上就要能夠運行成功了！因此當我們運行單元測試時，單元測試就會顯示「綠燈」，表示單元測試成功通過。\n所以透過 TDD 的開發流程，我們最終也是可以實作完「主功能程式」和「單元測試」的程式了！\n小結：TDD 開發流程 vs 傳統開發流程 # 所以透過這兩個流程也可以發現，不論我們使用的是「傳統的開發流程」、還是「TDD 的開發流程」，我們最終所實作完的程式，其實是一模一樣的，就是會包含「主功能程式」和「單元測試」這兩部分，因此不論我們使用哪一種方式來開發，最終的產出都是一樣的。\n只不過 TDD 相對於傳統的開發流程而言，就是提供了另外一種開發思路給我們，讓我們在真正實作程式的細節之前，能夠先從大方向去規劃每一個方法的用途為何，進而寫出功能拆分完整、職責分明的程式了！\nTDD（Test-Driven Development）總結 # 所以總結上述的介紹的話，現在我們回頭來看 TDD 的定義，就可以更了解 TDD 的核心理念是什麼了。\nTDD 的全稱是 Test-Driven Development，中文翻譯為「測試驅動開發」，也因為 TDD 是透過「撰寫單元測試」去驅動「程式的開發」，所以 TDD 的核心理念，就是貫徹「先寫測試、再寫開發」的精神。\n而 TDD 的開發流程，也可以總結成下面這張圖：\n所以大家如果有興趣想嘗試 TDD（測試驅動開發）的話，就只要照著上述的步驟實作，就可以體驗 TDD 的開發流程了！\n結語 # 這篇文章我們有去介紹了 TDD（Test-Driven Development，測試驅動開發）的核心理念是什麼，並且也介紹了 TDD 的開發流程，了解要如何透過「撰寫單元測試」去驅動「程式的開發」。\n如果你對後端技術有興趣的話，也歡迎免費訂閱《古古的後端筆記》電子報，每週二為你送上一篇後端技術分享，那我們就下一篇文章見啦！\n補充：我開設的 Spring Boot 零基礎入門、Spring Security 零基礎入門、GitHub 免費架站術 已在 Hahow 平台上架啦！輸入折扣碼「HH202601KU」即可享 85 折優惠。\n","permalink":"https://kucw.io/blog/test-driven-development/","tags":null,"title":"TDD 是什麼？認識 Test-Driven Development（測試驅動開發）"},{"categories":["自媒體經營"],"contents":"哈囉，我是古古，正如之前在創刊號中有提到，雖然我一開始是意外踏入自媒體，但現在我是認真的要經營《古古的後端筆記》這個個人品牌，剛好現在也滿流行 Build in Public 的創業模式，所以就想來彙整一下到目前所經營的成果，寫個月報出來總結一下，也當作給自己的一個記錄。\n補充：還沒看過創刊號的人，也可以先查看一下 電子報創刊號，了解一下前情提要。\n2024.8～9 月粉絲追蹤數、電子報訂閱人數 # 自從電子報創刊號（2024/8/6）以來，到目前為止（2024/9/24）的粉絲成長人數如下：\n初始人數 2024/9/24 人數 總成長人數 Facebook 粉專追蹤數 2480 2687 +207 電子報訂閱人數 326 1195 +869 Threads 粉絲追蹤數 29 535 +506 IG 粉絲追蹤數 96 130 +34 雖然從這張圖上可以看到人數成長的很快，兩個月電子報就破 1000 人訂閱了，但我覺得這是因為我本身已經有經營 Facebook 粉專、有開過線上課程，所以目前已經有一定的粉絲數了，因此我是可以到 Facebook 社團宣傳、或是到課程中宣傳，將一部分粉絲數轉化為電子報訂閱者的。\n所以說到底，現在人數會漲得這麼快，完全就是吃老本😂，目前我已經把 Backend 社團的宣傳量能、自己線上課程的宣傳量能都用完了，下一步真的就是開始拼內容，只有製作出更有價值的內容，才能靠內容獲取大家的芳心💪。\n但有一點讓我滿意外的是，就是 Threads 粉絲的人數漲得也太快了吧！不知道大家有沒有玩過 Threads，我自己也是為了做自媒體才去下載 Threads 來用。\n據說 Threads 上的台灣用戶大概有 350 萬人左右，佔全球第 7 名，我自己是覺得根本原因是因為台灣人沒有被 Twitter（現 X 平台）佔據市場，所以在 「純文字的熱點討論」 這一塊，就被 Threads 給吃下來了。\n如果大家閒著沒事滑滑 Threads 的話，我是覺得可以比 Facebook 看到更多同溫層以外的討論，雖然也稱不上每一篇都很有收穫啦，但是就看看同溫層以外的世界也滿有趣的。\n然後有一點觀察也滿有趣的，就是 IG 的粉絲數真的是慘不忍睹XDD，一下子就被 Threads 超車到看不到車尾燈，我想這應該還是「內容呈現形式」所導致的差異。\n以 Facebook、Threads 和電子報來說，他們全部都是以 「文字」 的形式來傳播，但是 IG 則是以圖片、短影音來傳播，也因為後端技術這種比較硬的知識，大部分都還是以文字為主，所以我這個主題跟 IG 的粉絲受眾調性不同，因此在 IG 的粉絲數才一直起不來吧。\n後續應該會再觀察一段時間，如果 IG 流量真的不太好，現階段就直接放生吧XD，把時間拿去做更重要的事！\n本月學習內容：SEO 優化 # 既然是要認真經營自媒體，我覺得這對於我來說完全是一個新的領域，而我踏入新的領域的第一步，就是 「先認真看一堆書」，至少要把這個領域的基本知識搞懂、知道自媒體運作的原理，這樣子後續自己在實戰時，才不會像無頭蒼蠅一樣到處亂飛。\n所謂 「知識就是力量」，真的是非常好的一句話！\n這個月我看了《SEO白話文：贏得免費流量，創造長期營收的「SEO行銷指南」》這本書，作者是邱韜誠 Frank Chiu。\n會先挑 SEO 這個主題下手，是因為既然我的文章調性是以長文、部落格為主，那麼把 SEO 做好，可以說是一個 「長期有效」 的事。\n所謂的 SEO，全稱是 Search Engine Optimization（搜尋引擎優化），而 SEO 簡單的說的話，就是盡量讓你的網站在 Google 中排名變高，就是這麼簡單暴力。\n舉例來說，大家現在到 Google 上搜尋「Java lombok」的話，那就可以看到我所寫的「Java - 五分鐘學會 Lombok 用法」文章，出現在搜尋排名的第 2 名。\n而排名越靠前，就表示被使用者點擊的機率越高，因此我所寫的文章就越可以被大家看見、進而提升《古古的後端筆記》的影響力。\n所以在我不斷精進自己的後端技術能力的同時，我也得維護好 SEO，盡量讓自己寫的文章靠前，這樣子才能夠達到長期有效的成長。\n當然啦，SEO 效益這麼高，一定是所有人都搶著要把排名拉高🥹，而我現在也就只有一篇 Lombok 是排名比較靠前的，而且這也只是剛好運氣好賽到（當時根本不知道什麼是 SEO）。\n所以有關 SEO 的部分，後續我仍舊會投入練習經營，雖然目前也不知道成效怎樣，但是至少知道 SEO 的玩法規則之後，再上戰場跟其他網站廝殺，希望成功率可以高一點吧🤣。\n本月撰寫的電子報主題、文章 # 這邊記錄了我這兩個月內撰寫了哪些電子報和文章，大家如果對於其中的內容有興趣的話，也可以前往查看。\n《古古的後端筆記》創刊號 iThome 鐵人賽 - 得《優選》獎項的寫作心法 RESTful API 設計指南，3 個必備條件缺一不可！ 一文搞懂 Http Status Code，詳細解析 200、301、401、403、500、503 Spring Boot - 監控工具 Actuator AI 名詞和概念介紹 - NLP、LLM、RAG Vertical Scaling 和 Horizontal Scaling 介紹 Docker 是什麼？他和 VM 的差別在哪裡？ Nginx 是什麼？認識反向代理、負載平衡 如何準備面試？後端工程師的求職全攻略 2024.8～9 月報總結 # 綜合以上的數據的話，雖然到目前為止都只是吃老本，但是老實說看到這個粉絲數的成長我真的超開心的🥹😭，超級感謝大家的支持和訂閱，沒想到電子報訂閱可以破 1000 人，我真的是又驚又喜！\n後續除了努力撰寫後端知識分享的文章之外，也會多花一些時間學習自媒體、行銷這方面的知識，我覺得創業者就是得當個 「多面手」，什麼事情都必須要會，才能夠解決大大小小的各種問題。\n老實說，雖然在學習的過程中可能會有很辛苦的地方、也會有很累的地方，但是能夠學習其他領域的知識，其實我還滿興奮的😆，這可是坐在辦公室寫程式接觸不到的！所以後續希望也能多揭露一些自媒體的幕後祕辛給大家～\n另外，創業的路上不是自己一個人閉門造車就好，多聆聽用戶的反饋也是非常重要的！所以大家如果有什麼想法，也歡迎隨時寄信給我（service@kucw.io），每一封信我都會看的。\n這條創作之路仍在繼續前行中，期待下個月的月報！\n如果你對後端筆記有興趣，也歡迎免費訂閱《古古的後端筆記》電子報，每週二為你送上一篇後端技術分享，一起變強💪\n","permalink":"https://kucw.io/blog/as-a-content-creator/monthly-report-202408-09/","tags":null,"title":"軟體工程師的自媒體之路 - 2024.8～9 月報"},{"categories":["職涯相關"],"contents":"在軟體工程師的世界中，大家可能常常聽到「漲薪水就是要靠跳槽」，但是，在跳槽之前，做好面試的準備是非常重要的！所以這篇文章就會來分析一下後端工程師在求職時，有哪些注意事項要準備。\n目錄 後端工程師的求職全攻略 履歷部分 履歷長度要濃縮成一頁 剛轉職後端，沒有過往的工作經驗該怎麼辦？ 履歷不要只描述產品本身，而是要描述「你做了什麼」 履歷不要有形容詞 海投履歷，渣男/渣女式求職法 先用中文寫履歷，再一口氣翻譯成英文 履歷小結 面試部分 面試前的心態準備 如果我是面試官… 1. 會做事 2. 能跟面試官溝通順暢 3. 認真負責任 面試小結 後端工程師的求職全攻略總結 結語 後端工程師的求職全攻略 # 在求職時，主要會分成兩個流程：「履歷審查」和「面試」，雖然這句話聽起來很像廢話沒😂，但是在求職時，一定要分清楚自己目前是處在哪個階段。\n如果你是海投了 100 家公司，但是連一封面試邀請信都沒有收到，那你就是「履歷」的部分有問題，需要回頭調整履歷呈現方式；相反的，如果你是滿手面試邀請信，但是沒有一家順利拿到 offer，那就是「面試」的部分有問題。\n所以大家在求職時，除了要好好準備面試大魔王之外，履歷的準備也是非常重要的！這兩項是相輔相成的，缺一不可！\n所以這篇文章也會分別從「履歷」和「面試」這兩個不同的角度，分別來介紹在這不同的階段該如何進行準備。\n補充：本篇文章主要是針對 Junior（初階）後端工程師所撰寫的求職攻略，Senior（資深）的部分會稍微提到一點，但是不會深入太多，所以大家如果是資深工程師、或是主管大大等級的話，這篇文章可能幫助不大🥹。\n履歷部分 # 履歷長度要濃縮成一頁 # 在撰寫履歷時，首先一定要把自己的豐功偉業濃縮成一頁，常見的履歷就真的是只有一頁而已（可能 HR 們也來不及全部看完，只會看一頁），所以想盡辦法把自己做過的事情濃縮成一頁是非常重要的。\n剛轉職後端，沒有過往的工作經驗該怎麼辦？ # 如果是剛轉職比較沒有過往工作經驗的話，那麼會建議可以放一些你自己實作的小專案，如果是轉職的話，通常是會跟著資策會、或是線上課程學習，所以就可以把那些學習過程中所實作的專案，當成是你的求職作品集這樣，比起什麼都沒放會好很多！\n至於後續有累積越來越多工作經驗之後，就可以把作品集的部分拿掉了，把履歷的空間留給你最新的工作經驗。\n履歷不要只描述產品本身，而是要描述「你做了什麼」 # 在撰寫履歷時，建議不要只描述產品、作品集本身，而是要描述「你做了什麼」。\n舉個例子來說的話：\n❌ 我使用 Spring Boot 實作了一個電商網站，裡面包含會員功能、訂單功能、商品功能。 ✅ 我使用 Spring Boot 實作了一個電商網站，裡面包含會員功能、訂單功能、商品功能，其中用到的技術有 Spring Boot、RESTful API、Spring MVC、Spring JDBC、單元測試。 在上面的例子中，上面的 ❌ 錯誤寫法，就只是在描述這個電商網站本身有什麼功能這樣，其實對於面試官來說，你實作的產品是什麼不重要，重點是你在實作的過程中，使用到了哪些技術，這個才是最重要的！\n所以在撰寫履歷時，建議可以改成下面的 ✅ 正確寫法，描述你在實作電商網站的過程中，使用到了哪些技術，像是 Spring Boot、RESTful API、Spring MVC…等等，這樣子面試官後續才可以透過這些關鍵字，延伸去考察你是否了解這些技術的運用。\n履歷不要有形容詞 # 在撰寫履歷時，還有一個很重要的重點，就是在履歷中 「不要出現形容詞」！！！\n舉例來說的話：\n❌ 我實作了一個具有高吞吐量、高擴展性的搶票功能，並且撰寫易於維護的程式，有效減少後期維護成本。 ✅ 我實作了一個能負擔 1000 人同時在線搶購的搶票功能，其中使用了限流器中的令牌桶算法（Token Bucket），確保伺服器不會因為過量的人流導致崩潰。並且我使用 JUnit 撰寫單元測試，單元測試覆蓋率為 80%。 透過上面這兩個例子，可以看到上面的 ❌ 錯誤寫法，用了非常多很厲害的形容詞，像是「高吞吐量」、「高擴展性」、「易於維護」…等，但老實說，這些形容詞對面試是一點幫助都沒有的，所以透過上面那句話所得到的資訊，就只有「你實作了一個搶票功能」而已。\n而至於下面的 ✅ 正確寫法，就提供了很多資訊，像是面試官就能知道你實作了一個能負擔 1000 人的搶票功能（對後端來說，能同時負擔 1000 人和 10 萬人是不同等級的系統架構），然後後面也呈現了你所用到的技術，像是限流器、令牌桶算法、JUnit 單元測試…等等。\n因此面試官之後在面試時，就可以根據你這份履歷中所提到的關鍵字，具體的問你「那你了解限流器是什麼嗎？請解釋一下你為什麼採用令牌桶算法」…等等，等於是埋了許多關鍵字給面試官問這樣。\n所以在撰寫履歷時，建議改成正確的寫法，就是 「在履歷中盡量不要出現形容詞」，反而是要好好的把你的實作給 「量化」 出來，這才是最重要的！\nPS: 這時候有的人可能會有疑問，啊我都離職了，要怎麼取得到當初我實作的系統數據？沒錯，你拿不到的（如果你拿得到，公司的資安就完了）。\n所以履歷其實是要在工作的過程中隨時更新的，建議是當你做完一個大案子的時候，就可以回頭拉一下數據、更新一下你的履歷，這樣子後續要求職的時候，才不會苦無找不到數據來佐證自己的情況出現🥹。\n海投履歷，渣男/渣女式求職法 # 抱歉這一個小節的標題有點聳動，但是這是我真實的想法😂。\n在投履歷時，除了那種「你上了也完全不想去的公司」不用投之外，其餘的公司，但凡你有一點點興趣，建議履歷就是直接給他大膽地投下去，等到你真的上了之後，再考慮要不要去。\n很多人在投履歷時，可能會陷入一個迷思，就是「我已經正在面試某幾家公司了，我還要繼續投履歷嗎？」，這個答案，一定是 Yes！ 在你真的拿到 offer 入袋之前，有幾家你就投幾家，每天照三餐投，反正就是有幾家就投幾家就對了！\n這樣子海投履歷的好處，就是 「你能掌握主動權」，舉例來說：\n假設你今天突然面試到一半被刷掉了，這時候就不需要特別擔心，因為你還有備胎 假設你今天同時得到 2 家公司以上的 offer，那太棒了，你們 2 家公司去打架吧，看誰給的錢高、待遇好、發展性好，我就去哪家 所以對於求職者來說，手上掌握越多 offer 通常是越好的，這代表你在市場上有競爭力，所以大家都搶著要你，所以你就越有底氣和 HR 談更好的薪資待遇，因此在求職時，如果時間允許的話（畢竟面試也是需要時間準備），還是會建議大家可以海投履歷，為自己掌握更多的主動權。\nPS：之所以說海投履歷是渣男/渣女式的求職法，是因為在還沒有正式交往（還沒有正式簽 offer）之前，你都還有許多備胎（其他公司）可以選擇；同樣的，公司也是除了你之外，還養著無數的備胎求職者，所以這就是一個比賽誰備胎比較多的世界，根本就是逼人當渣男/渣女😂。\n所以建議大家，在找工作時，就先放下你善良的感情觀，用渣男/渣女的方式來求職，讓自己成為許多公司搶著要的對象，才能成為真正的贏家！\n先用中文寫履歷，再一口氣翻譯成英文 # 這點我真的是恨不得早點發現🥹，在一剛開始求職時，我也常常遇到履歷寫不出來的情況出現，本來還怪說是不是自己英文太爛了才寫不出來，但是後來當我嘗試用中文寫寫看時，嗯.…我發現我還是寫不出來XDD。\n這就像是英文作文一樣，拿不到高分時，以為是自己英文不夠好、名言佳句背不夠多，才寫不到高分，後來才發現原來是自己中文不好，用中文寫的文章結構就很糟了，這樣就算翻譯成英文，仍然沒辦法變成一篇好作文，進而拿到高分的。\n所以就建議大家，一開始可以先用中文寫履歷，等到全部寫完之後，再叫 ChatGPT 幫我們翻譯成英文，最後再根據英文的長短句，精煉一些單字，努力把履歷塞到一頁裡面，這樣會是撰寫履歷效率最高的方式！\n履歷小結 # 所以綜合以上的討論的話，要撰寫一份好的履歷，建議滿足以下條件：\n履歷要濃縮成一頁 剛轉職時，可以放自己練習的專案當作作品集；等到工作經驗累積越來越多之後，再將作品集的部分刪掉，把版面留給工作經驗 履歷不要描述產品本身，要描述「你做了什麼」 履歷中不要有形容詞 海投履歷，當一個渣男/渣女，還沒正式簽 offer 之前都不算數 先用中文寫履歷，再一口氣翻譯成英文 只要滿足上述條件，基本上就可以寫出一份完整的履歷了！\n面試部分 # 忙完了履歷部分之後，再來就會進到面試的階段了！\n所謂 「履歷寫的好，面試沒煩惱」，面試官對於你一個未知的求職者，他所有的資訊都是從你的履歷上面展開的，就像是你不會突然問一個寫 Java 的工程師 Python 的問題一樣，面試官不可能天馬行空的亂問，所以能夠在有限的面試時間中，展現多少你的強項，這就是在履歷期間要下的功夫了。\n不過當然啦，履歷只能作為一個 Hook（鉤子），勾起面試官對你的興趣，但是實際上你是否能真正錄取，還是要看你在面試中的對應進退來評估的～\n所以接下來，我就會嘗試用面試官的角度，來分析面試官想要看到的東西是什麼，並且分析大家在求職時，又要如何來進行應對。\n面試前的心態準備 # 這裡要先給大家打一個預防針，就是面試的最終目標，是找到一個「面試官想用的人」。因為面試官通常就會是你未來的主管，所以如果我是主管的話，我當然會想找一個和我合的來的人（難不成要找一個天天跟我對著幹的人嗎？不會吧😂）。\n所以建議大家在求職前，要先建立一個良好的心態，就是 「面試是雙向的」，假設今天你沒面試上，不一定是你的錯，有可能就是你跟這個面試官磁場不合，這樣的話反而儘早結束面試比較好，勉強是不會幸福的！\n但我也能理解，有時候大家就是擠破頭很想進某些公司（ex: FAANG），所以除非是真的有很強烈的動機想進某些公司，逼自己容忍與面試官的不合，不然的話，建議還是順著自己的感覺走，畢竟工作是每天時間佔比最長的事情，能夠找到一個合的來的主管還是比較重要的。\n而在建立好心態之後，接下來就可以正式進到面試的環節了！\n如果我是面試官… # 假設我是一個面試官的話，我就會從 「會做事」、「能跟我溝通順暢」、「認真負責任」 這三種方向來面試後端求職者。\n1. 會做事 # 在這個面向中，就是考察求職者的基本技術能力，至少要會寫 CRUD、至少要能夠使用後端框架（ex: Spring Boot）來開發程式、至少要知道什麼是 API\u0026hellip;等等，這是最基本的要求，不達標的完全不考慮。\n而求職者達到上述的最低標準之後，接下來我就會考察深度，看看你到底懂多少，所以可能就會發生下面的對話（以下以 Spring Boot 為例）：\n👤 面試官（我）：你的作品是什麼？你是怎麼實作的？ 🧑‍💻 求職者（你）：我的作品是用 Spring Boot 架設一個簡易的電商網站，實作了會員功能、訂單功能、商品功能，並且用到的技術有 Spring Boot、Spring JDBC、Spring MVC、單元測試。 👤 面試官（我）：你說你有實作電商網站的訂單功能，那你知道什麼是「交易管理 Transaction」嗎？（內心：我想考考這人懂不懂 Transation，是否了解如何在 Spring Boot 中運用 @Transactional） 🧑‍💻 求職者（你）：交易管理就是 XXX\u0026hellip;.. 所以面試官就是會透過你的作品集、以及你在履歷中所描述的功能，用一問一答的方式，考驗你的技術能力，通常就是問到你答不出來為止（所以面試時被洗臉不用太緊張，大家都是這麼被洗過來的🥹）。\n所以透過這個例子，也再次說明了履歷的撰寫真的很重要，「履歷寫的好，面試沒煩惱」，只要履歷上你有提供足夠多的鉤子、好好的呈現你的技術實力，那麼在有限的面試時間裡面，面試官就可以直接切入重點，考察你的各項技術能力，讓你的所做所學能夠被看見，進而提升面試成功的機率！\n不過當然啦，就算你在履歷上撰寫了再多的技術，只要面試官一問下去你就含糊帶過，那面試成功的機率還是不高的，所以維持自身的實力還是很重要的！\n大家在面試前，可以先上網查詢一下「Java 面試題」、「Spring Boot 面試題」、「Python 面試題」\u0026hellip;等等，有很多人整理出相關問題集，可以先用這些題目暖身當作練習，如果遇到不會的問題，就回頭努力學習，讓自己變的更強💪。\n很多人也都是藉由面試的過程中發現自己的不足，然後慢慢成長的，只要一直往前走，就會越變越強了！\n補充：所以在投遞履歷時，建議也可以把比較想去的公司擺在後面一點投，先拿這些不太感興趣的公司練習面試，等到越來越熟悉面試的感覺之後，再去面試最想去的公司～\n2. 能跟面試官溝通順暢 # 在這個面向中，基本上就是考察求職者在面試的過程中，是否有辦法理解面試官所提出的問題，並且是否能夠用簡單易懂的方式，解釋到能讓面試官聽懂這樣。\n會考察這個方向，主要是因為在現實的工作中都是團隊合作，所以考察求職者能不能用言語、圖畫\u0026hellip;等等的方式，把你心中所想的內容呈現給別人，也是一個很重要的技能。\n3. 認真負責任 # 在這個面向中，就是考察求職者是否是一個認真負責的人，就是這麼簡單暴力。相信如果換作大家是主管，一定想要你招來的人是個認真負責任的好寶寶吧（最好是好寶寶印章集滿的那種），畢竟認真負責任的人誰不愛呢？\n但老實說這一個面向就比較玄了，沒有明確的問題可以問出這題的答案，面試官總不可能問求職者：「你是否認真負責？」吧😂，所以這題就只能夠在面試的對答過程中、或是依靠履歷上的過往工作經驗，讓面試官自己去感受出來。\n如果大家是面試 FAANG 的大公司的話，一定會有一關是 「Behavior Question（行為面試）」，這一關基本上就是在考察你是否是一個好寶寶、個性是否符合公司的文化這樣。\n像是在 Behavior Question 中，就會有下列的題目：\nTell me about a time when you disagreed with someone. How did you approach the disagreement?（你有沒有和同事意見不合的時候？你是如何處理的？） Tell me about a time you failed or made a mistake（介紹一個你曾經失敗、或是犯錯的經驗） Tell me about a time your responsibilities got a little overwhelming. What did you do?（當你的任務實在太多，根本就無法處理完時，你是怎麼處理的？） 不得不說，Behavior Question 真的每一題都很尖銳，尖到要把你的心剖出來看的那種🥹，老實說我也不知道為什麼要問這麼血流成河的題目，才能證明自己是一個好寶寶，但是如果大家的目標是 FAANG 的話，那麼 Behavior Question 是一定要準備的方向。\nBehavior Question 的題目我覺得是比前面的技術問題更難準備（因為沒有標準答案），所以大家如果想挑戰 FAANG 的話，建議還是要多花一些時間來準備這部分會比較好。\n面試小結 # 所以綜合以上的討論的話，要完成一次好的面試，建議滿足以下條件：\n做好面試前的心態準備：面試是雙向的 從「會做事」、「能跟面試官溝通順暢」、「認真負責任」這三個面向，訓練自己的技術能力、溝通能力、以及認真負責的價值觀 履歷寫的好，面試沒煩惱 面試可能還有更多細節要顧，不過如果能做到上述的幾種事項，相信絕對是可以提高面試的成功率的！\n後端工程師的求職全攻略總結 # 所以總結一下上面的介紹的話，最後可以歸納出下面這張表格：\n履歷注意事項 面試注意事項 履歷要濃縮成一頁 做好面試前的心態準備：面試是雙向的 剛轉職時，可以放自己練習的專案當作作品集；等到工作經驗累積越來越多之後，再將作品集的部分刪掉，把版面留給工作經驗 從「會做事」、「能跟面試官溝通順暢」、「認真負責任」這三個面向，訓練自己的技術能力、溝通能力、以及認真負責的價值觀 履歷不要描述產品本身，要描述「你做了什麼」 履歷寫的好，面試沒煩惱 履歷中不要有形容詞 海投履歷，當一個渣男/渣女，還沒正式簽 offer 之前都不算數 先用中文寫履歷，再一口氣翻譯成英文 也建議大家在求職時，可以針對 「履歷」和「面試」，分別去對症下藥，了解自己不足的地方、並且努力學習、持續成長變強，最終就能夠收穫自己心儀公司的 offer 了！\n結語 # 這篇文章我們針對「後端工程師的求職全攻略」主題，分別從「履歷」和「面試」這兩個方向，來探討每個階段該做什麼事，希望可以透過這篇文章，幫助大家在求職路上更順暢！\n如果你對後端技術有興趣的話，也歡迎免費訂閱《古古的後端筆記》電子報，每週二為你送上一篇後端技術分享，那我們就下一篇文章見啦！\n補充：我開設的 Spring Boot 零基礎入門、Spring Security 零基礎入門、GitHub 免費架站術 已在 Hahow 平台上架啦！輸入折扣碼「HH202601KU」即可享 85 折優惠。\n","permalink":"https://kucw.io/blog/backend-developer-interview/","tags":null,"title":"如何準備面試？後端工程師的求職全攻略"},{"categories":["其他技術分享"],"contents":"Nginx 可以說是在大型的微服務架構中，必備的核心功能之一，所以這篇文章我們就來介紹一下 Nginx 到底是什麼，以及介紹一下反向代理、負載平衡的概念吧！\n目錄 什麼是 Nginx？ 在 Nginx 被發明出來之前：單體式架構 微服務架構所碰到的問題 Nginx 的反向代理 Nginx 介紹 反向代理（Reverse Proxy） 負載平衡（Load Balancing） Http Cache Nginx 總結 補充：什麼是正向代理（Forward Proxy）？ 結語 參考資料 什麼是 Nginx？ # Nginx 是一個輕量級的 Web 伺服器，通常用在以下三種情境：\n反向代理（Reverse Proxy） 負載平衡（Load Balancing） Http Cache 不過在我們開始了解 Nginx 的這三種特性之前，要先回頭來介紹一下 Nginx 最一開始要解決的問題是什麼，了解了 Nginx 要解決的問題之後，我們才能夠延伸去介紹「反向代理」、「負載平衡」、以及「Http Cache」的概念。\n補充：Nginx 的唸法是「Engine X」（中文發音近似於「安金 欸可斯」），也就是「引擎 X」的意思，這裡開頭的 N 字母就是使用到英文語法中常見的縮寫。像是 How are you 可以簡寫成 How r u、而 Airbnb 其實是 AirBed \u0026amp; Breakfast 的簡寫（n 的發音近似於 \u0026amp;），所以在這裡就是用到了英文的語法，將「Engine X」縮寫為「Nginx」。\n在 Nginx 被發明出來之前：單體式架構 # 在我們一開始學習後端程式時，我們就是寫好一個後端程式（ex: Spring Boot 程式），然後運行他，接著我們就可以用 Postman 這類的工具，去發起一個 API call，去請求我們電腦上所運行的後端程式，而這個就是最簡單的 單體式架構（Monolithic），也就是同時間我們只會有一個後端程式存在。\n不過當有越來越多使用者，慕名前來使用我們的後端服務時，這時候就會導致流量上升，使得一台 Server 沒辦法支撐住這麼高的流量。\n所以這時候，為了確保 Server 能負擔這麼高的流量，我們就有兩個選擇：\n使用 Vertical Scaling（垂直擴展），為這台 Server 升級 cpu、ram…等設備，讓他從一台普通的「2 核 cpu、4 GM ram」的電腦，變成是一台「64 核 cpu、128 GB ram」的超級電腦。 使用 Horitontal Sclaing（水平擴展），也就是多新增幾台 Server 出來，大家人多勢眾，一起對付更高的流量。 如果這時我們選擇 Vertical Scaling（垂直擴展）的話，就只是從一台普通的 Server，進化成一台超級電腦而已。這個選擇對整體的架構沒有影響，仍舊是只有一個後端程式在運行，所以此時依舊是單體式的架構，因此不需要 Nginx 上場。\n但如果我們選擇的是 Horitontal Sclaing（水平擴展）的話，那麼我們在同一時間，就會有非常多台的 Server 聚集在一起，準備聯合起所有 Server 的力量，一起對付高流量。所以這時候，整個後端的架構，就會從「單體式架構（Monolithic）」變成「微服務架構（Microservices）」，也就是同時間有多個後端程式在運作。\n所以這個時候，我們就會遇到微服務架構所要面對的問題，因此就需要 Nginx 上場了！\n補充：如果想更了解 Vertical Scaling（垂直擴展）和 Horizontal Scaling（水平擴展）的介紹，可以參考 Vertical Scaling 和 Horizontal Scaling 介紹 文章的介紹。不過這邊只要先知道 Horizontal Scaling 的概念是新增許多台 Server 出來，就可以繼續閱讀本文對 Nginx 的介紹了。\n微服務架構所碰到的問題 # 在微服務的架構中，因為同時間會有多個後端 Server 在運作，所以這時候對於前端而言，最最最大的問題，就是他不知道要去 call 哪一台 Server 的 API（對這個聽起來有點笨，但是前端就真的不知道啊！）。\n像是在下面這張圖中，同時間有 3 台後端 Server 在運作，這時候前端就會很困惑，他現在到底是要請求哪一台 Server？或是當流量又升高之後，這時候我們添加到 10 台 Server 來處理時，這時候要怎麼通知前端，現在有 10 台 Server 可以接受前端的請求？\n所以為了解決這個問題，Nginx 就被發明出來了！\nNginx 的反向代理 # Nginx 其中的一個核心功能，就是 「反向代理（Reverse Proxy）」，而所謂的反向代理，就是讓 Nginx 一個人擋在所有後端程式的最前面，由 Nginx 作為統一的守門人。\n所以當前端想要來請求後端的 API 時，前端就會改成請求 Nginx，由 Nginx 決定這一次的請求要分配到哪一台後端 Server 上，而這個行為，就是反向代理（Reverse Proxy）了！\n所以有了 Nginx 之後，Nginx 就可以作為所有後端 Server 的守門人，因此今天當前端來請求後端的 API 時，前端就必須改成去 call Nginx，由 Nginx 將這個請求「轉發」給任一台後端 Server（轉發規則由 Nginx 說了算），達到反向代理的效果。\n所以透過 Nginx 的反向代理，我們就可以統一的處理所有前端傳遞過來的請求了！\nNginx 介紹 # 透過上面的例子大概了解 Nginx 的概念之後，我們也可以回頭正式來介紹一下 Nginx 的用途。\nNginx 是一個輕量級的 Web 伺服器，通常用在以下三種情境：\n反向代理（Reverse Proxy） 負載平衡（Load Balancing） Http Cache 而透過上述的例子，現在我們也了解了反向代理的概念是什麼：\n反向代理（Reverse Proxy） # 所謂的「反向代理」，其實就只是 Nginx 一個人擋在所有後端 Server 的最前面，由 Nginx 作為後端 Server 的守門人，因此所有前端傳遞過來的請求，都一定都要先經過 Nginx，再經由 Nginx 後續去轉發給內部的後端 Server。\n而使用反向代理的好處非常多，因為在反向代理中，是由 Nginx 一個人扛住所有對外的連接，所以我們只需要在 Nginx 中設定好 Https 的憑證即可，因此內部的後端 Server 就不需要處理網路相關的憑證問題。\n又像是防火牆的問題，我們只要統一的在 Nginx 處理好 DDoS 之類的駭客攻擊就好，就不需要每一個後端 Server 都去處理，也大大的節省了資訊安全的維護成本。\n如果大家有用過 AWS、GCP…這類雲端服務的話，其實 AWS 中的 API Gateway，就會擋在 Amazon EC2 前面（EC2 就是 AWS 中提供 VM 的服務），由 API Gateway 統一處理所有對外的溝通。所以如果你的 Server 是部署在 AWS 上的話，那麼可以直接選擇 AWS 的 API Gateway 來負責反向代理的部分，因此就不用自己架一台 Nginx 來維護了。\n圖片來源： Amazon API Gateway 負載平衡（Load Balancing） # 只要講到反向代理，那麼就一定會提到 負載平衡（Load Balancing），他們是必定會一起出現的一對名詞。\n在前面我們有提到，Nginx 會作為所有後端 Server 的守門人，透過反向代理的機制，將前端傳過來的請求，「轉發」 給任一台後端 Server 上。\n所以換句話說的話，今天這個請求會轉發到哪一台後端 Server 上，完全是看 Nginx 心情，假設 Nginx 沒設定好的話，可能就會導致每一個請求都轉發到同一台後端 Server 上，造成「一台有難，其他台隔岸觀火」的情況，而這個情形是我們不想看見的。\n所以為了讓 Nginx 在轉發請求時，能盡量轉發的更平均一點，也就是讓每一台 Server 都有在工作，不會某一台過勞，這就是負載平衡的目的了！\n所以所謂的 負載平衡（Load Balancing），就是一種將流量平均分配到後端 Server 的方法，讓每一台後端 Server 都可以被均等使用。\n而在 Nginx 中，常見的負載平衡演算法有：\n1. Round Robin 演算法（Nginx 預設使用此演算法）： 所謂的 Round Robin，就是 Nginx 會照順序一台一台發送請求，所以就會變成第一個請求轉發給第一台 Server、第二個請求轉發給第二台 Server…等等，依此類推。運行邏輯可參考下圖中的 1. Round Robin 所描述。\n2. Least Connected 演算法： 當請求來時，Nginx 查看目前哪一台 Server 負責的請求數最少，就轉發給他。運行邏輯可參考下圖中的 5. Least Connections。\n3. IP Hash 演算法： Nginx 會取得請求發起方的 IP 地址，然後 hash 一下這個 IP 地址之後，將這個請求轉發到 hash 出來的 Server 上。運行邏輯可參考下圖中的 4. IP/URL Hash。\n圖片來源： ByteByteGo - EP47: Common Load-balancing Algorithms 當然上面提到的這 3 種負載平衡的演算法，僅是 Nginx 所提供的演算法而已，如果大家使用的是 AWS 的 API Gateway 的話，有提供更多種的負載平衡演算法讓大家選擇，詳情可以參考 AWS 的《What is Load Balancing?》介紹。\nHttp Cache # 除了上述的「反向代理」以及「負載平衡」的強大功能之外，Nginx 的最後一個特性，即是「Http Cache」。\n像是我們可以把一些靜態的資源（ex: HTML 檔案、圖片）放在 Nginx 中，由 Nginx 儲存在 Http 的 Cache 中，這樣子當下次前端來請求靜態資源時，Nginx 就可以直接回傳這些靜態資源給前端，就不需要後端 Server 的介入了。\n不過老實說，現在這個 Http Cache 的功能，已經被其他更厲害的工具（ex: CDN）給取代了，所以在實務上，不會真的去使用 Nginx 本身的 Http Cache 的功能，因此建議大家對這部分有個概念就可以了。\nNginx 總結 # 所以透過上面的介紹，現在我們就了解到，Nginx 是一個輕量級的 Web 伺服器，並且他通常會用在以下三種情境：\n反向代理（Reverse Proxy） 負載平衡（Load Balancing） Http Cache 其中「反向代理」和「負載平衡」這兩個核心功能，是 Nginx 最強大的地方，就是因為 Nginx 提供了「反向代理」和「負載平衡」的功能，所以我們才能夠將 Nginx 應用在微服務架構上，進而解決統一眾多後端 Server 入口的問題了！\n補充：什麼是正向代理（Forward Proxy）？ # 在上述的介紹中我們有提到，Nginx 擅長的部分是「反向代理」，也就是將後端 Server 隱藏起來，統一只由 Nginx 作為對外的出口，所以所有的前端請求都必須要經過 Nginx，才能夠到達內部的後端 Server。\n而有反向代理，就會有正向代理（但老實說他們之間沒什麼關係），既然我們都談到了反向代理，就順便一起補充正向代理給大家。\n所謂的 正向代理（Forward Proxy），就是將 Client 的資訊隱藏起來，由代理人統一的對外溝通。\n像是公司的內網，一定是所有人的電腦先連線到 IT 所架設的路由器上，最終才由這個路由器出去對外和外部的網路世界溝通，所以在這個情境中，這個 IT 所架設的路由器就是負責「正向代理」，也就是所有 Client 所發出的請求，都會經過這個路由器，最終才會連線到真實的網路世界。\n所以這也是為什麼大家在工作時，常常會遇到某些網站被公司 IT 給擋住，這就是因為所有的網路請求，實際上都會經過 IT 的路由器，最終才會傳到外部的公開網路上，因此 IT 就可以在路由器那裡設定一些規則，將某些網站給封住，進而讓你在上班時沒辦法瀏覽某些網站了。\n所以比較一下正向代理和反向代理的話：\n正向代理（Forward Proxy）： 將 Client 的資訊隱藏起來，由代理人統一的對外溝通。 反向代理（Reverse Proxy）： 相反過來，將 Server 的資訊隱藏起來，由代理人統一的對外溝通。 雖然大家在日常的後端開發中，很少會遇到正向代理的設定，但是多少了解一下正向代理的概念，仍舊是很有用的。\n結語 # 這篇文章我們有詳細的去介紹了一下 Nginx 的用途，以及反向代理、負載平衡的概念是什麼，這些概念非常的重要，希望可以透過這篇文章，讓大家更了解 Nginx 這個工具實際要解決的問題是什麼。\n如果你對後端技術有興趣的話，也歡迎免費訂閱《古古的後端筆記》電子報，每週二為你送上一篇後端技術分享，那我們就下一篇文章見啦！\n補充：我開設的 Spring Boot 零基礎入門、Spring Security 零基礎入門、GitHub 免費架站術 已在 Hahow 平台上架啦！輸入折扣碼「HH202601KU」即可享 85 折優惠。\n參考資料 # https://blog.bytebytego.com/p/ep25-proxy-vs-reverse-proxy https://www.nginx.org.cn/article/detail/545 https://www.explainthis.io/zh-hant/swe/why-nginx ","permalink":"https://kucw.io/blog/nginx/","tags":null,"title":"Nginx 是什麼？認識反向代理、負載平衡"},{"categories":["其他技術分享"],"contents":"作為軟體工程師，大家可能多多少少聽過什麼是 Docker，但是卻不了解 Docker 實際要解決的問題是什麼、以及他和 VM 之間的區別。\n所以這篇文章就會來介紹一下，到底什麼是 Docker、什麼又是 VM，並且他們兩個之間的差別又是什麼，那我們就開始吧！\n目錄 什麼是 VM？ 使用 VM 的注意事項 補充：常見的 VM 例子 什麼是 Docker？ 有了 VM 之後，我們還需要 Docker 嗎？ VM 和 Docker 總結 結語 什麼是 VM？ # 在了解 Docker 之前，一定要先了解什麼是 VM 才可以，所以我們先來介紹一下 VM 是什麼。\nVM 的全稱是 Virtual Machine，中文翻譯為「虛擬機」，而 VM 要解決的問題，就是要達到「硬體資源的共享」。\n在很久以前 VM 還沒被發明出來的時代，這時候如果我們想要在一台電腦上運行程式，那我們首先要做的，就是要先帶著你的錢錢，先到 3C 商店買一台實體的電腦回家之後，你才能夠在那台電腦上面運行你所寫的程式。\n所以在 VM 被發明出來以前的時代，我們所有的程式，就都是直接運行在實體的主機上。\n不過隨著網路的發展，大家就漸漸發現，每次在運行程式之前，都還得要提前去買一台實體的電腦，這真的是太麻煩了！所以大家就開始思考：「我們是否能夠讓一台實體的電腦，分身成無數台電腦？」，這樣子我們就再也不用提前去購買實體的主機了，只要按一下按鍵就可以生成一部新的電腦出來。\n而正是這個想法，就造就了 VM（虛擬機）的出現了！\n所謂的 VM，就是將「一台實體的主機」，拆分成「許多個作業系統」的技術。 所以舉例來說的話，假設我們有一台超強的實體主機（64 核 cpu、128 GB ram），那麼我們就可以透過 VM 的技術，將這台實體主機「拆分」成是三台電腦，而每一台電腦，我們就可以自由的選擇我們想要灌哪個作業系統。\n所以像是在下圖中，在 VM 虛擬機 1 這台電腦上，我們可以灌 Linux 這個作業系統；而在 VM 虛擬機 2 這台電腦上，我們可以灌 Windows 這個作業系統…等等，所以當我們使用了 VM 之後，我們就只要購買一台實體的主機，就可以拆分成許多台小電腦出來，因此就達到了 「硬體資源的共享」 了！\n使用 VM 的注意事項 # 在使用 VM 時，因為 VM 本質上是去共享一台實體主機，所以所有 VM 的運算資源，都是從實體主機上面瓜分出來的。\n所以像是在上面的例子中，假設實體主機的運算能力是 64 核 cpu、128 GB ram，那麼 VM 1 可能只會分到 2 核 cpu、4G ram，VM 2 可能會分到 4 核 cpu、8G ram…等等，每一台 VM 都可以依照自身的需求，去和實體的主機請求適量的運算資源。\n也因為 VM 的運算資源都是從實體主機上面瓜分出來的，所以一台實體主機能創建的 VM 也是有限的，沒辦法無限的創建下去，所以萬一 VM 的需求越來越多的話，仍舊是會需要我們提前去購買新的實體主機回來的。\n補充：常見的 VM 例子 # 其實大家平常在用的雲端服務，就是 VM 最常見的用法。像是我們可以用滑鼠點一點，就能夠在 AWS 中去租用一台 EC2 的 VM 出來。\n像是在下圖中，AWS 預設就是租用 t2.micro 的 VM 給我們，所以這一台 VM 就是擁有 1 核 cpu、並且有 1G 的 ram，而運行這台 VM 的實體主機，就是 AWS 提前採購好的實體主機。\nOK 所以到這邊為止，我們已經了解到什麼是 VM 了，所謂的 VM，就是要達到「硬體資源的共享」。\n那麼在了解了 VM 的概念之後，接著我們可以來了解一下，什麼是 Docker？他和 VM 又有什麼差別？\n什麼是 Docker？ # 如果說 VM 的目的，是為了要達到「硬體資源的共享」，那麼 Docker 的目的，則是要達到「應用程式的隔離」。\n大家可以想像一個情境，假設你今天上網看到了一段爬蟲程式，然後你想把他載下來使用，但是這段程式要求要使用 Python 2.x 的環境才能夠運行，所以你為了運行這段程式，你就努力的在你的電腦上安裝好 Python 2.x 的環境，最後就成功的運行了這段程式。\n但是，當你好不容易處理完環境的問題之後，假設你又要執行另一段網頁程式，他所需要的是 Python 3.x 的版本，這時候你又得大費周章，努力的去研究要怎麼將 Python 2.x 更新到 Python 3.x、以及怎麼樣同時在你的電腦上安裝 Python 2.x 和 Python 3.x 的開發環境。\n這時候，你可能心已經累了，你明明只是想去運行網路上的那段程式而已，但是你卻得花非常多的心力，去處理架設開發環境的設定。\n所以為了解決這個問題，Docker 就被發明出來了！\n所謂的 Docker，他的目的是要達到「應用程式的隔離」，所以在你的電腦中，就會有很多個「容器」存在，每一個容器都是一個箱子，裡面會放置你想運行的程式、以及該程式需要的開發環境，並且每一個箱子之間不會互相干擾。\n所以像是在下圖中，在 VM 1 這個 Linux 的作業系統裡面，我們就可以創建許多個 Docker 容器出來，而每一個 Docker 容器，我們都可以安裝不同的開發環境、並且運行不同的程式，這樣子就可以達到開發環境之間的隔離，進而節省我們反覆架設開發環境的時間。\n所以舉例來說的話，我們就可以將「爬蟲程式 + Python 2.x 的開發環境」，放置在 Docker 容器 1 裡面，而我們也可以將「網頁程式 + Python 3.x 的開發環境」，放置在 Docker 容器 2 裡面。因此當我們之後想要執行爬蟲程式的時候，就直接去運行 Docker 容器 1 就好，而如果我們想要運行的是網頁程式，那就是改成運行 Docker 容器 2。\n所以透過 Docker 容器的概念，我們就可以達到「應用程式之間的隔離」了！\n有了 VM 之後，我們還需要 Docker 嗎？ # 在了解了 VM 和 Docker 的概念之後，接著我們也可以來討論一下一個很常見的問題，那就是：有了 VM 之後，我們還需要 Docker 嗎？\n在看完了上面的介紹之後，大家心裡可能會有一個疑惑，就是上述的 Python 環境的問題，我們創建兩個 VM 出來，不就也可以解決了？譬如說我們可以創建一個 VM 1，裡面安裝 Linux 的作業系統，並且安裝 Python 2.x 的環境，然後我們也可以再創建 VM 2，裡面也是安裝 Linux 的作業系統，但是改成安裝 Python 3.x 的環境，這樣不是也能解決上面的開發環境的問題嗎？\n確實透過創建兩個 VM 的方法，是可以解決 Python 的環境問題沒錯，不過相較來說，Docker 的解法會更加輕量化。\n因為對於傳統的 VM 來說，每一個 VM 都需要安裝一個作業系統（ex: Linux），然後才能在這個作業系統上面安裝 Python 的開發環境。但是在作業系統中，其實是包含非常多的功能的（ex: 操作介面、驅動程式、網路管理…等等），所以每當我們創建一個 VM 出來，就必須要一起創建這些我們根本用不到功能出來，所以我們就會浪費不少的運算資源，在維護這些不必要的功能上。\n而 Docker 之所以可以更加輕量化，是因為他是在同一個作業系統底下，去創建許多的容器出來，然後再在每一個容器中，各自去安裝需要的開發環境。所以這些容器，他們就會共享同一個作業系統的所有功能，所以我們就不需要重複去安裝驅動程式這類的功能，因此就可以節省許多的運算資源，降低 cpu 的負擔了。\n所以 Docker 之所以這麼好用，就是因為他除了能夠達到「應用程式的隔離」之外，同時他也能達到「作業系統的共享」，所以 Docker 容器們能夠去共用同一個作業系統的共通部分，這樣子就不用再額外花費多餘的運算資源，重新蓋一套作業系統出來，進而就可以降低 cpu 的負擔了。\n所以如果你只是想要隔離不同的應用程式的話，那就非常推薦使用 Docker 來解決，而如果是想要直接操作底層的作業系統的話，那就推薦使用 VM 來解決，因此大家就可以根據自己的需求，決定要使用哪種方式來實作了。\nVM 和 Docker 總結 # 所以總結上面的介紹的話，最後可以歸納出下面這張表格：\nVM 虛擬機 Docker 容器 用途 達到「硬體資源的共享」 達到「應用程式的隔離」，並且同時達到「作業系統的共享」 優點 能夠直接操作底層的作業系統 執行起來更輕量化 缺點 運算資源負擔較大 需要了解如何撰寫 Docker file、如何管理 Docker 集群 適用情境 所有情境皆適用 所有情境皆適用 所以 VM 和 Docker，他們並沒有誰好誰壞，就單純是根據不同的使用場景，而有不同的選擇而已，只不過如果要使用 Docker 的話，確實會需要具備比較多相關知識。\n不過在實際的工作中，通常是會交由 DevOps 維運工程師，負責管理 Docker 的相關設定，所以我們身為後端工程師，就只要了解 Docker 的概念、以及知道他所解決的問題是什麼就可以了，至於詳細的 Docker 操作，就再請教公司的 DevOps 大大就可以了😆。\n如果大家對 Docker 有興趣的話，也可以到 Docker 的官方網站 下載 Docker 來玩玩看～現在的 UI 介面都做得很親民了😆，多了解一點總是不吃虧的對吧！\n結語 # 這篇文章我們有分別的去介紹了什麼是 Docker、什麼是 VM，以及他們之間的差異在哪裡，希望可以透過這篇文章，讓你更了解 Docker 和 VM 的概念！\n如果你對後端技術有興趣的話，也歡迎免費訂閱《古古的後端筆記》電子報，每週二為你送上一篇後端技術分享，那我們就下一篇文章見啦！\n補充：我開設的 Spring Boot 零基礎入門、Spring Security 零基礎入門、GitHub 免費架站術 已在 Hahow 平台上架啦！輸入折扣碼「HH202601KU」即可享 85 折優惠。\n","permalink":"https://kucw.io/blog/docker-vs-vm/","tags":null,"title":"Docker 是什麼？他和 VM 的差別在哪裡？"},{"categories":["其他技術分享"],"contents":"你有沒有曾經好奇過，在雲端的世界裡 Server 是如何進行擴展的呢？\n這篇文章我們就來介紹一下雲端服務中兩種常見的擴展方式：Vertical Scaling 和 Horizontal Scaling 吧！\n目錄 什麼是 Vertical Scaling 和 Horizontal Scaling？ 什麼是 Vertical Scaling（垂直擴展）？ 什麼是 Horizontal Scaling（水平擴展）？ 小結 Vertical Scaling（垂直擴展）的優缺點、以及適用的情境 Vertical Scaling 的優缺點 Vertical Scaling 的適用情境 Horizontal Scaling（水平擴展）的優缺點、以及適用的情境 Horizontal Scaling 的優缺點 Horizontal Scaling 的適用情境 Vertical Scaling 和 Horizontal Scaling 總結 結語 什麼是 Vertical Scaling 和 Horizontal Scaling？ # 想像一下，假設現在你正在經營一間新創公司，一開始的流量很小，所以就只要到 AWS 或是 GCP 上面，隨便租用一台 VM（虛擬機）當作你的 Server，就可以直接應付這些使用者的流量了。\n但是，當你的業務慢慢擴張時，這時候當初租用的那台 Server 已經不夠用了，那麼這時候，你該怎麼辦？所以為了讓 Server 能夠應付更高的流量，這時候就是 Vertical Scaling 和 Horizontal Scaling 出場的時候了！\n什麼是 Vertical Scaling（垂直擴展）？ # 所謂的 Vertical Scaling（垂直擴展），就是表示「直接在該 VM 上加一堆 cpu 和 ram，讓這台 VM 變成一台超級強大的 VM」，讓他能夠對付更高的流量。\n所以在 Vertical Scaling 中，你就只會有一台 VM，只是你把這台 VM 從一台小型的「2 核 cpu、4 GM ram」Server，變成是一台「64 核 cpu、128 GB ram」的超級電腦而已。\n另外英文口語中的「Scale Up」，就是表示 Vertical Scaling（垂直擴展）的意思。\n什麼是 Horizontal Scaling（水平擴展）？ # 而所謂的 Horizontal Scaling（水平擴展），則是表示「多新增幾台小型的 VM 出來，大家人多勢眾，一起對付更高的流量」。\n所以在 Horizontal Scaling 中，你就會從「只有一台小型的 VM」，變成是「擁有很多台小型的 VM」，所以你就可以聯合這些小型的 VM 們，一起去對付更高的流量。\n注意在 Horizontal Scaling 中，你所擁有的一定是「很多台小型的 VM」，而不是「很多台超級電腦」，因為 Horizontal Scaling 的定義就是水平擴展，即是聯合許多小型的 VM，一起去克服龐大的流量。所以假設今天其中一台 VM 倒下了、或是流量又撐不住了，那麼就趕快再招一個小型的 VM 來加入戰場，而不是為戰場中的 VM 們升級裝備（添加 cpu、ram），這個是在了解 Horizontal Scaling 的定義時，一定要特別注意的一點。\n另外在英文口語中的「Scale Out」，則是表示 Horizontal Scaling（水平擴展）的意思。\n小結 # 所以到這邊先小結一下的話，Vertical Scaling 是「為一個 VM 不斷增強他的添加 cpu、ram，將他變成一台超級電腦，以應付更高的流量」，而 Horizontal Scaling 則是「添加許多小型的 VM，一起聯合起來對付更高的流量」，而他們兩種方式所要解決的問題，就都是 克服更高流量的問題。\n而在了解了 Vertical Scaling 和 Horizontal Scaling 的概念之後，接下來我們就可以來比較一下這兩種方式的優缺點，以及在什麼樣的情境下，更適合選擇哪一種 Scaling 機制了。\nVertical Scaling（垂直擴展）的優缺點、以及適用的情境 # Vertical Scaling 的優缺點 # 因為 Vertical Scaling 的方式，就是不斷為一台 VM 中添加 cpu、ram，將他變成一台超級電腦，來應對更高的流量，所以在 Vertical Scaling 的世界中，就只會有一台 VM 來處理請求，因此他的優點，就是維護和升級非常容易，所以我們只要管好這一台 VM 就好，不需要處理多台 VM 所帶來的分散式系統（Distributed System）的問題。\n不過 Vertical Scaling 的缺點，就是他的擴展是有限的，因為就算不斷的為一台 VM 添加 cpu、ram，在物理上總是有極限的，不可能真的無限擴展下去，所以 Vertical Scaling 的缺點，就是他的擴展是有限的，到一定程度之後一定得改成 Horizontal Scaling 擴展方式。\nVertical Scaling 的適用情境 # 其實在業務擴張的初期，Vertical Scaling 是非常好用的選擇，因為我們只要無腦的為那一台 VM 不斷的添加 cpu 和 ram 就好（錢給到位，什麼都給你加），不需要額外處理多台 VM 所帶來的分散式系統的問題。所以在業務擴張的初期，只要啟動資金足夠，Vertical Scaling 會是一個滿不錯的選擇。\n不過當業務漸漸擴展時，這時候用 Vertical Scaling 的效益就不太好、而且可能也無法應付大量的使用者流量，所以這時候就會需要一次大型的重建，將程式改為分散式系統，後續改為使用 Horizontal Scaling 來擴展。\n所以如果是去很早期的新創、或是自己做 Side Project 的話，就可以考慮先用 Vertical Scaling 來撐住，至少讓公司先活下去這樣，但是後續如果想要長期發展、或是想要進大公司的話，那就一定要了解 Horizontal Scaling 和分散式系統的概念，因為大公司的流量通常都不是一台 VM 可以抵擋得住的。\nHorizontal Scaling（水平擴展）的優缺點、以及適用的情境 # Horizontal Scaling 的優缺點 # 因為 Horizontal Scaling 的方式，是聯合一群小型的 VM 們，一起應對更高的流量，所以 Horizontal Scaling 的優點，就是擴展沒有極限，只要流量變大，那我就多添加一台小型的 VM 到群組裡，增加更多的戰力來應對更高的流量。\n不過 Horizontal Scaling 的缺點，就是他在維護上會比較麻煩，因為有了多台 VM 的概念，所以就必須要建立一個分散式系統（Distributed System），並且處理分散式系統所會帶來的相關問題。\n所以 Horizontal Scaling，他就是屬於前期需要投入許多的成本，去架設分散式系統、並且處理分散式系統所帶來的問題，但是一但建立起來之後，後期可以無限制擴張的一種擴展方式（用遊戲的術語來描述的話，他就是一個前期發育緩慢、但是大後期很強的角色）。\nHorizontal Scaling 的適用情境 # 因為要使用 Horizontal Scaling 的話，首先就需要建立分散式系統，所以確實會對開發帶來一定的成本，但是如果只要後續業務有成長的話，後期通常都會轉成 Horizontal Scaling。\n所以如果在開發時有餘裕的話，建議一開始在設計系統時，最好就直接朝「分散式系統」來設計，這樣子就可以直接套用 Horizontal Scaling 的好處，並且也省去了由 Vertical Scaling 轉成 Horizontal Scaling 的陣痛期。\n不過當然啦，如果你的情況是創業初期已經快活不下去、或是只是自己做 Side Project 的話，那麼就不用直上 Horizontal Scaling，回頭使用 Vertical Scaling 可能會是更好的選擇。\nVertical Scaling 和 Horizontal Scaling 總結 # 所以總結上面的介紹的話，Vertical Scaling 就是「為一個 VM 不斷增強他的添加 cpu、ram，將他變成一台超級電腦，以應付更高的流量」，而 Horizontal Scaling 則是「添加許多小型的 VM，一起聯合起來對付更高的流量」，而他們兩種方式所要解決的問題，就都是為了 克服更高流量的問題。\n下表也將上述所提到的用途、以及優缺點統整在一起，提供給大家參考：\nVertical Scaling（垂直擴展） Horizontal Scailng（水平擴展） 用途 為單一的 VM 增加 cpu、ram，將他變成一台超級電腦，對付更高的流量 添加許多台小型 VM，一起聯合起來對付更高的流量 優點 容易維護和升級 擴展無上限 缺點 擴展有上限 需要處理分散式系統（Distributed System）帶來的問題 適用情境 創業初期、個人 Side Project 業務可預期會長期發展時 不過有一點也是要再提醒大家，就是 Scaling 只是一個選擇，重點是你是否能在有限的時間、金錢、以及開發階段中，為你的團隊選擇當下最好的作法，並且盡量不要留下技術債給後人🥹。\n結語 # 這篇文章我們有去介紹了什麼是 Vertical Scaling 和 Horizontal Scaling，並且也有去探討他們之間的優缺點、以及適用的情境，希望可以透過這篇文章，讓大家對於 Scaling 的機制有更多的了解。\n如果你對後端技術有興趣的話，也歡迎免費訂閱《古古的後端筆記》電子報，每週二為你送上一篇後端技術分享，那我們就下一篇文章見啦！\n補充：我開設的 Spring Boot 零基礎入門、Spring Security 零基礎入門、GitHub 免費架站術 已在 Hahow 平台上架啦！輸入折扣碼「HH202601KU」即可享 85 折優惠。\n","permalink":"https://kucw.io/blog/vertical-and-horizontal-scaling/","tags":null,"title":"Vertical Scaling 和 Horizontal Scaling 介紹"},{"categories":["其他技術分享"],"contents":"最近實在是看到太多 AI 的專有名詞了（ex: NLP、LLM、RAG），雖然我不搞 AI，但是稍微理解一下這些名詞在幹嘛還是有必要的，不然搞得好像全世界都在追一場很好看的劇，但是自己卻完全跟不上🥹。\n所以這篇文章就會從頭來介紹一下 AI 的概念和邏輯（不需要任何程式背景也能看得懂），以及介紹常見的 AI 名詞，那麼我們就開始吧！\n目錄 什麼是 NLP（自然語言處理）？ 什麼是 LLM（大型語言模型）？ 什麼是 RAG（檢索增強生成）？ 結語 什麼是 NLP（自然語言處理）？ # 在談 LLM、RAG、GPT 這類的 AI 名詞之前，首先最最最重要的，是要先搞懂他們是要解決什麼問題。\n這一系列 AI 的名詞，他們最根本的，是要解決「自然語言處理」的問題，而這個白話來說的話，就是要讓這些 AI 們「能夠說人話」（我們平常說的語言就是自然語言）。\n像是在 AI 出現之前的時代，程式的運作是非常直覺的，工程師會寫一堆 if...else... 的判斷句，就是「當什麼事情發生時\u0026hellip;.程式就做什麼反應」。\n所以在以前的年代，工程師就會寫出 if 有人說 \u0026quot;你好\u0026quot;，程式就輸出 \u0026quot;Hello World\u0026quot; 這種程式，所以假設到時候，真的有人來說了 \u0026ldquo;你好\u0026rdquo;，那麼程式就會輸出 \u0026ldquo;Hello World\u0026rdquo; 這個字串，就是這麼簡單直覺暴力（所以這也是為什麼以前的客服機器人很笨，因為他就是只看得懂特定的句子，然後回覆固定的罐頭回答）。\n但是自從 ChatGPT 出現之後，世界就開始變得不一樣了！\n所謂的 ChatGPT，他是屬於一種生成式 AI，而他最大的不同點，就是「他會自己決定他要回覆什麼答案」。\n所以當我們使用了 ChatGPT 之後，工程師就再也不用寫出 if 有人說 \u0026quot;你好\u0026quot;，程式就輸出 \u0026quot;Hello World\u0026quot; 這種死板的程式了，工程師要做的，反而是告訴 ChatGPT 各式各樣的情境，讓 ChatGPT 自己去旁觀學習這樣。\n所以譬如說工程師可能就會輸入下面這兩段對話給 ChatGPT：\nA：你好 B：哈囉你好，你吃飽了沒？ A：還沒，正要去吃，你要一起嗎？ B：好啊！走吧 C：你好 D：心情不好，滾 C：別這樣嘛，走請你吃飯 D：你請客，謝謝 而當 ChatGPT 在「旁觀」完這兩段對話之後，他心中可能就會對於 \u0026ldquo;你好\u0026rdquo; 這兩個字，有自己的理解（這就像是人類在學習一樣，小時候都是透過旁觀父母的行為，決定自己的成長人格）。\n所以下一次當你對 ChatGPT 說 \u0026ldquo;你好\u0026rdquo; 的時候，他的反應可能會是：\n你：你好 ChatGPT：滾 又或是\n你：你好 ChatGPT：哈囉滾 所以對於 ChatGPT 會回答什麼，你是完全不會預先知道的，甚至就連養出他的工程師也不知道他會回什麼😂，因為實際上工程師所做的，就只是輸入一大堆片段的對話範例，讓 ChatGPT 自己去感悟理解而已。\n也因為對於每一個 ChatGPT 的模型而言，他們都是獨一無二的孩子，所以每一個孩子都會針對「同樣的對話範例」，會有「不一樣的理解」，而這個不斷拿範例對話去給 ChatGPT 旁觀學習的過程，就是俗稱的「訓練模型」。\n所以實際上 ChatGPT 能夠長成什麼樣子，初始的範例對話是影響非常大的（就跟父母的言行對於孩子的影響很大一樣），所以這也是為什麼 ChatGPT 剛上市的時候常常被吐嘈中文很奇怪，估計就是因為初始的範例對話數據很少中文，啊就父母不會講中文，孩子不會講中文也很合理吧🤣🤣🤣。 󠀠 所以到這邊先小結一下的話，就是 ChatGPT 所要解決的問題，就是要解決「自然語言處理（NLP）」的問題，而這個白話來說的話，就是要讓 AI「能夠說人話」。\n至於 ChatGPT 的解決方法，就是透過不斷的輸入初始的範例數據，去「訓練 ChatGPT 的模型」，進而養出一個獨一無二的孩子（ex: GPT-3、GPT-4、GPT-4o\u0026hellip;等），然後再來比較看看誰養的好這樣（天下父母心，我家的孩子就是要比別人家的好！）。\n什麼是 LLM（大型語言模型）？ # OK 在了解了 ChatGPT 要解決的是「自然語言處理」的問題之後，接下來要理解 LLM 和 RAG 就比較容易了。\n其實在「自然語言處理」這個領域中，有一個分類，叫做 LLM（Large Language Models），也就是「大型語言模型」，只要是透過前面所提到的「不斷輸入初始化的範例數據，去訓練一個語言模型出來」的流程，那這個被訓練出來的模型，就叫做「大型語言模型（LLM）」。\n所以其實 ChatGPT 在定義上，就是屬於 LLM 分類中的一種實作，只不過因為 ChatGPT 實在太紅了，所以他的傳播度才大於 LLM 這樣，但是在定義上，LLM 是比較廣泛的定義，但凡是被訓練出來的語言模型，就都可以是屬於 LLM 的一種。\n所以像是目前市面上常見的 Gemini、GPT-4、Claude\u0026hellip;等等，這些都是一個一個的大型語言模型（只是父母不同人而已，像是 Google、OpenAI\u0026hellip;等），所以這些語言模型，就都是屬於 LLM 的一種實作。\n所以簡單的說的話，LLM 就是「大型語言模型」，而市面上常見的 AI 產品，就都是屬於 LLM 中的一種實作，目的都是為了解決「自然語言」的問題（就是要讓 AI 說人話）。\n什麼是 RAG（檢索增強生成）？ # 而至於 RAG，就是比較新的概念了。所謂的 RAG，是一種結合 「大型語言模型」+「外部數據來源」 的技術。\n舉個例子來說的話，假設 Google、OpenAI 他們透過很大量的初始範例對話，生成了一個一個的語言模型 Gemini、GPT-4\u0026hellip;出來，而當你真的訂閱了這個模型來用的時候，你就會發現，怎麼 AI 所回答出來的內容，好像都是幾個月前的內容，就沒辦法回答最近兩天的內容這樣。\n譬如說 GPT-4 只能告訴你：「籃球比賽的規則是什麼」，但是他卻沒辦法告訴你：「昨天獲勝的 NBA 球隊是哪一隻」，因為在 GPT-4 的初始訓練數據裡面，並沒有昨天獲勝的 NBA 球隊，所以他就不懂，所以他就沒辦法告訴你到底是誰獲勝。\n而如果要解決這個問題的話，最直觀的想法，可能是「啊那就把昨天獲勝的 NBA 球隊也拿去訓練一下 GPT-4 不就好了？」，老實說拿著新數據重新去訓練 GPT-4 這條路是可行的，但是成本代價太高，所以基於成本考量，一般不太會這樣做。\n所以為了要解決這個問題，RAG 就出現了！ 󠀠 所謂的 RAG，可以把他想像成是一個補丁包，就是你訂閱了一個 GPT-4 來用之後，你可以再跟他說：「這裡有昨天的 NBA 比賽數據，啊你不用訓練自己沒關係，你把他當小抄，如果我來問你 NBA 的比賽情況，你就順便看一眼這個小抄，然後再回答我就好」。\n所以當我們在 GPT-4 這個模型之上，再去添加了 RAG 之後，就可以讓這個 GPT-4 在「不需要重新訓練模型」的情況下，也能夠「理解最新的客製化數據」，這樣子不僅可以省下許多成本，也可以達到取得到最新數據的目的了。\n也因為 RAG 他是一種結合「大型語言模型」+「外部數據來源」的技術，讓 GPT-4 就像是得到了一堆小抄一樣，可以知曉外部數據中的內容。所以目前 RAG 比較常見的用法，就是透過 RAG 的技術，將 GPT-4 和企業內部的數據結合在一起，讓 GPT-4 變身成為一個知曉企業內部數據的強大語言模型！\n有關 RAG 和語言模型的介紹，也可以參考下圖 OpenAI 對 LLM optimization context 的介紹，裡面就有提到，如果想要「加強 Context（上下文）的準確度」，那麼除了要設置 Prompt 之外，也可以透過 RAG 來加強。\n所以總結來說的話，RAG 可以說是一個省錢 + 客製化模型的新武器，我們是可以透過外掛一堆外部數據，來補足語言模型對於客製化數據（ex: NBA 昨天比賽結果、企業內部的數據）的精準理解。\n結語 # 這篇文章我們先去介紹了 ChatGPT 的運行邏輯是什麼，並且也有去介紹 AI 中常見的名詞，像是 NLP、LLM、RAG\u0026hellip;等等，就希望讓大家可以對這些 AI 的專有名詞，有一個初步的了解。畢竟 AI 可以說是全球一起在追的劇，多少了解一下概念還是會很有幫助的💪。\n雖然這篇文章是對於 AI 的介紹，但我的本業是後端工程師，後續還是會專注在後端技術的介紹上，所以如果你對後端技術有興趣的話，也歡迎免費訂閱《古古的後端筆記》電子報，每週二為你送上一篇後端技術分享，那我們就下一篇文章見啦！\n補充：我開設的 Spring Boot 零基礎入門、Spring Security 零基礎入門、GitHub 免費架站術 已在 Hahow 平台上架啦！輸入折扣碼「HH202601KU」即可享 85 折優惠。\n","permalink":"https://kucw.io/blog/ai-intro/","tags":null,"title":"AI 名詞和概念介紹 - NLP、LLM、RAG"},{"categories":["Spring Boot"],"contents":" 本文使用的 Spring Boot 版本：3.3.2\nActuator 是 Spring Boot 所提供的監控功能，可以用來查看當前的 Spring Boot 程式運行的情況，像是可以查看當前運行的健康指標、查看 Spring Boot 所創建的 beans、以及獲取當前的 applicaiton.properties 的屬性的值。\n目錄 使用 SpringBoot Actuator Actuator 提供的常見的 api 開啟受保護的 Actuator 監控 api 的方法 結語 使用 SpringBoot Actuator # 如果要使用 SpringBoot Actuator 提供的監控功能，需要先加入相關的 maven dependency。\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-actuator\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 只要加上了這個 maven dependency，Spring Boot 在運行時，就會自動開啟 /actuator/health 這個 api 給我們使用，因此當我們去請求 http://localhost:8080/actuator/health 這個 api 時，就可以查看當前 Spring Boot 程式的運行狀況。\n像是下圖中就顯示，當前的 Spring Boot 運行狀態為 UP，UP 即為正常運行的意思。\nActuator 提供的常見的 api # 除了上述自動開啟的 /actuator/health api 之外，Actuator 其實還提供更多樣化的 api，讓我們可以從不同的角度，去監控 Spring Boot 程式（不過因為安全因素考量，大部分的 api 都需要另外設定才能夠開啟，詳細的設定方式在下方介紹）。\n因為監控 api 眾多，以下僅列出常用的監控 api，所有監控 api 可查閱 Spring 官方文件\nHTTP 方法 Endpoint 描述 GET /actuator 查看有哪些監控的 api 有開放使用 GET /actuator/env 查看此 Spring Boot 程式載入了哪些 application.properties 的值（不過為了保護安全資訊，所以會自動碼掉帶有 key、password、secret 等關鍵字的 properties 的值） GET /actuator/flyway 查看 flyway DB 的 migration 資訊 GET /actuator/health 查看當前 Spring Boot 程式的運行健康指標，UP 即為正常運行 GET /actuator/heapdump 取得 JVM 當下的 heap dump，會下載一個檔案 GET /actuator/metrics 查看有哪些指標的數據可以看（ex: jvm.memory.max、system.cpu.usage），可再使用 /actuator/metrics/{metric.name} 分別查看各個指標的詳細資訊 GET /actuator/scheduledtasks 查看定時任務的資訊 POST /actuator/shutdown 唯一一個需要 POST 請求的 api，關閉這個 Spring Boot 程式 開啟受保護的 Actuator 監控 api 的方法 # 因為安全的因素，所以 Actuator 預設只會開啟 /actuator/health 這個監控的 api 讓我們使用，如果要開放其他的 api 的話，需要額外在 application.properties 中進行設定\n# 可以這樣寫，就會開啟所有的 api（但不包含 shutdown） management.endpoints.web.exposure.include=* # 也可以這樣寫，就只會開啟指定的 api，像是此處就只會再額外開啟 /actuator/beans 和 /actuator/mappings 這兩個 api management.endpoints.web.exposure.include=beans,mappings # exclude 可以用來關閉某些 api # exclude 通常會和 include 一起搭配使用，就是先去 include 全部進來，然後再 exclude 想要關閉的部分 # 像是此處就是關閉 /actuator/info 這個 api management.endpoints.web.exposure.include=* management.endpoints.web.exposure.exclude=info # 如果要開啟 /actuator/shutdown api 的話，需要額外再加這一行 management.endpoint.shutdown.enabled=true 除此之外，也可以改變 /actuator 的路徑，自定義成自己想要的 url 路徑\n# 這樣寫的話，原本內建的 /actuator/xxx 的 url 路徑，就都會變成 /my/xxx # 這樣做可以防止 Actuator 的監控 api 路徑被其他人猜到 management.endpoints.web.base-path=/my 結語 # 本篇文章介紹了 Spring Boot Actuator 的用法，以及列出的常見好用的監控 api 有哪些，提供給大家參考。\n如果你對後端技術有興趣的話，也歡迎免費訂閱《古古的後端筆記》電子報，每週二為你送上一篇後端技術分享，那我們就下一篇文章見啦！\n如果想了解更多 Spring Boot 的用法，也歡迎參考我開設的線上課程 Java 工程師必備！Spring Boot 零基礎入門 （輸入折扣碼「HH202601KU」即可享 85 折優惠）。\n","permalink":"https://kucw.io/blog/2020/7/spring-actuator/","tags":null,"title":"Spring Boot - 監控工具 Actuator"},{"categories":["其他技術分享"],"contents":"大家在 call API 時，是否曾經好奇過他所返回的 200、401、403、500\u0026hellip;等數字是代表什麼意思？其實這些 3 位數的數字，就是 Http Status Code（又稱 Http 狀態碼）。\n因此這篇文章我們就來詳細介紹一下，Http Status Code 的用途到底是什麼，以及常見的 Http Status Code 有哪些吧！\n目錄 什麼是 Http Status Code（Http 狀態碼）？ 常見的 Http Status Code 1xx：資訊 2xx：成功 3xx : 重新導向 4xx : 前端請求錯誤 5xx : 後端處理有問題 Http Status Code 總結 結語 什麼是 Http Status Code（Http 狀態碼）？ # 所謂的「Http Status Code」，中文是翻譯成「Http 狀態碼」，而他的目的，就是 「用一個簡短的值，快速的表示當前 API 的請求結果是什麼」。所以舉例來說的話，大家常見的「200」的回覆，其實就是表示這一次的 API 請求成功了，就只是這麼簡單的用途而已。\n而在 Http Status Code 的世界裡面，除了有「200」這個值可以使用之外，也是有其他的返回值可以使用的，而這些 Http Status Code 的返回值，我們是可以根據他們的 首位數字，去分成是五個大類：\n1xx : 資訊 2xx：成功 3xx：重新導向 4xx：前端請求錯誤 5xx：後端處理有問題 所以舉例來說的話，但凡是 2 開頭的 Http Status Code，不管你是 200、201、還是 202…等等，只要你是 2 開頭，那就是屬於「2xx」那一個大類，就都是表示「成功」的意思。\n又或是說 400、401、403…等等的這些值，因為他們都是 4 開頭，所以他們就都是屬於「4xx」那一個大類，所以就都是表示「前端請求錯誤」的意思。\n所以透過這個 Http Status Code，我們就可以快速的知道，這一次 API 的請求結果為何了！\n常見的 Http Status Code # 在我們了解了 Http Status Code 的用途之後，接下來我們就可以來看一下，常見的 Http Status Code 有哪些（以下分別介紹各大類常使用的值）。\n1xx：資訊 # 很神奇的是，明明 Http Status Code 有定義 1xx 這個分類出來，但是在實際的應用中，基本上很少很少會用到 1xx 的返回值，因此在這個大類裡面，沒有常見的 Http Status Code。\n2xx：成功 # 在 2xx 開頭的大類中，所有的 Http Status Code，就都是表示 「請求成功」 的意思。而在 2xx 的大類裡面，常見的 Http Status Code，就有 200、201、以及 202。\n200 OK # 首先是「200 OK」，200 這個 Http Status Code，這個估計是大家最最最熟悉的值XD，就是表示這一次的 API 請求成功了的意思。\n不過大家觀察一下的話，就可以發現，在 200 的後面，多了一個「OK」的英文單詞，而這個「OK」的英文單詞，其實就是每一個 Http Status Code 的專屬短語，就是簡單描述一下當前這個 Http Status Code 的用途是什麼。\n所以像是「200 OK」裡面的這個「OK」，就是表示 200 這個 Http Status Code，他的意義是代表請求成功的意思。\n不過老實說，這個短語其實幫助不大😂（我個人感覺啦），每次遇到不熟悉的 Http Status Code 時，還是得要乖乖的上網查詢他的用途，而那些常見的 Http Status Code（ex: 401、403、500），又已經熟悉到像呼吸一樣自然，不需要看短語就也可以直接回想起他的意思，所以這個短語的用途，大家就作為參考就好～\n201 Created # 在 2xx 的大類中，另一個常見的 Http Status Code 則是「201 Created」，201 所代表的，不僅僅是請求成功而已，他還有另一個含義，就是「有一個新的資源被成功創建出來了」。\n所以當 API 返回 201 的時候，就是表示這一次的請求成功、並且也有成功的去創建一筆數據出來，而也因為在 REST 風格中，POST 方法通常就是拿來表示對應到資料庫的 Create 操作，因此「201 Created」這個 Http Status Code，通常就是會用在 POST 方法的 API 返回值上（就是用來表示有一個數據被創建出來了）。\n補充：不熟悉 RESTful API 的話，可以參考這篇 RESTful API 設計指南 文章的介紹\n202 Accepted # 而在 2xx 的大類中，「202 Accepted」所代表的，是「這一次的請求已經被接受，但是尚未處理完成」這樣。\n所以當前端收到 202 的返回值時，前端就可以知道，後端已經有收到這一次的請求了，但是因為這個任務實在要做太久，所以後端就先返回 202 的 Http Status Code 給前端，用來表示「我已經開始做了！」的意思，所以當前端收到 202 之後，前端就可以先去處理其他的事情，而不用被這個 API 給 blocked 住這樣。\n3xx : 重新導向 # 看完了 2xx 的大類之後，接下來我們接著來看 3xx 的大類。\n在 3xx 開頭的大類中，所有的 Http Status Code，就都是表示 「重新導向」 的意思。而在 3xx 的大類中，常見的 Http Status Code，有 301 和 302。\n301 Moved Permanently # 所謂的「301 Moved Permanently」，就是表示這個 url 「永久的」 搬家了，注意這裡的關鍵字是「永久的」。\n所以假設當前端去請求某個 API，但是該 API 返回 301 時，那這時候就是表示，前端所請求的這個 API 的 url，他已經永久搬家了，而至於這個 API 搬去哪裡呢？通常就是會放在 Response header 的 Location，告訴前端說「我搬去了哪裡」。\n所以前端就可以再去請求 Response Header 中的這個新的 url，進而就可以真正的取得到新的 API 所返回的數據了。\n舉例來說的話，像是我之前在架設個人網站時，就有從 https://kucw.github.io，搬家到 https://kucw.io，所以現在如果請求舊的 https://kucw.github.io 的網站的話，就會返回 301 的 Http Status Code，告訴前端這個網站已經永久性的搬家了，並且會將新家的網址（也就是 https://kucw.io），放在 Response header 中的 Location 的裡面。\n302 Found # 如果說 301 是表示「永久的」搬家的話，那麼「302 Found」所表示的，就是 url「暫時性」的搬家。\n所以假設某個 API，他只是「暫時性」的搬家的話（ex: 這個 API 目前可能正在調整功能中），那麼就可以回傳 302 的值給前端，就是去告訴前端，你這一次先去請求這個臨時的 url 這樣。\n所以 302 和 301 一樣，就都是會將新的 url，放在 Response header 的 Location 裡面，告訴前端「我搬去了哪裡」，就讓前端可以再去 call Location 中所提供的網址，找到確切的新 url。\n不過老實說，對於後端工程師而言，通常是感覺不太到 301 和 302 的差別，反正他們就都是表示 url 搬家的意思，只不過 301 是永久性的搬家、而 302 是暫時性的搬家而已。\n但是對於 SEO 而言，301 和 302 可是天差地遠的！301 是能夠將網頁的權重、流量、排名，一口氣轉移到新的網站，而 302 則沒辦法，所以對於有在經營 SEO 的團隊而言，分清楚 301 和 302 所帶來的影響還是滿重要的。\n不過我也是因為有在經營自媒體，所以才會知道 301、302 對 SEO 的影響，大家如果是純後端工程師的話，其實不用了解的那麼詳細，只要知道 301 是「永久性」的搬家、302 是「暫時性」的搬家，這樣子就可以了～\n4xx : 前端請求錯誤 # 了解了 3xx 的大類之後，接下來我們終於可以進到 4xx 的大類了！\n在 4xx 開頭的大類中，所有的 Http Status Code，都是表示 「前端請求錯誤」 的意思，所以這也是變相的表示，只要看到 4xx，第一時間應該是要回頭去檢查，自己 call API 時的參數有沒有帶對、或是 url 有沒有填寫正確…等等，反正就是要回頭檢查請求的參數就對了。\n在 4xx 的大類中，常見的 Http Status Code，有 400、401、403、以及 404，以下分別介紹他們的用途。\n400 Bad Request # 只要在請求 API 時看到「400 Bad Request」，那通常就是表示，前端在請求這個 API 時，他的參數名字可能帶錯了、參數的格式可能寫錯了…等等，反正就是前後端之間的「請求參數」喬不攏，所以才會出現 400 的錯誤。\n因此只要看到 400 的錯誤，就可以回頭檢查一下，是否在 call 此 API 時，有帶上正確格式的參數。\n401 Unauthorized # 接下來是 4xx 類別中的重頭戲了！401 和 403，他們可以說是大家最容易搞混的兩個 Http Status Code，但是又因為他們真的很常出現，所以搞懂他們之間的差別還是很重要的。\n所謂的「401 Unauthorized」，是表示這一次的請求「沒有通過身份驗證」，所以就是表示前端在請求 API 的時候，沒有去帶上使用者的帳號密碼、或是沒有去帶上 Token，也就是沒有帶上「身分證」，所以後端就沒有辦法去辨認說，這一次的請求到底是哪位使用者發起的（後端：你到底是叫小明、還是叫老王，你倒是給我個身分證啊！），因此後端就只好回傳 401 的錯誤，表示這一次的請求沒有通過身份驗證。\n所以只要看到 401，通常就是表示「認證失敗」，也就是你連個身分證（ex: 帳號密碼、Token）都沒帶在身上，後端無法辨認出你到底叫做什麼名字，才導致請求失敗。\n或是大家也可以把這個 401，簡單的想像成是會員的身份驗證錯誤，譬如說帳號密碼輸入錯誤的情況。所以在這種情況，後端就會返回 401 的錯誤，就告訴前端說，這個人並不是我們網站的會員。\n403 Forbidden # 而至於「403 Forbidden」，他的概念就不太一樣了。\n所謂的 403，是表示這一次的請求「權限不足」，譬如說當一個普通會員，他想要收看 VIP 會員才能看的影片的時候，那這時候，因為這個普通會員的「權限不足」，因此後端就會返回 403 的錯誤給前端，就告訴前端說，這個普通會員的權限不足，因此我們不能讓他收看 VIP 會員才能看的影片。\n所以總結來說的話：\n當前端在請求時，如果連身分證（ex: Token）都沒帶在身上，那後端就會直接回傳 401 的錯誤，表示「身份認證失敗」，因為後端不知道這一次來請求的使用者到底是誰。 如果前端有帶上身分證，但是當這個身分證的人，他的權限不足的話（ex: 普通會員想要收看 VIP 會員的影片），那後端則是會回傳 403 的錯誤，表示「權限不足」。 因此 401 和 403，他們可以說是關係非常緊密的兩個 Http Status Code，所以就建議大家，一定要搞清楚他們之間的差別會比較好！\n404 Not Found # OK 那在 4xx 的大類中，最後一個常見的 Http Status Code，就是「404 Not Found」。\n404 可以說是一個大家在日常生活中，也滿接觸到的 Http Status Code，那 404 的意思，就是表示這個網頁不存在，也就是前端所請求的 url 已經失效、或是 url 的值輸入錯誤，反正就是這個網頁已經不存在就對了。\n5xx : 後端處理有問題 # 呼～看完了前面那麼多的大類，最後我們就進到最後一個大類，也就是 5xx 這個大類。\n那在 5xx 開頭的大類中，所有的 Http Status Code，就都是表示 「後端處理有問題」 的意思，所以這也是變相的表示，只要看到 5xx，就是表示後端這邊的程式出了問題，所以就要第一時間去檢查後端的程式哪裡有寫錯、或是哪個 Server 又壞掉了這樣。\n也因為 5xx 所表示的，就是後端處理有問題，所以身為一個後端工程師，最怕的就是工作上看到一堆 5xx 的 Http Status Code，因為這就表示後端又出問題，今天晚上我們又要加班了🥹。所以在這眾多的 Http Status Code 中，最讓後端工程師聞風喪膽的，就是 5xx 這類的 Http Status Code。\n而在 5xx 的大類中，常見的 Http Status Code，有 500、503、以及 504，這三個 Http Status Code。\n500 Internal Server Error # 首先是「500 Internal Server Error」，500 的意思是表示，後端在處理這一次請求的時候發生了錯誤，那這個錯誤可能是因為程式內有 bug、或是其他後端相關的原因所導致的，所以後端工程師這時候就必須要回頭去檢查，是不是哪一段程式寫錯了…等等，進而去解決這個問題。\n那 500 其實是一個滿通用的 Http Status Code，基本上後端的程式出現 Error、或是噴出 Exception 時，常見的後端框架（像是 Spring Boot），都會自動將他轉為 500 的錯誤，然後返回給前端。因此在實作上，只要是沒有特殊處理過的 Error，通常就是會以 500 的錯誤返回給前端。\n503 Service Unavailable # 再來是「503 Service Unavailable」，503 的意思是表示，目前因為「臨時維護」或是「流量太大」，導致後端沒有辦法處理這個 API 的請求。因此當前端收到 503 時，就是表示伺服器現在非常的忙碌，沒有辦法正常的運作，所以前端只能夠稍後再重試一次，直到後端的伺服器恢復正常為止。\n不過這裡要特別補充一下，其實 503 並不一定都是不好的錯誤，譬如說遊戲內常見的停機維護，這種會提前預告時間的臨時維護，如果在維護期間去 call API 的話，理論上也是會得到 503 的錯誤的。\n所以大家當看到 503 時，就不用太緊張，因為他有可能是真的在進行「已知的臨時維護」，除非他現在明明不是維護時間，但是又出現 503，這時候才有可能是因為「短時間內流量太大，後端真的撐不住了」所導致的錯誤，所以只有這個時候，才會需要後端工程師和 DevOps 工程師，趕快進去查看伺服器遇到了什麼狀況，進而去排除這個問題。\n504 Gateway Timeout # 最後一個常見的 Http Status Code，就是「504 Gateway Timeout」，504 所表示的，就是這一次的請求超時了，所以中間的代理層就直接強制結束，直接回傳 504 的錯誤給前端。\n所以舉例來說，當前端去請求後端的 API 時，如果後端處理了太久的時間（譬如說 20 分鐘之類的），這時候中間的 Cloudflare 代理層就會認為，這個後端實在是處理得太久了，這樣一直無止盡的等下去也不是辦法，所以中間的 Cloudflare 就會直接卡掉這個請求，並且回傳 504 的錯誤給前端，表示這個請求實在做太久，已經超過容許的等待時間了。\n所以當 504 出現的時候，這時候後端工程師就要去查看說，是否有哪一個環節出了問題，導致程式執行過久，才會出現 504 的超時錯誤。\nHttp Status Code 總結 # 所以總結來說的話，透過上面的介紹，我們就是針對了常見的 Http Status Code，去解析每一個 Http Status Code 的意義分別是什麼。\n而如果我們回頭來看一下 Http Status Code 的定義的話，所謂的「Http Status Code」，就是 「用一個簡短的值，快速的表示當前 API 的請求結果是什麼」。\n並且這些 Http Status Code 的返回值，我們就是可以根據他們的 首位數字，去分成是五個大類：\n1xx : 資訊 2xx：成功 3xx：重新導向 4xx：前端請求錯誤 5xx：後端處理有問題 所以當大家以後看到 4xx 的值時，就可以快速的知道，他們就都是表示「前端請求錯誤」的意思；而看到 5xx 的值時，就也可以知道，這是表示出現了「後端處理有問題」的錯誤。因此透過 Http Status Code，我們就可以快速的知道這一次 API 的請求結果為何了！\n下圖也統整這篇文章中所提到的 Http Status Code 給大家參考：\n結語 # 這篇文章我們有去介紹了什麼是 Http Status Code，並且也有詳細的介紹了每一個大類中（ex: 1xx、2xx、3xx\u0026hellip;），常見的 Http Status Code 有哪些。\n如果你對後端技術有興趣的話，也歡迎免費訂閱《古古的後端筆記》電子報，每週二為你送上一篇後端技術分享，那我們就下一篇文章見啦！\n補充：我開設的 Spring Boot 零基礎入門、Spring Security 零基礎入門、GitHub 免費架站術 已在 Hahow 平台上架啦！輸入折扣碼「HH202601KU」即可享 85 折優惠。\n","permalink":"https://kucw.io/blog/http-status-code/","tags":null,"title":"一文搞懂 Http Status Code，詳細解析 200、301、401、403、500、503"},{"categories":["其他技術分享"],"contents":"RESTful API 可以說是在後端日常的開發中，很常見的一種設計 API 的方式，因此這篇文章我們就來介紹一下，到底要如何才能設計出一個正確的 RESTful API 吧！\n目錄 什麼是 RESTful API？ 如何設計出 RESTful API？ 1. 成為 RESTful API 的條件一：使用 Http method，表示要執行的資料庫操作 2. 成為 RESTful API 的條件二：使用 url 路徑，描述資源之間的階層關係 3. 成為 RESTful API 的條件三：Response body 返回 JSON 或是 Xml 格式 設計 RESTful API 的總結 補充：我們真的需要 RESTful API 嗎？ 結語 什麼是 RESTful API？ # 所謂的 RESTful API，他是一種設計 API 的風格，而他的目的，就是為了 「簡化工程師之間的溝通成本」。\n所以 RESTful API，他的目的其實非常單純，就只是為了簡化工程師之間的溝通成本，才提出了一系列的方法，去統一不同工程師所設計出來 API 的風格。\n不過在這邊要先強調一下，RESTful API 他只是一種設計風格而已，並不是強制的規定，所以如果你在設計上，完全不遵守 RESTful API 的建議，也是完全沒問題的！\n只不過因為 RESTful API 的設計風格，他非常的通用，所以有非常多工程師，都很喜歡使用 RESTful API 的設計方式，因此了解 RESTful API 的設計理念，還是會非常吃香的～\nOK 那所以，我們就來看一下，到底什麼是 RESTful API。\n那如果我們把「RESTful API」這兩個單字給拆解一下的話，就可以將他們拆解成是「RESTful」和「API」。\n那後面的 API 的部分就比較簡單，基本上就是設計出一個 url，然後讓前端可以去 call 這個 url，去和後端請求數據這樣，那不過前面的 RESTful，他就大有來頭了！\n其實 RESTful，他是一個形容詞，意思是「符合 REST 風格的」，所以 RESTful API 合在一起看的話，就是指「設計出一套符合 REST 風格的 API」。\n那 RESTful 在這裡，他其實是用到了英文的文法邏輯，在英文的文法中，如果想要把一個「名詞」，變成是「形容詞」的話，那就只要在後面加一個 ful 就好。\n所以像是在英文裡面：\nbeauty 是名詞（意思是漂亮），beautiful 是形容詞（意思是漂亮的） peace 是名詞（意思是和平），peaceful 是形容詞（意思是和平的） 所以同樣的道理，REST 是名詞，表示「REST 設計風格」，而 RESTful 是形容詞，就是表示「符合 REST 設計風格的」。\n所以當我們在說 RESTful API 的時候，我們實際上所表示的，就是指「你的 API 設計的很符合 REST 的風格」，或是更白話一點，就是表示「欸～你的 API 很 REST 哦😏」，所以這個 RESTful，他本質上是一個形容詞，用途就是用來形容目前這個 API，是不是符合 REST 這個設計風格。\n那所以當大家看到某個 API 很符合 REST 的設計風格時，就可以稱呼這個 API，他是一個 RESTful API，那就表示他是一個「很符合 REST 風格的 API」了！\n如何設計出 RESTful API？ # 當大家了解了 RESTful API 的概念之後，接下來我們就可以來探討一下，什麼是「REST 設計風格」，而我們又要如何將我們的 API，去設計成「符合 REST 風格」的 API 了。\n如果我們想要設計出一個「符合 REST 設計風格」的 API，也就是設計出一個 RESTful API 的話，那這個 API，就必須要滿足 3 個條件。\n1. 成為 RESTful API 的條件一：使用 Http method，表示要執行的資料庫操作 # 如果想要設計出 RESTful API 的話，那麼這個 API，他就必須要使用 Http method，去表示這個 API 的行為動作。\n舉例來說的話，目前在 Http 的世界中，就有非常多的 Http method 可以選擇，像是大家如果有安裝 Postman、或是 Chrome 的擴充功能 - Talend API Tester 這類的 api 請求工具的話，那麼在請求的時候，就有非常多種的 Http method 可以選擇（如下圖所示）。\n而要怎麼樣在設計 API 的時候，去選擇合適的 Http method，這個就非常的重要了！\n如果我們想要去設計出 RESTful API（也就是設計出符合 REST 風格的 API）的話，那麼這個 API，他就必須要 「使用 Http method，去對應到資料庫的 CRUD 操作」。\n這邊我們先題外話補充一下「資料庫中的 CRUD 操作」的概念，在資料庫中，CRUD 就是描述了資料庫中的四個基本操作，也就是：\nCreate（新增） Read（查詢） Update（修改） Delete（刪除） 也因為這四個操作，他們可以說是資料庫中最基本的數據操作，因此他們也常常合稱為「CRUD」，即是「增查改刪」（或是也有人稱「增刪改查」）。\n而在我們了解了資料庫中的 CRUD 的概念之後，如果我們想要去設計出 RESTful API 的話，那我們在設計 API 的時候，就必須要去 「使用 Http method，去對應到資料庫的 CRUD 操作」。\n在 RESTful API 的定義中，假設這個 API 想要執行的，是 Create（新增數據）的操作的話，那麼 REST 風格就會建議，要在 Http method 中使用 POST 方法來請求；而如果這個 API 想要執行的，是 Delete（刪除數據）的操作，那麼 REST 風格就會建議，在 Http method 中要使用 DELETE 方法來請求。\n所以在設計一個 RESTful API 時，基本上我們就是會去依據這個 API 想要執行的操作，去設計成要使用哪一個 Http method 來請求。\n所以簡單的說的話，如果大家都使用 REST 的風格來設計 API 時，那麼以後當我們看到某個 API 是使用 GET 方法來請求時，那我們就可以快速的知道，這個 API 是要去執行 Read（讀取數據）的操作；而假設這個 API 是使用 POST 方法來請求時，那我們也可以快速的知道，這個 API 是要去執行 Create（新增數據）的操作。\n所以假設我們想要設計出 RESTful API 的話，那麼第一個必要條件，就是 「使用 Http method，去對應到資料庫的 CRUD 操作」。\n2. 成為 RESTful API 的條件二：使用 url 路徑，描述資源之間的階層關係 # 而至於成為 RESTful API 的第二個條件，則是 「使用 url 路徑，描述資源之間的階層關係」，那這個聽起來可能有點抽象，所以我們就直接透過一個例子，來了解一下這個概念是什麼。\n假設現在我們有一個使用 GET 方法來請求的 API，即是 GET /users，那麼當我們第一眼看到這個 API 時，因為這個 API 是使用 GET 方法來請求，所以我們可以知道他是要去執行 Read（讀取數據）的操作，所以這個 GET /users 的含義，就是「取得所有 user 的數據」。\n那麼假設現在，我們又有一個使用 GET 方法去請求的 API，即是 GET /users/123，那麼這個 GET /users/123 的含義，就是「取得 user id 為 123 的那個 user 的數據」。\n那到這邊，REST 風格的階層概念就出現了！\n大家可以把 url 中的每一個斜線 /，想像成是一個階層，也就是一個子集合的感覺，或是說得更白話一點，就是可以直接把這個斜線 /，替換成是中文的「的」。\n所以像是上面的 GET /users，就是表示去「取得所有的 user 數據」 而至於下面的 GET /users/123，則是表示，去取得所有 user 裡面 「的」 user id 為 123 的那個 user，所以就是「取得 user id 為 123 的那個 user 的數據」 所以透過 REST 風格中的「階層」的概念，我們就可以去使用 url 路徑，去表達我們想要取得的資源是什麼了。\n所以如果舉更多例子來看的話，就會像是下面這張圖這樣，我們是可以透過不斷的添加斜線 /，去表達子集合的概念，也就是中文的「的」的概念。\n所以透過上面這些例子，我們就可以得出一個結論，當我們今天看到某個 API 是 GET /users 時，那就可以直接透過 /users 這個 url 路徑，就知道他是要取得所有的 user 數據，而如果我們看到 GET /users/123/videos 這個 API 時，那就可以直接透過 /users/123/videos 這個 url 路徑，去知道他是要取得「user id 為 123，他旗下的所有 videos 的數據」。\n所以透過這個 url 的階層概念，我們就可以直接利用 url 路徑，去表達「資源之間的階層關係」了。\n3. 成為 RESTful API 的條件三：Response body 返回 JSON 或是 Xml 格式 # 而至於成為 RESTful API 的最後一個條件，這個就超級簡單了，就只要讓 Response body 所返回的數據，返回成是 JSON 或是 Xml 的格式，這樣子就滿足 RESTful API 的第三個條件了。\n設計 RESTful API 的總結 # 所以總結上面的三個條件的話，如果想要設計出 RESTful API 的話，那就只要同時滿足以下這三個條件：\n使用 Http method，表示要執行的資料庫操作 使用 url 路徑，描述資源之間的階層關係 Response body 返回 JSON 或是 Xml 格式 只要同時滿足上面這三個條件，那麼這個 API，他就是一個符合 REST 設計風格的 API，所以也可以稱呼他為 RESTful API 了！因此大家之後如果想要設計出 RESTful API 的話，就只要滿足上面的三個條件，就也能夠設計出 RESTful API 了～\n也因為 REST 這個設計風格，他很明確的去定義出設計 API 的建議做法，所以就可以讓所有工程師，按照一個共同的默契來設計 API，因此就不會出現那種大家都隨便亂設計 API 的情況出現，進而就可以達到「簡化工程師之間溝通」的效果了！\n譬如說我們在查看別人所寫的 API 時，就可以直接先透過這個 API 的 Http method（ex: GET、POST…等等），就可以先快速的知道這個 API 的行為，是要去讀取資料庫中的數據、還是要去新增一筆數據到資料庫；並且我們也可以直接去查看他的 url 路徑 /users/1/articles，就可以知道當前這個 url 路徑，他的階層的意義是什麼（ex: /users/1/articles 的意思是「user id 為 1 的那個使用者，他所寫的那些文章們」）。\n所以透過 RESTful API，就可以讓彼此不認識的工程師們，快速的透過一些約定成俗的習慣，知道對方設計的 API 想幹嘛，這樣子就可以節省許多閱讀 API 文件的時間了！\n補充：我們真的需要 RESTful API 嗎？ # 不過，這裡還是要特別強調的一點是，RESTful API 只是一種設計風格（或者說一種約定成俗的習慣），不是強制性的規定，所以大家在實作功能時，如果有一些特殊的考量，那也是完全不需要遵守 RESTful API 的建議的。\n譬如說今天你開發了一個「查詢使用者數據」的 API，那麼按照 REST 的設計風格，你可能會設計成 GET /users/{userId} 這樣子的 API。但是因為在你的系統中， user id 是使用「身分證字號」來記錄，所以假設這時候，你硬要去套用 REST 的設計風格的話，那就會變成是使用者要把他的身分證字號，去放在 url 路徑中來傳遞，所以就會像是 GET /users/B123456789 這樣。\n不過因為「身分證字號」，他可以說是非常敏感的資訊，因此基於資訊安全的考量，就會不建議將這類的敏感資訊，去放在 url 路徑中傳遞。\n所以在這個情境中，將「查詢使用者數據」的 API，改成是使用 POST 方法來實作，然後把 user id 的值放在 request body 來傳遞，這樣子才是最合理的設計。\n所以即使大部分的 API 在設計上，都會盡量遵守 REST 這個設計風格，但是如果真的有遇到一些特殊的情況，那就直接按照自己的需求來設計就可以了，並不是符合 REST 風格的 API 才是最好的，因此這部分，就要麻煩大家再留意一下～\n結語 # 這篇文章我們有先去介紹了一下 RESTful API 的概念，並且也有介紹到，要如何去設計出符合 REST 風格的 API（就是滿足 3 個必要條件即可），那就希望可以透過這篇文章，讓大家對於 RESTful API 有更多的認識。\n如果你對後端技術有興趣的話，也歡迎免費訂閱《古古的後端筆記》電子報，每週二為你送上一篇後端技術分享，那我們就下一篇文章見啦！\n補充：我開設的 Spring Boot 零基礎入門、Spring Security 零基礎入門、GitHub 免費架站術 已在 Hahow 平台上架啦！輸入折扣碼「HH202601KU」即可享 85 折優惠。\n","permalink":"https://kucw.io/blog/restful-api/","tags":null,"title":"RESTful API 設計指南，3 個必備條件缺一不可！"},{"categories":["自媒體經營"],"contents":" 記錄經營《古古的後端筆記》個人品牌的重大事件\n最後更新時間：2025.7.7\n2025 年 # 2025.7.7：暫時休刊（因為新工作原因，無法兼顧兩者，因而暫時休息，詳情查看 2025.5～6 月報） 2024 年 # 2024.12.10：Threads 經營 4 個月破 5000 人追蹤（2024.8.27～2024.12.10） 2024.11.12：出版人生中的第一本書，Spring Boot 零基礎入門：從零到專案開發，古古帶你輕鬆上手（iThome鐵人賽系列書） 詳細記錄：2024.11 月自媒體活動：我出書了！！ 2024.8.6：夢開始的地方，《古古的後端筆記》個人品牌誕生，發送第一封電子報創刊號 ","permalink":"https://kucw.io/blog/as-a-content-creator/milestone/","tags":null,"title":"軟體工程師的自媒體之路 - 創業大事記"},{"categories":["其他技術分享"],"contents":"哈囉，我是古古！最近又到了 iThome 鐵人賽的開賽期（每年 9 月附近），在 2023 年時我也有報名參加過 iThome 鐵人賽，題目是《Spring Boot 零基礎入門》，當時有幸得到了《優選》的獎項（得獎名單），因此希望可以透過這篇文章，分享一些寫作心法給大家。\n不過要先在此申明一下，我不是什麼技術大神，並且也不是得到最高級別的《冠軍》的獎項，所以以下的分享，就單純只是我個人的參賽心得而已，不具有 iThome 鐵人賽任何的官方效力唷！\n目錄 iThome 鐵人賽官方得獎評判標準 道理我都懂，但是要如何選題？ 題目挑好了，然後呢？ 題目挑好了、大綱也寫好了，再來呢？ 文章段落 文章的易讀性 上面我都照做了，但是還是沒得獎怎麼辦… 結語 iThome 鐵人賽官方得獎評判標準 # 但凡是參加 iThome 鐵人賽的參賽者們，可能或多或少目的都是為了得獎去的，因為得獎可以出書啊哈哈哈哈！！！我能理解出書真的是很誘人的一個因素（我自己其實也是為了出書來的😆），所以假設我們今天參賽是以「得獎」為目標的話，那麼搞懂 iThome 官方的得獎判斷標準就很重要。\n以下內容擷取自 2024 年 iThome 鐵人賽的官方活動簡章：\n陸、 主題競賽評審要點： - 主題：主題規劃符合該組別的立意，並能充份切合所選參賽主題下，參賽者所訂定之議題 - 結構：30 篇文章組織良好、其所規劃結構足以引導讀者理解參賽者訂定之議題 - 內容：文章內容的技術或經驗具備專業性、豐富性、深入性 - 表達：透過適當文字、圖片、程式碼或影片等方式，讓人更容易理解 透過這份官方活動辦法也可以看到，想要得獎的話，必須要有 「組織良好」 的文章，並且該文章的內容，需要具備 「專業性」、「豐富性」、「深入性」，而且需要在文章中添加 「圖片」 或是 「程式碼」 的輔助，使人更容易理解。\n所以這個簡單的說的話，就是除了你的主題要寫的夠深、夠豐富之外，也需要寫出一個結構良好，並且有圖、有程式碼的文章。\n所以只要抓好這幾個重點的話，就能盡量提升得獎的機率，最終拿到出書的資格了！\n道理我都懂，但是要如何選題？ # 當我們了解了 iThome 鐵人賽官方的得獎標準之後，再來就可以進到選題的部分了！\n不得不說，選題的好壞真的影響很大，因為得獎的標準之一是 「專業性」 和 「深入性」，所以如果你今天挑的題目是「XXX 入門」的話，那麼在「深入性」上就會比較吃虧（因為你沒辦法真的寫得很深入）。\n舉例來說，我當時參賽的題目是《Spring Boot 零基礎入門》，因為我的定調是「入門」文章，所以其實這個選題，就注定了我在「深入性」這一點上，沒辦法寫的太詳盡。\n如果拿 2023 那一年「Software Development 區」的冠軍名單出來看的話：\n《為你自己學 Ru\u0026hellip;..st》— 高見龍 《圖解C++影像處理與OpenCV應用：從基礎到高階，深入學習超硬核技術！》— VincentYeh 就可以發現，得到冠軍的這兩位大大，他們寫的內容真的都是很有深度的內容，更別說其中一位參賽者，還是很有名的高見龍老師，所以這個廝殺真的是只有激烈可言😂。\n所以假設你想要得獎，那麼寫一個超級深入的硬派文章，確實可能會提升得獎的機率。不過老實說，我其實不是很建議大家一定要挑超級艱深的題目寫，因為這樣你只是為了寫而寫而已，就算這樣的文章得獎了，裡面也沒有靈魂的啊！！！\n所以會比較建議大家，你所寫的文章，盡量還是和你自己課業上所學、工作上有接觸的部分會比較好，因為自己熟悉的題目才是最好發揮的，而且就算挑的題目是「XXX 入門」的題目，只要掌握好文章結構的話，仍舊是能拿到《優選》或是《佳作》的獎項的（而且其實這兩個獎項也都可以出書的！）。\n所以就建議大家，不用太糾結《冠軍》這兩個字，建議還是挑你平常接觸最多、你最熟悉的那個主題來寫，這樣子寫起來才會快樂，得獎的時候成就感才會爆棚啊XDD（媽！這我寫的！）。\n題目挑好了，然後呢？ # 題目挑好之後，就可以「Welcome to 寫作地獄」了🤗。（我是指，Welcome to 快樂的寫作人生了）\n好啦說正經的，其實邊挑題目的時候，大家就可以開始思考：「我這篇文章是要寫給哪類人群看的？」，這個問題非常的重要，重要到會影響你整體的文章編排架構，所以一開始多花一點時間練習思考這個問題，是非常有意義的。\n舉例來說，像是我之前參賽的《Spring Boot 零基礎入門》主題，因為我的定調是入門文章：\n所以我預設的讀者人群，就是「完全沒有碰過（甚至沒聽過） Spring Boot」的人 而我希望這些人在看完我的文章之後，就「能夠使用 Spring Boot，實作出一個簡易的後端系統」 所以其實我在開始動筆寫第一篇文章之前，我就已經先決定了這 30 篇文章的走向，而我的目標，就是讓完全沒用過 Spring Boot 的人，在看完這 30 篇文章之後，就能夠去實作出一個簡易的後端系統這樣。\n所以圍繞著這個目標，我就可以開始思考，我要如何去介紹 Spring Boot 的基本用法、要如何去示範這些程式給大家看，然後就可以慢慢把 30 天的大綱給生出來了。\n所以總結來說的話，在我真的開始動筆寫第一篇文章之前，我其實就已經把這 30 篇文章的大綱都列好了。所以我會先列出說，我大概要講哪幾個部分、並且每個部分大概要佔幾篇文章的內容，所以就會像是下面這個樣子，就是先列出哪幾天要介紹哪些主題這樣：\nDay 1～4：Spring Boot 簡介、開發環境安裝 Day 5～12：Spring 框架的特性 - IoC 和 AOP Day 13～23：Spring MVC 介紹 Day 24～28：Spring JDBC 介紹 Day 29：實戰演練：打造簡易的圖書館系統 Day 30：Spring Boot 零基礎入門總結 如果要我說的話，「文章編排」這件事，可以說是整個 iThome 鐵人賽最難的地方，因為在這個環節中，你必須要去思考：「你想要介紹哪些內容？」、「你想要怎麼編排這些內容？」，而這個過程，等於是你要去逼自己，要想盡辦法的把你心目中零碎的知識片段，組織成一個完善的 30 篇文章架構。\n老實說這件事真的是最難的，所以一開始大家如果覺得很難排的話，是非常正常的，你在這個階段可能會覺得腦袋中東西很多、很混亂，不知道怎麼下手將他們呈現，有這些情況都是很正常的。\n所以我會建議大家，如果你真的覺得很混亂、不知道該怎麼下手，那你可以先跳過「文章編排」這一關，直接就動筆開始寫吧！等到你寫了一次、兩次，更有經驗之後，下一次參賽時，可以再回頭來挑戰「文章編排」這個大魔王。\n而等你真的克服這個大魔王之後，你就會發現自己的寫作技巧好像昇華了！以後不管是寫技術文件、或是寫其他的教學文章，都會寫得比以前還要順手，說不定等到那一天，就會換你在網路上分享寫作心法給其他參賽者了～（期待那一天的到來！）。\n題目挑好了、大綱也寫好了，再來呢？ # 當大家克服最難的大魔王「文章編排」之後，再來就是努力的寫稿子寫稿子\u0026hellip;loop，然後配上超級堅持不懈的精神，最終就可以順利完賽了！！\n不過其實寫稿子這件事，也是有一些心法可以分享給大家的，那就是要掌握好「文章的段落」，以及「文章的易讀性」。\n文章段落 # 以「文章段落」來說，其實當大家在閱讀這篇文章時，如果仔細觀察一下的話，就會發現我會使用 「H2（二級標題）」，為每個段落進行分段。\n所以像是在這篇文章中，一開始的段落標題就是「iThome 鐵人賽官方得獎評判標準」，這一段我們談的就是 iThome 的官方得獎標準；而像是目前這一段的標題就是「題目挑好了、大綱也寫好了，再來呢？」，談的就是文章寫作的內容。\n所以當大家在撰寫文章時，文章本身的段落，也是非常重要的，一個好的文章段落，可以讓讀者在閱讀時，清楚知道目前段落的主題為何。\n文章的易讀性 # 而至於「文章的易讀性」，這部分就比較彈性了，就只要確保文字通順、並且敘述描述清楚就可以了～\n這裡其實就很看個人的寫作風格了啦，像是我自己在寫文章時，偶爾就會有一些贅字，或是我打字的時候，也會用很多的「波浪號 ～」、或是「表情符號😉」，來幫助我表達文章的情緒，所以這部分大家也是多寫多練習，慢慢的就會找到自己的風格了！\n上面我都照做了，但是還是沒得獎怎麼辦… # 一個很殘酷的事實是，只要是比賽，就一定會有贏家和輸家，這是千古不變的事實。所以萬一這一次參賽的結果是沒得獎，就\u0026hellip;也希望大家可以調整好心情，多看看歷屆的得獎文章是怎麼寫的，慢慢磨練自己的技術、寫作技巧，等到蓄積好一波能量之後，就再來參賽一次，當成復仇戰吧！！\n不過我自己是覺得，目前只要能夠拿到《優選》或是《佳作》的獎項，就已經非常厲害了，因為你要知道，你的對手可是身經百戰的大神、或是有豐富教學經驗的老師啊！！這要贏也太難了吧😂！！所以我個人是覺得，能夠拿到《優選》或是《佳作》的獎項，就已經很厲害了，而至於要拿到《冠軍》，可能真的得要「優秀的文章編排」+「足夠深入的主題」，才有辦法奪冠吧🥹。\n不過以上都只是我自己的猜測，不代表 iThome 鐵人賽的立場，所以大家就隨意看看就好，具體的獲獎辦法，仍舊以 iThome 公佈的為準。\n結語 # 本來只是想稍微分享一點自己的寫作心得，但是不小心洋洋灑灑打了一大堆，果然講到 iThome 鐵人賽就是有滿滿數不盡的話題可以分享XDD。\n不得不說 iThome 鐵人賽從創辦到至今為止，真的提供了一個很好的舞台給我們這些工程師們，讓我們可以有一個地方發揮自己的所長、分享自己所學給其他人，雖然比賽是有輸有贏，但還是希望大家可以滿載而歸啦！連載的這 30 天絕對會是人生中最充實的一段日子（進過寫作地獄的都懂😆），大家有機會的話還是可以嘗試看看的～\n好啦，大概是這樣！希望這篇文章可以幫助到想參加 iThome 鐵人賽的參賽者們💪，不過最後我還是要再重申一下，本篇文章只是代表我自己的個人看法，不具有 iThome 鐵人賽任何的官方效力（拜託大家了，我真的很怕被吉😂），如果此文有侵權也再麻煩告知，感謝！\n最後，如果你對 Spring Boot、以及後端技術有興趣的話，歡迎查看我的參賽文章《Spring Boot 零基礎入門》，也歡迎免費訂閱《古古的後端筆記》電子報，每週二為你送上一篇後端技術分享！\n感謝大家閱讀到這裡，那我們就下一篇文章見啦～\n補充：如果對後續出書的幕後花絮有興趣，也可以參考 iThome 鐵人賽 - 出書的幕後花絮 的介紹\n","permalink":"https://kucw.io/blog/ithome-sharing/","tags":null,"title":"iThome 鐵人賽 - 得《優選》獎項的寫作心法"},{"categories":["自媒體經營"],"contents":"哈囉，我是古古，我的本業是軟體工程師，但是卻誤打誤撞走進了自媒體這條路。\n這個專欄裡面記錄了我作為一個軟體工程師，是如何踏入自媒體這條路，並且也記錄了我是如何在接觸了許多創作者之後，下定決心要認真嚴肅的看待自媒體這份事業。\n這份專欄不只是寫給我自己，也想寫給對自媒體有興趣的你，不管你的職業和身份是什麼，都希望這份專欄可以為你帶來一點幫助。\n現在時間是 2024.8.6，我在這裡寫下我的第一篇電子報《古古的後端筆記》的創刊號，作為我認真開始經營自媒體的起點，後續也會持續更新這份專欄，如果有興趣的話，也歡迎訂閱電子報：https://kucw.io/bio。\n踏入自媒體的起因 # 那！雖然有點突然，不過我還是先來個自我介紹吧XD\n我是古君葳，大家也可以叫我古古，我大學和研究所念的都是資工系（陽明交大資工系、台大資工所），然後在唸研究所的時候，我有申請去北京大學交換過半學期，所以也就剛好，在畢業之後，就在北京找過一份 Java 後端工程師的工作，這份工作大概是做了一年左右。\n然後在 2019 年初，大概是在 3 月附近，我因為家裡的事情，就決定回到台灣發展這樣，所以後續我就是加入 Garmin，負責開發 Java 後端程式，然後，就意外的開啟了這條自媒體之路了。\n所以如果回顧一下我的求學經歷、以及工作經歷的話，就也可以發現，在求學和工作的過程中，我真的是完全跟自媒體沾不上邊，就是一個照著社會安排的資工系學生的路線，穩穩地去做工程師的工作這樣。\n不過，我現在之所以能夠坐在這裡，寫著這個《古古的後端筆記》的創刊號，其中一個很大的轉折點，就是當時的我，接觸到了「線上課程」這件事。\n我當時在北京工作的時候，我身邊的同事、朋友，每一個人，真的不誇張，真的是每一個人，都是在談「你學了什麼課？」、或是「你最近買了什麼課？」，當然我的經驗不能代表所有人的經驗，不過這對於當時的我而言，完全就是文化衝擊XDD，就…沒想過在這個世界上，還有「線上課程」這麼好用的東西可以學習。\n比起實體課，不得不說我自己是更愛上線上課程，因為線上課程有字幕！！有動畫！！而且老師講廢話的時候還可以跳過（大家不要學🤣）！！還可以開 2 倍速看！！！完全就是超級高效率的學習方式！！！\n也就是因為當時在北京工作的時光中，我接觸到了不一樣的觀點和想法，所以也就間接導致我後續回台灣之後，會因緣際會投入到線上課程的教學。\n回台灣的發展期 # 所以在 2019 年回到台灣之後，我就進了 Garmin，就開始了 Java 後端工程師的工作了。\n不過在工作之餘，我就一個手癢，想說要不買點課來學吧XDD，但我一查了之後就發現，台灣怎麼好像….想要買課還買不到？可能是當時台灣的技術課程比較少人錄、也有可能是 Udemy 上面的英語課程就很實用了，反正就是當時在台灣的線上課程領域中，其實沒有多少選項可以選擇。\n那所以這時候我就想啦！如果我試著幫大家整理一下，把我所了解到的 Spring Boot 知識，都把他整理起來，然後錄製成課程，這樣子大家就有一個中文的課程可以考慮了嘛！所以大家就不用再去聽 Udemy 上面的印度老師的口音，然後很克難的，自己一個一個的去查這個英文單字的翻譯是什麼了（說的就是我🥹，有時候上課我都不知道是在學技術還是學英文\u0026hellip;）\n所以那時候我的想法很單純，就是想要結合我自己的工作經驗，幫大家整理出一個講中文、然後又是台灣用語的 Spring Boot 課程，就讓大家可以不用學的那麼克難這樣～\n但，事情的轉折點，就是這個「線上課程」！\n就是因為我錄製了線上課程，所以我開始有機會，去接觸到其他的創作者，去了解到他們是如何去進行創作的。然後我也慢慢的去了解到，原來身為一個創作者，除了要去創作你的原創內容之外（像是錄製線上課程），同時，你也必須要去經營你的粉絲、維護你的社群、打造你的影響力、進而讓你的個人品牌變得越來越茁壯。\n所以其實對於「自媒體」這條路而言，他並不只是「錄製線上課程」這麼單純而已，他要投入的，是更多角化的經營、是更嚴肅的態度，是要把這條自媒體的賽道，當成是一個事業來經營。\n所以在我了解到這個事實之後，我就開始思考，作為一個不小心踏進線上課程領域的工程師，我當初完全就是運氣好，所以才能夠走到這裡（再次感謝各位同學的支持🙏），但是，老天把我帶到了這裡，接下來我到底要不要認真嚴肅的，去看待這份自媒體的事業，就是我必須做出的決定了。\n那當然啦～我的決定就是「Yes！」，不然應該就沒有這個專欄文章了XDD，也因為我的決定是 Yes，所以接下來，我想要認真的，去經營自媒體這條路，我想試試看，到底可以將《古古的後端筆記》這個個人品牌，去成長到什麼樣的地步。\n所以接下來，就歡迎大家跟我一起，收看這個大型的真人秀吧！\n歡迎收看大型真人秀：軟體工程師的自媒體之路 # 打字打到這裡，我們終於可以來介紹《古古的後端筆記》的電子報了！\n簡單的說的話，這份電子報，就是我嘗試經營自媒體的第一步！不知道大家有沒有聽過國外一個很紅的後端技術分享的作者，就是 ByteByteGo，我之所以第一步會想要經營電子報，也是受到 ByteByteGo 影響，就覺得每週可以學習一點後端知識也很讚這樣！\n那既然我們都創刊了，夢想還是要有的，所以我就先來畫個餅，就希望可以把這份《古古的後端筆記》的電子報，做成是台灣的 ByteByteGo！\n不過當然我自己也知道，我本身的後端技術能力還不到頂尖，所以目前我離 ByteByteGo，仍舊是有一大段距離需要努力，但是，就希望可以透過這份電子報，每週輸出後端知識給大家，然後也藉著這份動力，能夠讓自己的後端技術可以更精進這樣。\n所以大家的訂閱，對我而言是一份責任、也是一份動力，所以大家如果後續對於電子報中的任何主題，有任何的想法的話，都歡迎直接回信給我，每一封我都會看的！電子報的優勢就是這樣，只要你回信，我就一定能收到，而且信件內容也不會公開，所以如果大家有什麼想對我說的話，都很歡迎大家回覆～\n結語 # 好啦！大概是這樣，總而言之這個大型的真人秀：軟體工程師的自媒體之路，仍舊會持續下去，我有打算把這個系列變成是一個專欄，就是會定期的跟各位老闆們回報一下，我目前的經營進度這樣XDD。最近不也挺流行 Build in Public 的創業模式嗎？那我就剛好也來把這份自媒體的創業之路，一起分享給大家～\n最後，我是古君葳（古古），是一個軟體工程師、同時也是一個自媒體的創業者，感謝大家的訂閱！就讓我們一起見證下去吧！\n如果你對後端筆記有興趣，也歡迎免費訂閱《古古的後端筆記》電子報，每週二為你送上一篇後端技術分享，一起變強💪\n","permalink":"https://kucw.io/blog/as-a-content-creator/1/","tags":null,"title":"軟體工程師的自媒體之路 - 電子報創刊號"},{"categories":["Spring Boot"],"contents":"哈囉大家好，我是古古。\n終於來到本系列文的最後一個文章啦！能看到這裡的你真的非常厲害！！這篇文章會總結一下，我們在這 30 篇文章中都介紹了哪些部分，最後也會補充一些有關 Spring Boot 的學習路徑，所以我們就開始吧！\n目錄 所以，我們到底學到了哪些東西？ Spring IoC Spring AOP Spring MVC Spring JDBC 實戰演練 Spring Boot 的學習路徑 深度：深入了解 Spring Boot 廣度：Spring 全家桶、軟體工程師的通用知識 關注我，學習更多後端知識 總結 所以，我們到底學到了哪些東西？ # 在最一開始，大家可能還不太熟悉 Spring Boot（甚至沒聽過 Spring Boot），不過經過了這 30 篇文章的介紹之後，大家基本上可以掌握：\nSpring IoC # 了解 IoC、DI、Bean 的概念 能夠在 Spring Boot 中創建一個 Bean、注入一個 Bean、初始化一個 Bean 能夠讀取 application.properties 中的設定值到 Bean 裡面 Spring AOP # 了解 AOP 中切面的概念 能夠在 Spring Boot 中運用 AOP 的用法 Spring MVC # 了解 Http request 和 response 中各項欄位的意義、JSON 格式的寫法 能夠在 Spring Boot 中運用四種註解，接住前端傳遞過來的參數 能夠在 Spring Boot 中設計和實作出 RESTful API Spring JDBC # 能夠在 Spring Boot 中執行 INSERT、UPDATE、DELETE、SELECT 的 SQL 語法，存取資料庫中的數據 了解 MVC 架構模式的概念 能夠在 Spring Boot 中套用 Controller-Service-Dao 三層式架構 實戰演練 # 能夠使用 Spring Boot，架設出一個簡單的圖書館管理系統（包含 CRUD 四大功能） 能夠熟練運用 IntelliJ 軟體開發 Spring Boot 程式 所以透過這 30 篇文章的介紹和練習，大家目前就具備 Spring Boot 的基礎實作能力了！恭喜！！\nSpring Boot 的學習路徑 # 而在看完此系列的 Spring Boot 零基礎入門文章，後續還想要進階學習 Spring Boot 的相關知識的話，建議可以分別朝「深度」和「廣度」來學習。\n深度：深入了解 Spring Boot # 以 Spring Boot 技術的深度來說，可以朝下列幾個方向下手：\nSpring MVC 的進階用法 # 驗證請求參數的方式：@Valid、@NotNull\u0026hellip;等用法 Controller 層的異常處理：@ControllerAdvice + @ExceptionHandler 攔截器（Interceptor）的用法 Spring JDBC 的進階用法 # @Transactional 交易管理 Spring Boot 單元測試 # JUnit、MockMvc、Mockito\u0026hellip;等用法 H2 資料庫的用法 測試驅動開發 TDD 的理念 套件管理工具 # Maven 或是 Gradle 廣度：Spring 全家桶、軟體工程師的通用知識 # Spring 全家桶 # 在了解了上述較進階的 Spring Boot 用法之後，接下來也可以學習 Spring 全家桶中的其他功能，增加知識的廣度，像是：\nSpring Security：資訊安全的驗證 Spring Cloud：微服務整合 軟體工程師的通用知識 # 或者也可以學習軟體工程師的通用知識，像是：\nGit RabbitMQ 或是 Kafka Elasticsearch \u0026hellip;等等 總之技術是沒有學完的一天的！只要隨時保持精進自己的步伐，不斷的累積實力，就能越變越強的💪。\n關注我，學習更多後端知識 # 如果你看完此系列文之後仍意猶未盡，也可以參考我開設的 Spring Boot 線上課程，裡面有針對 Spring Boot 做更完整的介紹，以及一個全新的實戰演練（實作簡易的電商網站），歡迎參考課程簡介 （輸入折扣碼「HH202601KU」即可享 85 折優惠）。\n又或是可以訂閱我經營的《古古的後端筆記》電子報，在這份電子報中就不僅僅是 Spring Boot 的介紹，而是會延伸出去分享更多後端工程師必備的知識，如系統設計、JWT 的用法\u0026hellip;等等，希望能夠在後端這條路上和大家一起學習成長！\n總結 # 寫在此系列文的最後，最後我要吶喊：「我終於寫完稿子，成功出書啦！！！好感動🥹！！！」能夠堅持到這一天真的是各種千辛萬苦，很感謝所有支持我創作的每一位粉絲、朋友，以及感謝你能耐心的閱讀到這裡。\n今後我仍舊會繼續精進後端知識，並且努力分享給大家的💪，那我們就在電子報《古古的後端筆記》中再見啦！\n","permalink":"https://kucw.io/blog/springboot/30/","tags":null,"title":"Spring Boot 零基礎入門 (30) - Spring Boot 零基礎入門總結"},{"categories":["Spring Boot"],"contents":"哈囉大家好，我是古古。\n在前面的文章中，我們有介紹了 Spring Boot 中的許多用法，包含 Spring IoC、Spring AOP、Spring MVC（和前端溝通）、以及 Spring JDBC（和資料庫溝通），並且我們也介紹了 MVC 架構模式的概念，以及 Controller-Service-Dao 三層式架構的實作。\n所以接著的這篇文章，我們就會來做個實戰演練，總和前面所學習到的所有功能，練習實作一個圖書館的管理系統出來，所以我們就開始吧！\n補充：本文中所使用的完整程式碼會放在 GitHub 上 springboot-library，建議可以搭配觀看，學習效果更好。\n目錄 功能分析：圖書館管理系統 資料庫 table 設計 1. 實作「查詢某一本書」的功能 BookController（Controller 層）的實作 BookService（Service 層）的實作 BookDao（Dao 層）的實作 API Tester 實際測試 補充：時間格式的設定 2. 實作「新增一本書」的功能 BookController（Controller 層）的實作 BookService（Service 層）的實作 BookDao（Dao 層）的實作 API Tester 實際測試 3. 實作「更新某一本書」的功能 BookController（Controller 層）的實作 BookService（Service 層）的實作 BookDao（Dao 層）的實作 API Tester 實際測試 4. 實作「刪除某一本書」的功 BookController（Controller 層）的實作 BookService（Service 層）的實作 BookDao（Dao 層）的實作 API Tester 實際測試 圖書館管理系統總結 總結 功能分析：圖書館管理系統 # 在我們開始動手寫程式去實作圖書館管理系統之前，首先可以先來分析一下，在這個圖書館的管理系統中，我們想要提供什麼樣的功能。\n像是圖書館管理系統顧名思義，就是用來管理「書」的，所以我們針對「書」這個資源，就可以去實作他的 CRUD 四大基本操作，也就是「新增一本書」、「查詢某一本書」、「更新某本書的資訊」、「刪除某一本書」。\n因此下面就會分別來介紹，要如何在 Spring Boot 中設計和實作出「書」的 CRUD 四個功能，完成一個簡易的圖書館管理系統。\n資料庫 table 設計 # 在設計資料庫 table 時，因為是針對「書本」這個資源來設計，因此我們可以設計一個 book table，去儲存書本的相關資訊。以下是創建 book table 的 SQL 語法：\nCREATE TABLE book ( book_id INT NOT NULL PRIMARY KEY AUTO_INCREMENT, title VARCHAR(128) NOT NULL, author VARCHAR(32) NOT NULL, image_url VARCHAR(256) NOT NULL, price INT NOT NULL, published_date TIMESTAMP NOT NULL, created_date TIMESTAMP NOT NULL, last_modified_date TIMESTAMP NOT NULL ); 其中各個欄位的含義如下：\nbook_id：表示 book 的唯一 id，由資料庫自動遞增\ntitle：表示此書的書名\nauthor：表示此書的作者\nimage_url：儲存此書的圖片連結\nprice：此書的販售價格\n補充：在實務上只要牽扯到「金錢」的部分，通常會用 BigDecimal 特別處理，不過由於此專案主要在練習 Spring Boot 的基礎結構和用法，因此此處使用 Integer 類型來簡化實作細節。\npublished_date：此書的上架時間\ncreated_date：創建這筆數據的時間\nlast_modified_date：最後修改這筆數據的時間\n而設計好資料庫 table 之後，就可以將這段 SQL 語法貼到 IntelliJ 中的 console 上，在 IntelliJ 中執行這個 SQL 語法，就可以在 myjdbc database 中創建 book table 出來。\n1. 實作「查詢某一本書」的功能 # 創建好 book table 之後，接下來我們就可以開始來實作 Spring Boot 程式了！\n通常在實作基礎的 CRUD 功能時，建議可以先從「查詢功能」開始實作，因此我們就先從「查詢一本書」這個功能開始實作。\nBookController（Controller 層）的實作 # 首先我們可以先在 BookController 中，添加如下的程式：\n@GetMapping(\u0026#34;/books/{bookId}\u0026#34;) public ResponseEntity\u0026lt;Book\u0026gt; getBook(@PathVariable Integer bookId) { Book book = bookService.getBookById(bookId); if (book != null) { return ResponseEntity.status(HttpStatus.OK).body(book); } else { return ResponseEntity.status(HttpStatus.NOT_FOUND).build(); } } 補充：由於程式的篇幅過長，因此本文中只會擷取部分重點來介紹，完整的程式碼可以前往 GitHub springboot-library 查看。\n在 BookController 中，因為他是屬於 Controller 層，所以他會使用 @GetMapping，去接住前端放在 url 路徑中的 bookId 的參數。\n而在接到 bookId 的值之後，BookController 就會直接往後傳給 BookService 去做後續處理，即是將商業邏輯寫在 Service 層，讓 Controller 層保持「和前端溝通」的部分。\n而當 BookService 返回查詢到的 book 數據之後，BookController 就可以根據「是否有查詢到數據與否」，去決定要返回給前端的 Http status code 為何。\n像是在下面的程式中，if 區塊就呈現出「當 book 不為 null 時，就返回 200 OK 的 Http status code 給前端，並且把 book 數據放在 response body 中」的資訊。而在 else 區塊中，則是呈現「當 book 為 null 時，就返回 404 Not Found 的 Http status code 給前端」。\nif (book != null) { return ResponseEntity.status(HttpStatus.OK).body(book); } else { return ResponseEntity.status(HttpStatus.NOT_FOUND).build(); } 補充：如果不熟悉 Http status code 的話，可以回頭參考 Day 23 - Http Status Code（Http 狀態碼）介紹 的文章。\nBookService（Service 層）的實作 # 實作完 BookController 之後，接著我們往下實作 BookService。\n當 BookService 收到 Controller 傳過來的 bookId 之後，因為這裡的邏輯比較簡單，沒有太複雜的商業邏輯要處理，因此 BookService 就只要直接去 call BookDao 的方法，交由 Dao 層去資料庫查詢數據即可。\npublic Book getBookById(Integer bookId) { return bookDao.getBookById(bookId); } BookDao（Dao 層）的實作 # 而在 BookDao 這裡，因為他是 Dao 層，負責和「資料庫」溝通，因此就可以在這裡使用 Spring JDBC 的 query() 方法，在資料庫中執行 SELECT SQL，去查詢這一筆 bookId 的數據出來。\npublic Book getBookById(Integer bookId) { String sql = \u0026#34;SELECT book_id, title, author, image_url, price, published_date, created_date, last_modified_date \u0026#34; + \u0026#34;FROM book WHERE book_id = :bookId\u0026#34;; Map\u0026lt;String, Object\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); map.put(\u0026#34;bookId\u0026#34;, bookId); List\u0026lt;Book\u0026gt; bookList = namedParameterJdbcTemplate.query(sql, map, new BookRowMapper()); if (bookList.size() \u0026gt; 0) { return bookList.get(0); } else { return null; } } 因此到這邊，「查詢某一本書」的功能就實作完畢了！\nAPI Tester 實際測試 # 因為目前 book table 中沒有任何數據，因此在測試「查詢某一本書」的功能之前，我們需要先在 IntelliJ 的 console 中執行下列的 SQL 語法，手動插入一筆數據到 book table 中。\nINSERT INTO book (title, author, image_url, price, published_date, created_date, last_modified_date) VALUES (\u0026#39;先問，為什麼？：顛覆慣性思考的黃金圈理論，啟動你的感召領導力\u0026#39;, \u0026#39;賽門‧西奈克\u0026#39;, \u0026#39;https://im1.book.com.tw/image/getImage?i=https://www.books.com.tw/img/001/092/65/0010926506.jpg\u0026#39;, 331, \u0026#39;2018-05-23 00:00:00\u0026#39;, \u0026#39;2023-10-14 02:42:02\u0026#39;, \u0026#39;2023-10-14 02:42:02\u0026#39;); 插入這本書的數據之後，接著就可以在 API Tester 中，填上以下的參數設定，來測試「查詢某一本書」的功能：\n填寫完成之後，就可以按下 Send 鍵進行測試，結果如下：\n補充：時間格式的設定 # 這裡題外話補充一下，如果大家不是直接下載 GitHub 上的 springboot-library 程式來使用，而是靠自己自己一行一行輸入程式的話，那麼你在上圖中所返回的 publishedDate、createdDate、以及 lastModifiedDate 的值，就會是 2018-05-22T16:00:00.000+00:00 的格式，而不是上圖中的 2018-05-23 00:00:00 的格式。\n之所以會有這個差異，是因為 Spring Boot 預設的時間格式為 2018-05-22T16:00:00.000+00:00，而要改變這個格式成 2018-05-23 00:00:00 的話，會需要在 application.properties 檔案中進行相關的設定。\n因此就要麻煩大家，手動在 application.properties 檔案中添加下面這兩行程式，這樣子才能夠將 Spring Boot 的時間格式，改成是 2018-05-23 00:00:00 的樣子。\nspring.jackson.time-zone=GMT+8 spring.jackson.date-format=yyyy-MM-dd HH:mm:ss 2. 實作「新增一本書」的功能 # 實作完「查詢某一本書」的功能之後，第二個推薦實作的，就是「新增一本書」的功能。\nBookController（Controller 層）的實作 # 首先我們一樣是可以先在 BookController 中，添加以下的程式，去接住前端所傳過來的參數：\n@PostMapping(\u0026#34;/books\u0026#34;) public ResponseEntity\u0026lt;Book\u0026gt; createBook(@RequestBody BookRequest bookRequest) { Integer bookId = bookService.createBook(bookRequest); Book book = bookService.getBookById(bookId); return ResponseEntity.status(HttpStatus.CREATED).body(book); } 而在實作「新增一本書」時，通常會分成兩個步驟來實作：\n先去 call BookService 的 createBook() 方法，真的去資料庫中創建一筆 Book 數據出來 當資料庫創建好數據之後，重新查詢一次該筆 Book 數據，然後將這筆 Book 數據原封不動的回傳給前端 首先第一步比較單純，就是在 BookController 接收到前端傳過來的 BookRequest 參數，接著將 BookRequest 往後傳遞給 BookService 去做處理。\n範例的前端請求如下：\n{ \u0026#34;title\u0026#34;: \u0026#34;原子習慣：細微改變帶來巨大成就的實證法則\u0026#34;, \u0026#34;author\u0026#34;: \u0026#34;詹姆斯‧克利爾\u0026#34;, \u0026#34;imageUrl\u0026#34;: \u0026#34;https://im1.book.com.tw/image/getImage?i=https://www.books.com.tw/img/001/082/25/0010822522.jpg\u0026#34;, \u0026#34;price\u0026#34;: 260, \u0026#34;publishedDate\u0026#34;: \u0026#34;2019-06-01 00:00:00\u0026#34; } 而第二步的實作與否，其實不會影響到「新增一本書」的具體功能（因為第二步只是查詢而已），因此可以看個人的喜好，決定是否要實作第二步。\nBookService（Service 層）的實作 # 在「新增一本書」的實作中，因為 BookService 的實作也是比較簡單，因此只要直接去 call BookDao 的方法，交由 Dao 層去資料庫中創建一筆數據就可以了。\npublic Integer createBook(BookRequest bookRequest) { return bookDao.createBook(bookRequest); } BookDao（Dao 層）的實作 # 而在 BookDao 裡面，因為他是 Dao 層，負責和「資料庫」溝通，因此就可以在這裡使用 Spring JDBC 的 update() 方法，在資料庫中執行 INSERT SQL，去新增一筆 Book 的數據。\npublic Integer createBook(BookRequest bookRequest) { String sql = \u0026#34;INSERT INTO book(title, author, image_url, price, published_date, created_date, last_modified_date) \u0026#34; + \u0026#34;VALUES (:title, :author, :imageUrl, :price, :publishedDate, :createdDate, :lastModifiedDate)\u0026#34;; Map\u0026lt;String, Object\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); map.put(\u0026#34;title\u0026#34;, bookRequest.getTitle()); map.put(\u0026#34;author\u0026#34;, bookRequest.getAuthor()); map.put(\u0026#34;imageUrl\u0026#34;, bookRequest.getImageUrl()); map.put(\u0026#34;price\u0026#34;, bookRequest.getPrice()); map.put(\u0026#34;publishedDate\u0026#34;, bookRequest.getPublishedDate()); Date now = new Date(); map.put(\u0026#34;createdDate\u0026#34;, now); map.put(\u0026#34;lastModifiedDate\u0026#34;, now); KeyHolder keyHolder = new GeneratedKeyHolder(); namedParameterJdbcTemplate.update(sql, new MapSqlParameterSource(map), keyHolder); int bookId = keyHolder.getKey().intValue(); return bookId; } 這裡比較值得注意的是後面的 KeyHolder 的用法，他是在 update() 的一種進階的用法。\nKeyHolder 的用途，是在創建一筆數據到資料庫時，取得「資料庫自動生成的 id 的值」。\n之所以要特別使用 KeyHolder，是因為我們前面在設計 book table 時，其中的 book_id 欄位，我們是設定成 AUTO_INCREMENT，而這就會導致一種現象，即是「我們在 Spring Boot 中插入了一筆數據，但是我們卻不知道這筆數據的 id 值是多少」。\nbook_id INT NOT NULL PRIMARY KEY AUTO_INCREMENT, 因此 KeyHolder 就是為了解決這個問題而誕生的！\n只要在執行 update() 方法時，同時也加入一個 KeyHolder 的參數，這樣子就可以在創建數據的同時，取得「資料庫自動生成的 id 的值」了（也就是取得 book_id 的值）。\nKeyHolder keyHolder = new GeneratedKeyHolder(); namedParameterJdbcTemplate.update(sql, new MapSqlParameterSource(map), keyHolder); int bookId = keyHolder.getKey().intValue(); 所以到這邊，我們也完成了「新增一本書」的功能實作了！\nAPI Tester 實際測試 # 要測試「新增一本書」的功能的話，只需要在 API Tester 中，填上以下的參數設定：\n{ \u0026#34;title\u0026#34;: \u0026#34;原子習慣：細微改變帶來巨大成就的實證法則\u0026#34;, \u0026#34;author\u0026#34;: \u0026#34;詹姆斯‧克利爾\u0026#34;, \u0026#34;imageUrl\u0026#34;: \u0026#34;https://im1.book.com.tw/image/getImage?i=https://www.books.com.tw/img/001/082/25/0010822522.jpg\u0026#34;, \u0026#34;price\u0026#34;: 260, \u0026#34;publishedDate\u0026#34;: \u0026#34;2019-06-01 00:00:00\u0026#34; } 填寫完成之後，就可以按下 Send 鍵進行測試，結果如下：\n注意這裡有一個小細節，就是「返回的 Http status code 為 201，而不是普通的 200」。\n201 表示的不僅是這一次的 Http 請求成功而已，他還額外表示「有一個新的資源成功的被創建了」的含義。也因為如此，201 很常被用在 POST 請求所返回的 Http status code 上。\n補充：有關 201 的詳細介紹，可以回頭參考 Day 23 - Http Status Code（Http 狀態碼）介紹 的文章。\n3. 實作「更新某一本書」的功能 # 實作完「新增一本書」的功能之後，接著我們往下實作「更新某一本書」的功能。\nBookController（Controller 層）的實作 # 首先我們一樣是可以先在 BookController 中，添加以下的程式，去接住前端所傳過來的參數：\n@PutMapping(\u0026#34;/books/{bookId}\u0026#34;) public ResponseEntity\u0026lt;Book\u0026gt; updateBook(@PathVariable Integer bookId, @RequestBody BookRequest bookRequest) { // 檢查 book 是否存在Book book = bookService.getBookById(bookId); if (book == null) { return ResponseEntity.status(HttpStatus.NOT_FOUND).build(); } // 修改 Book 的數據 bookService.updateBook(bookId, bookRequest); Book updatedBook = bookService.getBookById(bookId); return ResponseEntity.status(HttpStatus.OK).body(updatedBook); } 在實作「更新某一本書」的功能時，也是會分成兩個步驟來進行：\n先檢查此 Book 是否存在，如果不存在，就直接返回 404 Not Found 的錯誤給前端 如果此 Book 存在，則修改該 Book 的數據，並且返回修改後的 Book 數據給前端 之所以會分成兩個步驟來執行，是因為透過這樣子的寫法，才能讓前端知道「他具體遇到的是什麼狀況」。\n舉例來說，當前端拿到 404 的錯誤時，前端就知道可能是他的 bookId 參數寫錯，導致他嘗試去更新一個不存在的 Book，因此這時後前端就可以回頭去修改他的請求參數。而如果當前端拿到的是 200 成功，那就表示 Book 數據更新成功了。\n假設我們不分成兩步驟來做，而是一拿到前端的 bookId 參數，就直接去更新該 bookId 的數據的話，雖然在資料庫的執行上不會出問題，但是對於前端來說，他卻會拿到 200 的成功回應，因此就會出現 「前端明明嘗試更新一筆不存在的數據，但是我們卻跟他說 OK 更新成功」 的奇怪情境，邏輯上並不是很合理。\n所以這裡在實作上，才會特別分成兩個步驟，先判斷 Book 是否存在，如果存在，才更新該 Book 的數據，透過這樣的實作，才能讓我們的後端程式更忠實的去呈現正確的邏輯。\nBookService（Service 層）的實作 # 在實作「更新某一本書」時，因為 BookService 的實作也是比較簡單，因此只要直接去 call BookDao 的方法，交由 Dao 層去修改資料庫中的數據即可。\npublic void updateBook(Integer bookId, BookRequest bookRequest) { bookDao.updateBook(bookId, bookRequest); } BookDao（Dao 層）的實作 # 而在 BookDao 裡面，則可以使用 Spring JDBC 的 update() 方法，在資料庫中執行 UPDATE SQL，去更新這一筆 book 的數據。\npublic void updateBook(Integer bookId, BookRequest bookRequest) { String sql = \u0026#34;UPDATE book SET title = :title, author = :author, image_url = :imageUrl, \u0026#34; + \u0026#34;price = :price, published_date = :publishedDate, last_modified_date = :lastModifiedDate\u0026#34; + \u0026#34; WHERE book_id = :bookId \u0026#34;; Map\u0026lt;String, Object\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); map.put(\u0026#34;bookId\u0026#34;, bookId); map.put(\u0026#34;title\u0026#34;, bookRequest.getTitle()); map.put(\u0026#34;author\u0026#34;, bookRequest.getAuthor()); map.put(\u0026#34;imageUrl\u0026#34;, bookRequest.getImageUrl()); map.put(\u0026#34;price\u0026#34;, bookRequest.getPrice()); map.put(\u0026#34;publishedDate\u0026#34;, bookRequest.getPublishedDate()); map.put(\u0026#34;lastModifiedDate\u0026#34;, new Date()); namedParameterJdbcTemplate.update(sql, map); } 這裡在實作上需要注意一個細節，即是在更新數據時，要記得也去更新 book table 中的 last_modified_date 欄位的值，將他更新成當前的時間。\n之所以要特別更新 last_modified_date 的時間，是因為 last_modified_date 的含義是「最後修改此筆數據的時間」，因此其他人就可以透過這個欄位，知道這筆數據最後是在什麼時候被修改過。\n因此當我們對 book table 中的數據進行更新時，就要記得同時也去更新 last_modified_date 的值，確保「最後更新時間」的值有一起被修改成當前時間。\n所以到這邊，我們就完成了「更新某一本書」的功能實作了！\nAPI Tester 實際測試 # 假設我們要更新 id 為 2 的那本書，那麼就只需要在 API Tester 中，填上以下的參數設定：\n{ \u0026#34;title\u0026#34;: \u0026#34;Atomic Habits: An Easy \u0026amp; Proven Way to Build Good Habits \u0026amp; Break Bad Ones\u0026#34;, \u0026#34;author\u0026#34;: \u0026#34;James Clear\u0026#34;, \u0026#34;imageUrl\u0026#34;: \u0026#34;https://im1.book.com.tw/image/getImage?i=https://www.books.com.tw/img/001/082/25/0010822522.jpg\u0026#34;, \u0026#34;price\u0026#34;: 1000000, \u0026#34;publishedDate\u0026#34;: \u0026#34;2019-06-01 00:00:00\u0026#34; } 填寫完成之後，就可以按下 Send 鍵進行測試，結果如下：\n4. 實作「刪除某一本書」的功 # 實作完上述的功能之後，最後我們可以來實作「刪除某一本書」的功能。\nBookController（Controller 層）的實作 # 首先我們一樣是可以先在 BookController 中，添加以下的程式，去接住前端所傳過來的參數：\n@DeleteMapping(\u0026#34;/books/{bookId}\u0026#34;) public ResponseEntity\u0026lt;?\u0026gt; deleteBook(@PathVariable Integer bookId) { bookService.deleteBookById(bookId); return ResponseEntity.status(HttpStatus.NO_CONTENT).build(); } 在實作「刪除某一本書」的功能時，他的設計理念，會和上面的「更新某一本書」有點不一樣。\n在上面的「更新某一本書」中，我們會先去檢查該書是否存在，然後再根據該書是否存在，去返回不同的 Http status code 給前端。但是在實作「刪除某一本書」時，不管這本書存不存在，我們就只要通通回傳「成功的 204 No Content」的 Http status code 給前端即可。\n之所以會有這樣子的差異，是因為在「刪除某一本書」的觀念裡，他的目的就是「要去刪除那一本書」，所以換句話說的話，就是「要讓那本書的數據從地球上消失」就對了，因此這時會有兩種情況：\n假設這本書存在，那麼我們就刪除他，所以這本書的數據就不存在了，完美！因此就回傳 204 No Content 給前端 假設這本書不存在，那麼即使我們沒有執行刪除的動作，這本書的數據本身也是不存在的，所以同樣也是回傳 204 No Content 給前端 所以對於「刪除某一本書」的功能來說，他在意的「不是」有沒有真的刪除到數據，他在意的是「該數據是否真的消失了」。 只要數據消失，不管他是曾經出現過然後被刪除、或是從來就沒出現過，對於「刪除某一本書」這個功能來說，就通通都是回傳成功的 204 No Content 就對了！\nBookService（Service 層）的實作 # 在「刪除某一本書」的功能中，因為 BookService 的實作也是比較簡單，因此只要直接去 call BookDao 的方法，交由 Dao 層去刪除資料庫中的數據即可。\npublic void deleteBookById(Integer bookId) { bookDao.deleteBookById(bookId); } BookDao（Dao 層）的實作 # 而在 BookDao 裡面，則是可以使用 Spring JDBC 的 update() 方法，在資料庫中執行 DELETE SQL，去刪除這一筆 book 的數據。\npublic void deleteBookById(Integer bookId) { String sql = \u0026#34;DELETE FROM book WHERE book_id = :bookId \u0026#34;; Map\u0026lt;String, Object\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); map.put(\u0026#34;bookId\u0026#34;, bookId); namedParameterJdbcTemplate.update(sql, map); } 所以到這邊，我們就完成了「刪除某一本書」的功能實作了！\nAPI Tester 實際測試 # 假設我們要刪除 id 為 1 的那本書，那麼就只需要在 API Tester 中，填上以下的參數設定：\n填寫完成之後，就可以按下 Send 鍵進行測試，結果如下：\n圖書館管理系統總結 # 在實作完上述的四個功能之後，我們就完成了針對「書本」這個資源的 CRUD 實作了！所以在上面的實作中，我們完成了以下四個功能：\n新增一本書（Create） 查詢某一本書（Read） 更新某一本書的資訊（Update） 刪除某一本書（Delete） 因此對於管理員來說，就可以透過這個後端系統，在資料庫中去新增、刪除、查詢、和修改裡面的書本了！\n不過，對於一個圖書館管理系統來說，其實單單只有 CRUD 的功能，是沒辦法滿足所有需求的。\n像是管理員可能需要「查詢書本列表」的功能，要能夠根據出版時間、價格、名字\u0026hellip;等等的因素，去列出符合條件的書本有哪些。\n又或者是管理員可能想要「權限管理」的功能，只讓正職員工擁有「新增、修改、刪除」書本的功能，而讓實習生只有「查詢」書本的功能，避免實習生誤操作，使得資料庫中的書本資料被刪除。\n因此針對一個圖書館管理系統，背後還是有許多功能可以延伸的！不過這些強大的功能，都是建立在 CRUD 功能已經完成的前提下，才有辦法往下延伸。\n所以大家在剛入門 Spring Boot 時，建議一定要打好 CRUD 的基礎，只有當你能夠獨當一面實作出 CRUD 的功能時，才算是具備後端工程師的基本實作能力。\n補充：雖然大家在實作 CRUD 時可能會覺得很重複很無聊，但還是建議大家要好好打下這邊的基礎，練好 CRUD 的基本功，這樣後續不管是要繼續去學習 Spring Boot 的進階功能，還是延伸去學習 Spring Security\u0026hellip;等框架，才能更好上手。\n總結 # 這篇文章我們先分析了「圖書館管理系統」需要實作哪些功能，並且針對「書本」這個資源，去設計了 CRUD 的四大基本操作，同時我們也有實際到 Spring Boot 中，練習去實作出 CRUD 的四個功能出來。\n那麼有關 Spring Boot 的基礎入門介紹，到這邊就告一個段落了，因此下一篇文章我們就會來總結一下，在這 30 篇文章中我們都介紹了哪些知識，來做一個大總結，那我們就下一篇文章見啦！\n補充：本文是擷取自我開設的線上課程 Java 工程師必備！Spring Boot 零基礎入門 的內容，如果你想了解更多的 Spring Boot 的用法，歡迎參考課程簡介 （輸入折扣碼「HH202601KU」即可享 85 折優惠）。\n","permalink":"https://kucw.io/blog/springboot/29/","tags":null,"title":"Spring Boot 零基礎入門 (29) - 實戰演練 - 打造一個簡單的圖書館系統"},{"categories":["Spring Boot"],"contents":"哈囉大家好，我是古古。\n在上兩篇文章中，我們有介紹了 Spring JDBC 中的兩個核心用法 update() 和 query()，因此大家就可以透過這兩個方法，在 Spring Boot 中執行想要執行的 SQL 語法了。\n而在介紹完 Spring JDBC 的核心用法之後，接著這篇文章要介紹的，是軟體工程中一個很重要的概念，即是「MVC 架構模式」，所以我們就開始吧！\n目錄 什麼是軟體工程？ 什麼是 MVC 架構模式？ Model Controller View 小結 MVC 架構模式的優點 Controller-Service-Dao 三層式架構 Controller 層 Service 層 Dao 層 小結 實際使用 Controller-Service-Dao 三層式架構 在使用 Controller-Service-Dao 三層式架構之前\u0026hellip; 使用 Controller-Service-Dao 三層式架構之後！ Controller 層：StudentController Service 層：StudentService Dao 層：StudentDao 小結 使用 Controller-Service-Dao 三層式架構的注意事項 注意事項一：透過 Class 名字結尾，表示這是哪一層 注意事項二：將 Controller、Service、Dao，全部變成 Bean 注意事項三：不能在 Controller 中直接使用 Dao 注意事項四：Dao 層只能執行 SQL 語法，不能添加商業邏輯 小結 總結 什麼是軟體工程？ # 在介紹什麼是「MVC 架構模式」之前，我們可以先來看一下，「軟體工程」到底是個什麼樣的概念。\n所謂的軟體工程，即是「在面對一個大型的系統時，工程師們要如何分工合作，一起去解決問題？」，在這句話裡面有兩個重點，分別是「大型的系統」和「如何分工合作」。\n所以簡單的說的話，當你今天要寫的是一個超過一兩千行的程式，並且在你們的團隊中，是由好幾位工程師一起分工合作來開發，在這種情況下，就會開始需要去注重「軟體工程」了。\n補充：當然小型的系統也可以注重軟體工程，不過效益相對不會那麼大。另外也因為在實際的工作中，都是會由許多工程師共同合作、一起合力開發某個大型的功能的，因此掌握好軟體工程的概念可以說是非常重要！\n什麼是 MVC 架構模式？ # 大概了解了軟體工程的概念之後，我們可以接著來介紹「MVC 架構模式」的概念是什麼，在了解了MVC 架構模式的概念之後，我們會再來介紹，要如何在 Spring Boot 中去套用 MVC 架構模式的概念。\n所謂的「MVC 架構模式」，他是軟體工程中的一種軟體架構，而 MVC 架構模式的用途，就是將一個系統，去拆分成「Model、View、Controller」三個部分，並且讓每一個部分都各自負責不同的功能。\n因此在 MVC 架構模式中，各個部分的功能如下：\nModel # 在 MVC 架構模式中，Model 負責的是「實作商業邏輯，並且處理數據」。\n由於 Model 是負責商業邏輯的實作，所以我們都會將核心的商業邏輯，寫在 Model 這個部分裡面。\n也因為 Model 同時要負責處理數據，因此 Model 也會需要去跟資料庫做溝通，將這些數據的改動給儲存起來。\nController # 在 MVC 架構模式中，Controller 負責的是「轉發 Http request」。\n所以簡單來說，當 Controller 收到來自前端的 Http request 之後，Controller 就會負責將這些 reque轉發給 Model，讓 Model 去處理後續的操作。\nView # 在 MVC 架構模式中，View 負責的是「使用 Html 的模板去呈現數據」。\n不過因為近幾年提倡「前後端分離」的關係，所以版面設計就都會交給前端去處理，因此後端就不需要處理 Html 的版面部分了，只需要改成回傳 JSON 格式的數據給前端即可。\n也因為後端不需要處理 Html 的部分（會交由前端處理），因此 View 在現今的後端架構中，相對來說就沒有那麼重要了。\n小結 # 所以在這裡先簡單小結一下的話，MVC 架構模式是軟體工程中的一種架構，會將系統拆分成「Model、View、Controller」三個部分，並且讓每一個部分都各自負責不同的功能。\n不過雖然 MVC 架構模式會將程式拆分成三個部分，但是他實際上並不會去修改程式，MVC 架構模式只是將我們所寫的程式分類一下而已，可能你今天寫的這段程式是屬於 Model 部分、又或是你今天所寫的程式是屬於 Controller 部分，僅此而已，MVC 架構模式並不會添加什麼新功能到你的程式裡面。\n所以當大家以後看到 MVC 架構模式時，就不用太緊張，他只是試圖要將我們所寫的程式進行分類，這樣在開發大型的系統時，才能更好的進行管理和維護。\n補充：MVC 架構模式之所以被稱為是 MVC，原因就是取自於 Model-View-Controller 這三種分類的第一個字母的縮寫，所以才簡稱為 MVC 架構模式。\nMVC 架構模式的優點 # 當我們使用了 MVC 架構模式，將後端程式區分成 Model-View-Controller 這三個部分之後，可以得到以下幾個好處：\n職責分離，更容易維護程式 使程式結構更直覺，有利於團隊分工 可重複使用寫好的程式 也因為使用 MVC 架構模式的好處非常多，因此在現今的 Spring Boot 開發中，基本上統統都是按照這個模式來開發程式，因此了解 MVC 架構模式的概念可以說是非常重要！我們日常的開發基本上都會按照這個模式進行開發。\nController-Service-Dao 三層式架構 # 了解了 MVC 架構模式的運作方式和優點之後，接著我們就來介紹一下，要如何在 Spring Boot 中，中，去套用 MVC 架構模式的概念。\n補充：MVC 架構模式其實是一個比較抽象的概念，具體要怎麼實作，就會依照不同的框架，而有不同寫法。\n在 Spring Boot 中，會將「MVC的架構模式」轉化成是 「Controller-Service-Dao 的三層式架構」 來實作。 因此大家以後只要在 Spring Boot 中看到「Controller-Service-Dao」這種三層式架構時，就可以知道他是套用了 MVC 的架構模式在設計了！\n而在 Controller-Service-Dao 的三層式架構中，其實就是將一份 Spring Boot 專案，區分成 Controller、Service、以及 Dao 這三層來管理，讓每一層都去負責不同的功能。\n像是在下圖中就列出了 Controller、Service、Dao 這三層架構之間的關係，以及他們個別負責的功能：\nController 層 # 首先 Controller 層的用途，是負責去「接收前端傳過來的 Http request，並且去驗證請求參數」。\n所以像是我們在 Spring MVC 中所介紹的那些註解，如 @RequestMapping、@RequestParam\u0026hellip;等等，只要是和「前端」進行溝通的部分，就都會放在 Controller 層裡面。\nService 層 # 而當 Controller 層接收到前端傳過來的 Http request、並且對其進行驗證之後，這時候 Controller 就會去 call Service層，讓 Service 負責去接手後續的處理。\n而 Service 層的用途，主要是負責「商業邏輯的處理」，所以主要的核心商業邏輯，通常都會放在 Service 層裡面來實作。\nDao 層 # 而在 Service 層實作核心的商業邏輯時，多多少少都會需要去操作資料庫，因此這時 Service 層就會去 call Dao 層，使用 Dao 層去和資料庫進行溝通。\n因此 Dao 層所負責的功能，就是「專門去和資料庫進行溝通的」，所以像是我們在 Spring JDBC 中所介紹的所有用法，只要是和「資料庫」溝通的部分，就都會放在 Dao 層裡面來實作。\n補充：Dao 層為 Data access object 的縮寫。\n小結 # 所以在套用 Controller-Service-Dao 三層式架構的設計之後，我們就可以將 Spring Boot 中的程式，依照不同的功能，把他放在不同的層級中來管理。\n因此我們之後就可以透過 Controller-Service-Dao 的三層式架構，更好的去管理和維護 Spring Boot 的程式了！\n實際使用 Controller-Service-Dao 三層式架構 # 了解了 Controller-Serivce-Dao 的三層式架構的概念之後，接著我們也可以來看一下，要如何把我們在上一篇文章中所實作的 StudentController，將他拆分為 Controller、Service、Dao 這三層，進而形成 Controller-Service-Dao 的三層式架構。\n在使用 Controller-Service-Dao 三層式架構之前\u0026hellip; # 在以前沒有 Controller-Service-Dao 三層式架構的概念時，我們所寫出來的 Spring Boot 程式，會將「取得前端參數的 @GetMapping \u0026hellip;等功能」以及「和資料庫溝通的 namedParameterJdbcTemplate 功能」，全部放在同一個 class 中實作。\n這樣子雖然同樣可以完成功能，但是在後續的管理和維護上，就會比較吃力。\n使用 Controller-Service-Dao 三層式架構之後！ # 而當我們將上面的程式，改成是使用 Controller-Service-Dao 的三層式架構來改寫的話，就可以改成下面這種寫法：\n當我們套用了 Controller-Service-Dao 的三層式架構之後，就會將原本的程式，拆分成「三個 class」來負責。\nController 層：StudentController # 首先第一個 class 是 StudentController，因為這個 class 的名字是以 Controller 做為結尾，因此他是代表 Controller 層，負責去和「前端」溝通。\n在 StudentController 裡面，我們只保留 @GetMapping 和 @PathVariable 的部分，也就是使用 Spring MVC 的功能，去和前端溝通，取得前端傳過來的參數 studentId。\n並且在取得 studentId 這個參數的值之後，StudentController 就會去 call StudentService 的 getById() 方法，後續交由 Service 層來處理。\nService 層：StudentService # 第二個 class 則是 StudentService，因為這個 class 的名字是以 Service 做為結尾，因此他是代表 Service 層，負責進行商業邏輯的處理。\n在 StudentService 裡面，我們新增了一個 getById() 的方法，而這個方法的用途，就是「根據 student 的 id，去查詢這一筆 student 的數據出來」。\n因為目前這個例子比較簡單，所以我們沒有太複雜的商業邏輯要實作，所以此處只需要去資料庫中，查詢這一筆 student 的數據出來就可以了。不過因為 Service 層不可以直接和資料庫溝通，因此在 StudentService 這裡，需要再去 call StudentDao 的 getById() 方法，後續交由 Dao 層去和資料庫溝通。\nDao 層：StudentDao # 最後第三個 class 則是 StudentDao，因為這個 class 的名字是以 Dao 做為結尾，因此他是代表 Dao 層，負責和「資料庫」溝通。\n也因為 StudentDao 是 Dao 層，負責處理和資料庫的溝通，因此我們在這裡就可以使用 Spring JDBC 的功能（即是使用 namedParameterJdbcTemplate 的 query() 方法），從資料庫中查詢 student 的數據出來。\n小結 # 所以透過上面這樣子的改寫，我們就將原本的 class 拆分成了三個 class，分別透過 StudentController、StudentService、StudentDao 這三個 class，各自去完成 Controller 層、Service 層、以及 Dao 層的功能。\n因此後續在維護上，假設我們想要修改「查詢的 SQL 語法」的話，那我們就只要去修改 StudentDao 中的程式即可（因為是由 Dao 層管理和資料庫的溝通）。\n又或是如果我們想要修改的是「前端的請求參數」，那我們就只要去修改 StudentController 中的程式即可（因為是由 Controller 層管理和前端的溝通）。\n所以透過 Controller-Service-Dao 的三層式架構，我們就可以將 Spring Boot 程式變得更好管理，以利後續的維護了。\n使用 Controller-Service-Dao 三層式架構的注意事項 # 在使用 Controller-Service-Dao 的三層式架構時，有幾個注意事項會需要遵守：\n注意事項一：透過 Class 名字結尾，表示這是哪一層 # 像是在上面的例子中，StudentController class 因為是以 Controller 做為結尾，因此在默契上，我們就會將他視為 Controller 層。\n又或是 StudentService 這個 class，因為他是以 Service 做為結尾，所以我們就會將他視為 Service 層。\n因此大家之後在使用 Controller-Service-Dao 的三層式架構時，就可以透過這個 class 名字的結尾，快速的知道這個 class 是屬於哪一層，進而知道他所負責的功能是「和前端溝通」、「處理商業邏輯」、還是「和資料庫溝通」了。\n注意事項二：將 Controller、Service、Dao，全部變成 Bean # 在實作上，我們通常會將 Controller、Service、Dao 這些 class，全部變成是由 Spring 容器所管理的 Bean，並且在後續想要使用他們的時候，再透過 @Autowired 的方式，去注入想要使用的 Bean 進來。\n舉例來說，我們就可以在 StudentController 裡面，使用 @Autowired 去注入 StudentService 進來，這樣子就可以在 StudentController 中去 call StudentService 的方法來使用了。\n同樣的道理，假設 StudentService 想要使用 StudentDao 的話，那就一樣是可以使用 @Autowired 去注入 StudentDao，因此後續就可以在 StudentService 中使用 StudentDao 中的方法，進而去取得資料庫中的數據了。\n所以到這邊大家也可以發現，其實我們在 Day 5～Day 10 所介紹的 Spring IoC 的部分，全部都是為了這裡在鋪陳啊啊！！！\n為了要能夠在 Spring Boot 中運用 Controller-Service-Dao 的三層式架構，所以我們必須要先有 Bean 的概念，了解如何創建 Bean、以及 Bean 之間是怎麼注入的，這樣子後續在實作時，才知道要如何在 StudentService 中，去注入一個 StudentDao 進來。\n因此想要掌握 Spring Boot 中的 Controller-Service-Dao 的用法的話，先決條件就是先了解 Bean 的相關操作！如果對 Bean 不熟悉的話，常常就會被 @Autowired 的各種注入給搞混，這樣反而會不利於大家的開發。\n所以在掌握 Controller-Service-Dao 的三層式架構之前，建議大家一定要了解 Bean 的概念會比較好！\n補充：如果對於 Bean 的相關註解 @Component、@Autowired \u0026hellip;等不太熟悉的話，也可以回頭查看 Day 5～Day 10 的介紹。\n注意事項三：不能在 Controller 中直接使用 Dao # 在 Controller-Service-Dao 的三層式架構中，每一層的分層是很明確的，而其中就有一項潛規則，即是「Controller 層不能直接使用 Dao 層的 class」。\n所以簡單來說，Controller 就一定只能去 call Service，再讓 Service 去 call Dao，絕對不能讓 Controller 直接去 call Dao 就對了。\n注意事項四：Dao 層只能執行 SQL 語法，不能添加商業邏輯 # 在 Controller-Service-Dao 的三層式架構中，因為 Dao 層的功能是負責「和資料庫溝通」，所以在 Dao class 裡面，只能夠去執行 SQL 語法，去和資料庫中的數據互動，但是 「不能」 在 Dao 層裡面添加商業邏輯的程式。\n舉例來說，在取得資料庫的數據之後，如果想要進行排序、或是進行篩選之類的動作，就得回到 Service 層再進行處理（因為 Service 層是負責商業處理）。\n因此在 Controller-Service-Dao 的三層式架構裡面，就會盡量保持 Dao 層僅僅是執行 SQL 語法（或是 ORM 的語法），讓他負責和資料庫溝通的部分就好，而至於複雜的商業邏輯處理，就要回到 Service 層再進行。\n小結 # 所以在實作 Controller-Service-Dao 的三層式架構時，除了要將原本的程式拆分成三個 class，分別由 StudentController、StudentService、StudentDao 來負責不同的部分之外，在使用上，也要遵守以下四個注意事項：\n透過 Class 名字結尾，表示這是哪一層 將 Controller、Service、Dao，全部變成 Bean 不能在 Contoller 層中直接使用 Dao 層 Dao 層只能執行 SQL 語法，不能添加商業邏輯 只要遵守這些注意事項，就能夠實作出一個符合規範的 Controller-Service-Dao 三層式架構了！\n總結 # 這篇文章我們先介紹了軟體工程的概念，接著介紹了 MVC 架構模式，以及如何將「MVC 架構模式」轉化成 Spring Boot 中的「Controller-Service-Dao 三層式架構」。\n而在 Controller-Service-Dao 的三層式架構中，我們也詳細介紹了 Controller-Service-Dao 三層式架構的用法，並且比較了使用三層式架構的前後差別，最後也補充了實作的注意事項，因此大家後續就可以透過這些用法，在你的 Spring Boot 程式中運用 Controller-Service-Dao 的三層式架構了！\n那麼到這篇文章為止，我們就介紹完 Spring Boot 的基本用法，分別是：\nDay 1 ～ Day 4：Spring Boot 簡介、環境安裝 Day 5 ～ Day 10：Spring IoC（Bean 的用法） Day 11 ～ Day 12：Spring AOP Day 13 ～ Day 23：Spring MVC（和前端溝通） Day 24 ～ Day 28：Spring JDBC（和資料庫溝通） 因此學習到這裡，大家就已經具備 Spring Boot 開發的基礎能力了！讚！！所以現在大家其實已經有足夠的能力，能夠去搭建一個簡易的後端系統了。\n所以下一篇文章，我們就會來進行一個實戰演練，總和前面所學習到的所有內容，練習去實作一個圖書館的管理系統出來，那我們就下一篇文章見啦！\n補充：本文是擷取自我開設的線上課程 Java 工程師必備！Spring Boot 零基礎入門 的內容，如果你想了解更多的 Spring Boot 的用法，歡迎參考課程簡介 （輸入折扣碼「HH202601KU」即可享 85 折優惠）。\n","permalink":"https://kucw.io/blog/springboot/28/","tags":null,"title":"Spring Boot 零基礎入門 (28) - MVC 架構模式 - Controller-Service-Dao 三層式架構"},{"categories":["Spring Boot"],"contents":"哈囉大家好，我是古古。\n在上一篇文章中，我們有介紹了 Spring JDBC 中的 update() 的用法，了解要如何透過 update() 方法，去執行 INSERT、UPDATE、DELETE 這三種 SQL 語法。\n那麼這篇文昭，我們就會接著來介紹 Spring JDBC 中的另一個方法，也就是 query() 的用法，了解要如何透過 query() 方法去執行 SELECT SQL。\n目錄 query() 方法的用法 RowMapper 的用途 實作 RowMapper 使用 query() 方法查詢數據 實際測試 query() 方法的用法總結 總結 query() 方法的用法 # 在 Spring JDBC 中，query() 方法的用途是「執行 SELECT SQL 語法」，因此我們就可以使用 query() 方法，去查詢資料庫中的數據。\n而 query() 的用法其實和前一篇文章我們所介紹的 update() 方法非常相似，前兩個參數都和 update() 方法一樣，都是先放入「想要執行的 SQL 語法」，接著再放入「動態決定 SQL 變數的 map 參數」。\n因此在學習 query() 的用法之前，建議大家一定要先學會 update() 的用法，這樣子在學習 query() 方法時才會更好上手。\n不過 query() 方法特別的地方，就在於他的第三個參數 RowMapper，RowMapper 可以說是影響 query() 方法的核心參數，因此接下來我們就來介紹一下，RowMapper 的用途為何、以及要如何實作 RowMapper。\nRowMapper 的用途 # 在 query() 方法中的第三個參數 RowMapper，他的用途是「將資料庫查詢出來的數據，轉換成是 Java object（物件）」。\n舉例來說，我們可以創建一個新的 class，名字叫做 StudentRowMapper，並且讓這個 class 去 implements RowMapper interface（此處要注意 implements 的是 org.springframework.jdbc.core.RowMapper 底下的 RowMapper，要小心不要選到其他的 RowMapper）。\n讓 StudentRowMapper 去 implements RowMapper interface 之後，接著我們可以在這個 class 中點擊右鍵，然後選擇「Generate…」，並且選擇「Implement Methods」。\n然後選擇實作 mapRow() 這個方法，接著按下 OK 鍵。\n操作到這裡，我們其實就完成 RowMapper 的實作雛形了！因此接下來我們只要實作剛剛所生成的 mapRow() 方法，就可以將資料庫中查詢出來的數據，轉換成 Java 物件，最後再返回給前端了。\n實作 RowMapper # 在這個 RowMapper 的實作中，我們的目的是「將資料庫中所查詢出來的數據，轉換成是一個 Java 物件」，因此我們的目標，就是要提取出下面這條 SQL 語法中的 id 和 name 的欄位的值，並且將他轉換成 Student 物件中的 id 和 name 變數。\nSELECT id, name FROM student 所以在 StudentRowMapper 中，我們可以依照下面的方式來實作 mapRow() 方法，這樣子就可以將資料庫中查詢出來的 id 和 name 的欄位，轉換成是 Student 物件中的 id 和 name 變數的值了。\npublic class StudentRowMapper implements RowMapper\u0026lt;Student\u0026gt; { @Override public Student mapRow(ResultSet rs, int rowNum) throws SQLException { Student student = new Student(); student.setId(rs.getInt(\u0026#34;id\u0026#34;)); student.setName(rs.getString(\u0026#34;name\u0026#34;)); return student; } } 使用 query() 方法查詢數據 # 在實作完上述的 StudentRowMapper 之後，接著我們就可以回到 StudentController，並且就可以在 StudentController 裡，使用 query() 方法去執行 SELECT SQL，進而從資料庫中查詢數據出來了。\n所以我們可以在 StudentController 中，實作下列的程式：\n@RequestMapping(\u0026#34;/getStudents\u0026#34;) public List\u0026lt;Student\u0026gt; query() { String sql = \u0026#34;SELECT id, name FROM student\u0026#34;; Map\u0026lt;String, Object\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); StudentRowMapper rowMapper = new StudentRowMapper(); List\u0026lt;Student\u0026gt; list = namedParameterJdbcTemplate.query(sql, map, rowMapper); return list; } 當我們這樣子寫之後，到時候當前端來請求 /getStudents 這個 API 時，Spring Boot 程式就會去執行第 34～45 行的程式，而當 Spring Boot 執行到第 42 行程式時，就會使用 query() 方法去執行 \u0026quot;SELECT id, name FROM student\u0026quot; 的 SQL 語法，從資料庫中的 student table 中查詢數據出來，並且將查詢出來的 Student 數據，儲存在第 42 行的 List\u0026lt;Student\u0026gt; list 的變數中，最終再將這些數據返回給前端。\n因此透過這樣的實作，就可以達到「在 Spring Boot 中查詢資料庫中的數據」的效果了！\n實際測試 # 完成上述的程式之後，我們可以運行這個 Spring Boot 程式，來測試一下效果。\n成功運行 Spring Boot 程式之後，接著我們可以回到 API Tester 中，並且填上以下的請求參數：\n填寫完畢之後，就按下右側的 Send 鍵，去發起一個 Http 請求。\n而當請求成功之後，這時候往下拉的話，在下方的 response body 區塊中，就可以看到 Spring Boot 程式返回了「資料庫中的所有學生數據」給前端，因此在這裡就呈現了 3 筆數據，分別是：\nid 為 1 的 Judy id 為 3 的 John id 為 4 的 Bob 而這就和 IntelliJ 中所呈現的 student table 的數據，是一模一樣的。\n所以這就表示，我們就成功的透過了 Spring JDBC 的 query() 方法，在 Spring Boot 中執行 SELECT SQL 語法，從資料庫中查詢數據出來了！因此後續我們就可以透過這種寫法，從資料庫中查詢想要的數據出來了。\n補充：除了上述最基礎的 query() 的用法之外，大家也可以試試看像上一篇文章一樣，去修改 SQL 語法、以及在 map 參數中添加相關的變數的值，這樣就可以根據不同的查詢參數，從資料庫中查詢出指定的數據了。\nquery() 方法的用法總結 # 所以總結來說，如果想要使用 query() 方法，在 Spring Boot 中執行 SELECT SQL 語法的話，那麼就只要在 query() 方法中，按照順序填入以下三個參數：\nsql 參數： 放想要執行的 SQL 語法 map 參數： 動態的決定 SQL 變數中的值 rowMapper 參數： 將資料庫中查詢出來的數據，轉換成 Java object（物件） 這樣子就可以在 Spring Boot 中，去執行你想要執行的 SELECT SQL 語法了！\n總結 # 在這篇文章中，我們介紹了 Spring JDBC 中的 query() 的基本用法，了解要如何透過 query() 方法，在 Spring Boot 程式中執行 SELECT SQL 語法，進而從資料庫中查詢數據出來，最終再返回給前端。\n在了解了 Spring JDBC 中的兩大核心用法 update() 和 query() 之後，基本上就可以涵蓋大多數的日常開發了，因此下一篇文章，我們會延伸去介紹軟體工程中的一個很重要的概念，也就是「MVC 架構模式」，那我們就下一篇文章見啦！\n補充：本文是擷取自我開設的線上課程 Java 工程師必備！Spring Boot 零基礎入門 的內容，如果你想了解更多的 Spring Boot 的用法，歡迎參考課程簡介 （輸入折扣碼「HH202601KU」即可享 85 折優惠）。\n","permalink":"https://kucw.io/blog/springboot/27/","tags":null,"title":"Spring Boot 零基礎入門 (27) - Spring JDBC 的用法（下）- 執行 SELECT SQL"},{"categories":["Spring Boot"],"contents":"哈囉大家好，我是古古。\n在上一篇文章中，我們有在 Spring Boot 中載入了 Spring JDBC 的功能，並且也有設定好了 MySQL 資料庫的連線資訊。\n那麼接著這篇文章，我們就會正式來介紹，要如何使用 Spring JDBC 的功能，在 Spring Boot 程式中執行 SQL 語法，進而去操作資料庫內部的數據。\n目錄 Spring JDBC 用法介紹 補充：怎麼背哪種 SQL 語法用哪個方法來執行？ update() 的基本用法 步驟一：注入 NamedParameterJdbcTemplate Bean 步驟二：撰寫 SQL 語法 步驟三：新增一個 Map\u0026lt;String, object\u0026gt; 的 map 變數 步驟四：使用 update() 方法 實際測試 update() 中的 map 參數用法 例子：根據前端的參數，動態的決定 SQL 中的值 前置準備 修改 SQL 語法、添加 map 變數中的值 實際測試 update() 方法的用法總結 總結 Spring JDBC 用法介紹 # 在 Spring JDBC 中，會根據 SQL 語法區分成兩大類，分別是「update 系列」和「query 系列」。\n在 update 系列的方法中，可以執行 INSERT、UPDATE、DELETE 這三種 SQL 語法 而在 query 系列的方法中，只能執行 SELECT 這一種 SQL 語法 因此大家如果想要執行的是 INSERT SQL，那就是得使用 update() 方法來執行，而如果想執行的是 SELECT SQL 的話，則是得改用 query() 方法來執行。\n也因為 update() 和 query() 這兩個方法在用法上會有點差別，因此接下來我們就會分成上、下兩篇文章，分別來介紹這兩種方法的用法。\n因此在這篇文章中，我們就會先來介紹 update() 的用法。\n補充：怎麼背哪種 SQL 語法用哪個方法來執行？ # 因為在 Spring JDBC 中，INSERT、UPDATE、DELETE 這三種 SQL 語法，必須要用 update() 方法來執行，而 SELECT 這一種 SQL 語法，則是得改用 query() 方法來執行，所以大家一開始接觸的時候，可能會怕自己忘記哪種 SQL 語法要用哪個方法來執行。\n不過這個對應關係其實是不用特別背的！因為我們可以透過「方法的名稱」，去推敲出當下這個 SQL 語法要用哪種方法來執行。\n舉例來說，像是 update() 方法代表的是「更新資料庫中的數據」的意思，所以在 INSERT、UPDATE、DELETE 這三種情境中，都是廣義的表達「改變資料庫中儲存的數據」的含義。\nINSERT：在資料庫中「新增」一筆數據 UPDATE：在資料庫中「修改」一筆已存在的數據 DELETE：在資料庫中「刪除」一筆數據 因此對於 INSERT、UPDATE、DELETE 這三種 SQL 語法，就都可以使用 update() 方法來執行。\n而同樣的道理，因為另一個 query() 方法代表的是「查詢資料庫中的數據」的意思，所以他就會去對應到 SELECT 這一種 SQL 語法，專門去查詢資料庫中的數據。因此針對 SELECT SQL，就是只能使用 query() 方法來執行。\n所以大家以後在使用 Spring JDBC 時，就不用特別背誦哪種 SQL 要用哪一個方法來執行，只要直接從方法名稱上去推敲就可以了！\nupdate() 的基本用法 # 大概了解了 update() 和 query() 方法之間的差別之後，接著我們就可以來詳細介紹一下，要如何使用 update() 方法去執行 INSERT、UPDATE、DELETE 這三種 SQL 語法。\n要使用 update() 方法去執行 INSERT、UPDATE、DELETE 這三種 SQL 語法的話，可以分成四個步驟來實作：\n步驟一：注入 NamedParameterJdbcTemplate Bean # 使用 update() 的第一步，就是要先在你的 Bean 裡面，去注入 NamedParameterJdbcTemplate 進來。\n因此我們就可以在 StudentController 中，先使用 @Autowired，去注入 NamedParameterJdbcTemplate 這個 Bean 進來（如下圖中的第 14～15 行所示）。\n@Autowired private NamedParameterJdbcTemplate namedParameterJdbcTemplate; 而我們之所以可以直接在 StudentController 中去注入 NamedParameterJdbcTemplate 這個 Bean，就是因為這個 Bean 是由 Spring JDBC 自動幫我們生成的 Bean，他會負責去處理和資料庫溝通的所有事項，因此後續我們就可以透過 NamedParameterJdbcTemplate，去執行想要執行的 SQL 語法了。\n所以簡單來說，當我們在使用 Spring JDBC 的功能時，其實很大部分的時間都是在和 NamedParameterJdbcTemplate 打交道，即是學習要如何使用 NamedParameterJdbcTemplate 中所提供的 update() 和 query() 方法，去執行我們想執行的 SQL 語法。\n步驟二：撰寫 SQL 語法 # 在 StudentController 中注入好 NamedParameterJdbcTemplate 進來之後，接著第二步，就是去寫出我們想要執行的 SQL 語法。\n所以我們可以先在 StudentController 中創建一個 String 類型的變數 sql，並且在裡面寫上我們想要執行的 SQL 語法（如下圖中的第 20 行所示）。\n舉例來說，下方就是將一條 INSERT SQL 的語句，儲存在 sql 的變數裡面，而這條 INSERT SQL 的用途，就是「在 student table 中插入一筆 id 為 3、並且 name 為 John」的數據。因此到時候當 Spring JDBC 去執行這條 SQL 時，就會在 student table 中插入 John 這筆新數據。\nString sql = \u0026#34;INSERT INTO student(id, name) VALUES (3, \u0026#39;John\u0026#39;)\u0026#34;; 步驟三：新增一個 Map\u0026lt;String, object\u0026gt; 的 map 變數 # 撰寫完想要執行的 SQL 語句之後，接著第三步，就是去新增一個類型為 Map\u0026lt;String, object\u0026gt; 的 map 變數出來。\n因此就可以在 StudentController 中添加下方的程式（如下圖中的第 22 行所示）：\nMap\u0026lt;String, Object\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); 補充：我們後續就會介紹這個 map 變數的用途了，因此目前就先照抄即可。\n步驟四：使用 update() 方法 # 當前面的步驟都完成之後，最後要做的第四部，就是去使用 namedParameterJdbcTemplate 中的 update() 方法，並且把上面所宣告的 sql 和 map 這兩個變數，依照順序傳進去 update() 方法裡面（如下圖中的第 24 行所示）。\nnamedParameterJdbcTemplate.update(sql, map); 只要完成了這四個步驟，我們就完成了 Spring JDBC 的實作了！\n因此到時候當 Spring Boot 執行到第 24 行的 update() 方法時，就會去執行我們所指定的 SQL 語法（即是執行 sql 變數中所儲存的 SQL 語法，INSERT INTO student(id, name) VALUES (3, 'John')），所以最終 Spring Boot 就可以成功的在 student table 中，插入這筆 John 的新數據了！\n實際測試 # 完成上述的程式之後，我們可以來運行這個 Spring Boot 程式，測試一下他的效果。\n成功運行 Spring Boot 程式之後，接著就回到 API Tester 中，並且填入以下的請求參數：\n填寫完畢之後，接著按下右側的 Send 鍵，就可以去發起一個 Http 請求。\n而在請求成功之後，就可以回到 IntelliJ 上，然後點開右側的資料庫圖示，並且開啟 student table。\n這時在 student table 中，就可以看到多出了一筆「id 為 3、並且 name 為 John」的數據。\n所以這就表示，我們就成功的透過了 Spring JDBC 的 update() 方法，在 Spring Boot 中執行 INSERT SQL 的語法，進而新增一筆數據到資料庫中了！\n而在我們練習完 update() 方法的基本用法之後，接下來我們也可以來介紹一下，前面我們所創建的 Map\u0026lt;String, object\u0026gt; map 變數，他的用途為何。\nupdate() 中的 map 參數用法 # 在上面的「步驟三：新增一個 Map\u0026lt;String, object\u0026gt; 的 map 變數」小節裡，我們當時有先創建了一個 map 變數（下圖中的第 22 行），並且當時告訴大家先照抄就好，不過現在我們就可以回頭來介紹這個 map 變數的用法了。\n這個 map 變數的用途，是用來「放置 SQL 語法中的變數的值」，這句話聽起來可能有點抽象，所以我們可以直接透過一個例子，來了解一下 map 變數的用法為何。\n例子：根據前端的參數，動態的決定 SQL 中的值 # 在上面那段程式中，我們是直接寫死一條 SQL 語法 INSERT INTO student (id, name) VALUES (3, 'John') 在程式裡面，因此不管前端傳了什麼參數過來，我們始終都只能夠在資料庫中，去新增一筆「id 為 3、並且 name 為 John」的數據。\n不過這樣子的寫法非常的不彈性，如果我們想要改成是去新增一筆「id 為 4、name 為 Bob」的數據的話，那麼就得先停止 Spring Boot 程式，修改這一行 SQL 語法，然後再重新運行 Spring Boot 程式，在實作上就會變得非常麻煩。\n因此，假設我們想要「動態的決定」當前 SQL 語法中的值的話，那就需要依靠 map 這個變數來幫忙了!\n前置準備 # 為了練習 map 變數的用途，首先我們得先做一些前置準備，去接住前端傳過來的參數。\n因此大家可以先創建一個 Student class，並且在裡面創建兩個變數 id 和 name，程式如下：\npublic class Student { private Integer id; private String name; public Integer getId() { return id; } public void setId(Integer id) { this.id = id; } public String getName() { return name; } public void setName(String name) { this.name = name; } } 接著在 StudentController 裡，在第 19 行的 insert() 方法的實作中，添加 @RequestBody 註解，後續就可以使用 @RequestBody 去接住前端傳過來的參數。\n補充：不熟悉 @RequsetBody 的用法的話，可以回頭參考 Day 19 - 取得請求參數（上）- @RequestParam、@RequestBody 的介紹。\n修改 SQL 語法、添加 map 變數中的值 # 使用了 @RequestBody 接住前端傳來的變數之後，接著我們就可以將前端傳過來的 id 和 name 的值，去放到 map 變數裡面，這樣後續就可以插入這筆新的數據到資料庫中了。\n因此此處有兩個地方需要修改：\n首先是第 19 行的 SQL 語法，要將 (3, John) 的程式，改寫成 (:studentId, :studentName)。\nString sql = \u0026#34;INSERT INTO student(id, name) VALUES (:studentId, :studentName)\u0026#34;; 接著需要在 map 變數下方，添加第 24、25 行的程式，也就是在 map 變數中新增兩組 key-value 的值。\nmap.put(\u0026#34;studentId\u0026#34;, student.getId()); map.put(\u0026#34;studentName\u0026#34;, student.getName()); 在這些改動中，首先我們先將 SQL 語法從 (3, John) 改寫成是 (:studentId, :studentName)，而只要在 SQL 語法中加上了「:」，就表示這是一個「SQL 中的變數」。\n舉例來說，像是 :studentId，就表示我們指定這是一個 SQL 中的變數，名字叫做 studentId。\n至於後面的 :studentName，就是表示我們指定另一個 SQL 中的變數，名字叫做 studentName。\n因此我們就可以透過這個邏輯，在同一句 SQL 語法裡面，添加無數個 SQL 中的變數了。\n而在 SQL 語法中的 :studentId、:studentName 這些變數，我們後續就可以使用第 23 行的 map，來指定這些變數的值為多少。因此在使用 map 變數時，前面要放的是「SQL 變數的名字」，後面放的則是「這個 SQL 變數的值是多少」。\n舉例來說，假設我們想要指定 :studentId 的值為 5 的話，那麼就可以寫成：\nmap.put(\u0026#34;studentId\u0026#34;, 5); 如果我們想要指定 :studentId 的值為「前端傳過來的 id 的值」的話，那麼就可以寫成是：\nmap.put(\u0026#34;studentId\u0026#34;, student.getId()); 因此透過 map 變數，我們就可以動態的去決定 SQL 中的變數的值，進而實作出「動態的決定要插入的數據為何」的效果了！\n補充：如果看到這裡仍舊覺得思緒有點亂、不太了解 map 的具體用法的話，建議可以先直接往下看後面的「實際測試」的部分，實際的用 API Tester 和 Spring Boot 程式來搭配練習，慢慢的就能夠掌握 map 的用法了。\n實際測試 # 完成上述的程式之後，需要先重新運行一下 Spring Boot 程式，等到重新運行成功之後，再回到 API Tester 中進行後面的測試。\n在 API Tester 中，我們要修改 request body 的部分，改成填入以下的參數，表示要插入一筆「id 為 4、 name 為 Bob」的數據到資料庫。\n修改好之後，就按下右邊的 Send 鍵，去發出一個 Http 請求。在請求成功之後，就可以回到 IntelliJ 上，然後開啟右邊側邊欄中的 student table 查看一下數據。\n這時候在 student table 中，就可以看到多出了一筆「id 為 4、並且 name 為 Bob」的數據。\n因此這就表示，我們就成功的透過了 update() 方法的 map 參數，動態的去決定 SQL 語法中的變數了！所以後續我們就可以根據前端所傳遞過來的參數，動態的在資料庫中插入不同的數據了，這也是實務上非常常見的作法，建議大家也可以多練習幾次，加深這邊的實作印象。\nupdate() 方法的用法總結 # 所以總結上述的介紹，如果想要使用 update() 方法，在 Spring Boot 中執行 INSERT、UPDATE、 DELETE 這三種 SQL 語法的話，那麼就只要在 update() 方法中，按照順序填入以下兩個參數：\nsql 參數： 放想要執行的 SQL 語法 map 參數： 動態的決定 SQL 變數中的值 這樣子就可以在 Spring Boot 中，去執行你想要執行的 INSERT、UPDATE、DELETE 的 SQL 語法了!\n總結 # 在這篇文章中，我們先去介紹了 Spring JDBC 中的 update() 的基本用法，並且也有深入介紹 update() 中的 map 參數用法，因此大家以後就可以透過這個寫法，在 Spring Boot 程式中去執行 INSERT、UPDATE、DELETE 這三種 SQL 語法了。\n那麼下一篇文章，我們就會接著來介紹 Spring JDBC 中的另一個核心方法，也就是 query() 方法，那我們就下一篇文章見啦！\n補充：本文是擷取自我開設的線上課程 Java 工程師必備！Spring Boot 零基礎入門 的內容，如果你想了解更多的 Spring Boot 的用法，歡迎參考課程簡介 （輸入折扣碼「HH202601KU」即可享 85 折優惠）。\n","permalink":"https://kucw.io/blog/springboot/26/","tags":null,"title":"Spring Boot 零基礎入門 (26) - Spring JDBC 的用法（上）- 執行 INSERT、UPDATE、DELETE SQL"},{"categories":["Spring Boot"],"contents":"哈囉大家好，我是古古。\n在上一篇文章中，我們先介紹了 Spring JDBC 的用途是什麼，先讓大家對 Spring JDBC 有一個簡單的認識。\n那麼接著這篇文章，我們就會實際的去創建一個資料庫，並且將 Spring Boot 程式連線到此資料庫上，同時也會補充要如何運用 IntelliJ 中的好用工具，去管理資料庫中的數據（僅限 IntelliJ 付費版才有此功能），所以我們就開始吧！\n目錄 回顧：什麼是 Spring JDBC？ 在 Spring Boot 中設定資料庫連線資訊 在 pom.xml 中載入 Spring JDBC 的功能 在 application.properties 中設定資料庫連線資訊 補充：IntelliJ 中的資料庫管理工具（僅限 IntelliJ 付費版） 在 IntelliJ 中添加 MySQL 資料庫連線 創建 myjdbc database 創建 student table 查看 student table 中的數據 總結 回顧：什麼是 Spring JDBC？ # Spring JDBC 的用途，就是「讓我們能夠在 Spring Boot 中執行 SQL 語法，進而去存取資料庫中的數據」，因此我們之後就可以透過 Spring JDBC 的功能，在 Spring Boot 中執行資料庫的 SQL 語法，因此就可以在資料庫中執行查詢數據、新增數據…等等的操作了！\n在 Spring Boot 中設定資料庫連線資訊 # 在 pom.xml 中載入 Spring JDBC 的功能 # 如果想要在 Spring Boot 中使用 Spring JDBC 的功能的話，首先會需要在 pom.xml 檔案中新增下方的程式，這樣才能夠將 Spring JDBC 的功能、以及 MySQL 資料庫的 driver 給載入進來。\n因此大家可以先打開左邊側邊欄中的 pom.xml 檔案，然後在第 29 行～第 37 行的地方，添加下面的程式：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-jdbc\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.mysql\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mysql-connector-j\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;8.0.33\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 添加好上述的程式之後，此時在 pom.xml 的右上角會出現一個 M 符號，這時記得要點擊一下這個 M 符號，這樣才能夠更新 Spring Boot 程式，把 Spring JDBC 的功能、以及 MySQL 資料庫的 driver，一起給載入進來。\n補充：如果大家在其他的 Spring Boot 專案中使用的是其他的資料庫（ex: PostgreSQL、SQL Server），則上圖中的第 33 行～第 37 行需要改成該資料庫的 driver。\n在 application.properties 中設定資料庫連線資訊 # 載入好 Spring JDBC 和 MySQL 的 driver 之後，接著我們就可以在 Spring Boot 中設定 MySQL 資料庫的連線，這樣我們後續就能夠在 Spring Boot 程式裡面，去操作 MySQL 資料庫中的數據了。\n而要在 Spring Boot 中設定資料庫的連線資訊的話，就只要先打開 application.properties 檔案，並且在裡面添加下列的程式，這樣就能完成 MySQL 資料庫的連線設定了！\nspring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver spring.datasource.url=jdbc:mysql://localhost:3306/myjdbc?serverTimezone=Asia/Taipei\u0026amp;characterEncoding=utf-8 spring.datasource.username=root spring.datasource.password=springboot 補充：application.properties 檔案是 Spring Boot 的設定檔，用來存放 Spring Boot 中的設定值。如果有點忘記 application.properties 的用法的話，也可以回頭參考 Day 10 - 讀取 Spring Boot 設定檔 - @Value、application.properties 的介紹。\n在 application.properties 檔案中添加好上述的程式之後，我們也可以分別來介紹一下，這四行程式的用途是什麼：\nspring.datasource.driver-class-name\nspring.datasource.driver-class-name 是表示「要使用的是哪種資料庫的 driver」，此處我們填寫的即是 MySQL 的 driver。\nspring.datasource.url\nspring.datasource.url 是表示「要連接到哪台資料庫上」。像是前面的 jdbc:mysql://localhost:3306 是表示要連接到我們自己電腦上的 MySQL 資料庫，而後面跟著的 /myjdbc，則是指定要連線到 MySQL 資料庫中的 myjdbc database。\n並且在 myjdbc 後面的 ? 中，我們也有加上兩個參數：\n其中 serverTimezone=Asia/Taipei 是表示我們指定時區為台北時區 而 characterEncoding=utf-8 則表示我們所使用的編碼是 utf-8，這樣後續在處理中文時，才不會出現亂碼 spring.datasource.username\nspring.datasource.username 是要我們填入 MySQL 資料庫中的帳號，此處就填上預設的帳號 root。\nspring.datasource.password\nspring.datasource.password 則是要我們填入上面那個帳號的密碼，因此此處就填上 springboot（這裡所填上的密碼 springboot，其實就是我們一開始在安裝 MySQL 時，所設定的那組密碼。當時有建議大家可以和此系列文一樣設定為 springboot，不過如果你所當初不是使用 springboot 當作密碼，那麼這裡即是填入你當時所設定的密碼）。\n在了解了這四行程式所代表的意義、並且也有在 application.properties 檔案中設定好這四行程式之後，這樣 Spring Boot 到時候就會去根據這四行程式，去連線到我們所指定的資料庫了！\n所以到目前為止，大家只要先完成 application.properties 的設定即可，有關 Spring JDBC 的用法，我們在下一篇文章會繼續介紹。\n補充：IntelliJ 中的資料庫管理工具（僅限 IntelliJ 付費版） # 在設定好 application.properties 中的資料庫連線之後，其實我們就可以使用 Spring JDBC 的功能，在 Spring Boot 中操作 MySQL 資料庫中的數據了。\n不過，在我們正式進入到 Spring JDBC 的用法介紹之前，這裡先和大家補充一個 IntelliJ 中的好用工具，這個工具可以讓我們直接透過 IntelliJ 中的介面，去管理資料庫中的數據，可以為將來我們的 Spring JDBC 開發，提供非常大的幫助！\n補充：不過此工具僅限 IntelliJ Ultimate（付費版）可以使用，因此大家如果是使用 IntelliJ Community（社群版）的話，就無法啟用此功能，只能使用其他的資料庫管理工具（ex: MySQL Workbench），實時的去查看資料庫中的數據。\n在 IntelliJ 中添加 MySQL 資料庫連線 # 如果要直接透過 IntelliJ 去管理 MySQL 資料庫中的數據的話，就只要點擊 IntelliJ 右側的資料庫圖示，就可以開啟 IntelliJ 中的資料庫管理工具。\n接著可以點擊上方的 + 號，去新增一個 MySQL 資料庫的連線，連線到安裝在我們電腦中的 MySQL 資料庫。\n開啟設定的視窗之後，就先在 User 處填上 root，並且在 Password 處填上 springboot（此密碼即是當初安裝 MySQL 時設定的密碼）。\n填寫完成之後，可以先試著點擊左下角的「Test Connection」按鈕，先測試一下 MySQL 資料庫的連線，這裡只要出現 Succeeded 就表示連線成功！\n測試成功之後，記得要再重新輸入一次 Password 的值 springboot（因為會被 IntelliJ 清掉），然後再按下右下角的 OK 保存即可。\n按下 OK 之後，這時候 IntelliJ 就成功的連線到 MySQL 資料庫了，而此時 IntelliJ 就會跳出一個 console 的視窗，讓我們在裡面撰寫 SQL 語法。\n所以後續我們就可以在這個 console 中撰寫 SQL 語法，就可以直接在 IntelliJ 中存取資料庫中的數據了。\n創建 myjdbc database # 將 IntelliJ 連線好 MySQL 資料庫之後，接著我們可以試著在資料庫中創建一個新的 database 出來。\n因此我們可以在 console 中添加下方的 SQL 語法，嘗試在 MySQL 資料庫中創建 myjdbc database。\nCREATE DATABASE myjdbc 寫好之後，只要按下左上方的「播放鍵」，就可以去執行這條 SQL 語法。\n當這條 SQL 語法執行成功之後，在右側的視窗就會出現 myjdbc 的 database 資訊了！因此這就表示我們成功的在 MySQL 裡面，創建了一個 myjdbc database 出來了。\n補充：如果在右邊的 Database 側邊欄中沒有看到 myjdbc database 的話也不用緊張，這時只要點擊右上角的「0 of 5」，然後勾選 myjdbc，這樣子 myjdbc 這個 database 就會出現在右邊的側邊欄了。\n創建 student table # 我們除了能夠在 console 中創建 myjdbc database 之外，我們也是可以在這個 console 中執行「創建 table」的 SQL 語法，在 myjdbc database 中創建一個新的 table 出來的。\n要在 myjdbc database 中創建一個新的 table 的話，首先要先點擊右上方的 \u0026lt;schema\u0026gt; 按鈕，且選擇 myjdbc，這樣子才能夠切換到 myjdbc database，確保我們後續所執行的 SQL 語法，真的是在 myjdbc database 中執行。\n切換好之後，接著我們可以在 console 中添加以下的 SQL 語法，去創建一個 student table 出來。\nCREATE TABLE student ( id INT PRIMARY KEY , name VARCHAR(30) ) 添加好這段 SQL 之後，只要反白這段 SQL 語法，接著再按下播放鍵，這樣蓻就可以去執行這一段 SQL 語法，在 myjdbc database 中去創建一個 student table 出來了！\n因此在執行完成之後，在右邊的側邊欄中，就會出現 student table 的資訊了。\n查看 student table 中的數據 # 創建好 student table 之後，這時只要使用滑鼠左鍵，對著右邊側邊欄中的 student table 點擊兩下，就可以開啟這個 student table，去查看該 table 中的數據。\n所以像是目前在 student table 中，就沒有任何一筆數據存在，是一張空的 table。\n但是如果我們回到 console 上，然後添加下面這行 INSERT SQL，並且去執行這一條 SQL 語法，在 student table 中插入一筆 Judy 的數據的話：\nINSERT INTO student(id, name) VALUES (1, \u0026#39;Judy\u0026#39;) 那麼這時候再回到 student table 中，並且點擊「重新整理」的按鈕之後，就可以看到 student table 中多出一筆 Judy 的數據出來了！\n因此透過 IntelliJ 所提供的資料庫工具，我們後續就可以直接在 IntelliJ 中查看和修改資料庫中的數據了！所以我們之後就只需要使用 IntelliJ 這套軟體，就可以完成大部分的後端開發了，讚！\n補充：IntelliJ 真的是很強大的軟體，大家有興趣的話，也可以玩玩 IntelliJ 的用法，摸熟之後就可以提升開發的效率了！\n總結 # 這篇文章我們先介紹了如何在 Spring Boot 中載入 Spring JDBC 的功能，並且也介紹了 application.properties 中的程式設定的含義，最後也補充了 IntelliJ 所提供的好用的資料庫管理工具，因此後續我們就可以透過這個工具，去管理資料庫中的數據了。\n那麼下一篇文章，我們就會正式來介紹 Spring JDBC 的用法，也就是會來介紹要如何在 Spring Boot 程式中執行 SQL 語法，進而去操作資料庫中的數據，那我們就下一篇文章見啦！\n補充：本文是擷取自我開設的線上課程 Java 工程師必備！Spring Boot 零基礎入門 的內容，如果你想了解更多的 Spring Boot 的用法，歡迎參考課程簡介 （輸入折扣碼「HH202601KU」即可享 85 折優惠）。\n","permalink":"https://kucw.io/blog/springboot/25/","tags":null,"title":"Spring Boot 零基礎入門 (25) - 資料庫連線設定、IntelliJ 資料庫管理工具介紹"},{"categories":["Spring Boot"],"contents":"哈囉大家好，我是古古。\n在前面的文章中，我們介紹了 Spring MVC 中的許多特性，因此大家現在就可以在 Spring Boot 中，透過 Spring MVC 和前端進行溝通了。\n而在了解了如何和前端溝通之後，在接下來的文章中，我們就會來介紹另一個也很重要的部分，即是如何透過 Spring JDBC，去和「資料庫」進行溝通，所以我們就開始吧！\n目錄 回顧：前端和後端的差別、Spring MVC 負責的部分 什麼是 Spring JDBC？ 補充一：Spring JDBC 和 Spring Data JPA 的差別在哪裡？ 補充二：什麼是 CRUD？ 總結 回顧：前端和後端的差別、Spring MVC 負責的部分 # 在前面的文章中我們曾經提到，在現今的網站架構中，前端是負責進行排版設計，後端則是負責數據處理。而前端除了設計網頁的排版之外，同時也需要去問後端：「這裡應該要呈現哪些商品？」，這樣前端才能夠將數據和排版結合再一起，最後再將結果呈現給使用者看。\n也因為如此，所以在上一個 Spring MVC 的部分中，我們就都是在介紹：要如何透過 Spring MVC 去和「前端」溝通。\n但是這些商品的數據，我們總是得在後端程式中找個地方來儲存，因此後端通常就會將這些商品數據，存放在「資料庫」裡面。 所以後續當前端來詢問：「這裡要呈現哪些商品？」時，後端就可以從資料庫中查詢商品數據，接著再將這些商品的數據返回給前端。\n所以在接下來的 Spring JDBC 的部分中，我們就是要來介紹，要如何透過 Spring JDBC，去和「資料庫」溝通，進而存取資料庫中的數據。\n什麼是 Spring JDBC？ # 大概了解了 Spring JDBC 的用途之後，接著我們可以回頭來看一下 Spring JDBC 的定義。\nSpring JDBC 的用途，就是「讓我們能夠在 Spring Boot 中執行 SQL 語法，進而去存取資料庫中的數據」，因此我們之後就可以透過 Spring JDBC 的功能，在 Spring Boot 中執行資料庫的 SQL 語法，所以就可以透過這些 SQL，在資料庫中執行查詢數據、新增數據\u0026hellip;等等的操作了！\n補充：因此在閱讀後續的文章時，建議大家一定要預先了解資料庫的 SQL 語法，這樣子才會比較好上手。\n補充一：Spring JDBC 和 Spring Data JPA 的差別在哪裡？ # 在上面的那張圖中，大家可能有發現在上方的紅字中，不僅出現了「Spring JDBC」的文字，也出現了「Spring Data JPA」的文字（如下圖黃底處所示）。\n其實「在 Spring Boot 中操作資料庫數據」這件事，是有許多工具可以選擇的！\n像是在 Spring Boot 中，常見的操作資料庫的工具有：\nSpring JDBC MyBatis Spring Data JPA Hibernate \u0026hellip;等等 而在這些操作資料庫的工具中，又可以將他們分成兩類：\n在 Spring Boot 中執行 SQL 語法，使用 SQL 語法操作資料庫\n這一類的工具，就是直接在 Spring Boot 中執行原始的 SQL 語法，然後透過這些 SQL 語法去新增或是修改資料庫中的數據。Spring JDBC 和 MyBatis 都屬於這一類。\n使用 ORM 的概念操作資料庫\n這一類的工具，則是會透過 ORM（Object Relational Mapping）的概念，在 Spring Boot 操作資料庫。因此在使用這類的工具時，基本上就很少寫 SQL 語法了，反而是會使用 ORM 的概念，去存取資料庫的數據。Spring Data JPA 和 Hibernate 都屬於這一類。\n所以回到最一開始的問題：「Spring JDBC 和 Spring Data JPA 的差別在哪裡？」的話，簡單來說，Spring JDBC 是透過執行 SQL 語法去操作資料庫，而 Spring Data JPA 則是透過 ORM 的概念去操作資料庫。\n也因為這兩種概念差異比較大，因此在此系列文中只會介紹 Spring JDBC 的部分，而不會介紹 Spring Data JPA 的用法。如果大家後續對 Spring Data JPA 有興趣，也可以再上網查詢相關的資料。\n補充二：什麼是 CRUD？ # 其實在前面的 Day 22 - RESTful API 實作 - @GetMapping、@PostMapping\u0026hellip; 文章中，我們曾經短暫的提到過 CRUD 這個關鍵字，不過當時我們沒有針對 CRUD 進行太多的介紹，因此這裡我們可以正式的來介紹一下，CRUD 所代表的含義是什麼。\nCRUD 所代表的，是資料庫中的「Create（新增）、Read（查詢）、Update（修改）、Delete（刪除）」這四個操作的統稱，用來表示資料庫中最基礎的行為。\n而這四個操作之所以會簡稱為 CRUD，是因為如果我們把這四個操作擺成直排來看的話，就會發現 CRUD 這個單字，只是各取他們的第一個英文字母來簡稱而已。\nCreate（新增） Read（查詢） Update（修改） Delete（刪除） 之所以說 CRUD 是資料庫中最基礎的實作，是因為不管我們想要實作什麼功能（ex: 商品功能），我們通常都得去實作數據的「新增、查詢、修改、刪除」這四個操作，因此實作 CRUD 可以說是後端工程師必備的基礎能力！建議大家一定要好好掌握才行。\n總結 # 這篇文章我們先回顧了前端和後端之間的區別，接著也介紹了 Spring JDBC 的用途是什麼，以及補充 Spring JDBC 和 Spring Data JPA 的差異在哪裡，讓大家先對 Spring JDBC 有一個簡單的認識。\n那麼下一篇文章，我們就會接著來介紹，要如何透過 Spring JDBC 的功能，在 Spring Boot 中設定資料庫的連線資訊，那我們就下一篇文章見啦！\n補充：本文是擷取自我開設的線上課程 Java 工程師必備！Spring Boot 零基礎入門 的內容，如果你想了解更多的 Spring Boot 的用法，歡迎參考課程簡介 （輸入折扣碼「HH202601KU」即可享 85 折優惠）。\n","permalink":"https://kucw.io/blog/springboot/24/","tags":null,"title":"Spring Boot 零基礎入門 (24) - Spring JDBC 簡介"},{"categories":["Spring Boot"],"contents":"哈囉大家好，我是古古。\n在上一篇文章中，我們有介紹要如何去設計和實作 RESTful API，因此大家就可以透過前面所學到的內容，實際的在 Spring Boot 中實作出 RESTful API 出來了。\n那麼接著這篇文章，我們就會回頭來介紹一下 Http response 中也很重要的一個部分，也就是 Http status code（Http 狀態碼），所以我們就開始吧！\n目錄 什麼是 Http status code（Http 狀態碼）？ Http status code 中的分類 常見的 Http status code 1xx：資訊 2xx：成功（200、201、202） 3xx：重新導向 4xx：前端請求錯誤 5xx：後端處理有問題 常用的 Http status code 總結 總結 什麼是 Http status code（Http 狀態碼）？ # Http status code 又稱為 Http 狀態碼，他是屬於 Http response 的一部分，而 Http status code 的用途，就是「用來表示這次 Http 請求的結果為何」。\n所以簡單來說，Http status code 就是會透過一個簡短的數字，呈現這一次請求結果為何，因此前端就可以透過 Http status code，快速的知道這一次的 Http 請求是成功還是失敗了。\nHttp status code 中的分類 # 在 Http status code 的世界中，可以根據「首位數字」，分成 5 個大類，分別是：\n1xx：資訊 2xx：成功 3xx：重新導向 4xx：前端請求錯誤 5xx：後端處理有問題 而在每一個大類中，可以再去細分出更多的 Http status code 出來。不過其實只要在同一個大類中的 Http status code，他們的意思都是類似的！\n舉例來說，只要是 2 開頭的 Http status code，不管你是 200、201、還是 202\u0026hellip;等等，只要你是 2 開頭，就都是屬於「2xx」那一個大類，也就是表示「成功」的意思。\n像是我們之前在 API Tester 中發起 Http 請求時，就會看到 Spring Boot 回傳了「200」的 Http status coe 給我們。而這個「200」，就是屬於「2xx」的大類，也就是表示「請求成功」的意思。\n所以透過 Http status code 的簡短數字，我們就可以快速的知道這一次 Http 請求的結果為何了！\n常見的 Http status code # 大概了解了 Http status code 的用途之後，接下來我們就詳細的來介紹一下，每一個大類底下都有哪些常見的 Http status code。\n補充：因為 Http status code 的數量還滿多的，因此這邊只會列出比較常見的 Http status code，如果大家在工作上遇到比較罕見的 Http status code 時，可以再上網查詢一下相關的含義。\n1xx：資訊 # 首先我們先從 1 開頭的大類開始看起，1 開頭的 Http status code 代表的是「取得資訊」的意思。\n不過因為在實際的應用中，1 開頭的 Http status code 非常少用，因此在這個大類中，就沒有常見的 Http status code。\n2xx：成功（200、201、202） # 看完了 1 開頭的大類，接著我們可以看 2 開頭的大類。\n2 開頭的 http status code 所代表的，就都是「請求成功」的意思。 而 2 開頭的 Http status code，他們在使用上可以說是非常頻繁了，常見的有以下三個：\n200 OK # 首先第一個是 200 OK，200 所代表的，就是「這一次的 Http 請求成功了」。\n200 可以說是使用最廣泛的一個 Http status code，通常只要看到 200，就表示這一次的請求成功了（特殊情境例外），因此 200 可以說是工程師裡面的天使等級的角色。\n201 Created # 接著是 201 Created，201 所代表的，不僅是這一次的 Http 請求成功而已，他還額外表示「有一個新的資源成功的被創建了」的含義。\n也因為 201 除了表示請求成功之外，還多表示了「創建資源成功」的含義，因此 201 通常會被用在 POST 請求的 response 中（因為 REST 風格中的 POST 就是對應到資料庫的創建操作）。\n202 Accepted # 最後一個則是 202 Accepted，202 所代表的，是「這一次的請求已經被接受了，但是尚未處理完成」。 因此大家可以把 202 想像成是「你拜託別人去買東西，但是他還在買的路上，還沒幫你買好」這樣。\n所以當大家以後看到 202 時，就表示後端已經開始處理這件事情了，只是他目前還沒處理完成，因此先返回一個 202 給你，告知你需要再等待一段時間才能完成。\n補充：每一個 Http status code 其實都會有一個專屬的英文短語，用來表達這個 Http status code 的意思，像是 200 他所對應的英文短語是「OK」，而 202 所對應的短語是「Accepted」。\n而這個短語的用途，其實就只是簡短的去描述這個 Http status code 是什麼意思而已，目的是為了幫助工程師了解這個 Http status code 的含義是什麼，因此當大家遇到不熟悉的 Http status code 時，也可以參考他的短語描述。\n3xx：重新導向 # 看完了 2 開頭的 Http status code，接著我們可以來看 3 開頭的大類。\n3 開頭的 http status code 所代表的，都是「重新導向」的意思。 而在 3 開頭的大類中，常見的有以下兩個：\n301 Moved Permanently # 首先是 301 Moved Permanently，301 所代表的，是「這個 url 永久性的搬家了」，注意這裡的重點是 「永久性」。\n所以當前端去請求某個 API，但是該 API 返回 301 時，就是表示這個 API 搬家了。並且後端在回傳 301 時，通常會將新的 url 放在 response header 中的 Location 中，告訴我們新的搬家地址在哪，因此前端就可以改成去請求新的 url，進而訪問搬家後的網址了。\n舉例來說，我之前在架設個人網站時，就有從 https://kucw.github.io 搬家到 https://kucw.io，所以現在如果請求舊的 https://kucw.github.io 網站的話，GitHub 就會返回 301 的 Http status code，告訴前端這個網站已經永久性的搬家了，並且 GitHub 也會將新家的網址（也就是 https://kucw.io）放在 response header 中的 Location 中，因此前端就可以改成去請求新的 url https://kucw.io，進而去訪問搬家後的網址了。\n所以當 url 永久性的搬家時，後端就可以返回 301 的 Http status code，用來表示這種情況。\n302 Found # 而至於 302 Found，他就和 301 有點細微的差別。302 所代表的，則是「這個 url 暫時性的搬家」，注意這裡的重點是 「暫時性」。\n所以假設某個 API 只是「暫時性」的搬家的話（ex: 這個 API 的功能目前正在調整中），那麼後端就可以回傳 302 的值給前端，並且臨時的 url 放在 response header 的 Location 中，因此前端就可以改成去請求臨時的 url，進而訪問臨時的新網址。\n補充：所以 301 和 302 的差別，就只差在這個 url 是「永久性的搬家」還是「暫時性的搬家」而已。 如果是永久搬家，那就是回傳 301，如果只是暫時性的搬家，則是回傳 302。不過不管是回傳 301 或是 302，後端都是會將新的（臨時的）url 放在 response header 的 Location 中，供前端存取新網址。\n4xx：前端請求錯誤 # 看完了 3 開頭的大類之後，接著我們也可以繼續來看 4 開頭的 Http status code 的含義。\n4 開頭的 Http status code 所代表的，都是「前端請求錯誤」的意思。 4 開頭的大類在使用上的頻率也很高，常見的有以下四個：\n400 Bad Request # 首先是 400 Bad Request，400 所代表的，就是「前端的請求參數有錯誤」的意思。\n舉例來說，當前端在請求後端的 API 時，如果前端的請求參數名字寫錯了、或是請求參數的格式有問題\u0026hellip;等等，都可以被歸類在 400 這個 Http status code 中。\n所以大家以後只要看到 400，通常就是前端請求的參數寫錯了，因此可以回頭檢查一下請求參數的設置是否正確。\n401 Unauthorized、403 Forbidden # 再來是 401 和 403，通常他們兩個會一起介紹，因為他們是很容易被搞混的 Http staus code。\n首先 401 所代表的，是「沒有通過身份驗證」的意思。\n而 403 所代表的，則是「這一次的請求因為權限不足，所以被後端拒絕」。\n舉例來說，大家可以把 401 想像成是會員的「身份驗證錯誤」，譬如說帳密輸入錯誤時，後端就會返回 401 的錯誤給前端，告訴前端「這個人並不是我們網站的會員」。\n而 403 則是「權限不足」的意思，譬如說普通會員想要看 VIP 會員才能觀看的影片時，這時候後端就會返回 403 的錯誤給前端，告訴前端「這個會員的權限不足，所以我們不能讓他看 VIP 會員才能看的影片」。\n所以簡單來說，當大家看到 401 的時候，就是表示「這個使用者根本不是我們家的會員」，而看到 403 的時候，就表示「這個會員沒有權限執行這個功能」。 因此 401 和 403 之間的差別，要再麻煩大家留意一下，這兩個真的很容易被搞混。\n404 Not Found # 在 4 開頭的大類中，最後一個是 404 Not Found，而 404 所代表的，是「這個網頁不存在」的意思，通常就是由於 url 輸入錯誤、或是 url 失效（該資源被移走）所導致的。\n404 也是一個生活中滿常碰到的 Http status code，有時候大家在網路上看文章的時候，偶爾會遇到 404 Not Found 的錯誤，就是因為這篇文章被刪除了，導致 url 失效，因此才會出現 404 的錯誤。\n5xx：後端處理有問題 # 看完了 4 開頭的 Http status code 之後，最後我們可以來看一下 5 開頭的 Http status code 有哪些。\n5 開頭的 Http status code 所代表的，都是「後端處理有問題」的意思。 也因為 5 開頭的大類是用來表示「後端處理有問題」的情況，因此 5 開頭的 Http status code 也可以說是後端工程師最不想看見的一類（因為看見了這個，通常就表示你或你同事要加班修 bug 了🥹），常見的有以下三個：\n500 Internal Server Error # 首先是 500 Internal Server Error，500 所代表的，是「後端在處理這次請求時，發生了錯誤」，這個錯誤有可能是因為後端程式出了 bug、或是其他的原因造成的。\n500 是一個滿常見的 Http status code，通常只要看到 500，就表示是後端這邊有問題，所以後端工程師就得去檢查一下，是不是 Spring Boot 程式寫出 bug、或是伺服器出現問題\u0026hellip;等等，所以一般來說，大家都很恐懼看到 500 這個 Http status code，因為這就表示後端這邊出問題了，需要後端工程師盡快解決。\n503 Service Unavailable # 再來是 503 Service Unavailable，503 所代表的，是「臨時維護或者流量太大，所以後端目前沒有辦法處理請求」。\n因此當大家看到 503 的錯誤時，就可能是下面這兩種情況：\n瞬間流量太高，導致後端伺服器忙不過來，使得後端程式沒辦法正常運作 後端程式剛好處在維護期間 不過不管是哪一種情況，503 就都是表示後端程式目前沒辦法正常提供服務，因此前端在這段期間內，仍舊是無法正常 call API 的。\n504 Gateway Timeout # 最後一個則是 504 Gateway Timeout，504 所代表的，是「這一次的請求超時了」。\n所謂的「請求超時」，意思是「這一次 Http 請求花了太長的時間都還沒有完成，所以直接被強制結束」的意思。\n因此當大家看到 504 時，就表示後端的內部系統出了問題，沒辦法在容許的時間內執行完所有程式，所以這時後端為了避免前端等太久，就會強制結束該程式，直接返回一個 504 的錯誤給前端，避免讓前端無止盡的等待。\n常用的 Http status code 總結 # 所以總結上面的介紹的話，所謂的 Http status code，就是「用來表示這次 Http 請求的結果為何」，並且我們可以根據「首位數字」，將 Http status code 區分成 5 大類，分別是：\n1xx：資訊 2xx：成功 3xx：重新導向 4xx：前端請求錯誤 5xx：後端處理有問題 因此透過 Http Status Code，我們就可以快速的知道這一次 API 的請求結果為何了！\n下圖也統整這篇文章中所提到的 Http Status Code 給大家參考：\n總結 # 這篇文章我們先介紹了 Http status code 的用途，並且詳細介紹了 Http status code 中的五個大類，以及常見的 Http status code 有哪些。\n所以到這篇文章為止，有關 Spring MVC 的介紹就告一個段落了，在這個 Spring MVC 的部分中，我們介紹了以下內容：\n「Http 協議」和「JSON 格式」的用法，了解前後端的溝通方式有哪些 常見的 Http method（GET 和 POST）的用法 如何透過 @RequestParam、@RequestBody、@RequestHeader、@PathVariable 這四種註解，去接住前端所傳過來的參數 如何設計 RESTful API、如何在 Spring Boot 中實作 RESTful API 常見的 Http status code 有哪些 所以透過 Day 13～Day 23 的文章，我們就完成了 Spring MVC 的相關介紹了。\nSpring MVC 可以說是在 Spring Boot 開發中非常重要的一環，因為 Spring MVC 掌控了前端和後端之間的溝通，所以只要 Spring MVC 的部分沒有寫好，就會使得前端沒辦法正常的請求後端的 API，進而導致前後端串接失敗。\n因此也建議大家可以好好了解 Spring MVC 的用法，在實際的工作上是會非常有幫助的！\n那麼從下一篇文章開始，我們就會進入到下一個部分：Spring JDBC，我們會接著來介紹要如何在 Spring Boot 中和「資料庫」進行溝通，那我們就下一篇文章見啦！\n補充：本文是擷取自我開設的線上課程 Java 工程師必備！Spring Boot 零基礎入門 的內容，如果你想了解更多的 Spring Boot 的用法，歡迎參考課程簡介 （輸入折扣碼「HH202601KU」即可享 85 折優惠）。\n","permalink":"https://kucw.io/blog/springboot/23/","tags":null,"title":"Spring Boot 零基礎入門 (23) - Http Status Code（Http 狀態碼）介紹"},{"categories":["Spring Boot"],"contents":"哈囉大家好，我是古古。\n在上一篇文章中，我們有介紹了什麼是 RESTful API，以及在設計 RESTful API 時，需要滿足哪三個設計條件，先讓大家對 RESTful API 有基本的認識。\n而在了解了 RESTful API 的概念之後，接著這篇文章，我們就會實際到 Spring Boot 上，練習要如何在 Spring Boot 中設計和實作出 RESTful API，所以我們就開始吧！\n目錄 回顧：什麼是 RESTful API？ 設計 RESTful API 在 Spring Boot 中實作 RESTful API 指定 Http method 的方式：@GetMapping、@PostMapping\u0026hellip;等 Spring Boot 中常用的 RESTful API 註解 具體實作 前期準備 實作 POST /students（創建 Student 數據） 實作 GET /students/123（查詢 Student 數據） 實作 PUT /students/123（更新 Student 數據） 實作 DELETE /students/123（刪除 Student 數據） 實作成果 總結 回顧：什麼是 RESTful API？ # RESTful API 指的是「你所設計的 API 符合 REST 風格」，而 RESTful API 的目的，是為了「簡化工程師之間的溝通成本」，當每個工程師都安照共同的默契來設計 API 時，大家就可以設計出更一致的 API，因此就可以把溝通所花費的時間節省下來，進而提升開發的效率。\n而要設計出 RESTful API 的話，需要符合以下三個條件：\n使用 Http method，表示要執行的資料庫操作 使用 url 路徑，描述資源之間的階層關係 Response body 返回 JSON 或是 XML 格式 只要同時滿足這三個條件，就可以將你的 API 稱為是 RESTful API 了！\n設計 RESTful API # 了解了 RESTful API 的概念之後，接著我們也可以試著去設計出一套 RESTful API 出來，並且了解要如何透過 Spring Boot 程式，去實作這套 RESTful API。\n舉例來說，我們可以先設計出一個 Student class，並且在裡面新增 id 和 name 兩個變數，用來表示這個學生的 id 和名字，程式如下：\npublic class Student { Integer id; String name; } 接著，我們可以為 Student 這個資源，去設計出一連串的 RESTful API：\n像是我們需要一個「創建學生」的 API ，這樣子才能新增新同學的數據到資料庫 我們也需要一個「查詢學生」的 API，這樣子才能去查詢某一筆學生的數據 \u0026hellip;等等 所以針對 Student 這個「資源」，通常我們會設計四個最基本的 RESTful API 給他，也就是 CRUD（Create 新增、Read 查詢、Update 修改、Delete 刪除），具體設計方式如下圖所示：\n所以透過這四個 RESTful API，就可以完成 Student 的「新增、查詢、修改、刪除」的四個基本操作了！\n補充：「Create 新增、Read 查詢、Update 修改、Delete 刪除」這四個操作，又可以簡稱為 CRUD，幾乎每一種資源（ex: 商品、訂單、會員\u0026hellip;等），都會需要這四個操作，因此 CRUD 也可以說是大家剛入門 Spring Boot 時，最常撰寫的程式。\n在 Spring Boot 中實作 RESTful API # 指定 Http method 的方式：@GetMapping、@PostMapping\u0026hellip;等 # 當我們設計好 Student 資源的四個基本 RESTful API 之後，因此前端到時候想要去新增一筆 Student 數據時，前端就要使用 POST，去請求 /students 這個 url 路徑，這樣子才能夠創建一筆新的 Student 數據到資料庫中。\n而在 Spring Boot 中，有兩種方式可以「限制」前端只能用某個 Http method 來請求 url 路徑，分別是：\n@RequestMapping(value = \u0026#34;/students\u0026#34;, method = RequestMethod.POST) 以及\n@PostMapping(\u0026#34;/students\u0026#34;) 上面這兩種寫法，都可以限制前端只能使用 POST，去請求 /students 的 url 路徑，他們的差別就只是一行寫起來比較長、一行寫起來比較短而已。\n在之前的文章中，我們都是使用上面的 @RequestMapping 的寫法來設計 url 路徑，而他的缺點，就是寫起來比較冗長，不利於後續維護。\n因此一般在實作上，通常會改成使用下方的 @PostMapping 的寫法，直接透過 @PostMapping 這個註解，去「限制」前端只能使用 POST 來請求，這樣子的寫法會更簡潔、更一目瞭然，所以一般在設計 RESTful API 時，通常就是會採用下方的 @PostMapping 來實作！\nSpring Boot 中常用的 RESTful API 註解 # 在 Spring Boot 中，除了可以使用 @PostMapping，去限制前端只能使用 POST 來請求之外，Spring Boot 也是有提供其他好用的註解，讓我們去限制其他的 Http method 的。\n像是 Spring Boot 就提供了以下四個註解給我們使用：\n@GetMapping：限制前端只能使用 GET 來請求該 url 路徑 @PostMapping：限制前端只能使用 POST 來請求該 url 路徑 @PutMapping：限制前端只能使用 PUT 來請求該 url 路徑 @DeleteMapping：限制前端只能使用 DELETE 來請求該 url 路徑 不過這些註解大家不需要死背，因為大家如果觀察一下的話，可以發現「這些註解都是以 Http method 當作開頭」來設計，像是 @GetMapping 就是 Get + Mapping，而 @PostMapping 則是 Post + Mapping。\n所以當大家以後看到這些註解時，只要直接觀察註解的名稱（XXX + Mapping），就可以知道他想要限制的是哪一種請求方法了！\n具體實作 # 設計好 RESTful API，並且也了解了 Spring Boot 中的 @GetMapping、@PostMapping\u0026hellip;等註解的用法之後，接下來我們就可以實際到 Spring Boot 中，去實作這四個 RESTful API 出來了！\n前期準備 # 首先大家可以先刪除 MyController class，這個 class 後續不會再使用到了。刪好之後，接著在 Spring Boot 中創建一個新的 class 出來，並且命名為 Student class，然後在裡面寫上兩個變數 id 和 name，用來表示這個學生的 id 和名字，具體程式如下：\npublic class Student { private Integer id; private String name; public Integer getId() { return id; } public void setId(Integer id) { this.id = id; } public String getName() { return name; } public void setName(String name) { this.name = name; } } 接著我們再創建出一個新的 class，名字為 StudentController，並且在裡面寫上下方的程式：\n@RestController public class StudentController { } 所以整個 Spring Boot 程式的結構，就會像是下方這個樣子：\n實作 POST /students（創建 Student 數據） # 實作好前期準備的程式之後，接著我們就可以來實作第一個 RESTful API，也就是 POST /students 這個 API 了！\n首先 POST /students 這個 API 所代表的意義，即是「創建一個新的 Student 數據」。\n要實作 POST /students API 的話，我們可以先運用上面所介紹的 RESTful API 相關註解，即是使用 @PostMapping 這個註解，去限制這個 API 只能夠使用 POST 來請求。\n而至於在實作 POST 請求的方法時，要如何去接住前端所傳遞過來的參數，這部分我們可以照著 Day 19 - 取得請求參數 (上) - @RequestParam、@RequestBody 的介紹，使用 @RequestBody 去接住前端所傳遞過來的 JSON 參數。\n因此在我們使用 @RequestBody 之後，Spring Boot 到時候就會將前端所傳遞的 JSON 數據，自動地去轉換成 student 類型的參數了。\n程式實作 # @PostMapping(\u0026#34;/students\u0026#34;) public String create(@RequestBody Student student) { return \u0026#34;執行資料庫的 Create 操作\u0026#34;; } API Tester 中的請求寫法 # 實作 GET /students/123（查詢 Student 數據） # 實作完 POST /students 之後，接著我們可以來實作第二個 RESTful API，即是 GET /students/123。\nGET /students/123 這個 API 所代表的意義，是去「查詢 student id 為 123 的 Student 數據」。\n要實作 GET /students/123 這個 API 的話，則要運用 RESTful API 註解中的 @GetMapping，去指定這個 API 只能夠使用 GET 來請求。\n另外在實作 GET /students/123 時，因為 RESTful API 會使用「url 路徑來表達階層關係」，所以我們想要取得到的 student id 的值，就會被放在 url 路徑 /students/123 裡面。\n因此為了取得放在 url 路徑中的 student id 的值，我們就得使用到 Day 20 - 取得請求參數 (下) - @RequestHeader、@PathVariable 所介紹到的 @PathVariable 來實作，即是從 /students/123 這個 url 路徑中，取得到其中的 123 的數據。\n補充：不知道大家有沒有發現，其實我們在前面所學的內容，在這篇文章中全部應用起來了👍。這就是為什麼我們前面要花許多篇幅介紹 Http 協議、GET 和 POST、以及 Spring Boot 取得前端參數的四種註解，因為這些知識可以幫助我們更好的設計和實作 RESTful API，所以這些技術可以說是必學的知識！\n程式實作 # @GetMapping(\u0026#34;/students/{studentId}\u0026#34;) public String read(@PathVariable Integer studentId) { return \u0026#34;執行資料庫的 Read 操作\u0026#34;; } API Tester 中的請求寫法 # 實作 PUT /students/123（更新 Student 數據） # 實作完 GET /students/123 之後，接著我們也可以來實作第三個 RESTful API，即是 PUT /students/123。\nPUT /students/123 這個 API 所代表的意義，是去「更新 student id 為 123 的數據」。\n更新的 API 算是實作上比較複雜的 API，首先我們一樣是要先運用 RESTful API 註解中的 @PutMapping，去限制這個 API 只能夠使用 PUT 來請求。\n而在參數的部分，則會同時使用到 @PathVariable 和 @RequestBody 這兩個註解，去取得前端所傳過來的參數。\n@PathVariable 負責從 url 路徑中，取得「要更新的是哪一個 student id」的值（也就是從 /students/123 中，取得 student id 的值 123） @RequestBody 則是負責去接住前端傳過來的 JSON 數據，了解前端想要把這個 Student 數據更新成哪些值 如果不熟悉 @PathVariable 和 @RequestBody 的用法的話，一樣是可以參考前面的 Day 19 和 Day 20 的介紹，回頭複習一下他們的用法。\n也建議大家可以先完成前面的 POST 和 GET 的實作之後，再來練習 PUT 實作，會比較好上手一點（因為 PUT 在實作上確實比較複雜）。\n程式實作 # @PutMapping(\u0026#34;/students/{studentId}\u0026#34;) public String update(@PathVariable Integer studentId, @RequestBody Student student) { return \u0026#34;執行資料庫的 Update 操作\u0026#34;; } API Tester 中的請求寫法 # 實作 DELETE /students/123（刪除 Student 數據） # 實作完前面的 POST、GET、PUT API 之後，最後我們可以來介紹實作第四個 RESTful API，即是 DELETE /students/123。\nDELETE /students/123 這個 API 所代表的意義，是去「刪除 student id 為 123 的數據」。\n要實作 DELETE /students/123 這個 API 的話，就要運用 RESTful API 註解中的 @DeleteMapping，去指定這個 API 只能夠使用 DELETE 來請求。\n另外也因為 RESTful API 會使用「url 路徑來表達階層關係」，所以這裡和 GET API 的實作很類似，都是去使用 @PathVariable，從 url 路徑 /students/123 裡面取得 student id 的值 123。\n程式實作 # @DeleteMapping(\u0026#34;/students/{studentId}\u0026#34;) public String delete(@PathVariable Integer studentId) { return \u0026#34;執行資料庫的 Delete 操作\u0026#34;; } API Tester 中的請求寫法 # 實作成果 # 所以透過上述的實作，最終我們就可以在 StudentController 裡面，將這四個 RESTful API 給實作出來了，結果如下：\n因此後續我們就可以透過這四個 RESTful API，去對 Student 資源進行「Create 新增、Read 查詢、Update 修改、Delete 刪除」這四個 CRUD 的基本操作了！\n總結 # 這篇文章我們先介紹了如何針對 Student 這個資源，去設計出一套 RESTful API 出來，並且也有實際到 Spring Boot 中，去使用 @GetMapping、@PostMapping\u0026hellip;等註解，在 Spring Boot 中實作出 RESTful API。所以大家以後就可以透過同樣的方式，在你的 Spring Boot 程式裡面實作 RESTful API 了！\n而在我們了解了最重要的 RESTful API 的設計和實作之後，在下一篇文章中，我們就會回頭來介紹一下 Http response 中也很重要的一個部分：Http status code，了解要如何透過 Http status code，讓前端快速的知道這一次請求的結果為何，那我們就下一篇文章見啦！\n補充：本文是擷取自我開設的線上課程 Java 工程師必備！Spring Boot 零基礎入門 的內容，如果你想了解更多的 Spring Boot 的用法，歡迎參考課程簡介 （輸入折扣碼「HH202601KU」即可享 85 折優惠）。\n","permalink":"https://kucw.io/blog/springboot/22/","tags":null,"title":"Spring Boot 零基礎入門 (22) - RESTful API 實作 - @GetMapping、@PostMapping..."},{"categories":["Spring Boot"],"contents":"哈囉大家好，我是古古。\n在前幾篇文章中，我們分別介紹了 Spring Boot 中「取得前端參數」的四個註解，因此大家就可以根據不同的情境，使用不同的註解來取得前端傳遞過來的參數了。\n那麼這篇文章，我們就會介紹現今前後端開發非常流行的一種設計風格，也就是 RESTful API，所以我們就開始吧！\n目錄 什麼是 API？ 什麼是 RESTful API？ 1. 成為 RESTful API 的條件之一：使用 Http method，表示要執行的資料庫操作 2. 成為 RESTful API 的條件之二：使用 url 路徑，描述資源之間的階層關係 3. 成為 RESTful API 的條件之三：Response body 返回 JSON 或是 XML 格式 小結：滿足 RESTful API 的三個條件 補充：RESTful API 的注意事項 總結 什麼是 API？ # 在開始介紹「RESTful API」之前，大家需要先了解「API」是什麼，要先掌握 API 的概念，才能夠學習 RESTful API 的相關知識，因此我們就先來介紹一下，API 到底是什麼。\n所謂的 API，指的是「用工程師的方式，去說明某個功能的使用方法」，所以換句話說的話，API 就是用特定的格式，去表示某個功能到底要怎麼使用，等於是一個使用說明書的概念。\n舉例來說，假設我們在 Spring Boot 中實作了一個「取得商品列表」的功能，那麼當我們想要將這個功能開放給前端使用的話，總不可能直接把 Spring Boot 的程式貼給對方看（因為對方可能不熟悉 Spring Boot、或是他根本不了解 Java 程式語言），因此就會造成溝通效率低落。\n而為了解決這個問題，API 就出現了！\n因為 API 的目的，就是「用工程師看得懂的方式，去說明某個方法要如何使用」，所以我們就可以用下圖中的格式，去定義「取得商品列表」這個 API 的使用方法。\n像是在下圖中，就會說明「取得商品列表」這個 API，必須要使用 GET 來請求。並且這張圖也有詳細列出前端在請求時，可以帶上什麼樣的請求參數（query parameter），以及這個 API 可能返回的 Http response 為何。\n所以當前端拿到這份 API 文件時，前端就能夠照著上面的定義，去使用 GET 請求 /getProducts 這個 url 路徑，並且在請求時，帶上 size=5 這個請求參數（表示要取得 5 筆數據），這樣子就可以成功的去使用「取得商品列表」的功能，進而去取得 5 筆商品數據出來了！\n因此透過這份 API 文件，大家就可以更清楚的知道某個功能的使用方式，進而提升前後端溝通的效率！\n補充：一般在口語上，大家可能會聽到有人說「這支 API 要怎麼 call？」或是「你可以去 call 商品功能的 API」這種說法，其中的「call API」，其實就是指「對該 API 發起 Http 請求」的意思。\n所以假設我們在 Spring Boot 中實作了一個 API，他的 url 路徑是 /test，那麼當前端去請求 http://localhost:8080/test 時，就可以說「前端去 call 了 /test 這一支 API」。\n因此「call API」這個說法，在實務上是非常常見的講法，所以建議大家也要熟悉一下這個講法會比較好！\n什麼是 RESTful API？ # 了解了 API 的概念之後，接著就可以來介紹什麼是「RESTful API」了！\n所謂的「RESTful API」，就是表示去設計出一套「符合 REST 風格的 API」出來，所以換句話說的話，只要我們在設計 API 時，有去套用 REST 風格，那就可以稱呼我們所設計出來的這組 API，是 RESTful API 了！\n補充：大家看到這邊，可能會疑惑「REST 風格」和「RESTful」之間到底是什麼關係，其實這裡只是用到英文的文法特性而已。\n在英文的文法裡面，有一種用法，就是在字尾加個 ful，就可以把名詞轉成形容詞。\n舉例來說：\nBeauty 是名詞（意思是美麗），而 Beautiful 則是形容詞（美麗的） Peace 是名詞（意思是和平），而 Peaceful 則是形容詞（和平的） 因此同樣的邏輯，REST 是一個名詞，表示「REST 風格」，而 RESTful 就是形容詞，表示「符合 REST 風格的」，所以 RESTful API 的意思，就是表示「這個 API 是很符合 REST 風格的」！\n大概了解 REST 和 RESTful 的差別之後，所以現在我們知道，所謂的「RESTful API」，就是設計出一個「符合 REST 風格的 API」，而如果我們想要設計出一個「符合 REST 風格的 API」，那麼這個 API 就必須要滿足三個條件：\n1. 成為 RESTful API 的條件之一：使用 Http method，表示要執行的資料庫操作 # 如果想要設計出 RESTful API 的話，首先第一點，就是這個 API 必須要「使用 Http method，去表示要執行的資料庫操作」，也就是賦予了 Http method 更多的意義。\n在 REST 風格中，REST 風格會把 POST、GET、PUT、DELETE 這四種 Http method，分別去對應到資料庫的 Create、Read、Update、Delete 操作上。\n所以在 REST 風格中，只要看到某支 API 是使用 GET 來請求，那就是在暗示這個 API 會去資料庫中執行「Read（查詢數據）」的操作。或是如果該 API 是使用 POST 來請求，那就是在暗示這個 API 要去執行「Create（新增數據）」的操作。\n因此在 RESTful API 的世界裡面，Http method 影響的不僅僅是 GET、POST 這些請求參數的傳遞而已，也是在「暗示」這支 API 後續會去執行資料庫中的哪種操作。\n所以如果我們想要設計出一個 RESTful API 的話，那麼第一個必要條件，就是要「使用 Http method，去表示要執行的資料庫操作」。\n2. 成為 RESTful API 的條件之二：使用 url 路徑，描述資源之間的階層關係 # 成為 RESTful API 的第二個條件，就是「使用 url 路徑，描述資源之間的階層關係」。\n在 REST 風格裡面，url 路徑代表的是「每個資源之間的階層關係」，這個聽起來可能有點抽象，所以我們可以直接透過一個例子，來了解什麼是資源之間的階層關係。\n假設現在有一個使用 GET 來請求 API 為 GET /users，首先因為這個 API 是使用 GET 來請求，因此根據上面的條件一的介紹，GET 就是對應到 Read（讀取數據）的操作，又因為後面的 url 路徑是 /users，所以我們就可以知道他是要去「取得所有 user 的數據」。\n此時假設我們又有另一個 API GET /users/123，因為這個 API 也是使用 GET 來請求，所以也是去讀取數據，並且他的 url 路徑是 /users/123，因此這個 API 的含義，就是「取得 user id 為 123 的那個 user 的數據」。\n而到這邊，REST 風格的階層概念其實就出現了！\n大家可以把 url 路徑中的每一個斜線 /，想像成是一個個的階層，也就是一個子集合的感覺。或是說得更白話一點，就是可以直接把這個斜線 /，替換成是中文的「的」。\n所以像是上面的 GET /users，就是表示去「取得所有 user 的數據」 而下面的 GET /users/123，則是表示去取得所有 user 中「的」user id 為 123 的數據，所以就是「取得 user id 為 123 的那個 user 的數據」 因此在 REST 風格裡面，我們就要透過 url 路徑，去表達「階層」的概念，並且透過 url 路徑，就可以去表達我們想要取得的資源是什麼了！\n下面也提供更多例子給大家參考，讓大家感受一下在 REST 風格中，url 路徑所表示的階層關係：\n所以如果我們想要設計出一個 RESTful API 的話，第二個必要條件，就是要「使用 url 路徑，描述資源之間的階層關係」。\n3. 成為 RESTful API 的條件之三：Response body 返回 JSON 或是 XML 格式 # 而至於成為 RESTful API 的最後一個條件，這個就比較簡單了，只要確保「Response body 所返回的數據，是使用 JSON 或是 XML 格式來返回」，這樣子就滿足 RESTful API 的第三個條件了！\n補充：雖然一般在實作上，比較常使用 JSON 格式來返回數據，但是其實使用 XML 格式來回傳數據，也是符合 REST 風格的！\n而在 Spring Boot 中，如果要返回 JSON 格式的數據的話，就只要在 class 上面加上 @RestController，並且將返回的類型改成「Java 物件」，這樣子就可以回傳 JSON 格式的數據給前端了。\n如果對 Spring Boot 返回 JSON 數據的寫法不太熟悉的話，也可以回頭參考 Day 17 - 返回值改成 JSON 格式 - @RestController 那篇文章的介紹。\n小結：滿足 RESTful API 的三個條件 # 所以總和上述的介紹，如果我們想要設計出一個 RESTful API 的話，那麼就需要符合以下三個條件：\n使用 Http method，去表示要執行的資料庫操作 使用 url 路徑，描述資源之間的階層關係 Response body 返回 JSON 或是 XML 格式 只需要同時滿足這三個條件，那麼你的 API 就是一個「符合 REST 設計風格的 API」，所以也就可以稱呼他為 RESTful API 了！讚！！\n補充：RESTful API 的注意事項 # 介紹了這麼多 RESTful API 的設計方式，最後我們也來補充一下，在使用 RESTful API 的一些注意事項。\nRESTful API 的目的，是為了「簡化工程師之間的溝通成本」而設計出來的，所以 RESTful API 就是希望可以讓每個工程師能夠按照一個共同的默契來設計 API，這樣每位工程師所設計出來的 API 就不會相差太多，因此大家就可以節省溝通的時間，進而提升開發的效率。\n不過要特別注意的是，雖然 REST 風格的使用非常普遍，但是 REST 只是一個設計 API 的風格而已，並不是設計 API 的標準規範。\n所以換句話說的話，REST 風格只是一個建議做法，而不是必要的做法，因此如果你的使用情境比較特殊的話，那麼不遵守 REST 風格的設計，也是完全沒問題的！\n舉例來說，假設你有一個讀取資料庫的 API，因為讀取是對應到 GET 請求，所以在 REST 風格中就會設計成 GET 請求，也就是類似於 GET /users/{userId} 這種寫法。\n但是如果你的系統是要用比較敏感的資訊來查詢資料庫（ex: 身分證字號），那麼在這種情況下，硬要使用 REST 風格的 GET 請求反而是不恰當的，因為這樣身分證字號的資訊就會被放在 url 路徑中來傳遞 GET /users/B123456789，進而導致身分證字號洩漏出去。因此在這種情況下，反而是改用 POST 這種安全性較高的 Http method，才會是更好的 API 設計。\n所以總結來說，REST 只是一個設計的風格而已，並不是設計 API 的標準規範，所以如果在實務上真的遇到一些特殊情況時，那就仍舊是以當下的實際情況來做調整，並不是符合 REST 風格的 API 才是最好的。因此大家在實作上，要特別注意這個細節，切勿為了滿足 REST 設計風格，而使得你的 API 暴露在資安風險底下！\n總結 # 這篇文章我們先介紹了 API 和 RESTful API 的概念，也介紹了在設計 RESTful API 時要滿足的三個條件，並且最後也補充了使用 RESTful API 注意事項，因此大家就可以根據自己的需求，去決定是否要採用 REST 風格來設計你的 API 了！\n那麼在了解了 RESTful API 的概念之後，下一篇文章我們就會回到 Spring Boot 上，來練習要如何在 Spring Boot 中實作出 RESTful API 的程式，那我們就下一篇文章見啦！\n補充：本文是擷取自我開設的線上課程 Java 工程師必備！Spring Boot 零基礎入門 的內容，如果你想了解更多的 Spring Boot 的用法，歡迎參考課程簡介 （輸入折扣碼「HH202601KU」即可享 85 折優惠）。\n","permalink":"https://kucw.io/blog/springboot/21/","tags":null,"title":"Spring Boot 零基礎入門 (21) - RESTful API 介紹"},{"categories":["Spring Boot"],"contents":"哈囉大家好，我是古古。\n在上一篇文章中，我們有分別介紹 @ReqestParam 和 @RequestBody 的用法，了解要如何透過 @ReqestParam 取得 url 後面的參數，以及如何透過 @RequestBody 取得 request body 中的 JSON 數據。\n那麼這篇文章，我們就會接著來介紹另外兩個取得請求參數的註解，也就是 @RequestHeader 和 @PathVariable，那我們就開始吧！\n補充：想了解 @ReqestParam 和 @RequestBody 的用法的話，可以參考上一篇文章 Day 19 - 取得請求參數（上）- @RequestParam、@RequestBody 的介紹。\n目錄 3. @RequestHeader：接住放在 request header 中的參數 在 Spring Boot 中練習 @RequestHeader 的用法 4. @PathVariable：接住放在 url 路徑中的值 在 Spring Boot 中練習 @PathVariable 的用法 使用 @PathVariable 的注意事項之一：「url 路徑」和「參數的名字」要一致 使用 @PathVariable 的注意事項之二：參數類型需一致 小結：@PathVariable 用法總結 補充：為什麼我們需要 @PathVariable？ 總結 3. @RequestHeader：接住放在 request header 中的參數 # @ReqeustHeader 的用途，就是「接住放在 request header 中的參數」。\n雖然一般在開發上，不太會使用到 request header 來傳遞一般的參數（通常只有「權限驗證」或是「通用資訊」，才會使用 request header 來傳遞），不過我們仍舊可以來看一下 @RequestHeader 的用途為何，先對這個註解有個印象。\n在 Spring Boot 中練習 @RequestHeader 的用法 # 首先因為 request header 是不論使用哪一種 Http 請求都可以添加的參數，所以換句話說畫的，即是 GET、POST、PUT、DELETE…等請求，都可以添加 request header 的通用參數。\n舉例來說，如果前端在請求時，想要在 request header 中添加參數的話，那麼就可以在 API Tester 中，先去點擊 Add header 的按鈕，這樣子就可以去添加一個新的 request header 出來。\n在點擊 Add header 按鈕之後，就會出現一對 key-value 的格子讓我們填寫（沒錯 request header 也是使用 key 和 value 的方式來存放的），因此左邊就是這個 request header 的名字（也就是 key），而右邊就是這個 header 的值（也就是 value）。\n所以像是在下圖中，info 就是這個 request header 的 key、而 hello 就是他的 value 值。\n當我們這樣填寫之後，前端到時候在請求時，就會將 info: hello 這個 request header 的 key: value 的資訊，去傳遞給後端了。\n而當前端傳遞了 request header 的資訊過來之後，如果我們想要在 Spring Boot 中去接住這個 info: hello 的 request header 的值的話，那麼我們就可以像下圖一樣，在 test3() 方法的實作中，先新增一個 String 類型的參數 info，並且在 info 前面加上一個 @RequestHeader，這樣子就可以成功的取得到前端傳遞過來的 header 的值了！\n所以如果我們實際到 Spring Boot 上練習的話，就只要在 MyController 中，新增一個新的 test3() 方法，並且在裡面寫上下列的程式，這樣就可以取得前端所傳遞過來的 header 的值。\n@RequestMapping(\u0026#34;/test3\u0026#34;) public String test3(@RequestHeader String info) { System.out.println(\u0026#34;info 的值為: \u0026#34; + info); return \u0026#34;請求成功\u0026#34;; } 實作完 MyController 之後，接著就運行一下 Spring Boot 程式。\n運行成功之後，就回到 API Tester 中，並且在 Http method 中選擇 GET 請求（其實選擇哪一種請求方法都可以，此處以 GET 為例），url 的地方填上 http://localhost:8080/test3，然後 request header 的地方新增 info: hello 這組數據，這樣就可以模擬前端的請求。\n這時當我們按下 Send 鍵之後，在右下角的 response body 中，就會出現 Spring Boot 所回傳的「請求成功」的訊息。\n而當我們回到 IntelliJ 上查看的話，在下方的 console 中，就會出現「info 的值為: hello」的字串。\n所以這就表示，我們就成功的透過 @RequestHeader，接住前端放在 request header 中所傳遞的參數了！因此大家以後就可以透過這個寫法，去取得 request header 中的參數的值了。\n4. @PathVariable：接住放在 url 路徑中的值 # 在介紹完前面三個註解 @RequestParam、@RequestBody、@RequestHeader 之後，最後我們要來介紹第四個註解，也是跟其他人長得最不一樣的註解，即是 @PathVariable（前面的註解都是以 @Request... 開頭，只有他是以 @Path... 開頭）。\n@PathVariable 的用途，就是「接住放在 url 路徑中的值」，這句話的重點在於**「url 路徑」**，這也是 @PathVariable 和其他三個註解最不一樣的地方。\n舉例來說，假設我們今天有一個 url 如下：\nhttp://localhost:8080/test4/123 在這段 url 網址中，他的 url 路徑的值為 /test4/123，而如果我們想要取得到 url 路徑 /test4/123 中的 123 的值的話，那麼就要透過 @PathVariable 來取得。\n補充：此處大家先不用思考「為什麼我們需要讀取 url 路徑中的值？」，只要先學習 @PathVariable 的使用方法就好，後續會再回頭來解釋「為什麼我們需要 @PathVariable？」以及「@PathVariable 的應用場景為何」。\n在 Spring Boot 中練習 @PathVariable 的用法 # 大概了解了 @PathVariable 的概念之後，我們也可以實際到 Spring Boot 中，來練習一下 @PathVariable 的用法。\n舉例來說，假設前端今天請求了 http://localhost:8080/test4/123 這個 url，那麼在這個 url 裡面，他的 url 路徑即是 /test4/123。\n而如果我們想要在 Spring Boot 中，去接住 url 路徑 /test4/123 中的 123 的值的話，就必須要做兩件事：\n首先我們要先修改一下 @RequestMapping 的寫法，即是將 @RequestMapping 所對應的 url 路徑，改寫成 @RequestMapping(\u0026quot;/test4/{id}\u0026quot;)，這樣子 Spring Boot 才能夠將 /test4/123 的 url 路徑，去對應到 test4() 方法上。\n接著我們就可以在 test4() 的方法中，去添加一個 Integer 類型的參數 id，並且在 id 前面加上一個 @PathVariable，這樣子到時候，這個 id 的值就會是 url 路徑中的 123，因此就可以成功的取得到 url 路徑（/test4/123）中的 123 的值了！\n所以如果我們將這段 test4() 的方法實作到 MyController 中的話，就可以寫成下面這個樣子：\n@RequestMapping(\u0026#34;/test4\u0026#34;) public String test4(@PathVariable Integer id) { System.out.println(\u0026#34;id 的值為: \u0026#34; + id); return \u0026#34;請求成功\u0026#34;; } 修改好 MyController 之後，接著重新運行一下 Spring Boot 程式。\n運行成功之後，就可以回到 API Tester，然後在 Http method 中選擇 GET 請求，url 填上 http://localhost:8080/test4/123，就可以模擬前端的請求。\n這時當我們按下 Send 鍵之後，在右下角的 response body 中，就會出現 Spring Boot 所回傳的「請求成功」的訊息。\n而當我們回到 IntelliJ 上查看的話，在下方的 console 中，就會出現「id 的值為: 123」的字串。\n所以這就表示，我們就成功的透過 @PathVariable，去接住前端放在 url 路徑中的值了！\n使用 @PathVariable 的注意事項之一：「url 路徑」和「參數的名字」要一致 # 在使用 @PathVariable 去取得 url 路徑中的值的時候，有一點一定要特別注意，就是「url 路徑」和「參數的名字」必須要一致才可以。\n舉例來說，如果我們在 @RequestMapping 中設定的 url 路徑為 /test4/{id}，那麼在方法中所定義的參數名字，就也必須要定義成 id 才可以\n所以假設當我們在 @RequestMapping 中設定的 url 路徑為 /test4/{age} 時，那麼參數的名字，也必須一起改成 age 才可以。\n所以簡單來說，就是「url 路徑」和「參數的名字」一定要一致就對了！\n使用 @PathVariable 的注意事項之二：參數類型需一致 # 使用 @PathVariable 的第二個注意事項，就是「參數的類型需要一致」。\n這部分其實就跟之前的 @RequestParam 很類似，譬如說 url 路徑中的值是 /test4/123，那就是暗示 /test4/{id} 中的 id 的值是 123，所以我們就要將 id 參數宣告為 Integer 或是 int 類型，這樣子才能夠成功的取得到 url 路徑中的值。\n小結：@PathVariable 用法總結 # 綜合以上的介紹，我們也可以來總結一下 @PathVariable 的用法。\n@PathVariable 的用途，就是「接住放在 url 路徑中的值」，這句話的重點在於**「url 路徑」**，這也是 @PathVariable 和其他三個註解最不一樣的地方。\n而在使用 @PathVariable 時，要注意以下的事項：\n「url 路徑」和「參數的名字」要一致 參數的類型要一致 只要注意好上面兩個注意事項，就可以成功的運用 @PathVariable，去取得 url 路徑中的值了！\n補充：為什麼我們需要 @PathVariable？ # 了解了 @PathVariable 的用法之後，我們也可以回頭來解釋一下，為什麼我們需要實作「從 url 路徑中取得值」這種行為。\n假設前端想要傳遞「id 為 123」的資訊給 Spring Boot 的話，那麼前端完全可以使用上一篇文章所介紹的 @RequestParam 來傳遞，直接把 id=123 的資訊加在 url 最後面來傳遞就好了（如下圖左），為什麼要大費周章把 123 的值放到 url 路徑裡面，然後再透過 @PathVariable 來取得呢（如下圖右）？\n之所以會使用 @PathVariable 來傳遞參數的根本原因，就是「為了支援 RESTful API 的設計風格」！\n所謂的 RESTful API，他是在現今前後端開發中，非常流行的一種設計風格，而為了讓 Spring Boot 也能夠開發出符合 RESTful API 的設計風格，因此 Spring Boot 就設計出了 @PathVariable 這個註解，讓我們有能力去取得 url 路徑中的值。\n有關 RESTful API 的設計風格，在下一篇文章就會跟大家詳細的介紹了，所以大家只要先知道 @PathVariable 是真的在實務上很常使用的註解即可，在下一篇文章就會詳細介紹 RESTful API 的使用方法，以及如何將 @PathVariable 套用在 RESTful API 的設計風格上！\n總結 # 這篇文章我們先延續上一篇文章，詳細的介紹了後兩個註解 @RequestHeader 和 @PathVariable 的用法，了解要如何透過 @RequestHeader 取得 request header 中的參數，以及要如何透過 @PathVariable 取得 url 路徑中的值。\n所以到這邊為止，我們就詳細介紹完 Spring Boot 中的四種取得參數的註解了，分別是：\n@RequestParam：接住放在 Url 後面的參數 @RequestBody：接住放在 request body 中的參數 @RequestHeader：接住放在 request header 中的參數 @PathVariable：取得放在 url 路徑中的值 因此大家之後就可以根據不同的情境，去選擇不同的註解，進而去取得到前端傳遞給我們的參數了！\n而在我們更了解 Spring MVC 的用法之後，接著下一篇文章，我們就會來介紹現今前後端開發非常流行的一種設計風格，也就是 RESTful API，那我們就下一篇文章見啦！\n補充：本文是擷取自我開設的線上課程 Java 工程師必備！Spring Boot 零基礎入門 的內容，如果你想了解更多的 Spring Boot 的用法，歡迎參考課程簡介 （輸入折扣碼「HH202601KU」即可享 85 折優惠）。\n","permalink":"https://kucw.io/blog/springboot/20/","tags":null,"title":"Spring Boot 零基礎入門 (20) - 取得請求參數（下）- @RequestHeader、@PathVariable"},{"categories":["Spring Boot"],"contents":"哈囉大家好，我是古古。\n在上一篇文章中，我們先介紹了 Http method 的概念，並且也介紹了兩個常見的 Http method：GET 和 POST，分別了解他們是如何傳遞參數給後端的。\n那麼接著這篇文章，我們就會回到 Spring Boot 上，來介紹一下要如何在 Spring Boot 中，去接住前端所傳過來的這些參數的值。\n補充：不過也因為在 Spring Boot 有許多種方式可以接住前端所傳遞過來的參數，因此這裡會分成上、下兩篇文章來介紹，因此這篇文章我們就會先介紹 @RequestParam 和 @RequestBody 的用法。\n目錄 在 Spring Boot 中接住參數的四個註解 1. @RequestParam：接住添加在 url 後面的參數 在 Spring Boot 中練習 @RequestParam 的用法 使用 @RequestParam 的注意事項之一：參數名字須一致 使用 @RequestParam 的注意事項之二：參數類型需一致 小結：@RequestParam 用法總結 2. @RequestBody：接住放在 request body 中的參數 在 Spring Boot 中練習 @RequestBody 的用法 小結：@RequestBody 用法總結 總結 在 Spring Boot 中接住參數的四個註解 # 在 Spring Boot 中，有四個註解可以去接住前端傳遞過來的參數，分別是：\n@RequestParam @RequestBody @RequestHeader @PathVariable 這四個註解雖然長得有點像（都是以 @Request 開頭），但是他們功能是完全不同的！所以接下來這兩篇文章，我們就會分別來介紹這四個註解要如何使用。\n而在這篇文章中，我們就會先來介紹前兩個註解，也就是 @RequestParam 和 @RequestBody 的用法。\n1. @RequestParam：接住添加在 url 後面的參數 # 首先我們先來看第一個註解，也就是 @ReqeustParam。\n@ReqeustParam 的用途，就是「接住那些放在 url 後面的參數」，所以像是我們在上一個章節中所介紹到的 GET 請求，就是會把請求參數放在 url 的最後面來傳遞：\n因此當前端使用 GET 來請求時，我們就可以在 Spring Boot 中寫上 @ReqeustParam，去接住前端所傳遞過來的參數（query parameter）。\n在 Spring Boot 中練習 @RequestParam 的用法 # 大概了解了 @ReqeustParam 的概念之後，我們也可以實際到 Spring Boot 上來練習一下 @ReqeustParam 的用法。\n舉例來說，當前端使用 GET 來請求、並且在 url 的最後面加上了一個 id=123 的參數時，那麼前端的實際請求就會如下圖所示：\n而這個時候，如果我們想要在 Spring Boot 中去接住 id=123 的參數的話，那我們就可以像下圖一下，先在 test1() 方法中，新增一個 Integer 類型的參數 id，並且在 id 的前面加上一個 @RequestParam，這樣子就可以成功的取得到前端傳遞過來的 id=123 的值了！\n所以如果我們實際到 Spring Boot 上練習的話，就只要改寫一下 MyController，將他改成下面的程式：\n@RestController public class MyController { @RequestMapping(\u0026#34;/test1\u0026#34;) public String test1(@RequestParam Integer id) { System.out.println(\u0026#34;id 的值為: \u0026#34; + id); return \u0026#34;請求成功\u0026#34;; } } 寫上上述的程式之後，就可以運行一下 Spring Boot 程式。\n運行成功之後回到 API Tester 上，接著在 Http method 中選擇 GET 請求，url 填上 http://localhost:8080/test1?id=123，這樣子就可以模擬前端的請求。\n因此當我們按下 Send 鍵之後，在右下角的 response body 中，就會出現 Spring Boot 所回傳的「請求成功」的訊息。\n此時當我們回到 IntelliJ 上查看的話，在下方的 console 中，就會出現「id 的值為: 123」的字串。\n所以這就表示，我們就成功的透過 @RequestParam，接住前端放在 url 中所傳遞的參數了！\n使用 @RequestParam 的注意事項之一：參數名字須一致 # 在使用 @RequestParam 去接住 url 後面的參數時，首先有一個重點需要注意，就是在 Spring Boot 中的「變數的名字」，必須要和「url 中的參數的名字」一樣才可以。\n舉例來說，假設 url 中所添加的參數是 id=123，那麼在 Spring Boot 所使用的參數名字，就必須也是 id；又或是說假設 url 中添加的是 name=Judy，那麼在 Spring Boot 中所使用的參數名字，就必須是 name。\n假設參數名字不一致的話，@RequestParam 是沒有辦法成功取得到 url 中的參數的，因此大家在使用上，就要特別注意這兩個地方的名字一定要一致才可以！\n補充：如果真的發生參數名字不一樣的情況出現，那麼透過一些額外的設定，其實也是可以讓 @RequestParam 生效的。\n舉例來說，假設前端傳遞的參數為 myId=123，但是如果想要在 Spring Boot 上使用 id 來接住這個 myId 的參數的話，那麼就要改寫成 @RequestParam(name = \u0026quot;myId\u0026quot;) Integer id) 的寫法（也就是在 @RequestParam 後面多加上了 (name = \u0026quot;myId\u0026quot;) 的額外設定），這樣子才能夠將前端的 myId 對應到 Spring Boot 中的 id 參數。\n不過雖然 @RequestParam 有支援這種特殊的設定，但一般在實作上，還是會建議大家盡量讓「前端傳遞的參數」和「Spring Boot 中使用的參數名稱」一致，這樣子就不用多寫額外的程式來轉換，實作上也比較直覺方便，比較不會出問題。\n使用 @RequestParam 的注意事項之二：參數類型需一致 # 使用 @RequestParam 去接住 url 參數的第二個重點，就是「參數的類型需要一致」。\n舉例來說，假設前端在 url 中所添加的參數是 id=123，那麼就是在暗示這個 id 的值是一個整數，因此我們在 Spring Boot 中，就需要將該參數宣告為 Integer 類型或是 int 類型，這樣才能成功接住前端所傳過來的參數。\n又或是前端在 url 中所添加的參數是 name=Judy，那麼就是在暗示這個 name 參數的值是一個字串，因此我們在 Spring Boot 中，就需要將該參數宣告為 String 類型，這樣也才能成功接住前端所傳過來的參數。\n因此只有當類型一致時，Spring Boot 才有辦法成功的接住該參數，將該參數的值給轉換過來，否則的話 Spring Boot 可是會出錯的！會回傳一個請求失敗的資訊給前端。\n小結：@RequestParam 用法總結 # 綜合以上的介紹，我們可以先做個 @RequestParam 的用法總結。\n@RequestParam 的用途，就是「接住那些放在 url 後面的參數」，所以當前端將參數添加在 url 的後面來傳遞時，就是 @RequestParam 出馬的時候了！\n而在使用 @RequestParam 時，要注意以下的事項：\n參數的名字要一致（無額外的設定下） 參數的類型要一致 只要掌握好上面兩個注意事項，就可以成功的運用 @RequestParam，去接住前端放在 url 後面的那些參數了！\n2. @RequestBody：接住放在 request body 中的參數 # 了解了 @RequestParam 的用法之後，接著我們可以來看第二個註解 @RequestBody 的用法。\n@RequestBody 的用途，就是「接住放在 request body 中的參數」，所以像是我們在上一篇文章中所介紹到的 POST 請求，他就是會把參數放在 request body 中來傳遞：\n因此當前端使用 POST 來請求時，我們就可以在 Spring Boot 中寫上 @ReqeustBody，去接住前端放在 request body 中所傳遞的參數。\n在 Spring Boot 中練習 @RequestBody 的用法 # 大概了解了 @ReqeustBody 的概念之後，我們一樣也是可以實際到 Spring Boot 中，來練習一下 @ReqeustBody 的用法。\n舉例來說，當前端使用 POST 來請求、並且在 request body 中添加了下列的 JSON 格式的參數的話，那麼前端的實際請求就會如下圖所示：\n而這個時候，如果我們想要在 Spring Boot 中去接住這個 JSON 格式的參數的話，那我們首先要做的，就是先去創建一個 Java class 出來，並且這個 Java class 中的變數，會和 JSON 格式的數據「一一對應」。\n像是我們可以先去 new 一個 Student class 出來，並且在 Student 中添加下列的程式：\npublic class Student { private Integer id; private String name; public Integer getId() { return id; } public void setId(Integer id) { this.id = id; } public String getName() { return name; } public void setName(String name) { this.name = name; } } 當我們這樣寫時，就是去創建了一個「和 JSON 數據一一對應的 Student class」出來。\n之所以說這個 Student class 和 JSON 數據一一對應，是因為在上述的 JSON 數據中，他裡面有兩個 key 存在，分別是 id（整數）和 name（字串），而在 Student class 中也有兩個變數存在，變數名稱也是 id 和 name，並且 id 也為整數類型、name 也為字串類型。\n而當我們創建出「和 JSON 數據一一對應的 Student class」之後，Spring Boot 到時候就會自動將 request body 中的 JSON 參數，一口氣轉換成 Student class 了！magic！！\n寫好 Student class 之後，接著我們可以回到 MyController，並且在裡面新增另一個方法 test2()，接著我們在 test2() 中先新增一個 Student 類型的參數 student，並且在這個 name 的前面，加上一個 @RequestBody，如下方程式所示：\n@RequestMapping(\u0026#34;/test2\u0026#34;) public String test2(@RequestBody Student student) { System.out.println(\u0026#34;student 中的 id 值為: \u0026#34; + student.getId()); System.out.println(\u0026#34;student 中的 name 值為: \u0026#34; + student.getName()); return \u0026#34;請求成功\u0026#34;; } 當我們這樣寫之後，Spring Boot 到時候就會將 request body 中的 JSON 參數，自動轉換成我們自定義的 STudent class 了，因此我們後續就可以直接從 test2() 中的 student 參數，直接取得到前端所傳遞過來的 JSON 數據了！\n寫上上述的程式之後，可以重新運行一下 Spring Boot 程式，讓這段程式生效。\n運行成功之後回到 API Tester 上，接著在 Http method 中選擇 POST 請求，url 填上 http://localhost:8080/test2，並且在 request body 中填上下列的 JSON 參數，這樣就可以模擬前端的請求。\n{ \u0026#34;id\u0026#34;: 123, \u0026#34;name\u0026#34;: \u0026#34;Judy\u0026#34; } 而當我們按下 Send 鍵之後，在右下角的 response body 中，就會出現 Spring Boot 所回傳的「請求成功」的訊息。\n此時當我們回到 IntelliJ 上查看的話，在下方的 console 中，就會出現「student 中的 id 值為: 123」、「student 中的 name 值為: Judy」的字串。\n所以這就表示，我們就成功的透過 @RequestBody，去接住前端放在 request body 中所傳遞的 JSON 參數了！所以大家以後就可以透過 @RequestBody，在 Spring Boot 中取得前端所傳遞的 JSON 參數了。\n小結：@RequestBody 用法總結 # 綜合以上的介紹，我們也可以來對 @RequestBody 做個小總結。\n@RequestBody 的用途，就是「接住放在 request body 中的參數」，所以當前端將 JSON 參數透過 request body 來傳遞時，就可以使用 @RequestBody 來處理。\n而在使用 @RequestBody 時，重點是要自己創建「和 JSON 參數一一對應的 Java class」出來，只要創建好這個 Java class，後續 Spring Boot 就會自動將 JSON 參數轉換成該 Java 物件了，非常方便！\n補充：不過在創建和 JSON 參數一一對應的 Java class 時，就是考驗大家對於 JSON 格式的熟悉程度了，如果對 JSON 不太熟悉的話，也可以回頭參考 Day 16 - 結構化的呈現數據 - JSON 格式介紹 的介紹。\n總結 # 這篇文章我們先列出了 Spring Boot 中提供的四種取得前端參數的註解，並且詳細的介紹了前兩個註解 @RequestParam 和 @RequestBody 的用法，介紹要如何透過 @ReqestParam 取得 url 後面的參數，以及要如何透過 @RequestBody 取得 request body 中的 JSON 數據，這兩個都是實務上非常常用的作法，建議大家一定要熟練掌握才行！\n那麼下一篇文章，我們就會接著來介紹另外兩個取得前端參數的註解：@RequestHeader 以及 @PathVariable，那我們就下一篇文章見啦！\n補充：本文是擷取自我開設的線上課程 Java 工程師必備！Spring Boot 零基礎入門 的內容，如果你想了解更多的 Spring Boot 的用法，歡迎參考課程簡介 （輸入折扣碼「HH202601KU」即可享 85 折優惠）。\n","permalink":"https://kucw.io/blog/springboot/19/","tags":null,"title":"Spring Boot 零基礎入門 (19) - 取得請求參數（上）- @RequestParam、@RequestBody"},{"categories":["Spring Boot"],"contents":"哈囉大家好，我是古古。\n在前面的文章中，我們有介紹了 Spring MVC 的 @RequestMapping 和 @RestController 的用法，所以我們現在已經可以接住前端傳過來的請求，並且也能夠回傳 JSON 格式的數據給前端了。\n那麼這篇文章，我們就會回頭來探索 Http 協議中的其他部分，因此這篇文章我們就先來介紹一下，Http method 是什麼，以及常見的 Http method 有哪些。\n目錄 回顧：什麼是 Http Method？ GET 的用法和特性 POST 的用法和特性 GET 和 POST 的比較 總結 回顧：什麼是 Http Method？ # 在一個 Http reqeust 中，我們除了一定要填上 url 之外，另一個必填的資訊，就是 Http method。\n而 Http method 所表示的，是這一次請求所使用的「請求方法」，他的值有好幾種可以選，像是 GET、POST、PUT、DELETE…等等，不同的請求方法，會有不同的特性。\n而在這篇文章中，我們會來介紹最廣泛使用的兩個 Http method，也就是 GET 和 POST 的用法。\nGET 的用法和特性 # GET 是最常使用的 Http Method，大家可以把 GET 想像成是「明信片」的概念，所以換句話說，就是 「當你使用 GET 來請求時，你所傳遞的參數就會被別人看見」。\n補充：前端在發起 Http request 時，也是可以「傳遞參數」給後端的，就像是 Java 中的方法一樣，方法和方法之間是可以傳遞參數的。在前面的文章中我們還沒介紹到「傳遞參數」的實作方式，從這篇文章開始就會介紹到這部分。\n也因為當前端使用 GET 來請求時，他所傳遞的參數是完全公開、可以被大家所看見的，因此這就像是明信片一樣，你所寫的信件內容全部都會被大家所看見，所以才會說 GET 是明信片的概念。\n以下面這張圖為例，當我們使用 GET 來請求時，如果我們想要傳遞參數的話，那就只能夠在 url 的最後面，寫上 id=123\u0026amp;name=Judy 的字串，表示我們要傳遞兩個參數， 一個是「id 為 123」，另一個則是「name 為 Judy」。\n而在撰寫 GET 請求的參數時，有兩個重點要注意：\n參數以 key=value 的格式來撰寫，像是 id=123 就是表示「id 的值為 123」的意思 參數之間要用 \u0026amp; 隔開，像是在上面的例子中，在 id=123 這組參數後面，就要先寫上一個 \u0026amp;，後面才可以寫上下一組參數 name=Judy 另外這種「添加在 url 後面的參數們」，我們會稱呼這些參數為「query parameter」，因此在上圖中的 id=123\u0026amp;name=Judy，他們就稱為是 query parameter。\n所以總結來說，當前端使用 GET 來請求時，前端就必須將參數（query parameter）添加在 url 的最後面，同時也因為 url 是公開的、所有人都能看見，因此當前端使用 GET 來請求時，他所傳遞的參數就會被別人看見，所以 GET 也被稱為是「明信片」的概念。\nPOST 的用法和特性 # 了解了 GET 的用法之後，接下來我們也可以來看一下 POST 的用法和特性。\nPOST 作為也很常使用的 Http method 之一，他就和 GET 完全不一樣了！大家可以把 POST 想像成是「信封」的概念，因此「當你使用 POST 方法時，你所傳遞的參數就可以隱藏起來，不被別人看見」。\nPOST 之所以可以隱藏參數，就是因為在使用 POST 請求時，前端要將「參數放在 request body 中傳遞」，並且 request body 在傳遞的過程中會整個被封裝起來，不會被別人看見，因此放在裡面的參數就不會洩漏，所以才會說 POST 是信封的概念（因為請求的參數不會被別人看見）。\n舉例來說，當我們使用 POST 來請求時，就可以使用 JSON 格式，將「id 的值為 123、name 的值為 Judy」的資訊，放在 request body 中來傳遞：\n因此當前端使用 POST 來請求時，前端就可以將參數放在 request body 中來傳遞，又因為 request body 在傳遞的過程中是封裝起來、不會被別人看見的，因此當前端使用 POST 來請求時，他所傳遞的參數就可以隱藏起來，不被其他人看見，所以 POST 也被稱為是「信封」的概念。\n補充：透過上面的例子也可以發現一個亮點，就是在 request body 中的參數，通常都是用 JSON 格式來撰寫的！所以學好 JSON 格式真的很重要啊！！他在使用上非常廣泛，在各個地方都可以看到 JSON 的身影。\n如果不熟悉 JSON 用法的話，也可以回頭參考 Day 16 - 結構化的呈現數據 - JSON 格式介紹 的介紹。\nGET 和 POST 的比較 # 所以總結上面的介紹的話，我們可以將 GET 和 POST 的特性整理成下面這張表格：\nGET POST 概念 明信片 信封 用途 將參數添加在 url 後面傳遞 將參數放在 request body 中來傳遞（使用 JSON 格式） 參數可見度 所有人都能看到參數的資訊，安全性較低 參數是不公開的，其他人看不見傳遞的參數，安全性較高 因此後續我們就可以在不同的時機點，使用較適合當前情況的請求方式了。\n總結 # 這篇文章我們介紹了 Http method 中常用的兩個 method：GET 和 POST，並且也介紹了他們在傳遞參數之間的差別。\n在了解了 GET 和 POST 傳遞參數的差別之後，接著下一篇文章，我們就會回到 Spring Boot 上，來介紹要如何在 Spring Boot 中，去接住前端傳遞過來的參數，那我們就下一篇文章見啦！\n補充：本文是擷取自我開設的線上課程 Java 工程師必備！Spring Boot 零基礎入門 的內容，如果你想了解更多的 Spring Boot 的用法，歡迎參考課程簡介 （輸入折扣碼「HH202601KU」即可享 85 折優惠）。\n","permalink":"https://kucw.io/blog/springboot/18/","tags":null,"title":"Spring Boot 零基礎入門 (18) - 常見的 Http method - GET 和 POST"},{"categories":["Spring Boot"],"contents":"哈囉大家好，我是古古。\n在上一篇文章中，我們有介紹了 JSON 格式的寫法，所以之後我們就可以使用 JSON 格式，更簡單直覺的去呈現數據，進而提升前後端溝通的效率了。\n那麼接著的這篇文章，我們就會回到 Spring Boot 程式中，來看一下要如何將 MyController 所回傳的值，改成是以 JSON 的格式來返回，讓前端能夠取得到 JSON 格式的數據。\n目錄 回顧：到目前為止的返回數據 如何將 Spring Boot 的返回值轉換成 JSON 格式？ 步驟一：在 class 上面加上 @RestController 步驟二：將該方法的返回值，改成是「Java 物件」 小結：將 Spring Boot 的返回值轉換成 JSON 格式的步驟 補充：@Controller 和 @RestController 的差別在哪裡？ 總結 回顧：到目前為止的返回數據 # 在上兩篇文章中，我們有在 MyController 中添加了一個新的 product() 方法，並且為他添加對應的 url 路徑 /product，程式如下：\n所以目前當前端去請求 http://localhost:8080/product 時，後端的 Spring Boot 程式就會在 response body 中，返回「第一個是蘋果，第二個是橘子」的數據給前端。\n不過在我們了解了 JSON 格式的寫法之後，我們現在就可以將「第一個是蘋果，第二個是橘子」這種人類語言的句子，改成是以下列的 JSON 格式來撰寫：\n{ \u0026#34;productList\u0026#34;: [\u0026#34;蘋果\u0026#34;, \u0026#34;橘子\u0026#34;] } 因此在這篇文章中，我們的目標，就是要去修改 MyController 中的 product() 方法，將他的 return 返回值，從「第一個是蘋果，第二個是橘子」改成是返回上面的 JSON 格式的數據，這樣子才能夠成功的返回 JSON 格式的數據給前端。\n如何將 Spring Boot 的返回值轉換成 JSON 格式？ # 如果我們想要將 Spring Boot 程式中的某個方法，將他的返回值改成是以 JSON 格式來傳遞的話，那麼就需要兩個步驟：\n在該 class 上面加上 @RestController 將該方法的返回值，改成是「Java 中的物件」 只要完成了這兩個步驟，就可以改成用 JSON 格式去返回數據給前端了！\n步驟一：在 class 上面加上 @RestController # 在 Spring MVC 中，有一個非常厲害的註解 @RestController，他可以說是集多功能於一身的超強註解！只要在某個 class 上面加上 @RestController 之後，那麼就可以達到以下的效果：\n使這個 class 成為一個 Bean 讓該 class 中的 @RequestMapping 能夠生效 能夠將返回值自動轉換成 JSON 格式 因此 @RestController 在使用上可以說是非常的方便，一箭三鵰！\n而如果我們回頭看一下之前所寫的程式，其實我們已經有在 MyController 中添加 @RestController 這個註解了：\n所以其實到目前為止，我們已經完成了第一個步驟，也就是在 class 上添加 @RestController 了！\n步驟二：將該方法的返回值，改成是「Java 物件」 # 而當我們有在 class 上加上 @RestController 之後，那麼下一步，就是要將這個方法的返回值，改成是「Java 物件」。\n這裡的運作邏輯是這樣的：首先 Spring Boot 程式會將 Java class 中的變數，一一的去轉換成 JSON 格式中的 key，並且該 key 的 value 值，就是 Java class 中的變數所儲存的值。\n這個聽起來可能有點複雜，所以下面我們就透過一個例子，來了解一下他的運作邏輯。\n舉例來說，假設我們有一個 Student class，他裡面有兩個變數：一個是 Integer 類型的變數 id、另一個是 String 類型的變數 name，並且在這個 class 中，也有實作這兩個變數各自的 getter() 和 setter() 方法。\npublic class Student { private Integer id; private String name; public Integer getId() { return id; } public void setId(Integer id) { this.id = id; } public String getName() { return name; } public void setName(String name) { this.name = name; } } 此時，如果我們改寫一下 MyController 中的 test() 方法，將他的返回值，改成是回傳 Student 類型的話：\n@RequestMapping(\u0026#34;/test\u0026#34;) public Student test() { Student student = new Student(); student.setId(123); student.setName(\u0026#34;Judy\u0026#34;); return student; } 那麼這個時候，當前端來請求 http://localhost:8080/test 時，Spring Boot 就會執行第 11～14 行的程式，最終去回傳一個 student 物件給前端。\n而在 Spring Boot 在回傳 student 物件給前端時，Spring Boot 就會將這個 student 物件，先去轉換成 JSON 格式，最後才回傳給前端，因此前端最終所收到的結果，就會是 JSON 格式的數據了！\n所以透過這個邏輯，我們就可以用一樣的方式去改寫 product() 方法，將他的返回值，從 String 類型改為是其他的 Java 物件，這樣子就可以回傳 JSON 格式的數據給前端了！\n因此我們可以先去創建一個新的 class，該 class 的名字為 Store，並且其中的程式如下：\npublic class Store { public List\u0026lt;String\u0026gt; productList; public List\u0026lt;String\u0026gt; getProductList() { return productList; } public void setProductList(List\u0026lt;String\u0026gt; productList) { this.productList = productList; } } 接著我們用一樣的邏輯，回頭改寫一下 product() 方法，所以我們先將返回的類型改成是 Store，並且將「蘋果」和「橘子」這兩個值，添加到 store 中的 productList 變數裡面：\n@RequestMapping(\u0026#34;/product\u0026#34;) public Store product() { Store store = new Store(); List\u0026lt;String\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); list.add(\u0026#34;蘋果\u0026#34;); list.add(\u0026#34;橘子\u0026#34;); store.setProductList(list); return store; } 因此後續當前端來請求 http://localhost:8080/product 時，Spring Boot 就會執行第 22～27 行的程式，最終去回傳一個 store 物件給前端。\n而在 Spring Boot 在回傳 store 物件給前端時，Spring Boot 就一樣是會將這個 store 物件，先去轉換成 JSON 格式，最後才回傳給前端，因此前端最終所收到的結果，就也會是 JSON 格式的數據了！\n所以透過這樣子的寫法，我們就成功的將 Spring Boot 中所實作的程式，改成是以 JSON 格式來返回數據了！\n小結：將 Spring Boot 的返回值轉換成 JSON 格式的步驟 # 所以總合上面的介紹，我們總共只需要兩個步驟，就可以「將 Spring Boot 的返回值轉換為 JSON 格式來傳遞」，而這兩個步驟分別是：\n在該 class 上面加上 @RestController 將該方法的返回值，改成是「Java 中的物件」 只要完成這兩個步驟，Spring Boot 就會自動在回傳數據給前端之前，將「Java 物件」轉換成「JSON 格式」，因此前端最終所收到的數據，就會是 JSON 的格式了！\n因此我們後續就可以透過這個寫法，使用 JSON 格式和前端進行溝通了，這也是實務上非常常見的用法，建議大家一定要熟練掌握才行。\n補充：@Controller 和 @RestController 的差別在哪裡？ # 了解了如何在 Spring Boot 中返回 JSON 格式的數據之外，最後我們也可以來補充一下，@Controller 和 @RestController 這兩個很像的註解，他們的差別在哪裡。\n雖然 @Controller 和 @RestController 的用途有點像，不過他們之間還是有一個致命性的差別，也就是 @Controller 會將方法的返回值轉換為「前端模板的名字」、@RestController 會將方法的返回值轉換為「JSON 格式的數據」。\n因此像是在以前的時代，因為前後端之間的界線很模糊（那時候甚至還沒有專職的前端工程師），所以後端就需要在 Spring Boot 程式中返回前端的模板給使用者，因此當時通常都是在 class 上面加上 @Controller，指定「要返回的前端模板的名字」為何。\n不過隨著前後端分離的盛行、以及 JSON 格式的崛起，目前大部分的程式都是以 JSON 格式來傳遞數據，也因為如此，漸漸的我們在 class 上就會改成使用 @RestController，改成使用 JSON 格式來傳遞數據。\n因此 @Controller 和 @RestController 可以說是見證了網頁開發的歷史，就是因為前端的崛起，才使得我們要從 @Controller 轉換到 @RestController，因此大家目前在開發上，通常都是會使用 @RestController 來返回 JSON 數據比較多，只有少見的較舊的專案，仍舊會使用 @Controller 來回傳前端的模板。\n所以就建議大家，在實作上優先使用 @RestController 去回傳 JSON 格式的數據給前端，只有在使用 JSP 或是 Thymeleaf 這類的前端模板引擎時，才需要改用 @Controller，這個部分是大家在實作上要多加留意的細節。\n總結 # 這篇文章我們有去活用了前面所學到的內容，將 Spring Boot 所返回的回傳值，改成是以 JSON 格式來傳遞，並且也補充了 @Controller 和 @RestController 的差別。\n那麼到這邊為止，我們就大致了解了 Spring MVC 的基本用法了，像是我們已經知道：\n如何使用 @RequestMapping，去進行 url 的路徑對應 如何使用 @RestController，去返回 JSON 格式的數據給前端 JSON 格式的寫法 所以到目前為止，我們已經可以成功的接住前端所傳過來的請求，並且也能夠成功的回傳 JSON 數據給前端了，讚！！\n那麼在大家對 Spring MVC 有一個初步的認識之後，接下來的文章，我們就會繼續來探索 Http 協議中的其他部分，繼續介紹 Spring MVC 的相關用法。\n因此下一篇文章，我們就會接著來介紹 Http 協議中的「Http method」，了解什麼是 GET 和 POST，並且要在什麼時機點去使用他們，那我們就下一篇文章見啦！\n補充：本文是擷取自我開設的線上課程 Java 工程師必備！Spring Boot 零基礎入門 的內容，如果你想了解更多的 Spring Boot 的用法，歡迎參考課程簡介 （輸入折扣碼「HH202601KU」即可享 85 折優惠）。\n","permalink":"https://kucw.io/blog/springboot/17/","tags":null,"title":"Spring Boot 零基礎入門 (17) - 返回值改成 JSON 格式 - @RestController"},{"categories":["Spring Boot"],"contents":"哈囉大家好，我是古古。\n在上一篇文章中，我們有去要如何使用 @RequestMapping，將 url 路徑對應到 Spring Boot 程式的方法上。\n那麼這篇文章，我們就接著來介紹，要如何透過 JSON 格式，結構化的去呈現返回給前端的數據。\n目錄 回顧：到目前為止的返回數據 什麼是 JSON？ JSON 格式介紹 使用 {} 表示 object（物件） Key 和 Value 的概念 新增多組 Key-Value 使用 JSON 的注意事項 JSON 格式所支援的類型 補充：JSON 中的 List 概念 最後，讓我們回到最一開始的問題 總結 回顧：到目前為止的返回數據 # 在上一篇文章的最後面，我們有添加了一個新的 product() 方法，並且為他添加對應的 url 路徑 /product，程式如下：\n如果我們觀察一下的話，可以發現在這個 product() 方法中，他的 return 返回值是使用「字串」來表達「第一個是蘋果、第二個是橘子」的資訊，而這其實是非常人類語言的表達方式，因此對於電腦的程式語言來說，是很難辨別的。\n所以為了讓程式語言可以更有效率的讀取數據、呈現數據，因此 JSON 這個格式就被發明出來了！\n什麼是 JSON？ # JSON 是一種數據呈現的格式，而他的目的，就是用「更簡單、更直覺的方式去呈現數據」，因此當我們使用了 JSON 之後，就可以在前後端之間更有效率的傳遞數據，所以就不用再和上面一樣，藥用人類的語言去形容複雜的數據了。也因為 JSON 格式的應用非常廣泛，因此熟練掌握 JSON 格式的應用，可以說是對實務上非常有幫助！\n舉例來說，當我們使用了 JSON 之後，就可以將「我的學號是 123，名字是 Judy」這句話，改成用下面的 JSON 格式來呈現：\n{ \u0026#34;id\u0026#34;: 123, \u0026#34;name\u0026#34;: \u0026#34;Judy\u0026#34; } JSON 格式介紹 # 大概了解了 JSON 的好處之後，接下來我們也可以來看一下，要如何才能撰寫出 JSON 格式的數據。\n使用 {} 表示 object（物件） # 首先在 JSON 格式中，可以使用一組大括號 {} 來表示一個 object（物件），譬如說當我們寫出下面這一段 JSON 格式的數據時，就表示我們 new 出了一個 object：\n{ //.... } Key 和 Value 的概念 # 而在寫好一對大括號 {} 之後，我們就可以在大括號 {} 裡面，去定義「key 和 value 的配對」，這個 key 的地位就等同於是去宣告一個 Java 中的變數，而 value 就是去設定這個變數的值。\n舉例來說，假設我們在大括號裡面加上一行程式 \u0026quot;id\u0026quot;: 123，就表示我們去創建了一組 key-value 的配對，其中 key 就是 id，而 value 就是冒號右邊的 123。\n{ \u0026#34;id\u0026#34;: 123 } 所以在上面這行程式中，\u0026quot;id\u0026quot;: 123 就是表示「有一個變數 id，他的值為 123」的意思。\n所以在 JSON 格式中，我們就可以透過 key-value 的寫法，去新增許多組 key-value 出來了。\n新增多組 Key-Value # 延續上面的例子，現在在 JSON 的大括號中，我們已經寫上一組 \u0026quot;id\u0026quot;: 123 的 key-value 了，而 \u0026quot;id\u0026quot;: 123 所表達的邏輯意義，就是「我的 id 的值為 123」的意思。\n如果這時候，我們想要在大括號中再去新增一組 key-value 的話，那首先我們就要先在 \u0026quot;id\u0026quot;: 123 的後面加上一個逗點 ,，接著換行，然後輸入第二組 key-value 配對的值，譬如說寫上 \u0026quot;name\u0026quot;: \u0026quot;Judy\u0026quot;，用來表示「我的名字為 Judy」。\n{ \u0026#34;id\u0026#34;: 123, \u0026#34;name\u0026#34;: \u0026#34;Judy\u0026#34; } 所以在上面這個寫法中，\u0026quot;name\u0026quot;: \u0026quot;Judy\u0026quot; 中的 key 就是 name，表示我們創建了一個變數叫做 name，然後這個 name 變數的值，就是冒號右邊的 Judy。因此我們就可以用 \u0026quot;name\u0026quot;: \u0026quot;Judy\u0026quot; 這一行寫法，去表達「我的名字為 Judy」的意義。\n而當我們實作到這裡，如果現在回頭看這整個 JSON 的話，目前在這整個 JSON 裡面就表達了兩個資訊，分別是 \u0026quot;id\u0026quot;: 123（我的 id 為 123），以及 \u0026quot;name\u0026quot;: \u0026quot;Judy\u0026quot;（我的名字為 Judy）這兩個意義了！\n因此透過 JSON 格式的寫法，就可以用更簡單的結構去呈現數據，因此就可以簡化開發，進而提升前後端溝通的效率了！\n使用 JSON 的注意事項 # 在使用 JSON 時，有一個很重要的注意事項要留意，就是 「在 JSON 中的所有 key，都必須要加上雙引號 \u0026quot; \u0026quot; 來框住才可以」。\n像是在我們前面所撰寫的 JSON 例子，就有在 id 和 name 這兩個 key 的前後，使用一對雙引號，把這個 key 給框起來：\n{ \u0026#34;id\u0026#34;: 123, \u0026#34;name\u0026#34;: \u0026#34;Judy\u0026#34; } 這個是在撰寫 JSON 格式時，一定要注意的細節！因此大家後續在實作上，就要多加小心這個部分。\nJSON 格式所支援的類型 # 透過上述的介紹，現在我們知道，在 JSON 中是會透過 key-value 的配對，去創建許多組的變數和他對應的值的。\n而在這些值中，JSON 支援以下幾種類型，分別是：\nJSON 支援的類型 例子 整數 \u0026quot;id\u0026quot;: 123 浮點數 \u0026quot;score\u0026quot;: 1.111 字串 \u0026quot;name\u0026quot;: \u0026quot;Hello\u0026quot; Boolean \u0026quot;option\u0026quot;: true List \u0026quot;list\u0026quot;: [1, 2, 3] 因此大家在使用上，就可以根據不同的需求，去為 key 設定不同類型的 value 值了。\n補充：JSON 中的 List 概念 # 在 JSON 中，value 的值除了可以使用基本類型的整數、浮點數、字串\u0026hellip;等之外，value 的值也是可以設定成一個 List 的，因此我們就可以像 Java 一樣，在 List 裡去添加許多值（用法類似於 Java 中的 List）。\n而要在 JSON 中創建一個 List 的話，就只要寫上一對中括號 []，這樣就可以創建一個 List 出來了，因此我們後續就可以在這個 List 裡面，去填上我們想要放的內容了。\n舉例來說，當我們寫出下面這個 JSON 格式時：\n{ \u0026#34;appleList\u0026#34;: [\u0026#34;apple1\u0026#34;, \u0026#34;apple2\u0026#34;, \u0026#34;apple3\u0026#34;] } 就表示我們去定義了一個 key 叫做 appleList，並且這個 appleList 所對應的 value 值為 List 類型，同時在這個 List 裡面，我們就存放了 3 個值，分別是 apple1、apple2、以及 apple3。\n所以透過這一行 \u0026quot;appleList\u0026quot;: [\u0026quot;apple1\u0026quot;, \u0026quot;apple2\u0026quot;, \u0026quot;apple3\u0026quot;] 的寫法，就可以表達出「在這個 appleList 中有三個蘋果，並且第一個蘋果叫做 apple1、第二個蘋果叫做 apple2、第三個蘋果叫做 apple3」的資訊了。\n補充：因為篇幅的關係，所以本文中沒辦法完整介紹 JSON 中的所有內容，僅能做一個簡單的入門介紹而已，因此大家如果後續想要更了解 JSON 的話，建議可以再上網查詢「巢狀 JSON」的相關用法。\n最後，讓我們回到最一開始的問題 # 在了解了如何撰寫 JSON 格式之後，最後我們可以回到這篇文章最一開始的問題：要如何把 product() 方法所返回的「第一個是蘋果、第二個是橘子」的人類語言，改成用 JSON 的格式來傳遞？\n所以現在我們就可以運用前面所介紹的 JSON 用法，將「第一個是蘋果、第二個是橘子」的句子，改寫成下面的 JSON 格式：\n{ \u0026#34;productList\u0026#34;: [\u0026#34;蘋果\u0026#34;, \u0026#34;橘子\u0026#34;] } 因此透過上面這一行 \u0026quot;productList\u0026quot;: [\u0026quot;蘋果\u0026quot;, \u0026quot;橘子\u0026quot;] 的寫法，我們就可以表達出「在這個 productList 中有兩個商品，並且第一個商品叫做蘋果、第二個商品叫做橘子」的資訊了！\n總結 # 這篇文章我們先介紹了什麼是 JSON 格式，接著也介紹了 JSON 格式中的 key-value 的寫法、以及 JSON 所支援的類型，讓大家熟悉一下 JSON 格式的寫法。\n而在我們了解了 JSON 格式的用法之後，接著下一篇文章，我們就會回到 Spring Boot 程式中，嘗試去改寫一下 MyController 中的 product() 方法，將他所回傳的返回值改寫成 JSON 格式，那我們就下一篇文章見啦！\n補充：本文是擷取自我開設的線上課程 Java 工程師必備！Spring Boot 零基礎入門 的內容，如果你想了解更多的 Spring Boot 的用法，歡迎參考課程簡介 （輸入折扣碼「HH202601KU」即可享 85 折優惠）。\n","permalink":"https://kucw.io/blog/springboot/16/","tags":null,"title":"Spring Boot 零基礎入門 (16) - 結構化的呈現數據 - JSON 格式介紹"},{"categories":["Spring Boot"],"contents":"哈囉大家好，我是古古。\n在上一篇文章中，我們先介紹了 Http 協議的用途，也介紹了 Http request 和 Http response 的格式規範，並且也有實際到 API Tester 中，練習去發起一個 Http request、以及查看 Http response 的返回值。\n那麼這篇文章，我們就會回到 Spring MVC 中，來介紹要如何使用 @RequestMapping，將 url 路徑對應到 Spring Boot 程式的方法上。\n目錄 回顧：什麼是 Http 協議？ 什麼是 Url？ Url 的格式規範 1. 使用的協議 2. 域名 3. Port（端口） 4. url 路徑 Url 的例子分析 例子一：YouTube 的 url 分析 例子二：Instagram 的 url 分析 Url 路徑對應：@RequestMapping 使用 @RequestMapping 的注意事項：一定要在 class 上加上 @Controller 或是 @RestController 在 Spring Boot 中練習 @RequestMapping 的用法 練習 @RequestMapping 的用法 新增一個 url 路徑對應 總結 回顧：什麼是 Http 協議？ # 在我們開始介紹 @RequestMapping 的用法之前，我們先回顧一下 Http 協議的用途是什麼。\nHttp 協議的目的，是去「規定資料的傳輸格式，讓前端和後端能夠有效的進行資料溝通」，因此前後端就必須要按照 Http 協議的規定，去傳輸資料給對方。\n而在 Http 協議中，可以分為 「Http Request（請求）」 和 「Http Response（回應）」 兩個部分，而一個 Http request 加上一個 Http response，就可以組合成一次完整的 Http 溝通。\n另外 Http request 和 Http response 在使用上，也是有固定的格式規範的，具體的格式可以參考下面這張圖：\n在大概了解了 Http request 和 Http response 之後，那麼這篇文章要介紹的，就是 Http request 中的 url 的部分。\n什麼是 Url？ # 當我們發起一個 Http request 時，我們需要指定 url 的值，才能夠告訴 API Tester，這一次的請求要發送到哪裡去。\n而這個 url，其實就是我們平常在使用瀏覽器時，在上方網址列中會出現的這一串文字，也就是一般所俗稱的「網址」。\n所以其實我們在日常生活中，是很常去使用 url 的！不過 url 在使用上，也是有固定的格式規範要遵守的，因此接下來我們就來看一下，url 的格式規範為何。\nUrl 的格式規範 # Url 本身其實是可以拆解成許多部分，譬如說以我們在前面的文章中常常輸入的網址 http://localhost:8080/test 為例，這個 url 其實是由以下幾個部分所組成：\n1. 使用的協議 # 首先在 url 的最前面，就會呈現這個 url 所使用的協議是什麼。\n像是在這個例子中，我們所使用的就是「Http 協議」。\n2. 域名 # 在協議的後面，會有一個 :// 做為分隔，接著後面所寫上的就是這個 url 的「域名」。\n像是在上面的例子中，這個 url 的域名就是「localhost」。\n3. Port（端口） # 而在域名的後面，就是這個 url 所使用的 port（端口）。如果在域名的後面有加上一個 :，並且在 : 後面有加上一個數字的話，那這個數字就是 url 所使用的 port。\n所以像是在上面的例子中，因為在 : 後面有寫上 8080，因此就表示這個 url 所使用的 port 為 8080。\n不過在某些情況下，port 有時候可以省略不用寫，所以大家有時候在某些 url 中會看到 port、有時候又看不到，這個是正常的現象。\n補充：port 的概念稍微進階一點，因此建議大家先有個印象就好，基本上在這個系列文中不會再對 port 有更多的深入介紹，因此大家就只要先知道有這個東西存在即可。\n4. url 路徑 # 而在 port 之後的東西，就非常重要了！！\n當我們在 port 的後面，再加上一個斜線 / 之後（或是沒有 port 的話，就是在域名後面的斜線 /），從這個斜線 / 之後的所有東西，就是這個 url 的路徑。\n因此像是在上面的例子中，url 路徑的值就是 /test。\nurl 路徑的概念非常重要，他會決定這個 url 最終要去對應到 Spring Boot 程式中的哪一個方法上，因此大家在開發 Spring Boot 程式之前，一定要先搞懂「url 路徑」是位於整條 url 中的哪個部分，這樣子後續在實作 Spring Boot 程式時，才能夠更清楚了解他們之間的對應關係。\nUrl 的例子分析 # 因為 url 路徑實在是太重要了，他是在實務上使用頻率非常高的一項技術，因此這邊我們就多舉幾個例子，來讓大家更了解 url 路徑的計算方式。\n例子一：YouTube 的 url 分析 # 舉例來說，如果有一個 YouTube 的 url 如下：\nhttps://www.youtube.com/channel/UC3yK8-EsoU7vZNiLnuep1tQ/videos\n那麼這一條 url，就可以拆分成下圖所示，所以 url 路徑的值就會是 /channel/UC3yK8-EsoU7vZNiLnuep1tQ/videos。\n例子二：Instagram 的 url 分析 # 再舉一個例子，假設有另一個 Instagram 的 url 如下：\nhttps://www.instagram.com/p/CHNDtIVl_BS\n那麼這一條 url 就可以拆分成如下圖所示，所以 url 路徑的值就會是 /p/CHNDtIVl_BS。\nUrl 路徑對應：@RequestMapping # 在了解了 url 的格式規範、以及了解如何「計算 url 的路徑」之後，那麼我們就可以進到這篇文章的重頭戲，也就是來介紹要如何使用 @RequestMapping，將 url 路徑對應到 Spring Boot 程式的方法上了。\n所以回到我們最一開始的例子（也就是 http://localhost:8080/test），對於這個 url 來說，他的 url 路徑就是最後面的 /test。\n如果我們想要將這個 /test 的 url 路徑，去對應到 Spring Boot 的方法上的話，那我們就只要使用 @RequestMapping 這個註解就可以達成了！\n舉例來說，當我們在 MyController 中的 test() 方法上：\n先加上 @RequestMapping 並且在後面的小括號中，指定 url 路徑的值為 /test 只要完成上面這兩個步驟，就可以將 url 路徑 /test，去對應到下面的 test() 方法上了！！\n所以這時候，當前端發出一個 Http request、並且他的 url 路徑為 /test 時，那麼 Spring Boot 就會去找到這個 @RequestMapping(\u0026quot;/test\u0026quot;) 這一行程式，並且去執行他下面的 test() 方法了，所以這個就是「url 路徑的對應」，也就是 @RequestMapping 的運作邏輯了！\n使用 @RequestMapping 的注意事項：一定要在 class 上加上 @Controller 或是 @RestController # 在使用 @RequestMapping 去對應 url 的路徑時，有一個非常重要的前提一定要滿足，就是該 class 上面一定要加上 @Controller 或是 @RestController，這樣 @RequestMapping 才會真的生效；否則的話，@RequestMapping 是完全沒有作用的！\n所以像是在上面的例子中，我們就有先在 MyController 上面加上一個 @RestController，也是因為我們有預先加好了 @RestController，因此 @RequestMapping 才會真的生效。\n所以大家在使用 @RequestMapping 時，一定要記得，要在 class 上面加上 @Controller 或是 @RestController，這樣子@RequestMapping 才會真的生效！\n補充：後續的文章會再介紹 @Controller 和 @RestController 的差別，所以大家現在就只要先記得，如果想要讓 @RequestMapping 生效的話，就一定要在 class 上面加上@Controller 或 @RestController 其中一個就對了。\n在 Spring Boot 中練習 @RequestMapping 的用法 # 練習 @RequestMapping 的用法 # 看完了上述對 @RequestMapping 的介紹之後，接著我們也可以實際到 Spring Boot 程式中，來練習一下 @RequestMapping 的用法。這裡建議大家可以多練習幾次，因為 @RequestMapping 的概念可以說是非常的重要，因此掌握好他的用法是會有很大的幫助的！\n在 Spring Boot 的程式中，目前我們已經有在 MyController 的 test() 方法上，有去添加一個 @RequestMapping 了，並且在後面的小括號中，我們寫上了 /test，他的意思就是表示「我們要將 /test 這個 url 路徑，去對應到下面的 test() 方法上」。\n確認好上述的程式之後，接著我們也可以運行一下這個 Spring Boot 程式，來看一下效果。\n當成功運行 Spring Boot 程式之後，接著我們回到 API Tester 中，並且在 url 的地方，輸入 http://localhost:8080/test，表示我們要去請求 http://localhost:8080/test 這個 url。\n因此當我們按下 Send 鍵之後，這時候這個 url 路徑 /test，就會命中 MyController 中的 @RequestMapping(\u0026quot;/test\u0026quot;) 註解，因此到時候，Spring Boot 就會去執行他下面的 test() 方法，並且回傳「Hello World」的資訊給前端了。\n所以這也是為什麼當我們按下 Send 鍵時，就會在 Response body 中出現「Hello World」的結果，背後就是 Spring Boot 程式去執行了 test() 方法，並且將他的返回值回傳給前端。\n新增一個 url 路徑對應 # 練習完上述的請求之後，我們也可以試著在 MyController 中，再去創建一個新的 url 路徑對應來練習看看。\n像是我們可以在 MyController 中，再新增一個方法，這個方法的名字就叫做 product()，並且我們在他上面加上 @RequestMapping(\u0026quot;/product\u0026quot;) 這一行程式。\n@RequestMapping(\u0026#34;/product\u0026#34;) public String product() { return \u0026#34;第一個是蘋果、第二個是橘子\u0026#34;; } 當我們這樣子寫的話，就表示我們 「新增了一個 url 的路徑對應」，也就是將 url 路徑 /product，去對應到他下面的 product() 方法上。\n實作完上述的程式之後，我們也可以重新運行一下 Spring Boot，來看一下效果（記得要重新運行一下 Spring Boot 程式，上述的改動才會成功的被運行起來）。\n重新運行起 Spring Boot 程式之後，這時候我們可以回到 API Tester，並且將 url 改成 http://localhost:8080/product，表示我們要去請求 /product 這個 url 路徑。\n因此當我們按下 Send 鍵之後，Spring Boot 程式就會命中 MyController 中的 @RequestMapping(\u0026quot;/product\u0026quot;) 註解，並且去執行他下面的 product() 方法，因此最後就會在 Response body 中，呈現 product() 方法的返回值「第一個是蘋果、第二個是橘子」的資訊了！\n所以透過 @RequestMapping 的用法，我們之後就可以不斷的在 Spring Boot 程式中，去添加新的 url 路徑對應出來了！\n補充：在 Spring Boot 程式中，不管我們使用 @RequestMapping 創建了多少個 url 路徑對應出來，都是沒問題的！因此隨著專案不斷的推進，我們就會在同一個 Spring Boot 程式中越寫越多 @RequestMapping，這個是正常的現象。\n不過當 Spring Boot 程式中的 url 路徑越寫越多時，這時就要小心，不要重複使用到之前已經被定義過的 url 路徑，因此大家在實作上，要特別注意一下這個細節。\n而在一個 Spring Boot 程式中，有多少個 url 路徑對應都可以（Spring Boot 沒有限制），因此是有可能隨著專案的不斷推進，在該 project 中所寫的 url 路徑對應就越變越多這樣，這個現象是正常的，不過就變成大家後續在寫新的 url 路徑對應時，要小心不用重複使用到已經被定義過的 url 路徑\n總結 # 這篇文章我們先介紹了 url 的格式規範是什麼，並且也介紹了要如何使用 @RequestMapping，將 url 的路徑對應到 Spring Boot 的方法上。\n那麼下一篇文章，我們就會接著來介紹，要如何使用 JSON，結構化的去呈現數據，那我們就下一篇文章見啦！\n補充：本文是擷取自我開設的線上課程 Java 工程師必備！Spring Boot 零基礎入門 的內容，如果你想了解更多的 Spring Boot 的用法，歡迎參考課程簡介 （輸入折扣碼「HH202601KU」即可享 85 折優惠）。\n","permalink":"https://kucw.io/blog/springboot/15/","tags":null,"title":"Spring Boot 零基礎入門 (15) - Url 路徑對應 - @RequestMapping"},{"categories":["Spring Boot"],"contents":"哈囉大家好，我是古古。\n在前一篇文章中，我們先介紹了 Spring MVC 的用途是什麼，先讓大家對 Spring MVC 有一個簡單的認識。\n不過在我們開始介紹 Spring MVC 之前，會需要大家先對前後端溝通的協議有一些基本的認識，因此這篇文章，我們就會先來介紹前後端溝通最基礎的部分，也就是「Http 協議」。\n目錄 什麼是 Http 協議？ Http 協議的定義 Http Request（Http 請求）的格式規範 Http method 介紹 Url 介紹 Request header 介紹 Request body 介紹 Http Response 的格式規範 Http status code 介紹 Response header Response body 在 API Tester 中練習發起 Http request、查看 Http response API Tester 介面導覽 在 API Tester 中發起一個 Http request 在 API Tester 中查看 Http response 補充：發起 Http request 的工具 總結 什麼是 Http 協議？ # 所謂的「Http 協議」，就是「負責去規定資料的傳輸格式，讓前端和後端能夠有效的進行資料溝通」，所以換句話說，Http 協議就是訂定規則的裁判，只要前後端想要透過 Http 協議溝通，那就必須得按照 Http 協議的規則來走。\n舉例來說，像是 Http 協議可能會規定，當前後端在溝通時，每一句話都要加上「您好」，所以前後端的溝通就會變成這樣：\n前端會說：「您好，我想要商品列表」 接著後端會說：「您好，第一個是蘋果，第二個是橘子」 所以 Http 協議的用途，就是去「規範前後端溝通的格式」，因此前後端在溝通時，就會照著 Http 協議所定義的格式走，這樣子就可以讓前後端溝通的格式變得更規範，進而提升溝通效率了！\nHttp 協議的定義 # 大概了解了 Http 協議的概念之後，接著我們可以回頭來看一下 Http 協議的定義。\n所謂的「Http 協議」，就是「負責去規定資料的傳輸格式，讓前端和後端能夠有效的進行資料溝通」，因此前後端就必須要按照 Http 協議的規定，去傳輸資料給對方。\n而在 Http 協議中，可以分為 「Http Request（請求）」 和 「Http Response（回應）」 兩個部分，而一個 Http request 加上一個 Http response，就可以組合成一次完整的 Http 溝通。\n舉例來說：\n當前端向後端詢問：「我想要商品列表」時，這就是一個 Http request（也稱為 Http 請求） 當後端回應前端：「第一個是蘋果，第二個是橘子」時，這就是一個 Http response（也稱為 Http 回應） 而「一個 Http request + 一個 Http response」，就構成了一次完整的 Http 溝通，所以換句話說的話，就是前後端之間有來有往，這樣子就是一次完整的 Http 溝通了。\n當大家了解了 Http request 和 Http response 之間的運作邏輯之後，接著我們就可以詳細的來介紹一下，有關 Http request 和 Http response 的格式規範了！\nHttp Request（Http 請求）的格式規範 # 在一個 Http request 中，可以分成四個部分，分別是：\nHttp method Url Request header Request body 以下我們就分別來介紹一下，每個部分所代表的含義是什麼。\nHttp method 介紹 # Http method 所表示的，是這個 Http request 所使用的 「請求方法」。\nHttp method 有多種值可以選，像是常用的有 GET、POST、PUT、DELETE……等等，不同的請求方法會有不同的特性。\n在後續的文章中，我們會再對常見的兩個 Http method：GET 和 POST，進行更完整的介紹。\nUrl 介紹 # Url 所表示的，其實就是這個網站的網址，也就是會出現在瀏覽器上方網址列中的那一串文字。\nRequest header 介紹 # Request header 主要是放一些請求時的通用資訊，這部分相對比較進階，所以大家可以先略過這部分沒關係。\nRequest body 介紹 # Request body 的用途，是用來 「傳遞請求的參數」，並且只有在使用 POST 或是 PUT 這類的請求方法時，才可以使用 request body 來傳遞參數。\n這部分一樣是會在後續的文章中做更詳細的介紹，所以大家這邊只要先有個概念就可以了。\nHttp Response 的格式規範 # 看完了 Http request 的格式之後，接著我們也可以來看一下 Http response 的格式。\n在一個 Http response 裡面，則是會分成三個部分，分別是：\nHttp status code Response header Response body 以下也是來針對每一個部分，介紹他們所代表的含義是什麼。\nHttp status code 介紹 # Http status code 的中文翻譯為「Http 狀態碼」，用途是表達「這一次 Http 請求的結果為何」。\n譬如說在這次的 Http status code 裡面，如果顯示的是「成功」的狀態碼的話，那就表示這一次 Http 請求成功了；相反的，如果 Http status code 呈現的是「失敗」的狀態碼的話，那就表示這一次的 Http 請求失敗了。\n因此大家可以把這個 Http status code，想像成是一個 「快速確認次 Http 請求是成功還是失敗」 的依據，透過 Http status code，我們就可以快速的判斷這一次的 Http 請求到底是成功還是失敗，進而去執行後續的處理了。\n有關 Http status code 中常見的狀態碼，我們一樣是會在後續的文章中做更詳細的介紹，所以大家一樣先有個概念即可。\nResponse header # Response header 和上面的 Request header 類似，都是放一些通用的資訊，因為他也是屬於比較進階的部分，因此大家也是可以先略過這部分沒關係。\nResponse body # Response body 可以說是在 Http response 中最重要的部分！在 Response body 中所放的，就是「後端要回傳給前端的數據」。\n因此當前端收到了一個 Http response 時，如果這一次的請求是成功的話，前端就會去取得 Response body 中的數據，並且前端會將這些數據，去和前端的排版設計結合在一起，最終就可以呈現完整的網頁給使用者了！\n有關 Response body 的部分，我們也是會在後續的文章中詳細介紹他的用法，因此大家現在只要先知道 Response body 很重要就可以了。\n在 API Tester 中練習發起 Http request、查看 Http response # API Tester 介面導覽 # 了解了 Http request（Http 請求）和 Http response（Http 回應）的格式之後，接著我們也可以實際到 API Tester 中，來練習一下要如何發起一個 Http request。\n補充：此處提到的 API Tester，指的就是我們當初在 Day 2 - 開發環境安裝（Mac 版） 和 Day 3 - 開發環境安裝（Windows 版） 的文章中，有去安裝的 Chrome 擴充功能 Talend API Tester。本系列文後續也都會以 API Tester 來簡稱此擴充功能。\n首先大家可以先打開 Google 瀏覽器，然後點擊右上角的圖示，就可以開啟之前安裝的 Chrome 擴充功能 - API Tester。\n打開 API Tester 之後，會看到下圖中的畫面：\n其中上方是 Http request 的區域，也就是填上請求的參數、url…等等的資訊。\n而下方則是 Http response 的區域，這裡就會呈現後端所回傳的返回值。\n因此我們之後就會透過這個 API Tester 的介面，查看當前 Http request 的參數設定是什麼、以及 Http response 所回傳的內容又是什麼了。\n在 API Tester 中發起一個 Http request # 在 API Tester 中，上方的 Http request 裡的每一個部分，都可以對應到我們剛剛所介紹到的 Http request 的格式，也就是：\nHttp method Url Request header Request body 而此處大家可以先在 Http method 的部分選擇 GET，然後在 url 的部分填上下列的值 http://localhost:8080/test，這樣子就完成一個最簡單的 Http request 了！\n填寫好請求參數之後，接著我們可以回到 Spring Boot 程式中，並且將 MyController 中的程式改寫成下面這樣：\n@RestController public class MyController { @RequestMapping(\u0026#34;/test\u0026#34;) public String test() { System.out.println(\u0026#34;Hi!\u0026#34;); return \u0026#34;Hello World\u0026#34;; } } 補充：在前面文章中所練習的 HpPrinter、Printer、MyAspect…等等的程式，在後續的文章中就不會再使用到了，因此大家可以刪除這些程式，專注在 MyController 的開發上即可（在 Spring MVC 的部分中，我們會頻繁的修改 MyController 中的程式，練習如何和前端溝通）。\n修改好 MyController 中的程式之後，接著就可以運行起 Spring Boot 程式，來看一下效果。此時當右下角出現了「Started DemoApplication in 0.666 seconds」時，就表示 Spring Boot 程式運行成功了。\n當 Spring Boot 程式運行成功之後，接著我們可以回到 API Tester 中，然後去點擊右側的「Send」按鈕，這樣子就可以去發起一個 Http request（Http 請求），去請求我們剛剛所實作的後端 Spring Boot 程式了。\n在 API Tester 中查看 Http response # 當大家按下「Send」按鈕之後，此時在下面的 Response 的區塊中，就會呈現後端 Spring Boot 程式所返回的結果。\n並且在這個 Response 的區塊中，裡面的每一個部分，也可以對應到我們剛剛所介紹的 Http response 的格式，也就是：\nHttp status code Response header Response body 所以像是在這一次的 Http response 中，他的 http status code 的值就呈現了 200，而 200 就是表示「請求成功」的意思，因此我們就可以透過這個 Http status code，快速知道這一次的 Http 請求是成功的。\n而當請求結果為成功時，後端就會將返回的數據放在 Response body 裡面，提供給前端去存取。所以在上圖中也可以看到，Spring Boot 程式就將返回值「Hello World」呈現在 Response body 中。\n所以透過上述的練習，現在我們就可以成功的使用 API Tester，去發起一個 Http request，並且取得成功的取得後端 Spring Boot 程式所返回的 Http response 了，讚！\n補充：在後面的文章中，我們也會反覆的使用這個 API Tester 工具，去模擬前端所發起的 Http request，練習如何和後端的 Spring Boot 程式互動，因此建議大家在這裡也可以先熟悉一下 API Tester 的用法。\n補充：發起 Http request 的工具 # 除了上述所介紹的 API Tester 之外，其實市面上也是有很多其他的工具，像是 Postman、Insomnia、curl…等等，都可以去發起一個 Http request 的。\n不過這些發起 Http request 的工具，其實他們的底層邏輯都是一樣的，就都是去遵守了 Http 協議所規定的 request 和 response 的格式，因此才能夠正常的去發起一個 Http request。\n所以換句話說，只要我們好好的遵守 Http 協議所規定的 request 和 response 的格式，將來不管大家使用的是 API Tester、Postman 或是其他的工具，都是可以達到一樣的效果的！！差別只在於這些工具所提供的 UI 介面不同、以及一些獨家的進階的功能會不一樣而已，但是通用的邏輯部分是一模一樣的！\n所以大家在練習工具的用法時，一定要記得，他們其實都只是去遵守 Http 協議的規定而已，因此了解 Http 協議中的 request 和 response 的格式規範，可以說是非常非常的重要！\n總結 # 這篇文章我們先介紹了什麼是 Http 協議，並且分別介紹了 Http request 和 Http response 的格式規範，讓大家對 Http 協議有更多的認識。\n在大家了解了 Http 協議的基本概念之後，下一篇文章我們就會接著來介紹 Spring MVC 中的常用註解：@RequestMapping，了解要如何透過 @RequestMapping，將 url 路徑對應到 Spring Boot 的程式中，那我們就下一篇文章見啦！\n補充：本文是擷取自我開設的線上課程 Java 工程師必備！Spring Boot 零基礎入門 的內容，如果你想了解更多的 Spring Boot 的用法，歡迎參考課程簡介 （輸入折扣碼「HH202601KU」即可享 85 折優惠）。\n","permalink":"https://kucw.io/blog/springboot/14/","tags":null,"title":"Spring Boot 零基礎入門 (14) - Http 協議介紹"},{"categories":["Spring Boot"],"contents":"哈囉大家好，我是古古。\n在前面的文章中，我們介紹了 Spring 框架中最重要的兩個特性：IoC 和 AOP，所以到目前為止，大家對於 Spring Boot 的基本用法，就不會那麼陌生了。\n那麼從這篇文章開始，就會進入到下一個部分，也就是 Spring MVC 的介紹，Spring MVC 可以說是在 Spring Boot 中使用最頻繁的功能之一，所以我們就開始吧！\n目錄 回顧：前端和後端的差別 什麼是 Spring MVC？ 補充：原來我們已經用過 Spring MVC 了？ 總結 回顧：前端和後端的差別 # 在我們正式介紹 Spring MVC 之前，我們可以先來回顧一下「前端」和「後端」之間的差別。\n在現今的網站架構中，可以分成「前端」和「後端」兩部分：\n在現今的網站架構中，可以分成「前端」和「後端」兩部分：\n前端：負責網頁的排版設計。 所以像是網頁中要使用什麼顏色的按鈕、按鈕要放在哪裡、標題大小要多大…等等，這些都是屬於前端的範疇。 後端：負責數據處理。 所以像是商品的價格是多少、每一筆評價的留言內容是什麼…等等，這些有關數據內容的，都是屬於後端的範疇。 所以簡單來說，前端工程師就是去負責實作「這個網頁要長什麼樣子」，而後端工程師則是負責去處理「要在這個網頁上賣什麼東西」，所以前端工程師處理的是排版設計，而後端工程師處理的則是動態的數據。\n不過我們平常所瀏覽的網頁，其實是前端和後端整合在一起的結果，所以前端除了設計網頁的排版之外，同時也需要去問後端：「這裡應該要顯示哪些商品？」，而後端在收到詢問之後，就會提供商品的數據給前端，告訴前端「這裡要呈現的商品數據是什麼」。\n因此當前端拿到這些商品數據之後，前端就會將商品數據、以及網頁的排版設計結合在一起，最後再將結果呈現給使用者看。\n所以我們平常所瀏覽的網頁，就是由 「前端的排版」 加上 「後端的數據」，所組合出來的成果。\n而在這之中，要怎麼樣讓前端和後端之間能夠順暢溝通、傳遞商品的數據，就是 Spring MVC 所負責的範圍了。所以 Spring MVC 所負責的，就是解決「前端和後端之間的溝通問題」。\n所以換句話說的話，在接下來的 Spring MVC 的部分中，我們所介紹的所有內容，就都是在講「要如何和前端進行溝通」。\n什麼是 Spring MVC？ # 大概了解了 Spring MVC 功能的用途之後，接著我們可以回頭來看一下 Spring MVC 的定義。\nSpring MVC 的用途，就是「讓我們能夠在 Spring Boot 中，實作前後端之間的溝通」，這樣我們就可以透過 Spring MVC 的功能，在 Spring Boot 中創建一個 API 出來、或是去接住前端所傳過來的參數了！\n補充：原來我們已經用過 Spring MVC 了？ # 其實在前面的文章中，我們就已經有使用到 Spring MVC 的功能了！\n在 Day 4 - 第一個 Spring Boot 程式 的那篇文章中，我們在 Spring Boot 程式裡面，有去創建了一個 MyController 出來。當時是告訴大家，只要我們運行起 Spring Boot 程式，然後在瀏覽器中輸入 http://localhost:8080/test 時，這樣 Spring Boot 就會去執行 MyController 中的 test() 方法。\n因此我們在前面的文章中，就一直借用了這個方式，去練習前面的 IoC 和 AOP 的部分。\n而我們之所以在瀏覽器中輸入 http://localhost:8080/test，Spring Boot 就會去執行 MyController 中的 test() 方法，就是因為我們有在 MyController 中添加了 @RestController 和 @RequestMapping 這兩個註解，因此才能夠達到這個效果。\n而這兩個註解 @RestController 和 @RequestMapping，其實就是 Spring MVC 所提供的好用註解！\n所以在後面的文章中，我們就會來介紹 Spring MVC 中的好用功能，也會來介紹 @RestController 和 @RequestMapping 這些註解，他們分別的用途又是什麼。\n所以接下來的幾篇文章，就讓我們一起來探索 Spring MVC 的厲害之處吧！\n總結 # 這篇文章我們先回顧了前端和後端之間的區別，並且也介紹了 Spring MVC 的用途是什麼，先讓大家對 Spring MVC 有一個簡單的認識。\n不過在我們正式進入 Spring MVC 的介紹之前，會需要大家先了解什麼是「前端和後端之間的溝通協議」，因此下一篇文章，我們就會先來介紹前後端溝通最基礎的部分，也就是 Http 協議，那我們就下一篇文章見啦！\n補充：本文是擷取自我開設的線上課程 Java 工程師必備！Spring Boot 零基礎入門 的內容，如果你想了解更多的 Spring Boot 的用法，歡迎參考課程簡介 （輸入折扣碼「HH202601KU」即可享 85 折優惠）。\n","permalink":"https://kucw.io/blog/springboot/13/","tags":null,"title":"Spring Boot 零基礎入門 (13) - Spring MVC 簡介"},{"categories":["Spring Boot"],"contents":"哈囉大家好，我是古古。\n在上一篇文章中，我們有去介紹了 Spring AOP 的概念和原理，讓大家先對 Spring AOP 有一個初步的認識。\n那麼這篇文章，我們就會接著來介紹，要如何在 Spring Boot 中使用 Spring AOP 的功能。\n補充：目前在實務上，其實已經不太會直接實作 Spring AOP 的程式了，所以本章節的內容大家就有個印象就好，等到將來真的有需要實作 Spring AOP 時，再回來查看本章節的 @Aspect 用法即可。\n目錄 回顧：什麼是 Spring AOP？ 在 pom.xml 載入 Spring AOP 的功能 創建切面的方法：@Aspect 在切入點方法「執行前」執行切面：@Before 如何解讀 AOP 程式？ 步驟一：先閱讀 @Before 小括號中的程式 步驟二：查看前面的註解是什麼 步驟三：要執行的切面方法 小結：綜合上述的三個步驟 在 Spring Boot 中練習 @Aspect 和 @Before 其他時機點的用法：@After、@Around @After 的用法 @Around 的用法 補充一：切入點（Pointcut）如何撰寫？ 補充二：Spring AOP 的發展 總結 回顧：什麼是 Spring AOP？ # 在上一篇文章中有提到，AOP 的全稱是 Aspect-Oriented Programming，中文翻譯成「切面導向程式設計」或是「剖面導向程式設計」，而 AOP 的概念，就是「透過切面，統一的去處理方法之間的共同邏輯」。\n因此當我們使用了 AOP 之後，就再也不用去複製貼上程式了，我們只需要在切面裡面寫好測量時間的程式，之後就可以在任何地方去使用這個切面，讓這個切面替我們完成測量時間的功能了。\n在 pom.xml 載入 Spring AOP 的功能 # 如果想要在 Spring Boot 中使用 Spring AOP 的功能的話，首先會需要在 pom.xml 檔案中新增下列的程式，這樣才能將 Spring AOP 的功能給載入進來，後續我們才能夠在 Spring Boot 中使用 Spring AOP 所提供的註解。\n所以大家可以先打開左邊側邊欄中的 pom.xml 檔案，然後在第 25 行～第 28 行處，添加下面的程式：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-aop\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 添加好上述的程式之後，此時在 pom.xml 的右上角會出現一個 M 符號，這時記得要點擊一下 M 符號，才能夠成功更新這個 Spring Boot 程式，把 Spring AOP 的功能給載入進來。\n載入好 Spring AOP 的功能之後，接下來我們就可以在 Spring Boot 中使用 Spring AOP 專屬的註解，去實作一個 AOP 的切面出來了！\n創建切面的方法：@Aspect # 如果想要使用 Spring AOP 去創造一個新的切面出來的話，我們就只要在 class 上面，去加上一個 @Aspect 的註解，這樣子就可以成功創建一個切面出來了。\n譬如說我們可以先創建一個新的 class 叫做 MyAspect，然後在上面加上 @Aspect，這樣就可以將 MyAspect 變成是一個切面了。\n不過在使用 @Aspect 去創建新切面時，有一點一定要特別注意，就是「只有 Bean 才可以變成一個切面」。\n所以換句話說的話，在使用 @Aspect 去創建一個新的切面時，同時也必須要使用 @Component，將這個 class 變成是一個 Bean，這樣子 @Aspect 的切面設定才會真的生效！！如果單純只有在 class 上面加上 @Aspect 的話，是完全沒有任何效果的！\n所以大家在實作時一定要記得，在創建切面時，「@Component 和 @Aspect 要一起使用」 就對了。\n在切入點方法「執行前」執行切面：@Before # 創建好切面 MyAspect 這個切面 class 之後，我們就可以在這個 class 裡面，去撰寫切面的方法了。\n舉例來說，我們可以在 MyAspect 裡面，先寫上一個 before() 方法，然後在這個 before() 方法裡面，輸出一行「I\u0026rsquo;m before」的訊息到 console 上。\n接著，只要我們在這個 before() 方法上面，去加上一個 @Before 註解，並且在後面的小括號中，去指定想要的切入點，這樣子就可以在這個切入點的方法 「執行前」，去執行這個 MyAspect 中的 before() 方法了。\n不過看到這裡，大家可能還是會對 @Aspect 和 @Before 的用法有點疑惑（畢竟真的有點抽象），所以接下來我們可以再試著來拆解一下這段程式，了解要如何解讀這些 AOP 的程式。\n如何解讀 AOP 程式？ # 到目前為止，我們已經有在 MyAspect 中，先寫上了一個 before() 方法，並且在這個 before() 方法的上面，也有去加上了一個 @Before 的註解，完成這個切面的實作。\n不過其實上面這一段程式，他是可以拆成三個步驟來解讀的：\n步驟一：先閱讀 @Before 小括號中的程式 # 在 @Before 後面的小括號中的程式，稱為「切入點（Pointcut）」，即是去指定哪個方法要被切面所切。\n舉例來說，假設我們想要測量的是「HpPrinter 中的所有方法的時間」，那麼 HpPrinter 中的所有方法，就是切入點（Pointcut）。\n所以在下面這一段程式中，在 @Before 後面的小括號中的程式，即是去指定「切入點（Pointcut）」，表示我們想要使用這個 MyAspect 的切面，去切哪些方法。\n步驟二：查看前面的註解是什麼 # 確認好了切入點之後，接著就是查看前面所加上的 AOP 註解是什麼。\n像是在這個例子中，我們所加上的就是 @Before 註解，而 @Before 的用途，就是表示要在切入點 「執行前」，去執行 @Before 下面的方法（也就是 before() 方法）。\n所以簡單來說，前面的這個 @Before 註解，他指定的就是 「時機點」，而 @Before 所對應的時機點，就是在切入點的方法「執行前」執行。\n因此在步驟二這裡，就是去確認「切面方法執行的時機點」。\n補充：除了 @Before 之外，AOP 也有提供其他不同時機點的註解（像是 @After 和 @Around）給我們使用 ，本篇文章後面也會介紹這兩個註解給大家。\n步驟三：要執行的切面方法 # 當我們確認好「切入點」和「時機點」之後，最後就可以在下面的 before() 方法中，去實作切面的程式了。\n像是在這一段程式中，我們就只有在 before() 方法裡面寫上一行程式，去輸出「I\u0026rsquo;m before」的資訊到 console 上。\n小結：綜合上述的三個步驟 # 所以綜合上述的三個步驟，我們就可以去解讀這一段 AOP 的程式的含義是什麼了！\n步驟一：指定了「切入點」為「HpPrinter 中的所有方法」 步驟二：在切入點的方法「執行之前」 步驟三：執行下面的 before() 方法 因此最後的結果，就會長的像是下圖這樣：\n在 Spring Boot 中練習 @Aspect 和 @Before # 看完了上述對 @Aspect 和 @Before 的介紹之後，我們也可以實際到 Spring Boot 程式中，來練習這些程式，實際的去感受一下 Spring AOP 的「切面」到底是如何運作的。\n所以首先我們先把之前所實作的 HpPrinter 給刪減一下，將 count 變數的相關程式刪掉，只留下輸出「HP 印表機: ……」的程式即可。\n@Component public class HpPrinter implements Printer { @Override public void print(String message) { System.out.println(\u0026#34;HP 印表機: \u0026#34; + message); } } 接著同樣是在 com.example.demo 這個 package 底下，我們去創建一個新的 MyAspect class 出來，並且在裡面添加下列的程式：\n@Aspect @Component public class MyAspect { @Before(\u0026#34;execution(* com.example.demo.HpPrinter.*(..))\u0026#34;) public void before() { System.out.println(\u0026#34;I\u0026#39;m before\u0026#34;); } } 接著只需要確保 MyController 中有注入 HpPrinter 進來，並且會去執行 print() 方法，這樣子就可以了。\n實作完程式之後，接著就可以運行 Spring Boot 程式。\n等到 Spring Boot 運行成功之後，大家可以打開瀏覽器訪問 http://localhost:8080/test，理論上要變的跟前面的文章一樣，在瀏覽器中出現一個「Hello World」的字串。\n而這時候回到 IntelliJ 上的話，就可以看到在 console 中，多出現了兩行資訊，分別是「I\u0026rsquo;m before」以及「HP 印表機: Hello World」。\n在 console 上之所以會出現這兩行資訊，就是因為在 Spring Boot 執行 HpPrinter 的 print() 方法之前，Spring AOP 就先去執行了 MyAspect 中的切面方法 before()，因此才會使得「I\u0026rsquo;m before」比「HP 印表機: Hello World」還要早輸出到 console 上。\n因此透過這個例子，大家就可以體會到 Spring AOP 的強大功能了！有了 Spring AOP 之後，我們就可以在任意的時機點，去執行切面的程式，這樣子就可以把共同邏輯給拆分出來，統一的寫在切面中進行管理了。\n所以透過 Spring AOP 的幫助，就可以達到程式的重複利用，並且也可以讓各個 class 更加專注在處理他自己的功能，再也不用去添加一堆不相關的程式了。\n其他時機點的用法：@After、@Around # 在 Spring AOP 中，除了可以使用 @Before，去達到在方法「執行前」去執行切面之外，我們也是可以將 @Before 替換成 @After 或是 @Around，在不同的時機點去執行切面的。\n在 Spring AOP 裡面，有三種時機點可以選擇：\n@Before：在方法「執行前」執行切面 @After：在方法「執行後」執行切面 @Around：在方法「執行前」和「執行後」，執行切面 @After 的用法 # @After 的寫法其實和 @Before 一模一樣，因此只要把 @Before 替換成 @After，這樣子就可以了。所以實際使用起來會是下面這個樣子：\n@Aspect @Component public class MyAspect { @After(\u0026#34;execution(* com.example.demo.HpPrinter.*(..))\u0026#34;) public void after() { System.out.println(\u0026#34;I\u0026#39;m after\u0026#34;); } } @Around 的用法 # @Around 因為寫起來比較複雜，因此此處僅提供程式給大家參考，如果大家有興趣，可以再上網搜尋 @Around 的相關介紹\n@Aspect @Component public class MyAspect { @Around(\u0026#34;execution(* com.example.demo.HpPrinter.*(..))\u0026#34;) public Object around(ProceedingJoinPoint pjp) throws Throwable { System.out.println(\u0026#34;I\u0026#39;m around before\u0026#34;); // 執行切入點的方法，obj 為切入點方法執行的結果 Object obj = pjp.proceed(); System.out.println(\u0026#34;I\u0026#39;m around after\u0026#34;); return obj; } } 補充一：切入點（Pointcut）如何撰寫？ # 在前面的程式中，我們有在 @Before 後面的小括號中，加上一段看起來很長的程式，那一段程式就是在指定方法的切入點為何。\n切入點的寫法是有一定的規則的，像是上面這段程式，就是表示切入點為「HpPrinter 的所有方法」。\n不過由於切入點的語法寫起來還滿複雜的，並且使用頻率也不是很高，因此建議大家有個印象就好，真的需要實作時再去查詢就可以了。以下提供幾種常見的寫法邏輯給大家：\n補充二：Spring AOP 的發展 # 了解了 Spring AOP 的用法之後，最後也跟大家補充一下 Spring AOP 的相關發展。\nSpring AOP 以前最常被用在以下三個地方：\n權限驗證 統一的 Exception 處理 Log 記錄 但是由於 Spring Boot 發展逐漸成熟，因此上述這些功能，都已經被封裝成更好用的工具讓我們使用了，所以大家目前其實已經比較少直接使用 @Aspect 去創建一個切面出來了。\n不過，雖然 Spring AOP 已經漸漸淡出大家的日常使用，但是他作為 Spring 框架中的重要特性之一，還是會常常圍繞在我們周邊的，只是我們可能感覺不太到而已。\n因此上述所介紹的 Spring AOP 的相關用法，大家就有個印象就可以了，重點是要把 AOP 的切面概念搞懂，至於 @Before、@After、@Around 的用法，只要有個印象就可以了。\n總結 # 這篇文章我們先介紹了要如何透過 @Aspect 和 @Before，在指定的時機點去執行切面方法，並且也簡單介紹了另外兩個時機點 @After 和 @Around 的用法，最後我們也補充了切入點的撰寫方式，以及 Spring AOP 的相關發展。\n那麼有關 Spring AOP 的介紹就到這邊結束了，Spring AOP 作為 Spring 框架中的重要特性之一，即使我們在日常的開發中，已經很少直接使用到 AOP 的功能，但是 AOP 的切面的概念，仍舊在許多功能中被廣泛應用，因此了解一下切面的概念還是很不錯的！\n那麼從下一篇文章開始，我們就會進入到下一個部分：Spring MVC，介紹要如何在 Spring Boot 中和「前端」進行溝通，那我們就下一篇文章見啦！\n補充：本文是擷取自我開設的線上課程 Java 工程師必備！Spring Boot 零基礎入門 的內容，如果你想了解更多的 Spring Boot 的用法，歡迎參考課程簡介 （輸入折扣碼「HH202601KU」即可享 85 折優惠）。\n","permalink":"https://kucw.io/blog/springboot/12/","tags":null,"title":"Spring Boot 零基礎入門 (12) - Spring AOP 的用法 - @Aspect"},{"categories":["Spring Boot"],"contents":"哈囉大家好，我是古古。\n在前面的文章中，我們有介紹了 Spring IoC 的特性，先讓大家了解要如何在 Spring Boot 中創建、注入、以及初始化 Bean，為後續的部分打穩基礎。\n那麼從這篇文章開始，我們就會接著來介紹 Spring 框架中的另一個也很重要的特性，也就是 AOP，所以我們就開始吧！\n目錄 什麼是 Spring AOP？ 例子：測量時間的故事 透過 AOP（切面）來輔助 Spring AOP 的定義 總結 什麼是 Spring AOP？ # AOP 的全稱是 Aspect-Oriented Programming，中文翻譯成「切面導向程式設計」或是「剖面導向程式設計」，而 AOP 的概念，就是「透過切面，統一的去處理方法之間的共同邏輯」。\n這個「切面」聽起來可能有點抽象，所以我們就先透過一個例子，來了解一下 AOP（切面導向程式設計）到底是什麼。\n例子：測量時間的故事 # 假設我們有一個 HpPrinter，並且在這個 HpPrinter 裡面只有一個 print() 方法，在 console 上印出傳進來的參數：\n如果我們想要測量一下「執行 print() 方法需要花費多久的時間」的話，那麼最簡單的做法，就是直接在這個方法的最前面和最後面，分別去記錄開始時間和結束時間，最後再將這兩個時間相減，就可以計算出 print() 方法總共執行多久了。\n不過，雖然透過上面的寫法，是可以測量出 print() 方法的運作時間沒錯，但是大家如果觀察一下這段程式的話，就可以發現在這個 print() 方法裡面，充斥了許多跟「印東西」這個功能無關的程式。\n像是原本這個 print() 方法，他本來要做的事情，就只是在 console 上面輸出「HP 印表機: ..….」這一行資訊而已，但是因為我們想要測量 print() 方法的執行時間，所以加了許多不相關的程式進去，進而讓這個方法變得很複雜，不利於後續的程式維護。\n而且上面這樣子的寫法，也有可能會產生「過多程式重複」的問題。\n譬如說我們在 HpPrinter 裡面多新增了一個方法 printColor()，然後我們也想要去測量這個 printColor() 方法的時間的話，那我們就得從 print() 方法中複製所有測量時間的程式，然後貼到 printColor() 方法裡面。\n現在只有這兩個方法要測量時間，所以這樣的複製貼上大家可能覺得還好，但是如果有很多方法都需要測量執行時間時，這樣子的複製貼上就不會是一個好選項。\n所以為了解決這個問題，Spring AOP 就登場了！\n透過 AOP（切面）來輔助 # 我們可以透過下面這張圖來看一下，Spring AOP 是如何解決上面那個複製貼上的問題的。\n如果我們把剛剛的 HpPrinter 畫成圖的話，就可以畫成是下面這個樣子：\n上圖中呈現了 HpPrinter 中的兩個方法：print() 和 printColor()，每一個箭頭代表的是一個方法，而箭頭右邊的程式，就是這個方法裡面所寫的程式。\n在這張圖中可以看到，在這兩個方法裡面，一開始都會去記錄方法的開始時間，接著去執行「印東西」的程式，最後再是去記錄方法的結束時間，並且將結束時間和開始時間相減，計算總共執行多久。\n所以這時候，Spring AOP 就提出一個想法了，既然這些測量時間的程式是每個方法都要使用的共同邏輯，那我們就把這些共同邏輯的程式，去獨立出來成一個「切面」，由這個切面去橫貫所有的方法，替他們做測量時間的部分。\n所以當我們使用了 Spring AOP 之後，我們就不用在方法裡面再去寫上任何測量時間的程式了！我們只要將測量時間的共同邏輯，統一的交給切面去做處理，這個切面會去橫貫所有的的方法，分別去測量每一個方法的執行時間，所以每個方法就只要專注在各自要做的事情就好了，讚！！\n而這種使用「切面」的寫法，就會稱為 AOP，也就是 Aspect-Oriented Programming（切面導向程式設計）了！\nSpring AOP 的定義 # 大概了解了 Spring AOP 的概念之後，我們也可以回頭來看一下 AOP 的定義。\nAOP 的全稱是 Aspect-Oriented Programming，中文翻譯成「切面導向程式設計」或是「剖面導向程式設計」，而 AOP 的概念，就是「透過切面，統一的去處理方法之間的共同邏輯」。\n因此當我們使用了 AOP 之後，就再也不用去複製貼上程式了，我們只需要在切面中寫好測量時間的程式，之後就可以在任何地方去使用這個切面，讓這個切面替我們完成測量時間的功能了，讚啦！\n總結 # 這篇文章我們先透過測量時間的例子，介紹了 Spring AOP 的原理，讓大家更好去理解 Spring AOP 的核心概念是什麼（切面真是一個神奇的東西）。\n那麼下一篇文章，我們就會實際到 IntelliJ 中，練習要如何在 Spring Boot 程式中實作 Spring AOP，那我們就下一篇文章見啦！\n補充：本文是擷取自我開設的線上課程 Java 工程師必備！Spring Boot 零基礎入門 的內容，如果你想了解更多的 Spring Boot 的用法，歡迎參考課程簡介 （輸入折扣碼「HH202601KU」即可享 85 折優惠）。\n","permalink":"https://kucw.io/blog/springboot/11/","tags":null,"title":"Spring Boot 零基礎入門 (11) - Spring AOP 簡介"},{"categories":["Spring Boot"],"contents":"哈囉大家好，我是古古。\n在前面的文章中，我們已經對 Spring IoC 有了滿多的認識，並且也能夠在 Spring Boot 中應用 Spring IoC 的核心用法了。\n那麼接著這篇文章，我們就會繼續深入來介紹，要如何透過 @Value，將 Spring Boot 設定檔中的值讀取到 Bean 裡面，讓我們所寫的 Java 程式可以去運用 Spring Boot 設定檔中的值，所以我們就開始吧！\n目錄 什麼是 Spring Boot 設定檔？ application.properties 的寫法 properties 的語法介紹：key=value properties 語法的注意事項之一：不需要加上空白鍵排版 properties 語法的注意事項之二：key 中的 . 是表示「的」的概念 properties 語法的注意事項之三：使用 # 來表示 comment 讀取 Spring Boot 設定檔（application.properties）中的值：@Value @Value 用法介紹 @Value 的運行結果 使用 @Value 的注意事項之一：需要遵守固定格式寫法 使用 @Value 的注意事項之二：@Value 只有在 Bean 和 @Configuration 中才能生效 使用 @Value 的注意事項之三：類型需要一致 使用 @Value 的注意事項之四：@Value 可以設定預設值 小結：所以，@Value 到底要怎麼用？ 補充一：Spring Boot 設定檔的兩種語法（properties 和 yml） 補充二：yml 的語法介紹 key:value 的寫法 用「縮排」表示中文的「的」的概念 小結：properties 和 yml 的差別 總結 什麼是 Spring Boot 設定檔？ # 所謂的 Spring Boot 設定檔，指的是 「放在 src/main/resources 資料夾底下的 applicaiton.properties 檔案」，而這個 application.properties 的目的，就是「存放 Spring Boot 程式的設定值」。\n所以大家以後只要聽到別人在說「Spring Boot 設定檔」，就要第一時間想到他所指的其實是 application.properties 這個檔案。\n如果我們點擊兩下打開 application.properties 檔案的話，可以看到右邊有一行 spring.application.name=demo 的程式，這個是 IntelliJ 在創建 Spring Boot 專案時所自動生成的設定值。\n這裡大家可以自由選擇要不要將 spring.application.name=demo 這一行程式刪掉（刪掉此設定不影響 Spring Boot 運作），如果不想刪除的話，也可以直接按下 Enter 鍵換行，這樣子就可以繼續在這個 application.properties 檔案中，繼續添加其他的設定值了。\n補充：由於版面的緣故，因此在下面的截圖中不會出現 spring.application.name=demo 的設定。\napplication.properties 的寫法 # 如果想要在 application.properties 中，添加 Spring Boot 的相關設定的話，那就要遵循一定的寫法格式才可以。\n首先大家可以觀察一下，application.properties 這個檔案，他是一個「檔名為 application、並且副檔名為 .properties」的檔案。 因此這就表示，這個 application.properties 檔案，是使用 「properties 語法」 來撰寫設定值的。\nproperties 的語法介紹：key=value # 而在 properties 的語法中，是使用 key=value 的格式來撰寫設定值，並且每一行程式，就是一組 key 和 value 的配對。\n像是下面這個例子，我們就在第 1 行寫上了 count=5，所以這一行程式就是表示：我們定義了一個 key（他的名字是 count），並且這個 count 的 value 值，就是 5。\n所以大家其實可以把這個 key=value 的寫法，簡單的想像成是 變數=值 的概念，在前面的 key 就等同於是 Java 中的變數名稱，而後面的 value，就是這個變數的值，所以 properties 語法的概念其實和 Java 是很相近的！\n因此當我們在 application.properties 中，寫上了一行 count=5 的程式時，就表示我們定義了一個變數 count，然後他的值是 5 這樣，就是這麼的簡單暴力！\nproperties 語法的注意事項之一：不需要加上空白鍵排版 # 大概了解了 properties 語法的核心概念 key=value 的寫法之後，接著我們可以來看一些使用 properties 語法的注意事項。\n當我們以前在寫 Java 程式的時候，習慣會在 = 的前後加上空白鍵，去做排版的美化，所以就會像是下面這個樣子：\n// 美化前 int count=5; // 加上空白鍵美化後 int count = 5; 不過在 properties 語法裡面，是 「不需要」 在 = 的前後加上空白鍵，去做排版的美化的，只要全部連在一起寫就好，多加空白鍵反而會導致程式運行時出現問題。\n所以在 properties 語法裡面，建議就使用下面這種寫法，把你的空白鍵收起來，一路連字連到底就對了！\ncount=5 properties 語法的注意事項之二：key 中的 . 是表示「的」的概念 # 在前面我們有介紹到，properties 語法中是使用 key=value 來撰寫程式的，而 key 所代表的，就是變數的名字。\n不過這個 key 在命名上，是允許裡面帶上 . 符號的，並且這個 . 的符號的邏輯意義，就是中文的「的」的意思。\n舉例來說，我們可以在 application.properties 裡面，在第 2 行寫上 my.name=John 的程式，而當我們這樣寫之後，my.name 這個 key 就是變數的名字，其中文意義就是表示「我的名字」（因為 . 是表示「的」的意思）。\n所以 my.name=John 這一整行的意思，就是「我的名字叫做 John」。\n或是我們也可以在下面，再新增一行 my.age=20 的程式，而這一行程式所代表的，就是「我的年齡是 20 歲」的意思。\n所以大家以後在撰寫 properties 語法時，就可以將 key 中的 .，翻譯成是中文的「的」的意思，所以我們就可以透過這種方式，去傳遞更豐富的邏輯意義出來了。\nproperties 語法的注意事項之三：使用 # 來表示 comment # 在 properties 語法中，我們也是可以去添加 comment 的，只要在撰寫程式時，在最前面加上一個 # 的符號，那麼那一行就會被 properties 語法給忽略了（用法和 Java 中的 // 一樣）。\n讀取 Spring Boot 設定檔（application.properties）中的值：@Value # @Value 用法介紹 # 在了解了 Spring Boot 設定檔（也就是 application.properties 檔案）的用途、以及 properties 語法的 key=value 的寫法之後，接著我們就進到這篇文章的重頭戲，也就是來介紹：要如何透過 @Value，將 application.properties 中的設定值讀取到 Bean 裡面。\n這裡我們仍舊是舉之前的 HpPrinter 的例子，我們可以先稍微改寫一下 HpPrinter 中的程式，將它改回下面這個樣子：\n@Component public class HpPrinter implements Printer { private int count; @Override public void print(String message) { count--; System.out.println(\u0026#34;HP印表機: \u0026#34; + message); System.out.println(\u0026#34;剩餘使用次數: \u0026#34; + count); } } 在這段程式之中，HpPrinter 中的 count 變數沒有被初始化，因此 count 的值預設就會是 0。\n但是如果我們在這個 count 的變數上面，去添加一行 @Value(\u0026quot;${count}\u0026quot;) 的程式的話，這樣子就可以從 application.properties 中，去讀取 key 為 count 的值，並且將這個值給賦予到 HpPrinter 中的 count 變數裡面。\n而又因為我們前面有在 application.properties 的檔案中，在第 1 行寫上了 count=5 的設定。\n所以到時候 HpPrinter 中的 count 變數的值，就會被設定成是 application.properties 中所定義的「5」了！\n@Value 的運行結果 # 當大家改寫好上述的程式之後，我們也可以試著來運行一下 Spring Boot 程式，來實際感受一下 @Value 的效果。\n以目前的程式來說（記得將 MyController 的 @Qualifier 的值改回成 hpPrinter），只要大家運行起 Spring Boot 程式，並且請求 http://localhost:8080/test 之後，IntelliJ 就會在 console 下方呈現下列的資訊。\n其中之所以會輸出「剩餘使用次數: 4」，就是因為我們有在 HpPrinter 中添加一行 @Value(\u0026quot;${count}\u0026quot;) 的程式，因此 HpPrinter 中的 count 的值就會被設定成 5，才導致這裡會輸出「剩餘使用次數為 4 次」的資訊。\n大家如果想玩玩看的話，也可以試著把 application.properties 中的 count 的值改成別的數字，譬如說改成 count=10 之類的。修改完之後，只要重新運行 Spring Boot 程式，並且重新請求 http://localhost:8080/test，這樣子在 console 中所輸出的剩餘使用次數，就會變成是 99 了。\n總而言之，透過上述的運行結果，就代表我們能夠成功的透過 @Value 的用法，將 application.properties 中的設定值讀取到 Bean 裡面了！\n使用 @Value 的注意事項之一：需要遵守固定格式寫法 # 大概了解了 @Value 的用法之後，接著我們也來介紹一下使用 @Value 的一些注意事項。\n在使用 @Value 去讀取 application.properties 中的值時，一定要使用下面這種格式撰寫 @Value 的程式才可以：\n@Value(\u0026#34;${XXX}\u0026#34;) 在這個格式中，其中的 XXX 的部分，可以替換成 application.properties 中的任意一個 key，但是外層的 \u0026quot;${}\u0026quot; 是不能夠省略的！！切記！！！\n也因為 @Value 的固定格式寫法確實比較複雜一點，因此就建議大家，可以直接複製上面這段程式，後續再去修改裡面的 XXX 的值即可。\n舉例來說，假設我們想要讀取 application.properties 中的 printer.count 這個 key，那我們就可以這樣寫：\nprinter.count=100 而後續在使用 @Value 去讀取時，就直接把後面的 XXX 替換成 printer.count 就可以了，所以就可以在 Java 中實作下面這些程式：\n@Value(\u0026#34;${printer.count}\u0026#34;) private int count; 因此透過上述的寫法，我們就可以使用 @Value，去讀取 application.properties 中的設定值到 Bean 裡面了！\n使用 @Value 的注意事項之二：@Value 只有在 Bean 和 @Configuration 中才能生效 # 只要是有使用到 @Value 的地方，該 class 本身就得是一個 Bean、或是一個帶有 @Configuration 的設定 class，這樣子 @Value 才能夠真的生效。\n所以當大家在使用 @Value 時，當你覺得你的程式明明寫得很對，但是不知道為什麼卻沒有作用時，這時候就可以回頭檢查，是不是因為這個 class 還沒變成 Bean，所以 @Value 才會毫無作用。\n因此發生這種情況時，大家就只要在 class 上面加上一個 @Component，將這個 class 變成一個 Bean，這樣子就可以確保 @Value 能真的生效了！\n補充：@Value 除了能在 Bean 中生效之外，在那些帶有 @Configuration 的 class 中也是能生效的，不過因為在此系列文中不會特別介紹到 @Configuration 的用法，所以大家可以先有個印象就可以了。\n使用 @Value 的注意事項之三：類型需要一致 # 在使用 @Value 去讀取 application.properties 中的值時，那個被添加 @Value 的 Java 變數，他的變數類型必須要和 application.properties 中的類型一致才可以。\n舉例來說，在 application.properties 裡面，我們定義了一組 key 和 value 如下：\nprinter.count=5 上面這行程式的意思，是表示 printer.count 的值為 5，而 5 這個數字，就暗示了他的類型為「整數」。\n因此在 Spring Boot 的程式中，我們就必須將 @Value 加在一個「int 或是 long 類型」的變數上，這樣子到時候 @Value 在讀取值時，才不會出現問題。\n@Value(\u0026#34;${printer.count}\u0026#34;) private int count; 又或是說，假設我們在 application.properties 裡面定義了另一組 key 和 value 如下：\nmy.name=John 上面這行程式的意思，是表示 my.name 的值為 John，而 John 這個單字，就暗示了他的類型為「字串」。\n因此在 Spring Boot 的程式中，我們就必須將 @Value 加在一個「String 類型」的變數上，這樣子到時候 @Value 在讀取值時，也才不會出現問題。\n@Value(\u0026#34;${my.name}\u0026#34;) private String name; 使用 @Value 的注意事項之四：@Value 可以設定預設值 # 在使用 @Value 去讀取 application.properties 中的值時，有可能會發生一種情況，就是「該 key 不存在在 application.properties 裡面」的情形出現。\n像是如果我們在 Spring Boot 程式中，寫上了下面這一段程式，嘗試去將 application.properties 中的 printer.count 的值，將他儲存到 count 變數裡面：\n@Value(\u0026#34;${printer.count}\u0026#34;) private int count; 如果這時候 application.properties 中 「沒有」printer.count 這個 key 的話，那麼 Spring Boot 程式就會運作失敗，出現「Could not resolve placeholder \u0026lsquo;printer.count\u0026rsquo; in value \u0026ldquo;${printer.count}\u0026quot;」的錯誤，表示找不到 printer.count 這個 key，所以才會導致運行失敗。\n如果大家想要避免這個問題的話，@Value 也是有提供另一種輔助方式讓我們使用，也就是「設定預設值」。\n像是我們在撰寫 @Value 的程式時，可以在 @Value 中的 key 的後面加上一個 :，並且在後面寫上想要的預設值，譬如說這裡我們就寫上 200：\n@Value(\u0026#34;${printer.count:200}\u0026#34;) private int count; 所以上面這一段程式的意思就是：「@Value 會先去application.properties 中尋找有沒有 printer.count 這個 key，如果有的話，就讀取 application.properties 中的值到 count 變數裡面；如果沒有的話，則將 count 變數的值，設定成預設值 200」。\n因此當我們這樣寫之後，如果 application.properties 中「有設定」printer.count 的值的話（如下方程式所示），那麼 Spring Boot 程式中的 count 變數的值，就會是 5。\nprinter.count=5 但是如果 application.properties 中，「沒有設定」printer.count 的值的話（如下方程式所示），那麼 Spring Boot 程式中的 count 變數的值，就會是 @Value 所設定的預設值 200。\n# no key-value 所以總結來說，如果想要避免「application.properties 中找不到該 key，導致 Spring Boot 程式運行失敗」的狀況的話，那麼就可以在 @Value 中使用 :，接著在後面寫上預設值，這樣子當 application.properties 中找不到該 key 時，就可以直接改成使用預設值來運行。\n補充：不過老實說，@Value 的預設值的用法其實是有好有壞，因為當我們使用了 @Value 的預設值之後，就會讓設定值四散在各個 calss 裡面，後續會比較難統一進行管理，因此建議大家斟酌使用。\n小結：所以，@Value 到底要怎麼用？ # 因為 @Value 的注意事項比較多，所以我們也可以來總結一下 @Value 的用法和注意事項有哪些。\n想要使用 @Value 去讀取 Spring Boot 設定檔（也就是 application.properties 檔案）中的值的話，必須注意以下的事項：\n必須使用固定格式 @Value(\u0026quot;${XXXX}\u0026quot;) 該 class 必須是 Bean 或是 @Configuration 「Java 中的變數」和「application.properties 中的 key」，他們的類型必須要一致 可以視情況添加預設值 只要注意好上述這些地方，大家以後就可以自由的運用 @Value，在 Spring Boot 程式中去讀取 Spring Boot 設定檔（也就是 application.properties 檔案）中的值了！\n補充一：Spring Boot 設定檔的兩種語法（properties 和 yml） # 在前面我們有介紹到，Spring Boot 的設定檔指的就是「application.properties」這個檔案，而 application.properties 裡面所放的，就是 Spring Boot 程式的設定值。\n不過其實在 Spring Boot 中，可以使用兩種不同的語法來撰寫 Spring Boot 的設定，分別是「properties 語法」和「yml 語法」。\n舉例來說：\n當 Spring Boot 設定檔 「命名成 application.properties」 時，即是表示他是使用 properties 語法來撰寫，因此格式是 key=value。 當 Spring Boot 設定檔 「命名成 application.yml」 時，就表示他是使用 yml 語法來撰寫，格式則為 key:value。 所以在 Spring Boot 程式裡面，application.properties 和 application.yml 這兩個檔案，他們的目的都是一樣的，都可以作為 Spring Boot 的設定檔，去儲存相關的設定值，差別只在於他們使用了不同的語法來撰寫而已。\n不過在 Spring Boot 中，我們一次只能夠選擇一種語法來撰寫，所以換句話說的話，就是 application.properties 和 application.yml 這兩個檔案，不能同時存在，只能擇一使用，這是大家在使用上要特別注意的地方。\n補充：雖然我個人是比較喜歡使用 application.properties，不過實務上兩種語法都會看到，因此建議大家兩種語法都還是要熟悉一下會比較好。\n補充二：yml 的語法介紹 # 在前面我們有詳細介紹了 properties 語法的用法，在這裡我們也來補充一些 yml 語法的寫法，提供給大家參考。\nkey:value 的寫法 # 不同於 properties 語法，在 yml 語法中，是採用 key: value 的方式來撰寫設定值。\n不過這裡要特別注意，在 : 的後面，必須要先加上一個空白鍵，然後才能寫上 value 值，這是在撰寫 yml 語法的時候，要特別留意的地方。\ncount: 5 用「縮排」表示中文的「的」的概念 # 在 yml 中，除了會使用 key: value 來撰寫設定值之外，yml 中也改成用「縮排」的方式，來表示中文的「的」的概念。\n像是在前面所介紹的 properties 語法中，當我們寫了下面這行程式，他的中文意義為「我的名字叫做 John」（因為 properties 語法中的 .，就是表示中文的「的」的意思）。\nmy.name=John 但是在 yml 中，則是會改寫成下面這個樣子，透過 「將 name 這一行往右縮排 2 個空白鍵」，表示中文的「的」的意思。\nmy: name: John 所以上面這一段程式讀起來，一樣也是「我的名字是 John」，只是 yml 是透過縮排的方式來表達，而 properties 是使用 . 的方式來表達而已。\n小結：properties 和 yml 的差別 # 所以比較一下 properties 語法和 yml 語法的差別的話，基本上他們在 key 和 value 的寫法上是很類似的，但就是「縮排」的概念需要轉換一下，這是大家在實作上，要特別注意的細節。\n下圖也比較了 properties 語法和 yml 語法的差別，提供給大家參考：\n總結 # 這篇文章我們先介紹了什麼是 Spring Boot 的設定檔（即是 application.properties 檔案）、以及 properties 語法的使用方法，並且我們也介紹了要如何使用 @Value，去讀取 application.properties 中的值到 Bean 裡面。\n那麼到這篇文章為止，有關於 Spring IoC 的介紹就告一個段落了，在這個 Spring IoC 的部分中：\n我們先介紹了 Spring IoC 中最重要的兩個概念：IoC 和 DI 也介紹了什麼是 Spring 容器、什麼是 Bean 並且也有實際到 Spring Boot 中，練習了 @Component、@Autowired、@Qualifier 以及 @PostConstruct 這些註解的用法，去對 Bean 進行創建、注入、以及初始化。 最後也介紹了要如何透過 @Value，去讀取 application.properties 的值到 Bean 裡面 所以透過「Day 5～Day 10」的文章介紹，我們就介紹完 Spring IoC 的重要概念了，雖然這些內容沒辦法涵蓋 Spring IoC 的全部細節，不過作為入門來說，算是已經非常足夠的了！\n那麼從下一篇文章開始，我們就會來了解 Spring 框架中的另一個也很重要的特性：AOP，那我們就下一篇文章見啦！\n補充：本文是擷取自我開設的線上課程 Java 工程師必備！Spring Boot 零基礎入門 的內容，如果你想了解更多的 Spring Boot 的用法，歡迎參考課程簡介 （輸入折扣碼「HH202601KU」即可享 85 折優惠）。\n","permalink":"https://kucw.io/blog/springboot/10/","tags":null,"title":"Spring Boot 零基礎入門 (10) - 讀取 Spring Boot 設定檔 - @Value、application.properties"},{"categories":["Spring Boot"],"contents":"哈囉大家好，我是古古。\n在前幾篇文章中，我們分別介紹了 Bean 的相關特性，像是：\n創建 Bean 的方法：@Component 注入 Bean 的方法：@Autowired 以及指定 Bean 名字的方法：@Qualifier 所以到目前為止，我們可以說是對 Bean 有了更多的認識，並且已經可以成功的在 Spring Boot 程式中運用 Bean 了！\n那麼這篇文章，我們就會繼續來探討 Bean 的更多用法，來介紹要如何在創建一個 Bean 出來之後，去「初始化」這個 Bean 的值。\n目錄 什麼是 Bean 的初始化？ 初始化 Bean 的方法：@PostConstruct 使用 @PostConstruct 的注意事項之一：方法有特定格式 使用 @PostConstruct 的注意事項之二：在同一個 class 中，建議只有一個方法加上 @PostConstruct 補充一：我們真的需要 @PostConstruct 嗎？ 補充二：初始化 Bean 的另一種方法：afterPropertiesSet() 總結 什麼是 Bean 的初始化？ # 所謂的「Bean 的初始化」，就是指「在 Bean 被創建出來之後，對這個 Bean 去做一些初始值的設定」，譬如說把他內部的變數的值設定成 5、或是進行一些運算之類的，反正就是對這個 Bean 去做初始的出廠設定就對了。\n舉例來說，我們可以先改寫一下之前所寫的 HpPrinter，先在這個 HpPrinter 中去加上一個 count 變數，用 count 變數計算這台印表機還可以印幾次。\n所以每當我們 call 一次 print() 方法時，這個 count 的數量就要減一，表示已經印過一次了，實際程式如下：\n@Component public class HpPrinter implements Printer { private int count; @Override public void print(String message) { count--; System.out.println(\u0026#34;HP 印表機: \u0026#34; + message); System.out.println(\u0026#34;剩餘使用次數: \u0026#34; + count); } } 又因為我們有在這個 HpPrinter 上面加上 @Component，將他變成 Bean，所以 Spring Boot 到時候就會為我們創建一個 hpPrinter 的 Bean 出來，並且存放在 Spring 容器裡面。\n不過到目前為止，因為我們沒有去設定 Bean 的初始化，因此 Spring Boot 就只會去把這個 Bean 給創建出來，並不會為裡面的 count 值進行初始化，因此在這個 hpPrinter 中的 count 值，預設就會是 0。\n不過，如果我們想要讓 Spring Boot 在創建這個 hpPrinter 出來之後，同時也去為這個 count 變數賦予一個初始值的話，那麼我們就可以透過 @PostConstruct 來幫助我們達成這件事！\n初始化 Bean 的方法：@PostConstruct # @PostConstruct 的用途，就是「為這個 Bean 去進行初始化」，因此我們就可以透過 @PostConstruct，去設定這個 Bean 中的變數的初始值了。\n因此如果我們想要改寫上面的 HpPrinter，將他裡面的 count 變數的值「初始化成 5」的話，那麼我們就可以這樣做：\n首先我們先在 HpPrinter 新增一個新的方法 initialize()（方法名稱可以隨意取，後面會解釋），並且在這個方法上面，加上一行 @PostConstruct，這樣我們等一下就可以在這個方法中， 去初始化 Bean 的值。\n@PostConstruct public void initialize() { count = 5; } 像是我們可以在 initialize() 的方法中，去初始化這個 Bean 的值，譬如說我們可以把 count 的值設成 5，就可以將 count 變數的值初始化成 5。\n所以到時候，當 Spring Boot 創建出 hpPrinter 這個 Bean 之後，Spring Boot 就會接著去執行 initialize() 方法，將 count 的設定成 5，進而就可以完成 Bean 的初始化了！\n使用 @PostConstruct 的注意事項之一：方法有特定格式 # 在上面的實作中，當我們想要初始化 Bean 中的變數的值時，我們需要先在該 class 中，先去新增一個方法出來（像是 HpPrinter 中的 initialize() 方法），接著再為這個方法加上 @PostConstruct，這樣子我們就可以在這個方法裡面， 去實作初始化 Bean 的程式了。\n不過這個 initialize() 方法（也就是被加上 @PostConstruct 的方法），其實也是有一些格式需要遵守的：\n這個方法必須是 public 這個方法的返回值必須是 void 這個方法 「不能」 有參數 這個方法的名字可以隨意取，不影響 Spring Boot 運作 所以綜合以上四點的話，這個「初始化 Bean 的方法」，通常就會長得像是下面這個樣子：\n@PostConstruct public void XXX(); 其中的方法名稱 XXX()，可以替換成大家喜歡的單字，常見的有 setup()、init()、initialize()…等等，這些單字都可以拿來使用，不會影響到 Spring Boot 的運作。\n補充：Spring Boot 在判斷一個 Bean 中有沒有初始化的方法時，是 「尋找有沒有方法加上 @PostConstruct，如果有的話，就執行該方法」。也因為如此，所以這個初始化的方法名稱對 Spring Boot 而言是完全不重要的， 大家就選擇自己喜好的單字（ex: setup()、init()）來使用即可。\n使用 @PostConstruct 的注意事項之二：在同一個 class 中，建議只有一個方法加上 @PostConstruct # 由於當某個方法上面加上 @PostConstruct，該方法就會變成「初始化 Bean 的程式」，因此假設在同一個 class 裡面，同時有多個方法都加上 @PostConstruct 的話，那麼 Spring Boot 就會不知道要先運行哪一個方法去初始化 Bean。\n因此在這種情況下，雖然 Spring Boot 程式不會報錯，但是實際上初始化 Bean 的順序是完全隨機的，因此可能會造成程式邏輯的錯誤，並且後續也很難統一管理初始化的設定。\n所以就建議大家，在使用 @PostConstruct 去初始化 Bean 的時候，在同一個 class 中，只在其中一個方法上面加上 @PostConstruct，統一的去管理初始化 Bean 的設定，這樣子不管是在運作上、還是後續的維護，都是比較好的做法。\n補充一：我們真的需要 @PostConstruct 嗎？ # 由於上面的例子因為比較簡單，所以有的人可能會覺得：「為什麼我們不直接在宣告 count 變數的同時，把 count 值也設成 5 就好？」，就像是下面這個樣子，直接在宣告 count 變數的同時，也將他初始化成 5，這樣子就可以省去 @PostConstruct 的程式了。\n雖然在這個例子中，確實是可以透過上述的方式，簡單的將 count 值初始化成 5，但是在實際的工作中，@PostConstruct 的應用還是很廣泛的。\n使用 @PostConstruct 來初始化的優勢，就是 @PostConstruct 可以進行「複雜的初始化」，譬如說在 map 變數裡生成初始的數據、或是取得注入的 Bean 的資訊、或者檢查注入的 Bean 是否為 null 值…等等，這些實作只能夠透過 @PostConstruct 做到，使用一般的簡單方式無法實作出這些效果。\n因此在實務上，使用 @PostConstruct 來進行 Bean 的初始化仍舊是很常見的作法，建議大家還是要了解一下這個用法會比較好！\n補充二：初始化 Bean 的另一種方法：afterPropertiesSet() # 想要在 Spring Boot 中初始化 Bean，除了可以使用這篇文章所介紹 @PostConstruct 之外，其實 Spring Boot 也有支援另一種方法去初始化 Bean 的，也就是「實作 InitializingBean interface 裡面的 afterPropertiesSet() 方法」。\n用 afterPropertiesSet() 的方式所實作出來的效果，和 @PostConstruct 的效果一模一樣的。\n不過因為實作 afterPropertiesSet() 方法算是比較舊的寫法，在業界中越來越少用到，因此在本系列文中就不會特別介紹這部分，如果大家有興趣的話，可以再上網查詢相關資料。\n但一般在實作上，還是會建議使用 @PostConstruct 來初始化 Bean 會比較好！\n總結 # 這篇文章我們介紹了要如何使用 @PostConstruct，去初始化 Spring Boot 所創建出來的 Bean，所以大家以後就可以透過 @PostConstruct，去對 Bean 進行初始化的設定了。\n而到這篇文章為止，我們就算是對 Spring IoC 有了比較全面的認識，現在我們已經了解了什麼是 IoC、DI，也了解了 Spring 容器和 Bean，並且也知道要如何在 Spring Boot 中使用 @Component、@Autowired、@Qualifier 以及 @PostConstruct 這些註解，去對 Bean 進行創建、注入、以及初始化。\n那麼下一篇文章，我們就會繼續深入來介紹，要如何透過 @Value，將 Spring Boot 設定檔中的值讀取到 Bean 裡面，讓我們所寫的 Java 程式可以去運用 Spring Boot 設定檔中的值，那我們就下一篇文章見啦！\n補充：本文是擷取自我開設的線上課程 Java 工程師必備！Spring Boot 零基礎入門 的內容，如果你想了解更多的 Spring Boot 的用法，歡迎參考課程簡介 （輸入折扣碼「HH202601KU」即可享 85 折優惠）。\n","permalink":"https://kucw.io/blog/springboot/9/","tags":null,"title":"Spring Boot 零基礎入門 (9) - Bean 的初始化 - @PostConstruct"},{"categories":["Spring Boot"],"contents":"哈囉大家好，我是古古。\n在上一篇文章中，我們介紹了如何使用 @Component 來創建 Bean，也有介紹要如何使用 @Autowired 來注入 Bean。\n那麼接著這篇文章，我們就會來介紹，當 Spring 容器中有 2 個以上同樣類型的 Bean 存在時，該怎麼去選擇要注入的 Bean。\n目錄 回顧：注入 Bean 的方法 - @Autowired 指定注入的 Bean 的名字：@Qualifier 使用 @Qualifer 的注意事項之一：必須搭配 @Autowired 一起使用 使用 @Qualifer 的注意事項之二：指定的是「Bean 的名字」 在 Spring Boot 中練習 @Qualifier 的用法 運行 Spring Boot 程式 總結 回顧：注入 Bean 的方法 - @Autowired # 在前一篇文章中我們有介紹到，我們可以在變數上加上 @Autowired，將想要的 Bean 給注入進來。\n不過在使用 @Autowired 來注入 Bean 時，必須滿足以下事項：\n首先必須要確保 「自己也是一個 Bean」（即是有在 class 上面加上 @Component）。 並且 @Autowired 是透過 「變數的類型」 來注入 Bean。 所以在使用 @Autowired 去注入 Bean 進來時，Spring Boot 就是會透過「變數的類型」，去 Spring 容器中尋找是否有類型符合的 Bean，如果有同類型的 Bean 存在時，即可以注入成功，如果沒有 Bean 存在，則注入失敗，Spring Boot 就會報錯，並且運行失敗。\n所以像是在下面的例子中，因為 Spring 容器中只有 hpPrinter 這個 Bean，並且 hpPrinter 可以向上轉型成 Printer 類型，所以 Spring Boot 就會判定他們類型符合，因此就能夠注入成功。\n但是，假設在 Spring 容器中，同時有兩個一樣類型的 Bean 存在，譬如說像是下面這張圖，在 Spring 容器中同時有 hpPrinter 和 canonPrinter 這兩個 Bean 存在，那麼在這個情況下，Spring Boot 會如何運作呢？\n正確答案是：Spring Boot 會出現錯誤並且運行失敗。\n而 Spring Boot 之所以會出現錯誤，就是因為 hpPrinter 和 canonPrinter 都可以向上轉型成 Printer 類型，所以 Spring Boot 不知道該注入哪一個 Bean 進來，因此就發生錯誤。\n所以會導致這個錯誤的根本原因，就是因為在 Spring 容器中「同時有多個同樣類型的 Bean 存在」，因此 Spring Boot 就無法選擇要注入哪一個 Bean 進來。\n所以為了解決這個問題，就是 @Qualifier 登場的時候了！\n指定注入的 Bean 的名字：@Qualifier # @Qualifier 的用途，是去指定要注入的 Bean 的「名字」是什麼，進而解決同時有兩個同樣類型的 Bean 存在的問題。\n因此在一般的情況下，我們只要使用 @Autowired 就可以注入 Bean，但是假設今天有兩個同樣類型的 Bean 存在時，那麼我們在使用 @Autowired 的時候，就必須同時去搭配 @Qualifier，才能夠去選擇要注入的 Bean 是哪一個。\n所以簡單來說，Spring Boot 就是先由 @Autowired 篩選 Bean 的類型、再由 @Qualifier 篩選 Bean 的名字，透過這樣子的連環組合拳來解決這個問題！\n因此如果我們回頭看剛剛的例子，假設目前在 Spring 容器中有兩個 Bean：hpPrinter 和 canonPrinter，這時候如果我們想要指定要注入 hpPrinter 這個 Bean 的話，那麼就只要在 printer 變數上面，再加上一個 @Qualifier，並且在 @Qualifier 裡面指定「要注入的 Bean 的名字是hpPrinter」，這樣子就可以成功的注入 hpPrinter Bean 進來了！\n使用 @Qualifer 的注意事項之一：必須搭配 @Autowired 一起使用 # 在使用 @Qualifier 去指定「要注入的 Bean」時，一定要搭配 @Autowired 一起使用，單純使用 @Qualifier 是沒有任何用處的。\n其實大家也可以直接把 @Qualifier 當成是 @Autowired 的小弟看待，@Qualifier 只是專門在輔助 @Autowired 的，如果沒有 @Autowired 的話，那麼 @Qualifier 是完全沒有什麼作用的！\n使用 @Qualifer 的注意事項之二：指定的是「Bean 的名字」 # 如同前面所介紹的，@Qualifier 是為了解決「多個類型同時存在」的問題被發明出來的，因此他所指定的是 「Bean 的名字」。 也由於 @Qualifier 指定的是 Bean 的名字，因此掌握 Bean 的名字的生成方式就非常的重要！\n當我們平常使用 @Component 去創建 Bean 時，這些 Bean 的名字，就會是「class 名的第一個字母轉成小寫」。 所以像是由 HpPrinter class 所生成的 Bean，就會叫做 hpPrinter，由 CanonPrinter 所生成的 Bean，名字就會叫做 canonPrinter。\n因此大家在使用 @Qualifier 去指定要注入的 Bean 的名字時，一定要撰寫正確的 Bean 的名字，這樣子才能夠成功的去注入該 Bean 進來。\n補充：有關 Bean 的名字生成機制，可以回頭參考 Day 7 - Bean 的創建和注入 - @Component、@Autowired 的相關介紹\n在 Spring Boot 中練習 @Qualifier 的用法 # 了解了 @Qualifier 的用法之後，我們也可以實際到 Spring Boot 中，來練習 @Qualifier 的用法。\n延續上一篇文章的程式，目前在 Spring Boot 程式中，我們已經創建了 Printer interface 以及 HpPrinter class 出來，並且在 MyController 裡面，我們也使用了 @Autowired 去注入一個 Printer 類型的 Bean 進來。\n由於目前在這個 Spring Boot 程式裡面，只有一個 hpPrinter Bean 有辦法向上轉型成 Printer 類型，因此在 MyController 這裡所注入的，就會是 hpPrinter 這個 Bean。\n如果要練習 @Qualifier 的用法的話，我們可以先在 com.example.demo 這個 package 底下，再去新增一個 CanonPrinter 的 class 出來，並且在這個 CanonPrinter 的 class 中，實作以下的程式：\n@Component public class CanonPrinter implements Printer { @Override public void print(String message) { System.out.println(\u0026#34;Canon印表機: \u0026#34; + message); } } 創建好 CanonPrinter class 之後，整個結構會長得像是下面這個樣子：\n所以當我們這樣寫之後，就等於是 HpPrinter 和 CanonPrinter 這兩個 class，到時候都會被 Spring Boot 所管理，所以 Spring Boot 到時候就會各 new 出一份 bean，並且存放在 Spring 容器中。\n創建好 CanonPrinter 之後，這時候我們回到 MyController 上面來看一下的話，就會發現在第 11 行的 printer 變數下面，出現了一個紅色的波浪線。\n這是因為 IntelliJ 會主動檢查我們所寫的程式，並偵測出這裡到時候會出現注入的問題（Spring 容器同時存在多個同類型的 Bean），因此 IntelliJ 就提前出現了紅色的波浪線，提示我們此處有錯誤。\n如果我們不管這個紅色波浪線，執意要運行 Spring Boot 程式的話，那麼在啟動 Spring Boot 的過程中，console 就會噴出下列的錯誤訊息，提示我們啟動 Spring Boot 失敗。\n在上面這段 console 的錯誤訊息中，有出現一句「MyController required a single bean, but 2 were found」的訊息，這一行的訊息就是表示「MyController 想要注入一個 Bean，但是卻發現 Spring 容器中存在兩個同樣類型的 Bean，導致 MyController 不知道要選擇哪一個 Bean 注入，因此才導致注入失敗」。\n並且在下方的紅框處，Spring Boot 也有建議我們使用 @Qualifier，來解決這個「多個同樣類型的 Bean 同時存在」的問題。\n所以要解決這個問題的話，就是 @Qualifier 出場的時候了！\n因此我們可以回到 MyController 上，然後在 printer 變數上面，去加上一行 @Qualifier(\u0026quot;canonPrinter\u0026quot;) 的程式，表示我們想要注入的 Bean，是「名字為 canonPrinter」的那個 Bean。\n當我們這樣寫之後，到時候 Spring Boot 在注入 Bean 時，就會從 Printer 類型的 Bean 中，選出名字為 canonPrinter 的那個 Bean，然後把他注入到 MyController 裡面了！\n補充：因為當我們使用 @Component 去創建 Bean 時，這個 Bean 的名字就會是「class 名稱的第一個字母轉成小寫」，因此 CanonPrinter 所產生的 Bean，名字即是 canonPrinter（注意第一個字母為小寫）。\n運行 Spring Boot 程式 # 寫好上述程式之後，我們可以重新運行 Spring Boot 程式，來看一下效果。\n運行起來之後，當看到下方的 console 出現「Started DemoApplication in 0.663 seconds」時，就表示 Spring Boot 程式運行成功了。\n接著我們可以打開 Google 瀏覽器，然後在裡面輸入 http://localhost:8080/test ，再按下 Enter 鍵。\n這時候如果頁面中有呈現「Hello World」的字樣的話，就表示請求成功了，所以我們可以回到 IntelliJ 上來看一下結果。\n這時回到 IntelliJ 上，就可以在 console 下方看到一行「Canon印表機: Hello World」的輸出。\n而這裡之所以會出現「Canon印表機: Hello World」這一行輸出，就是因為我們在 MyController 中加上了第 12 行的 @Qualifier(\u0026quot;canonPrinter\u0026quot;)，而這一行 @Qualifier(\u0026quot;canonPrinter\u0026quot;) 所代表的意思，就是去指定「要去注入名字為 canonPrinter 的那個 Bean」。\n因此 Spring Boot 到時候就會將 canonPrinter 注入到 MyController 的 printer 變數裡面，所以後續執行到第 17 行的 printer.print(\u0026quot;Hello World\u0026quot;) 時，實際上就是去執行 canonPrinter 的 print() 方法，所以最後才會在 console 上輸出「Canon印表機: Hello World」的訊息。\n所以只要大家在 console 上看到「Canon印表機: Hello World」這一行輸出，就表示我們成功的透過 @Qualifier，去指定要注入哪一個 Bean 進來了！\n補充：大家也可以試著把 MyController 的第 17 行修改一下，多去體驗一下 @Qualifier 的用法。譬如說可以把他改成 @Qualifier(\u0026quot;hpPrinter\u0026quot;)，就表示要改成去注入 hpPrinter 那個 Bean 進來，因此到時候在 console 所上輸出的，就會變成是「HP印表機: Hello World」。\n總結 # 這篇文章我們介紹了要如何透過 @Qualifier，去指定要注入的 Bean 的名字，進而去輔助 @Autowired 透過變數的類型注入 Bean 所引發的衍生問題，並且我們也有實際到 Spring Boot 中練習了 @Qualifier 的用法，讓大家感受一下 @Qualifier 的效果為何。\n那麼在介紹完 Bean 的創建和注入之後，接著我們會來介紹「Bean 的初始化」，這也是在實戰中非常常用到的用法，那我們就下一篇文章見啦！\n補充：本文是擷取自我開設的線上課程 Java 工程師必備！Spring Boot 零基礎入門 的內容，如果你想了解更多的 Spring Boot 的用法，歡迎參考課程簡介 （輸入折扣碼「HH202601KU」即可享 85 折優惠）。\n","permalink":"https://kucw.io/blog/springboot/8/","tags":null,"title":"Spring Boot 零基礎入門 (8) - 指定注入的 Bean - @Qualifier"},{"categories":["Spring Boot"],"contents":"哈囉大家好，我是古古。\n在上一篇文章中，我們有介紹了 IoC、DI、和 Bean 的概念，先帶大家了解 Spring IoC 中的重要名詞的含義。\n那麼這篇文章，我們就會實際到 IntelliJ 中，練習要如何在 Spring Boot 程式中創建 Bean，以及要如何將 Bean 去注入到別的 class 中。\n目錄 創建 Bean 的方法：@Component 創建 Bean 的注意事項 注入 Bean 的方法：@Autowired 使用 @Autowired 的注意事項之一：該 Class 也必須也是 Bean 使用 @Autowired 的注意事項之二：@Autowired 是根據「變數類型」尋找 Bean 小結：所以，@Autowired 到底要怎麼用？ 在 Spring Boot 中練習 @Component 和 @Autowired 的用法 練習創建 Bean 的方法：@Component 練習注入 Bean 的方法：@Autowired 補充：為什麼 MyController 能使用 @Autowired？ 運行 Spring Boot 程式 總結 創建 Bean 的方法：@Component # 在 Spring Boot 中，最常見的創建 Bean 的方法，就是在 class 上面加上一行 @Component 的程式。只要在 class 上面加上一行 @Component 之後，就可以將這樣 class 變成一個 Bean 了，Magic！\n所以只要我們將 HpPrinter 改寫成是下面這個樣子（注意在最上面加了一行 @Componenet），就可以將 HpPrinter 變成一個由 Spring 容器所管理的 Bean 了。\n因此當 Spring Boot 程式運行起來之後，Spring Boot 就會去查看有哪些 class 上面加上了 @Component，然後 Spring Boot 就會提前去 new 一個 object 出來，並且存放在 Spring 容器裡面，等著其他人後續來跟他借。\n所以以 HpPrinter 這個例子來說，當 Spring Boot 看到 HpPrinter 上面有加上 @Component 之後，Spring Boot 就會去執行下面這行程式，提前去 new 出一個 HpPrinter 的 object 出來。\nPrinter hpPrinter = new HpPrinter(); 並且 Spring Boot 會將 hpPrinter 這個 object，存放在 Spring 容器中，等著後續其他人來借，因此架構就會長得像是下圖這樣（即是在 spring 容器中存放了一個 hpPrinter 的 object）：\n也因為使用 @Component 來創建 Bean 可以說是非常的神速，只需要在 class 上面加上一行程式就可以完成，因此 @Component 也可以說是在 Spring Boot 中使用頻率最高的註解之一。\n創建 Bean 的注意事項 # 在使用 @Component 來創建 Bean 時，有一個重點要特別提一下，就是這些被創建出來的 Bean，他們的名字，會是「class 名稱的第一個字母轉成小寫」。\n舉例來說，當我們在 HpPrinter class 上面加上一個 @Component 之後，那麼 Spring 所生成出來的 Bean 的名字，就會是 hpPrinter。\n所以同樣的道理，假設我們今天改成是將 @Component 加在 CanonPrinter class 上，那 Spring 所生成出來的 Bean，名字就會是 canonPrinter。\n因此大家之後在創建 Bean 時，就要記得 「Spring 所生成出來的 Bean 的名字，會是 class 名稱的第一個字母轉成小寫」，這個特性在下一篇文章中馬上就會用到，所以也是一個很重要的特性！\n補充：除了在 Class 上面加上 @Component 可以創建 Bean 之外，其實也是可以使用另一種方式 @Bean + @Configuration，去創建一個 Bean 出來的。不過因為這部分相對比較複雜，因此在本系列文中不會特別介紹到 @Bean + @Configuration 的實作。\n注入 Bean 的方法：@Autowired # 了解了創建 Bean 的方法之後，接著我們可以來看一下如何去「注入 Bean」。\n要注入 Bean 也很簡單，只需要在變數上面加上 @Autowired 這行程式，就可以將 Spring 容器中的 Bean 給注入進來了，Magic again！！\n不過，在使用 @Autowired 去注入 Bean 進來時，有兩個很重要的限制一定得遵守！如果不遵守的話，是沒辦法正常去注入 Bean 進來的。\n使用 @Autowired 的注意事項之一：該 Class 也必須也是 Bean # 當某個 class 想要使用 @Autowired 去注入一個 Bean 進來時，這個 class 自己本身也得變成是由 Spring 容器所管理的 Bean 才可以，因為這樣子 Spring 容器才有辦法透過 DI（依賴注入），將我們想要的 Bean 給注入進來。\n所以假設我們是一個 Teacher，然後我們想要使用 @Autowired，把 HpPrinter 這個 Bean 給注入進來的話，那麼 Teacher 本身也必須成為一個 Bean 才可以。\n因此這時候，我們就必須先在 Teacher class 上面，先去加上一行 @Component，將 Teacher 先變成是一個 Bean，這樣後續才可以將透過 @Autowired，將 HpPrinter 這個 Bean 給注入到 Teacher 裡面。\n補充：因此基本上當我們使用了 Spring Boot 這套框架之後，我們就會盡量把所有的 class 都變成 Bean，因為這樣才能夠去注入來注入去的，所以在 Spring Boot 程式裡面看到一堆 @Component 和 @Autowired 是很正常的！\n使用 @Autowired 的注意事項之二：@Autowired 是根據「變數類型」尋找 Bean # 使用 @Autowired 的第二個注意事項，即是 @Autowired 是根據 「變數的類型」來尋找 Bean。\n當我們在 Teacher class 中的 printer 變數上面，加上了一行 @Autowired 的程式之後，其實就表示「我們想要注入一個 Printer 類型的 Bean」，因此 Spring 容器就會查看他裡面有沒有 Printer 類型的 Bean，如果有的話，Spring 容器就會把這個 Bean 注入給 Teacher，如果沒有的話，就會出現錯誤並且停止程式。\n而 HpPrinter class 之所以能夠成功的被注入到 Printer 類型的變數裡面，原因就在於 Java 的多型（polymorphism）特性，使得 HpPrinter class 可以「向上轉型」成 Printer interface，因此透過 Java 的多型，Spring Boot 就能夠成功的將 hpPrinter Bean，注入到 Teacher class 中的 printer 變數了！\n補充：因為這裡牽涉到 Java 的多型特性，因此不熟悉這部分的話，建議要先回頭了解一下 Java 的多型特性會比較好，多型的概念會貫穿整個 Spring Boot 開發，因此這部分建議大家要了解一下會比較好。\n小結：所以，@Autowired 到底要怎麼用？ # 所以總結來說，如果想要使用 @Autowired 去注入一個 Bean 時，必須滿足：\n必須要確保 「自己也是一個 Bean」（即是有在 class 上面加上 @Component）。 並且 @Autowired 是透過 「變數的類型」 來注入 Bean 的（所以只要 Spring 容器中沒有那個類型的 Bean，就會注入失敗）。 只要記住以上兩點，大家就可以在想要的地方使用 @Autowired，去注入 Spring 容器中的 Bean 進來了！\n在 Spring Boot 中練習 @Component 和 @Autowired 的用法 # 了解了 @Component 和 @Autowired 的概念之後，接著我們也可以實的到 Spring Boot 中，來練習他們的用法。\n在前面的 Day 4 - 第一個 Spring Boot 程式 中，我們有去創建了一個 MyController class 出來，所以現在在 Spring Boot 的程式裡面，就會存在兩個 class，分別是 DemoApplication 以及 MyController。\n接著我們在 com.example.demo 這個 package 底下，再去創建一個 Printer interface 出來。所以我們可以在 com.example.demo 這個 package 上點擊右鍵，然後選擇 New，接著選擇 Java class。\n然後我們將這個 interface 的名字，取名成 Printer，並且在下面選擇 interface，這樣子就可以去創建一個 Printer interface 出來。\n接著在這個 Printer 的 interface 裡面，新增一個 print() 方法的宣告。\npublic interface Printer { void print(String message); } 所以創建好 Printer interface 之後，整個結構會長的像是下面這個樣子：\n練習創建 Bean 的方法：@Component # 創建好 Printer interface 之後，接著我們可以再去創建一個 class，來實作 Printer interface。\n所以我們就在 com.example.demo 底下，創建一個 HpPrinter class 出來，並且在這個 HpPrinter class 中，撰寫以下的程式：\n@Component public class HpPrinter implements Printer { @Override public void print(String message) { System.out.println(\u0026#34;HP印表機: \u0026#34; + message); } } 創建好 HpPrinter class 之後，整個結構會長的像是下面這個樣子：\n在這個 HpPrinter 的實作中，我們在第 5 行有添加了 @Component 的程式，又因為 @Component 的用途是「將 class 變成由 Spring 所管理的 Bean」，因此這段程式的意思就是將 HpPrinter 變成是一個 「由 Spring 容器所管理的 Bean」。\n所以到時候當 Spring Boot 程式運行起來時，Spring 就會預先去創建 hpPrinter 這個 Bean 出來，並且存放在 Spring 容器裡面了。\n練習注入 Bean 的方法：@Autowired # 創建好 HpPrinter 這個 Bean 之後，接著我們可以嘗試把這個 HpPrinter 這個 Bean，注入到我們想要的地方。\n這裡大家可以先回到 MyController class，然後在 MyController 中，加上下圖中第 10～11 行的程式：\n所以在 MyController 中，我們就新增了一個 Printer 類型的變數 printer，並且在這個 printer 變數上面，也加上了一行 @Autowired 的程式，因此到時候，Spring Boot 就會將「Spring 容器中類型為 Printer 的 Bean，注入到這個 printer 變數中」了！\n所以換句話說的話，到時候 Spring Boot 就會把存放在 Spring 容器中的 hpPrinter Bean，去注入到 MyController 的 printer 變數中，因此到時候這個 printer 變數所存放的，就會是一個 HpPrinter 的 object。\n而當 hpPrinter 被注入到 printer 變數中之後，我們就可以在下面的 test() 方法中，使用 printer 變數中的 print() 方法，嘗試去印出一行 Hello World 的字串出來了（如下圖中的第 15 行所示）。\n所以當我們寫到這裡之後，就能夠成功的使用 @Autowired，去注入一個 Bean 進來了！\n補充：為什麼 MyController 能使用 @Autowired？ # 到這邊大家可能會有一個疑問，就是「為什麼 MyController 可以使用 @Autowired 去注入 Bean？」。\n因為我們在前面有提到，如果想要使用 @Autowired 的話，這個 class 本身也得是一個 Bean 才行。但是在上面的程式中，我們明明沒有在 MyController 上面加上 @Component 將他變成一個 Bean，那為什麼 MyController 可以使用 @Autowired 去注入 Bean 呢？\n其實，MyController 在這裡也是有偷偷成為一個 Bean 的，而這就是 @RestController 這一行程式所造成的效果（如下圖中的第 7 行所示）。\n大家可以先把 @RestController 當成是一個厲害版的 @Component，他不僅可以將 class 變成 Bean，還有更多的功能在裡面。因此如果回到最一開始的問題「為什麼 MyController 可以使用 @Autowired？」，原因就是因為 MyController 其實本身也是一個 Bean！ 因此他才有能力去使用 @Autowired，將想要的 Bean 給注入進來。\n所以大家在使用 @Autowired 時，就一定要記得，只有當 class 本身是一個 Bean 時，才可以使用 @Autowired 去注入一個 Bean 進來，這點非常重要！！\n運行 Spring Boot 程式 # 當上述的程式都寫好之後，我們就可以回到 DemoApplication，然後點擊左側的播放鍵，去運行這個 Spring Boot 程式。\n運行起來之後，當看到下方的 console 出現「Started DemoApplication in 0.658 seconds」時，就表示 Spring Boot 程式運行成功了。\n接著我們可以打開 Google 瀏覽器，然後在裡面輸入 http://localhost:8080/test ，然後按下 Enter 鍵。\n這時候如果頁面中有呈現「Hello World」的字樣的話，就表示請求成功了，所以我們就可以回到 IntelliJ 上來看一下結果。\n這時回到 IntelliJ 上，就可以在 console 下方看到一行「HP印表機: Hello World」的輸出。\n之所以會出現這一行「HP印表機: Hello World」的輸出，是因為當我們在瀏覽器輸入 http://localhost:8080/test 時，Spring Boot 就會去執行 MyController 裡面的 test() 方法，因此就會執行到下圖中第 15 行的 printer.print(\u0026quot;Hello World\u0026quot;) 程式，所以最終才會在 console 上印出「HP印表機: Hello World」的字串。\n因此只要看到「HP印表機: Hello World」這一行出現，就表示我們成功的透過 @Component 和 @Autowired，在 Spring Boot 中創建一個 HpPrinter Bean 出來，並且將他注入到 MyController 裡面啦！讚！\n所以大家以後就可以透過這個用法，去使用 @Component 和 @Autowired 了！\n總結 # 這篇文章我們先介紹了要如何使用 @Component 去創建一個 Bean，也介紹了要如何使用 @Autowired 去注入一個 Bean，最後我們也有實際到 Spring Boot 練習這兩個註解的用法，讓大家了解要如何在 Spring Boot 程式中創建和注入 Bean。\n那麼到這邊，可能有的人開始會有一個疑惑，也就是：既然 @Autowired 是透過「變數的類型」來注入 Bean，那假設在 Spring 容器中，同時有 2 個以上同樣類型的 Bean 該怎麼辦？ 這時候 Spring 容器是會隨機挑選一個 Bean 來注入，還是會直接報錯？\n所以下一篇文章，我們就會接著來介紹另一個註解 @Qualifier 的用法，介紹要如何使用 @Qualifier，去協助 @Autowired 選擇要注入的 Bean，那我們就下一篇文章見啦！\n補充：本文是擷取自我開設的線上課程 Java 工程師必備！Spring Boot 零基礎入門 的內容，如果你想了解更多的 Spring Boot 的用法，歡迎參考課程簡介 （輸入折扣碼「HH202601KU」即可享 85 折優惠）。\n","permalink":"https://kucw.io/blog/springboot/7/","tags":null,"title":"Spring Boot 零基礎入門 (7) - Bean 的創建和注入 - @Component、@Autowired"},{"categories":["Spring Boot"],"contents":"哈囉大家好，我是古古\n在上一篇文章中，我們先介紹了 Spring IoC 的原理，以及使用 Spring IoC 的優點，讓大家先對 Spring IoC 有一個初步的認識。\n那麼這篇文章，我們就會接著來介紹，在 Spring IoC 中也很重要的兩個名詞：DI 和 Bean，讓大家更全面的了解 Spring IoC，並且這也是後續在實作 Spring Boot 程式時，一個非常重要的概念。\n目錄 回顧：什麼是 IoC？ 什麼是 DI？ 什麼是 Bean？ 總結 回顧：什麼是 IoC？ # 在上一篇文章中有提到，IoC 的全稱是 Inversion of Control，中文翻譯為控制反轉，而 IoC 的概念，就是「將 object（物件）的控制權，交給了外部的 Spring 容器來管理」，所以所謂的 Control（控制），就是「對於 object 的控制權」。\n所以有了 IoC 的概念之後，以後所有的 object，就都是由外部的 Spring 容器來進行管理，因此當 Teacher 想要去使用印表機時，就只要跟 Spring 容器去借就好了，Teacher 就不需要自己再去「控制」這個印表機的生命週期了。\n什麼是 DI？ # 而只要提到 IoC，就一定會提到另一個名詞 DI，這兩個名詞可以說是相輔相成的，缺一不可。\nDI 的全稱是 Dependency Injection，中文翻譯為「依賴注入」，而其實 DI 依賴注入的概念，我們已經有在前面的 IoC 過程中使用到了！\n像是在上面那張圖中，Spring 容器會預先儲存一個 HpPrinter 印表機，因此每當 Teacher 想要使用印表機時，Spring 容器就會將這個 HpPrinter 借給 Teacher 使用，其中這個「我借你」的動作，其實就是「DI 依賴注入」。\n所以換句話說的話，每當 Spring 容器想要把 HpPrinter 「借」給 Teacher 使用時，就是表示 Spring 容器把 HpPrinter 給「注入」到 Teacher 這個 class 裡面，因此才稱為是 「DI 依賴注入」。\n因此基本上只要有用到「IoC 控制反轉」的地方，一定就要搭配「DI 依賴注入」，因為 IoC 會讓我們把 object 的控制權給交出去，所以後續必定需要搭配 DI，才能夠又把這個 object 「注入」回來給我們使用，因此「IoC + DI」這兩個名詞，可以說是捆綁再一起的概念，他們兩個是相輔相成的！\n補充：這裡不得不佩服當初命名 DI 的人，到底是怎麼想到「注入」這個這麼艱難的詞的，文學造詣也太好了吧！！不過老實說他也真的描述的很形象就是了，就像是打針一樣，把 HpPrinter 給注入到 Teacher 裡面。\n什麼是 Bean？ # 介紹完了 IoC 和 DI，最後我們來介紹一下什麼是 Bean。\n這裡還是舉前面的印表機的例子，當我們使用了 IoC 之後，object 的控制權就會交給 Spring 容器來管理，因此以後所有的 object，他們就都是活在 Spring 容器裡面，由 Spring 容器來管理這個這些 object 的生命週期。\n而這些 「由 Spring 容器所管理的 object，我們就賦予他們一個新的名字，叫做 Bean」，所以 Bean 說穿了，其實就只是一個 object 而已，跟我們用 new 去創建的 HpPrinter 是一模一樣的！只是因為這些 object 是被放在 Spring 容器中來管理，所以他們就有了新的名字，叫做 Bean，就只是這樣子而已！\n所以以後大家在開發 Spring Boot 程式時，看到 Bean 就不用太緊張，想說這是什麼神奇的東西，他其實就只是由 Spring 容器所管理的 object 而已，本質上和我們直接去 new 一個出來的 object 沒什麼區別。\n但也因為 Bean 在 Spring Boot 程式中使用的層面實在是太廣了，後面許多技術都會牽扯到 Bean 的概念，因此建議大家一定要了解 Bean 的意義和用途會比較好！\n總結 # 這篇文章我們延續了上一篇文章對 Spring IoC 的介紹，補足了 Spring IoC 中也很重要的兩個名詞概念：DI 和 Bean，讓大家對於 Spring IoC 有一個更全面的了解。\n那麼下一篇文章，我們就會去實際到 IntelliJ 中應用 Spring IoC 的概念，練習在 Spring Boot 的程式中創建一個 Bean，並且將這個 Bean 注入到其他的 class 中，那我們就下一篇文章見啦！\n補充：本文是擷取自我開設的線上課程 Java 工程師必備！Spring Boot 零基礎入門 的內容，如果你想了解更多的 Spring Boot 的用法，歡迎參考課程簡介 （輸入折扣碼「HH202601KU」即可享 85 折優惠）。\n","permalink":"https://kucw.io/blog/springboot/6/","tags":null,"title":"Spring Boot 零基礎入門 (6) - IoC、DI、Bean 的介紹"},{"categories":["Spring Boot"],"contents":"哈囉大家好，我是古古。\n在前面的文章中，我們有先去安裝開發環境，並且成功使用 IntelliJ 這套軟體，去創建出了第一個 Spring Boot 程式，先對如何撰寫 Spring Boot 程式有了一個最基本的了解。\n那麼從這篇文章開始，我們就會開始來介紹 Spring 框架中一個非常重要的特性，也就是 IoC，所以我們就開始吧！\n目錄 什麼是 IoC？ 例子：印表機的故事 新增一個 Teacher class 但是\u0026hellip;如果 HpPrinter 印表機壞掉了怎麼辦？ IoC（Inversion of Control，控制反轉） Spring IoC 的定義 Spring IoC 的優點 1. Loose coupling（鬆耦合） 2. Lifecycle management（生命週期管理） 3. More testable（方便測試程式） 總結 什麼是 IoC？ # IoC 的全稱是 Inversion of Control，中文翻譯成「控制反轉」，不過這個控制是控制什麼、反轉又是反轉什麼，我們可以直接透過一個印表機的例子來了解一下。\n例子：印表機的故事 # 假設今天我們先設計一個印表機 Printer 的 interface，這個印表機裡面只有一個方法，就是 print() 方法印東西，程式如下：\npublic interface Printer { void print(String message); } 而有了 interface 之後，我們就可以去寫一個 class 來實作這個 Printer interface，所以我們可以寫一個 HpPrinter 的 class，表示這是一個 HP 牌子的印表機，程式如下:\npublic class HpPrinter implements Printer { @Override public void print(String message) { System.out.println(\u0026#34;HP印表機: \u0026#34; + message); } } 並且我們也可以再寫一個 CanonPrinter 的 class，表示這是一個 Canon 牌子的印表機，程式如下：\npublic class CanonPrinter implements Printer { @Override public void print(String message) { System.out.println(\u0026#34;Canon印表機: \u0026#34; + message); } } 所以到目前為止，我們就有了兩個 class，一個是 HpPrinter、另一個則是 CanonPrinter，而這兩個印表機裡面，就都會去 implements Printer 這個 interface，去實作他裡面的 print() 方法。\n新增一個 Teacher class # 有了兩個印表機之後，我們可以再去設計一個 Teacher class，然後在這個 Teacher class 裡面，宣告一個 Printer 類型的變數，並且在後面去 new 一個 HpPrinter 出來。\npublic class Teacher { private Printer printer = new HpPrinter(); public void teach() { printer.print(\u0026#34;I\u0026#39;m a teacher\u0026#34;); } } 補充：這裡使用到 Java 中的「多型（polymorphism）」的概念，因此 HpPrinter 才可以被向上轉型成 Printer 類型。如果對於 Java 中的多型概念不熟悉的話，建議一定要回頭去了解一下會比較好，Java 多型的應用，會非常常出現在 Spring Boot 的程式裡面。\n所以到這裡為止，整個結構圖就會像是下面這個樣子，剛剛我們所新增的 Teacher class，他就在 class 裡面宣告了一個 Printer 的變數，並且在裡面去 new 了一個 HpPrinter 出來，然後使用這個 HpPrinter 的印表機去印東西了。\n但是\u0026hellip;如果 HpPrinter 印表機壞掉了怎麼辦？ # 但是假設這個時候，HpPrinter 如果突然壞掉了，那 Teacher 就只能改成去使用 CanonPrinter 印表機，繼續去印東西出來。\n所以這個時候，我們就只能去改寫 Teacher 裡面的程式，將裡面的 Printer 變數，改成是去 new 一個 CanonPrinter 出來，因此結構圖就會變成是下面這個樣子：\n所以到這邊，我們可能就會產生了一個新的想法：就是身為一個 Teacher，我們其實只是想要一台印表機去印東西而已，不論這個印表機是 HP 還是 Canon 品牌，只要他可以印東西出來就好，我們根本不在意我們所使用的是哪個牌子的印表機。\n但是因為我們在 Teacher 的程式裡面，「具體的去指定了」要使用的是哪一牌的印表機，所以每當我們換一次牌子，我們就必須要把所有使用到印表機的程式，全部都修改一遍，因此就會變得非常麻煩（現在只有 Teacher 這個 class 需要修改，所以大家可能覺得還好，大不了就動手改一下，但是當 Project 越寫越大之後，要這樣一個一個修改是非常困難的）。\n所以這時候，Spring 就提出了一個新的概念來解決這個問題，也就是 IoC（Inversion of Control，控制反轉）。\nIoC（Inversion of Control，控制反轉） # 為了解決上面的「替換印表機」的問題，Spring 就提出了一個新的想法，也就是 「將這個 Printer 的 object（物件）交由 Spring 保管，當誰要使用印表機時，就再去跟 Spring 拿就好」。\n反正我們作為 Teacher 來說，也不是很在意使用到的是 HP 印表機、還是 Canon 牌的印表機，我們只要確保能夠拿到一個印表機來印東西就好。\n所以在這個情境下，HpPrinter 和 CanonPrinter 這兩個印表機，就統一交由 Spring 進行保管，而我們作為 Teacher，就不需要提前將 HpPrinter 和 CanonPrinter 的資訊寫死在 Java 程式裡面，所以 Teacher class 就可以改寫成像是下面這樣：\n可以看到在 Teacher class 中，我們只定義了一個 Printer 的變數，並且我們沒有為這個 printer 變數，去 new 一個 HpPrinter 或是 CanonPrinter 出來，因此這個 printer 變數的值，預設就會是 null。\n但是，當 Spring Boot 程式運作起來之後，Spring 就會去啟動一個 「Spring 容器（Spring Contianer）」，然後 Spring 會預先去 new 一台印表機出來（此處以 HpPrinter 當作例子），並且存放在 Spring 容器裡面保存。\n因此後續當 Teacher 想要使用印表機時，Spring 就會把這個預先 new 好、並且存放在 Spring 容器中的 HpPrinter，把他交給 Teacher，因此 Teacher 就可以正常的使用這個 HP 印表機，去印他想印的東西了。\n所以大家也可以簡單的想像成是：Spring 他會預先去買一台印表機，然後儲存在「Spring 容器」裡面，而誰想要印東西，他就去跟 Spring 借，所以印東西的人就再也不用自己去準備一台印表機，只要一直去跟 Spring 借就好了，這個就是「Spring IoC」的概念了！\nSpring IoC 的定義 # 所以透過上面的印表機例子，大概了解了 Spring IoC 的概念之後，我們也可以回頭來看一下 IoC 的定義。\nIoC 的全稱 是 Inversion of Control，中文翻譯成「控制反轉」，而 IoC 的概念，就是「將 object（物件）的控制權，交給了外部的 Spring 容器來管理」，所謂的 Control（控制），就是對於 object 的控制權。\n所以像是我們以前在寫 Java 程式時，我們就會在 Teacher class 中去 new 一個 HpPrinter 出來，因此這個 HpPrinter 的控制權，就是在自己（Teacher class）的手上（如下圖左）。\n而當我們用了 Spring 框架之後，則是會由 Spring 容器統一去 new 一個 HpPrinter 出來，再去提供給大家使用，因此 HpPrinter 的控制權，就是在外部容器（Spring 容器）的手上（如下圖右）。\n也因為我們 將 HpPrinter 的「控制權」，從自己手上「轉移到」外部的 Spring 容器，由外部的 Spring 容器統一去做管理，所以就稱為是 Inversion of Control，簡稱為 IoC。\nSpring IoC 的優點 # 了解了 IoC 的定義之後，接著我們可以來看一些使用 Spring IoC 的優點。\n使用 Spring IoC有三大好處，分別是：\n1. Loose coupling（鬆耦合） # 使用 Spring IoC 的第一個優點，就是可以達到 class 之間的鬆耦合，即是可以「降低各個 class 之間的關聯性」。\n像是我們本來必須要在 Teacher 中，手動去指定我們要使用的是 HpPrinter 印表機，而這就會讓 Teacher 和 HpPrinter 的關聯性變大。\n但是當我們改用了 Spring IoC 之後，Teacher 就只要去和 Spring 容器拿一台印表機，就可以直接直接去印東西了，所以 Teacher 就不需要了解這個印表機到底是 HP 牌還是 Canon 牌，如此就降低了 Teacher 和 HpPrinter 之間的關聯性。\n因此使用 Spring IoC 的第一個好處，就是可以降低 class 之間的關聯性。\n2. Lifecycle management（生命週期管理） # 使用 Spring IoC 的第二個優點，則是統一的生命週期管理。\n因為我們將 HpPrinter 改成交由 Spring 容器來管理，因此 Spring 就會負責 HpPrinter 的創建、初始化、以及銷毀，所以就不需要我們親自去處理這件事情。\n所以使用 Spring IoC 的第二個好處，就是讓 Spring 容器能夠統一的，對所有 object 進行生命週期的管理。\n3. More testable（方便測試程式） # 使用 Spring IoC 的第三個優點，即是更加方便的測試程式。\n因為所有的 object 都是由外部的 Spring 容器來做管理，因此我們就可以使用 Mock 的技術，在測試的過程中，將 Spring 容器中的 object 給替換掉，這樣子就可以變免受到其他的外部服務影響，更聚焦在當前這個單元測試想要測試的部分。\n補充：不過有關單元測試和 Mock 的部分，在本系列文中不會提及，大家如果有興趣的話，可以參考我撰寫的另一篇文章：SpringBoot - 單元測試工具 Mockito\n總結 # 這篇文章我們有先透過印表機的例子，先介紹了 Spring IoC 的原理，並且也一併介紹了使用 Spring IoC 的優點，希望可以透過比較生活化的例子，讓大 家更好理解 Spring IoC 的概念。\n那麼下一篇文章，我們就會接著來介紹，在 Spring IoC 中也很重要的兩個名詞：DI 和 Bean，讓大家更全面的了解 Spring IoC，那我們就下一篇文章見啦！\n補充：本文是擷取自我開設的線上課程 Java 工程師必備！Spring Boot 零基礎入門 的內容，如果你想了解更多的 Spring Boot 的用法，歡迎參考課程簡介 （輸入折扣碼「HH202601KU」即可享 85 折優惠）。\n","permalink":"https://kucw.io/blog/springboot/5/","tags":null,"title":"Spring Boot 零基礎入門 (5) - Spring IoC 簡介"},{"categories":["Spring Boot"],"contents":"哈囉大家好，我是古古。\n在前兩篇文章中，我們有分別去介紹了一下，要如何在 Mac 和 Windows 中架設 Spring Boot 的開發環境。\n所以這篇文章，我們就可以來使用前面所安裝的工具，建立你的第一個 Spring Boot 程式出來了！\n目錄 啟用 IntelliJ IDEA Ultimate 創建第一個 Spring Boot 程式 建立專案、Project 設定 選擇要載入的 Spring Boot 功能 IntelliJ 的操作介面 實作第一個 Spring Boot 程式 添加 demo 程式 運行 Spring Boot 程式 所以，我們剛剛都做了什麼？ 總結 啟用 IntelliJ IDEA Ultimate # 創建 Spring Boot 程式的第一步，就是要先啟用 IntelliJ IDEA Ultimate 的試用期。所以大家可以先開啟 IntelliJ 的程式，這時候 IntelliJ 就會跳出下面這個視窗，要你去登入帳號，並且確認這個帳號是否已經啟用 IntelliJ 的付費版本。\n如果要啟用 30 天的免費試用的話，只需要點擊右上角的「Start trial」，然後點擊下方的「Start Trial」按鈕，這樣子就可以取得 30 天的免費試用期了。\n補充：點擊 Start Trial 的按鈕之後，瀏覽器會跳出一個 IntelliJ 的頁面，詢問你要不要訂閱電子報，這部分可訂閱可不訂閱，不過不管有沒有訂閱，只要直接回到 IntelliJ 程式，都是可以成功啟用 30 天試用期的。\n創建第一個 Spring Boot 程式 # 建立專案、Project 設定 # 啟用 30 天試用期成功之後，我們就可以開始來創建你的第一個 Spring Boot 程式了！只要點擊 IntelliJ 中間的「New Project」，就可以去創建一個新的 Spring Boot 程式出來。\n接著 IntelliJ 就會跳出下面這個視窗，要我們進行 Project 的設定。這裡先點擊左邊側邊欄的「Spring Boot」，表示我們要創建的是 Spring Boot 的程式，接著右邊就是跟著下圖一樣，選擇一樣的設定即可。\n設定好右邊的 Project 設定之後，我們也可以回頭來看一下，右邊這些值分別代表什麼意思：\nName： 這個 Spring Boot 程式的資料夾名字。 Location： 這個 Spring Boot 程式預計創建出來的位置，預設是放在桌面上。 Language： 使用哪種語言來開發 Spring Boot 程式，預設是 Java。 Type： 選擇要使用哪種工具來構建 Spring Boot 程式，這部分比較複雜，因此先照著選 Maven 即可。 Group、Artifact、Package name： 這些值和上面的 Maven 有關，一樣是比較複雜所以可以先跳過不理他。 JDK、Java： 選擇想要使用的 Java 版本。 Packaging： 打包 Spring Boot 的方式，預設是 Jar，這部分一樣是比較複雜（牽涉到 Tomcat），所以也是可以先跳過不理他。 而當大家設定好右邊的參數設定之後，就可以按下 Next 繼續。\n選擇要載入的 Spring Boot 功能 # 進到下一個視窗之後，就可以在這裡選擇想要使用的 Spring Boot 的版本、以及想要載入哪些功能進來。\n像是在上圖的左上方紅框處，就可以去選擇 Spring Boot 的版本，這裡大家可以直接使用預設的最新版即可，不用特別去做調整。\n而在下方的部分，則是可以去選擇要載入哪些功能到這個 Spring Boot 程式裡面，這裡我們先展開Web，然後勾選裡面的「Spring Web」即可。\n勾選完成之後，就可以點擊右下角的 Create，完成 Spring Boot 程式的創建。\nIntelliJ 的操作介面 # 創建好 Spring Boot 程式後，IntelliJ 會開啟一個視窗，就會根據我們剛剛的設定，去創建這個 Spring Boot 程式出來。\n這時候右下角的進度條會開始跑，第一次創建會需要比較長的常見，並且需要確保網路的暢通（會下載許多 Spring Boot 的 library 下來），等到右下角的進度條跑完之後，就創建完 Spring Boot 程式了（約需要 3-5 分鐘左右）。\n而在 Spring Boot 程式創建的過程中，大家也可以先熟悉一下 IntelliJ 的軟體介面，像是在 IntelliJ 的介面中：\n左側的部分是側邊欄，呈現了這個 demo 資料夾中的所有程式。 右側則是程式的編輯區，只要在左側側邊欄對著檔案點擊兩下，就可以將程式開啟到右邊的編輯區，開始編輯這份程式。 補充：IntelliJ 的編輯區是會自動存檔的，因此大家不用擔心寫程式寫到一半沒存檔怎麼辦，揪甘心！\n另外也補充一下，因為 IntelliJ 預設的字體還滿小的，所以建議大家可以調大程式編輯區的字體，保護眼睛從你我做起。\n只要點擊右上方的齒輪，然後點擊「Settings」，就可以叫出偏好設定，接著在設定裡面，再點擊 Editor 中的 Font，就可以在右側設定編輯區的字型、以及字體大小了！\n實作第一個 Spring Boot 程式 # 設定好 IntelliJ 的字體偏好設定、並且確認右下角的進度條跑完之後，我們終於可以開始來實作我們的第一個 Spring Boot 程式了！\n首先我們先展開左側的資料夾，這時候可以看到，在 src/main/java/com.example.demo 底下，有一個 DemoApplication.class 的檔案，點擊兩下開啟這個檔案之後，在右側就可以看到他的內容。\n而在這個 DemoApplication 的程式裡面，其中最重要的，就是第 6 行的 @SpringBootApplication 程式。\n第一次接觸 Spring Boot 的大家，可能會覺得第 6 行這種前面帶有小老鼠 @ 的程式很奇怪，不過這種前面帶有小老鼠的寫法，在 Java 裡面稱作「annotation」，中文是翻譯為「標註」或是「註解」。\n補充：一般在口語上，會稱呼這種前面帶有小老鼠的程式為「annotation」，不過由於版面因素，後續都會使用「註解」來稱呼。\n第 6 行程式的這種寫法，在一般的 Java 程式中比較少看到，不過在 Spring Boot 裡面卻非常常見，所以在後續的文章中，我們也會介紹在 Spring Boog 中，好用的 annotation（註解）有哪些。\n如果你是第一次接觸「註解」的話，建議可以先把「註解」想像成是賦予一個新的功能，不同的註解所提供的功能不一樣，並且他們的使用方法也會不太一樣。\n所以像是第 6 行這個 @SpringBootApplication，他的用法是要加在 class 上面，而他的用途，則是表示這一個 DemoApplication.class，是這個 Spring Boot 程式的啟動入口。\n也因為我們有在第 6 行加上 @SpringBootApplication，所以在第 7 行的左邊，才會出現一個播放鍵的符號，讓我們可以直接點擊這個播放鍵，去運行這個 Spring Boot 程式。\n所以到這邊為止，我們就大致了解了 @SpringBootApplication 的用途（就是將該 class 變成 Spring Boot 程式的啟動入口），以及如何在 IntelliJ 中運行 Spring Boot 程式了，不過在我們真的去運行這個 Spring Boot 程式之前，我們可以先來添加一些 Java 程式在裡面。\n添加 demo 程式 # 首先我們先在 com.example.demo 這個 package 上點擊右鍵，然後選擇 New，接著選擇 Java class，這樣就可以去創建一個 Java class 出來。\n接著我們將這個 class 的名字，取名成 MyController。\n接著在這個 MyController 裡面，添加下列的程式（這裡看不懂程式沒關係，先全部照著寫就好）。\n@RestController public class MyController { @RequestMapping(\u0026#34;/test\u0026#34;) public String test() { System.out.println(\u0026#34;Hi!\u0026#34;); return \u0026#34;Hello World\u0026#34;; } } 當大家添加完上面這段程式之後，在 IntelliJ 中的呈現效果，應該要是下面這個樣子才對。\n補充：如果大家複製貼上這段程式時，發現 @RestController 和 @RequestMapping 沒有自動被 import 進來的話，建議可以改成一行一行手動輸入程式，IntelliJ 就會自動 import 相關的 library 進來了。\n大家在寫完這段程式之後，不了解 @RestController 和 @RequestMapping 這兩個註解的意思是正常的，這兩個註解的用途，會在後面介紹到「Spring MVC」的部分時再做詳細的介紹，所以這裡就先照著寫就好。\n運行 Spring Boot 程式 # 當寫好上述的 MyController 程式之後，接著就可以回到 DemoApplication class 上，然後點擊第 7 行的播放鍵，去運行這個 Spring Boot 程式了！\n所以我們只要使用左鍵，去點擊 DemoApplication 中的第 7 行的播放鍵，然後選擇「Run DemoApplication」，就可以去運行這個 Spring Boot 程式了。\n點擊運行之後，這時候下面就會顯示出一個 console 的視窗，而在這個 console 視窗的最一開始，就會出現一個 Spring 的 logo，接著後面就是實時呈現出 Spring Boot 程式的運行結果。\n只要看到最後一行「Started DemoApplication in 0.695 seconds」出現的時候，就表示你的 Spring Boot 程式運行成功了！\n而當 Spring Boot 程式運行成功之後，這時候就可以打開 Google 瀏覽器，然後在裡面輸入 http://localhost:8080/test ，接著按下 Enter 鍵。\n這時候如果頁面中有呈現「Hello World」的字樣的話，就表示你的第一個 Spring Boot 程式成功運作起來了！可喜可賀！！！\n所以，我們剛剛都做了什麼？ # 那到這邊，我們可以回頭來看一下，我們剛剛都做了什麼，才能夠成功的在瀏覽器中看到「Hello World」的字串。\n首先我們剛剛有去新增了一個 MyController 的 class 出來，然後在裡面加上一個 test() 方法，並且在裡面去回傳一個「Hello World」的字串，同時也添加了兩個註解 @RestController 和 @RequestMapping。\n這段程式的運作邏輯是這樣子的：當我們在 Google 瀏覽器輸入 http://localhost:8080/test 時，實際上 Spring Boot 程式就會去執行 MyController 裡面的 test() 方法中的程式。\n也因為 Spring Boot 會去執行 MyController 裡面的 test() 方法，所以這也是為什麼在 console 上，會印出一行「Hi!」的字串，並且這個 test() 方法的返回值「Hello World」字串，會顯示在 Google 瀏覽器上面。\n之所以能達到這個效果，就是多虧了 @RestController 和 @RequestMapping 這兩個註解的幫助。\n不過到目前為止，大家還不用先太深入了解這兩個註解的用法，現在只要先知道：「當我們在 Google 中輸入 http://localhost:8080/test 時，Spring Boot 程式就會去執行 MyController 中的 test() 方法」，這樣子就可以了。\n至於 @RestController 和 @RequestMapping 這兩個註解的實際用法，在後續的「Spring MVC」的部分中就會做詳細的介紹了。\n補充：如果想快轉到 Spring MVC 的部分，也可以直接跳到 Day 13～Day 23 - Spring MVC 的介紹。\n總結 # 所以到這邊為止，大家就成功的去創建出第一個 Spring Boot 程式了，恭喜恭喜！！\n透過這個練習，也是想讓大家先感受一下，使用 Spring Boot 來寫後端程式真的是很方便，我們只需要寫不到 10 行的程式，就可以快速運行起一個後端程式了，所以使用 Spring Boot 開發的效率真的是超級無敵霹靂高！\n那麼下一篇文章，我們就會開始來介紹 Spring 框架中一個非常重要的特性，也就是 IoC，那麼我們就下一篇文章見啦！\n補充：本文是擷取自我開設的線上課程 Java 工程師必備！Spring Boot 零基礎入門 的內容，如果你想了解更多的 Spring Boot 的用法，歡迎參考課程簡介 （輸入折扣碼「HH202601KU」即可享 85 折優惠）。\n","permalink":"https://kucw.io/blog/springboot/4/","tags":null,"title":"Spring Boot 零基礎入門 (4) - 第一個 Spring Boot 程式"},{"categories":["Spring Boot"],"contents":"哈囉大家好，我是古古。\n在上一篇文章中，我們有先針對 Mac 系統的使用者，介紹要如何在 Mac 系統中安裝此系列文會用到的所有開發工具。\n所以這篇文章，我們就接著來介紹一下，要如何在 Windows 系統中安裝此系列文的開發工具。\n補充：如果你是 Mac 系統的使用者，可以略過這篇文章，直接查看下一篇文章 Day 4 - 第一個 Spring Boot 程式 的介紹。\n目錄 此系列文中會使用到的開發工具 1. 安裝 IntelliJ IDEA Ultimate 付費版 下載 IntelliJ IDEA Ultimate 付費版 2. 安裝 Java 21 下載 Java 21 3. 安裝 MySQL 資料庫 下載 MySQL 資料庫 安裝 MySQL 4. 安裝 Chrome 擴充功能 - Talend API Tester 下載 Chrome 擴充功能 - Talend API Tester 5. 安裝 Git 下載 Git 總結 此系列文中會使用到的開發工具 # 此系列文會使用到的開發工具有：\nIntelliJ IDEA Ultimate 付費版（有 30 天試用期） Java 21 MySQL 資料庫 Chrome 擴充功能 - Talend API Tester 另外，雖然在此系列文中不會使用到 Git，但是因為 Git 可以說是工程師必安裝的程式，因此在這裡也會一併介紹安裝。\nGit 所以接下來，我們就一起來把這些開發工具給安裝完畢，為將來的 Spring Boot 之旅架設好開發環境吧！\n1. 安裝 IntelliJ IDEA Ultimate 付費版 # IntelliJ IDEA 這套軟體是目前開發 Spring Boot 的熱門軟體之一，他有分為 Community（社群版）以及 Ultimate（付費版）兩個版本。\nCommunity（社群版）對 Spring Boot 的支援比較少，許多功能都必須要額外裝插件才能使用，而 Ultimate（付費版）則是對 Spring Boot 的支援比較全面，但是就需要付費使用。\n不過因為 Ultimate（付費版）有 30 天免費試用期，因此如果是初學的話，建議可以先使用 Ultimate（付費版）的試用期來學習 Spring Boot，等到摸的比較熟之後，再換成 Community（社群版），這樣子在學習上，才不會一開始就被環境問題搞得心力交瘁。\n補充：如果大家有學生教育信箱，也可以到 JetBrains 的網站申請教育帳號，就能免費使用 Ultimate（付費版）一年（具體細節以 JetBrains 官網為準）。\n下載 IntelliJ IDEA Ultimate 付費版 # 想要下載 IntelliJ IDEA Ultimate 的話，可以點擊 IntelliJ 官網連結，就會進到 IntelliJ 的下載頁面。\n進到 IntelliJ 的下載頁面之後，IntelliJ 官網會自動偵測你的電腦系統，提供 Windows 的下載點給你，所以大家只需要點擊 Download 按鈕下載即可。\n下載好之後，點擊兩下執行安裝檔，並且先一路按下 Next 繼續。直到當 IntelliJ 呈現下面這個視窗時，建議勾選左上角的「Create Desktop Shortcut」，這樣安裝程式就會在桌面建立一個 IntelliJ 的捷徑，方便大家日後執行 IntelliJ 的程式。\n設定好之後，接著後面一路繼續點擊 Next，這樣子就可以完成 IntelliJ 的安裝了。\n有關IntelliJ的用法，會在後續的文章中繼續介紹，所以這裡只要先安裝成功就可以了。\n2. 安裝 Java 21 # 下載 Java 21 # 在開發 Spring Boot 程式時，首先我們必須要先安裝對應的 Java 版本，後續才能夠成功的運行起 Spring Boot 程式。目前市面上有非常多公司都有提供 Java 版本的下載，大家可以自由選擇自己喜歡的版本下載。\n在此系列文中，我們會下載由 Eclipse Adoptium 所維護的開源免費 Java 版本（即是 OpenJDK），大家可以點擊 Adoptium 官網連結，就可以進到 Adoptium OpenJDK 的下載頁面。\n進到 Adoptium OpenJDK 的下載頁面之後，下方可以選擇你的作業系統、以及想要安裝的 Java 版本，因為本文是 Windows 系統的安裝教學，所以我們就在 Operating System 中選擇「Windows」，並且在 Version 中選擇「21 – LTS」，這時網站就會列出相關的載點，提供給你下載。\n補充：Adoptium OpenJDK 有提供了非常多種 Java 版本給大家下載，如果大家之後有需要安裝其他版本的 Java，也可以到這個網站中下載。\n選擇好系統和 Java 版本之後，這時候在下方會出現多個載點，這裡就直接點擊最上面的載點下載即可。\n下載好之後，一樣點擊兩下執行安裝檔，接著在安裝過程中會出現下面這個視窗。這時建議在「Set JAVA_HOME variable」前面的「X」點擊一下左鍵，然後選擇「將安裝在本機磁碟上」。\n這樣子就可以在安裝 Java 版本的過程中，同步設定 JAVA_HOME 的環境變數，所以將來如果有需要透過 cmd 的指令執行 Java 的話，就可以直接使用了！\n所以設定好之後，接著後面就一樣是一直點擊下一步，就可以完成 Java 的安裝了。\n補充：不了解什麼是 JAVA_HOME 環境變數也沒關係，就直接照著上面的建議進行設定就好，反正 JAVA_HOME 就只是我們在安裝 Java 的過程中，順手一起設定好一個變數，在後續的文章中並不會使用到這個部分。\n3. 安裝 MySQL 資料庫 # 下載 MySQL 資料庫 # 因為此系列文會使用 MySQL 資料庫來串接 Spring Boot，因此會需要大家先在自己的電腦上安裝 MySQL，以利後續的文章使用。\n要安裝 MySQL 的話，可以點擊 MySQL Community Server 官網連結，就可以直接進到 MySQL Community Server 的下載頁面。\n進到 MySQL Community Server 的下載頁面之後，需要選擇我們想安裝的 MySQL 版本、以及安裝的作業系統，因為本文是 Windows 系統的安裝教學，所以我們在 Select Version 中選擇「8.0.39」，而 Select Operating System 中則選擇 「Microsoft Windows」，就可以篩選出 Windows 專用的下載載點。\n篩選出 MySQL 的版本之後，下方一樣是有多個載點可以選擇，這時我們先點擊上方的「MySQL Installer」。\n並且在跳轉到下一個頁面之後，再點擊上方的 Download 按鈕，去下載 MySQL 資料庫的安裝程式下來。\n不過在點擊下載的按鈕之後，此時 MySQL 會跳出一個頁面，詢問你要不要註冊新帳號，這時候可以不用管他，直接往下拉，然後點擊下方的「No thanks, just start my download.」，繼續 MySQL 的下載。\n下載好安裝檔之後，一樣是點擊兩下執行安裝檔，開始 MySQL 資料庫的安裝。\n安裝 MySQL # 執行 MySQL 的安裝程式之後，首先 MySQL 會跳出下面的視窗，要我們進行設定。這裡我們就改成勾選第一個「Server only」，這樣就只會安裝 MySQL 資料庫，而不會安裝其他額外的軟體。\n接著幾個視窗，都是直接按下 Next 繼續，直到出現下面這個視窗時，要開始特別注意一下。這個視窗是 MySQL 詢問我們要使用哪一種密碼加密，這裡就選擇上面的「Use Strong Password Encryption for Authentication (RECOMMENDED)」，然後點擊 Next 繼續。\n接著 MySQL 會要你設定這個資料庫中，權力最大的 root user 的密碼，這裡建議大家輸入 springboot 這個字串當作密碼。\n補充：因為這個密碼在後續的文章中會再度用到，並且忘記密碼的話，會需要重新安裝整個MySQL程式才可以，就還滿麻煩的。所以就建議大家，可以直接使用跟此系列文一樣的密碼 springboot，就可以避免後續不小心忘記密碼的情形出現了。\n設定好之後，就可以按下右下角的 Finish，就可以完成 MySQL 的安裝了。\n4. 安裝 Chrome 擴充功能 - Talend API Tester # 下載 Chrome 擴充功能 - Talend API Tester # 由於在後續的文章中，我們會使用到 Talend API Tester 這個擴充功能，去發起一個 API call，進而去call後端程式的API，去進行測試。所以在這裡，也會需要大家先去安裝這個擴充功能。\n補充：如果你已經有用的順手的 API call 軟體，像是 Postman、Insomnia\u0026hellip;等等，就不一定要安裝此擴充功能，因為他們的目的都只是發起一個 API call 而已，哪個順手使用哪個就可以了。\n如果要安裝 Talend API Tester 的話，可以點擊 Talend API Tester 的安裝連結，就可以進到 Talend API Tester 的安裝頁面。\n進到 Talend API Tester 的安裝頁面之後，接著點擊右側的「加到 Chrome」的按鈕，就可以在 Chrome 中安裝這個擴充功能了。\n安裝完成之後，點擊右上角的圖示，就可以打開 Talend API Tester。\n打開 Talend API Tester 後，大家可以先點擊右下角的箭頭，把下方的視窗給收起來，而後續我們就會透過這個工具，對 Spring Boot 的程式進行 API 的測試。\n5. 安裝 Git # 下載 Git # 安裝完前面所有的工具之後，最後一個我們要安裝的工具是 Git。Git 是在開發程式的過程中，幫助我們進行版本管理的工具，所以 Git 對於軟體工程師而言，也是一個非常重要的技能。\n要安裝 Git 的話，可以點擊 Git 官網連結，就可以進到 Git 的官方網站。\n進到 Git 的網站之後，接著點擊右方的 Download 按鈕，就可以下載 Git 的安裝檔。\n下載好之後，一樣點擊兩下執行安裝檔，開始 Git 的安裝。\n在安裝過程中，先按下幾個 Next 繼續之後，當 Git 呈現下面這個視窗時，建議可以勾選左上角的「Additional icons」，這樣安裝程式就會在桌面建立一個 Git Bash 的捷徑，方便大家日後使用。\n設定好之後，接著就是一直按下 Next 繼續，就可以完成 Git 的安裝了！\n總結 # 這篇文章我們也安裝好了 Windows 系統中的所有開發工具，所以在後續的文章中，我們就可以直接透過這些工具來開發 Spring Boot 了，讚！\n經過這兩篇文章的介紹，Mac 和 Windows 的大家應該都設定好開發的環境了，所以從下一篇文章開始，我們就可以正式進入到 Spring Boot 的介紹了，那我們就下一篇文章見啦！\n補充：本文是擷取自我開設的線上課程 Java 工程師必備！Spring Boot 零基礎入門 的內容，如果你想了解更多的 Spring Boot 的用法，歡迎參考課程簡介 （輸入折扣碼「HH202601KU」即可享 85 折優惠）。\n","permalink":"https://kucw.io/blog/springboot/3/","tags":null,"title":"Spring Boot 零基礎入門 (3) - 開發環境安裝（Windows 版）"},{"categories":["Spring Boot"],"contents":"哈囉大家好，我是古古。\n在學習 Spring Boot 之前，環境的架設也是很重要的，所以這篇文章，我們就先來進行環境設定，為將來的 Spring Boot 之旅架設好開發環境。\n不過因為 Mac 和 Windows 系統的安裝方式差異比較大，所以這邊會拆成兩篇文章來介紹。 如果你的電腦是 Mac 系統，可以直接查看這篇文章，如果你的電腦是 Windows 系統，則可以直接查看下一篇文章 Day 3 - 開發環境安裝（Windows 版） 的介紹。\n目錄 此系列文中會使用到的開發工具 1. 安裝 IntelliJ IDEA Ultimate 付費版 下載 IntelliJ IDEA Ultimate 付費版 2. 安裝 Java 21 下載 Java 21 3. 安裝 MySQL 資料庫 下載 MySQL 資料庫 安裝 MySQL 4. 安裝 Chrome 擴充功能 - Talend API Tester 下載 Chrome 擴充功能 - Talend API Tester 5. 安裝 iTerm2、oh-my-zsh、Homebrew 安裝 iTerm2 安裝 oh-my-zsh 安裝 Homebrew 6. 安裝 Git 總結 此系列文中會使用到的開發工具 # 此系列文會使用到的開發工具有：\nIntelliJ IDEA Ultimate 付費版（有 30 天試用期） Java 21 MySQL 資料庫 Chrome 擴充功能 - Talend API Tester 另外，雖然此系列文中不會使用到下面這些工具，但是因為這些工具非常的好用，可以說是 Mac 開發者必安裝的工具，因此在這裡也會一併介紹安裝。\nHomebrew + iTerm2 + oh-my-zsh Git 所以接下來，我們就一起來把這些開發工具給安裝完畢，為將來的 Spring Boot 之旅架設好開發環境吧！\n1. 安裝 IntelliJ IDEA Ultimate 付費版 # IntelliJ IDEA 這套軟體是目前開發 Spring Boot 的熱門軟體之一，他有分為 Community（社群版）以及 Ultimate（付費版）兩個版本。\nCommunity（社群版）對 Spring Boot 的支援比較少，許多功能都必須要額外裝插件才能使用，而 Ultimate（付費版）則是對 Spring Boot 的支援比較全面，但是就需要付費使用。\n不過因為 Ultimate（付費版）有 30 天免費試用期，因此如果是初學的話，建議可以先使用 Ultimate（付費版）的試用期來學習 Spring Boot，等到摸的比較熟之後，再換成 Community（社群版），這樣子在學習上，才不會一開始就被環境問題搞得心力交瘁。\n補充：如果大家有學生教育信箱，也可以到 JetBrains 的網站申請教育帳號，就能免費使用 Ultimate（付費版）一年（具體細節以 JetBrains 官網為準）。\n下載 IntelliJ IDEA Ultimate 付費版 # 想要下載 IntelliJ IDEA Ultimate 的話，可以點擊 IntelliJ 官網連結，就會進到 IntelliJ 的下載頁面。\n進到 IntelliJ 的下載頁面之後，IntelliJ 官網會自動偵測你所使用的 Mac 是屬於 Intel 晶片、還是屬於 Apple 的M1、M2\u0026hellip;等等的晶片，並且提供相對應的下載檔給你。\n所以大家只需要點擊 Download 按鈕，就可以下載你的晶片所對應的 IntelliJ 程式了（或是也可以點擊右邊的 .dmg，手動選擇你想下載哪一種晶片的程式）。\n下載好之後，開啟 .dmg 檔案，並且將 IntelliJ IDEA Ultimate 的程式拉到「應用程式」的資料夾裡面，就可以完成 IntelliJ 的安裝了。\n有關 IntelliJ 的用法，會在後續的文章中繼續介紹，所以這裡只要先安裝成功就可以了。\n2. 安裝 Java 21 # 下載 Java 21 # 在開發 Spring Boot 程式時，首先我們必須要先安裝對應的 Java 版本，後續才能夠成功的運行起 Spring Boot 程式。目前市面上有非常多公司都有提供 Java 版本的下載，大家可以自由選擇自己喜歡的版本下載。\n在此系列文中，我們會下載由 Eclipse Adoptium 所維護的開源免費 Java 版本（即是 OpenJDK），大家可以點擊 Adoptium 官網連結，就可以進到 Adoptium OpenJDK 的下載頁面。\n進到 Adoptium OpenJDK 的下載頁面之後，下方可以選擇你的作業系統、以及想要安裝的 Java 版本，因為本文是 Mac 系統的安裝教學，所以我們就在 Operating System 中選擇「macOS」，並且在 Version 中選擇「21 – LTS」，這時網站就會列出相關的載點，提供給你下載。\n補充：Adoptium OpenJDK 有提供了非常多種 Java 版本給大家下載，如果大家之後有需要安裝其他版本的 Java，也可以到這個網站中下載。\n選擇好系統和 Java 版本之後，這時候在下方會出現多個載點，這裡就需要根據你自己的 Mac 晶片，去選擇對應的載點。\n如果你的 Mac 是 Apple 的 M1、M2\u0026hellip;等晶片，那就是點擊上方的 aarch64 的載點；如果你的 Mac 是 Intel 晶片，則是點擊下方的 x64 的載點，這部分因為牽涉到比較底層的硬體環境，因此需要小心選擇。\n下載好之後，一樣是雙擊 .dmg 的下載檔，然後一路按「下一步」，就可以完成 Java 的安裝了。\n3. 安裝 MySQL 資料庫 # 下載 MySQL 資料庫 # 因為此系列文會使用 MySQL 資料庫來串接 Spring Boot，因此會需要大家先在自己的電腦上安裝 MySQL，以利後續的文章使用。\n要安裝 MySQL 的話，可以點擊 MySQL Community Server 官網連結，就可以直接進到 MySQL Community Server 的下載頁面。\n進到 MySQL Community Server 的下載頁面之後，需要選擇我們想安裝的 MySQL 版本、以及安裝的作業系統，因為本文是 Mac 系統的安裝教學，所以我們在 Select Version 中選擇「8.0.39」，而 Select Operating System 中則選擇 「macOS」，就可以篩選出 Mac 專用的下載載點。\n篩選出 MySQL 的版本之後，接著在下方的載點中，一樣是需要根據你的 Mac 晶片，選擇對應的下載點。\n如果你的 Mac 是 Apple 的 M1、M2\u0026hellip;等晶片，那就是點擊上方的 aarch64 的載點；如果你的 Mac 是 Intel 晶片，則是點擊下方的 x64 的載點，這裡就必須要小心選擇，以免下載到錯誤版本。\n在確定好晶片的版本之後，就可以點擊對應的下載按鈕，進行 MySQL 的下載。\n不過在點擊下載的按鈕之後，此時 MySQL 會跳出一個頁面，詢問你要不要註冊新帳號，這時候可以不用管他，直接往下拉，然後點擊下方的「No thanks, just start my download.」，繼續 MySQL 的下載。\n下載好安裝檔之後，一樣是雙擊 .dmg 的下載檔，開始 MySQL 資料庫的安裝。\n安裝 MySQL # 執行 MySQL 的安裝程式之後，前面先一直點擊「繼續」和「同意」就好。不過安裝到一半時，MySQL 會跳出下面的視窗，要我們設定資料庫，注意這裡的設定非常重要，會影響到後續文章的操作。\n在這個視窗中，MySQL 會詢問我們要使用哪一種密碼加密，這裡就選擇上面的「Use Strong Password Encryption」即可，選好之後接著點擊 Next 繼續。\n接著 MySQL 會要你設定這個資料庫中，權力最大的 root user 的密碼，這裡建議大家就直接輸入 springboot 這個字串當作密碼。\n補充：因為這個密碼在後續的文章中會再度用到，並且忘記密碼的話，會需要重新安裝整個MySQL程式才可以，就還滿麻煩的。所以就建議大家，可以直接使用跟此系列文一樣的密碼 springboot，就可以避免後續不小心忘記密碼的情形出現了。\n設定好之後，就可以按下右下角的 Finish，就可以完成 MySQL 的安裝了。\n而在安裝好 MySQL 之後，如果大家想要查看 MySQL 目前的運作狀況的話，可以打開 Mac 的「系統偏好設定」，這時候在左邊側邊欄的下方，就會出現 MySQL 的標籤，點擊 MySQL 的標籤之後，就可以在這裡查看 MySQL 的運作狀況了。\n4. 安裝 Chrome 擴充功能 - Talend API Tester # 下載 Chrome 擴充功能 - Talend API Tester # 由於在後續的文章中，我們會使用到 Talend API Tester 這個擴充功能，去發起一個 API call，進而去call後端程式的API，去進行測試。所以在這裡，也會需要大家先去安裝這個擴充功能。\n補充：如果你已經有用的順手的 API call 軟體，像是 Postman、Insomnia\u0026hellip;等等，就不一定要安裝此擴充功能，因為他們的目的都只是發起一個 API call 而已，哪個順手使用哪個就可以了。\n如果要安裝 Talend API Tester 的話，可以點擊 Talend API Tester 的安裝連結，就可以進到 Talend API Tester 的安裝頁面。\n進到 Talend API Tester 的安裝頁面之後，接著點擊右側的「加到 Chrome」的按鈕，就可以在 Chrome 中安裝這個擴充功能了。\n安裝完成之後，點擊右上角的圖示，就可以打開 Talend API Tester。\n打開 Talend API Tester 後，大家可以先點擊右下角的箭頭，把下方的視窗給收起來，而後續我們就會透過這個工具，對 Spring Boot 的程式進行 API 的測試。\n5. 安裝 iTerm2、oh-my-zsh、Homebrew # 雖然在此系列文中不會使用到 iTerm2、oh-my-zsh、Homebrew 這些工具，但是因為這些工具非常的好用，可以說是 Mac 開發者必安裝的工具，因此在這裡也會一併介紹安裝。\n安裝 iTerm2 # iTerm2 是一個強大的「終端機（Terminal）」軟體，他的優點是介面比較好看，然後有很多地方可以做個人化的調整設定，像是主題背景顏色、或是透明度\u0026hellip;等等，可以讓寫程式的心情變得好一點。因此只要是 Mac 的開發者，都非常推薦安裝 iTerm2 這個軟體，使用 iTerm2 取代 Mac 內建的終端機。\n而要安裝 iTerm2 的話，可以點擊 iTerm2 官網連結，就可以進到 iTerm2 的官方網站。\n進到 iTerm2 的網站之後，直接往下拉到最下面，在最下面有一個 Download 的按鈕，點擊這個按鈕，就可以下載 iTerm2 的安裝程式了。\n下載好 iTerm2 之後，點擊兩下就可以直接打開 iTerm2 的程式。\n如果想要調整 iTerm2 的主題顏色的話，可以先打開 iTerm2 的設定，然後點擊「Profiles」，接著就可以在「Colors」標籤底下調整主題的顏色。\n而如果想要調整 iTerm2 的視窗透明度的話，則是可以進到「Profiles」中的「Window」標籤，在這裡面進行調整。\n安裝 oh-my-zsh # 不管你是使用 Mac 內建的終端機、還是使用 iTerm2，只要提到下指令，那麼就會想到 oh-my-zsh 這個工具。\noh-my-zsh 也是一個 Mac 工程師推薦安裝的功能，他除了可以讓我們在下指令時變的更方便之外，同時他也可以在終端機上呈現更多的資訊，所以也是非常增進開發效率的一個好用工具。\n而要安裝 oh-my-zsh 的話，可以點擊 oh-my-zsh 官網連結，就可以進到 oh-my-zsh 的官方網站。\n進到 oh-my-zsh 的網站之後，先點擊右側的「Install oh-my-zsh」的按鈕，此時他就會自動跳轉到下面這行程式上。\n所以只要複製這一行程式，然後貼到 iTerm2 上，接著按下 Enter 鍵，他就會開始進行安裝。\n安裝完成之後，這時候 iTerm2 上面會出現一個大大的「Oh My Zsh」，只要看到這個 Logo，就表示 oh-my-zsh 也安裝完成了。\n安裝 Homebrew # 安裝完 iTerm2 和 oh-my-zsh 之後，接下來要安裝的是 Homebrew，他也是 Mac 開發中一個很好用的工具。\nHomebrew 他是一個套件管理系統，大家可以把 Homebrew 想像成是一個集中管理處的感覺，不論你今天想安裝的是什麼套件（ex：Git、Python\u0026hellip;等等），都可以來 Homebrew 找找看，熱門的套件都是可以透過 Homebrew 進行安裝的。\n而要安裝 Homebrew 的話，可以點擊 Homebrew 官網連結，就可以進到 Homebrew 的官方網站。\n進到 Homebrew 的網站之後，可以稍微往下拉一點，然後複製「Install Homebrew」下面的這一行程式。\n接著將這行程式貼到 iTerm2 上，然後按下 Enter 鍵，就可以開始安裝 Homebrew 了。\n不過這時候，當你按下 Enter 鍵時，你可能會發現「程式怎麼卡住了？」，這時候安裝程式這時候會停在「Password」這一行，表示要我們輸入密碼，才可以繼續往下運行。\n所以這時候，大家可以直接對著鍵盤輸入你的 Mac 密碼，輸入完成之後再按下 Enter 鍵，就可以繼續往下運行程式了。\n補充：在這裡輸入密碼的過程中，是不會有任何星號出現的，所以大家可以直接盲打你的密碼，輸入完成之後，再按下 Enter 鍵就可以了。\n輸入完密碼、並且按下 Enter 鍵之後，這時候 iTerm2 會出現「Press RETURN to continue」的訊息，此時就只要再按一下 Enter 鍵，就可以繼續執行安裝程式了。\n最後當大家看到「Installation successful」的訊息出現的時候，就表示 Homebrew 也安裝完成了。\n6. 安裝 Git # 安裝完前面所有的工具之後，最後一個我們要安裝的工具是 Git。Git 是在開發程式的過程中，幫助我們進行版本管理的工具，所以 Git 對於軟體工程師而言，也是一個非常重要的技能。\n而在大家完成了上述的安裝之後，我們現在其實可以透過「下指令」的方式，使用 Homebrew 去安裝 Git 這個工具的。\n所以要安裝 Git 的話，就只要打開 iTerm2，然後輸入以下的程式，接著按下 Enter 鍵。\nbrew install git 這樣子就可以完成 Git 的安裝了，世界和平啦！\n總結 # 這篇文章我們先安裝了 Mac 系統中的所有開發工具，所以在後續的文章中，我們就可以直接透過這些工具來開發 Spring Boot 了，讚！\n那麼下一篇文章，我們則會接著來介紹，要如何在 Windows 系統中也去安裝 Spring Boot 的開發工具，那我們就下一篇文章見啦！\n補充：Mac 的使用者可以直接跳到 Day 4 - 第一個 Spring Boot 程式 繼續查看 Spring Boot 的介紹。\n補充：本文是擷取自我開設的線上課程 Java 工程師必備！Spring Boot 零基礎入門 的內容，如果你想了解更多的 Spring Boot 的用法，歡迎參考課程簡介 （輸入折扣碼「HH202601KU」即可享 85 折優惠）。\n","permalink":"https://kucw.io/blog/springboot/2/","tags":null,"title":"Spring Boot 零基礎入門 (2) - 開發環境安裝（Mac 版）"},{"categories":["Spring Boot"],"contents":"哈囉大家好，我是古古。\n這次希望可以透過 30 天的鐵人賽文章，讓沒接觸過（甚至沒聽過）Spring Boot 的人，了解 Spring Boot 到底是什麼，以及如何運用 Spring Boot 搭建一個簡易的後端系統。\n那麼我們就開始吧，Let\u0026rsquo;s go！\n目錄 學習目標（你可以學到什麼？） 哪些人適合閱讀這個系列文（適合誰？） 閱讀前的準備（須具備什麼知識？） 正文開始：什麼是 Spring Boot？ 「前端」和「後端」的差別 「框架」是什麼意思？ 所以，Spring Boot 到底是什麼？ Spring Boot 的優勢在哪裡？ 優勢一：簡化 Spring 開發 優勢二：快速整合主流框架 其他優勢 系列文章規劃 1. Day 1～4：Spring Boot 簡介、開發環境安裝 2. Day 5～12：Spring 框架的特性 - IoC 和 AOP 3. Day 13～23：Spring MVC 介紹 4. Day 24～28：Spring JDBC 介紹 5. Day 29：實戰演練：打造簡易的圖書館系統 Final. Day 30：Spring Boot 零基礎入門總結 總結 學習目標（你可以學到什麼？） # 經過這 30 篇系列文，你可以學到：\n了解什麼是 Spring Boot，以及如何運用 IntelliJ 這套軟體開發 Spring Boot 程式 了解 Spring 框架的兩大特性 - IoC 和 AOP 了解 Spring MVC、Spring JDBC 的基本用法 能夠運用 Spring Boot，實作出一個簡易的後端系統 哪些人適合閱讀這個系列文（適合誰？） # 想學習 Spring Boot，但不知道從何入門 看過 Spring Boot 的相關介紹，但不了解實際要如何運用 閱讀前的準備（須具備什麼知識？） # 閱讀此系列文前，必須具備「Java 程式語言」和「MySQL 資料庫設計」的知識：\nJava：了解基本 Java 的語法，並且至少要知道 「多型（polymorphism）」 的概念 MySQL：了解基本的 SQL 語法（Select、Update、Insert、Delete）即可 另外 Mac / Windows 皆可閱讀，電腦環境不影響。\n正文開始：什麼是 Spring Boot？ # 所謂的 Spring Boot，他是目前 Java 後端中最主流的開發框架，不過在開始介紹什麼是 Spring Boot 之前，我們需要先來了解一下「前端」跟「後端」之間的差別、以及「框架」又是代表什麼意思。\n「前端」和「後端」的差別 # 在現今的網站架構中，可以分成「前端」和「後端」兩部分：\n前端：負責網頁的排版設計。 所以像是網頁中要使用什麼顏色的按鈕、按鈕要放在哪裡、標題大小要多大\u0026hellip;等等，這些都是屬於前端的範疇。 後端：負責數據處理。 所以像是商品的價格是多少、每一筆評價的留言內容是什麼\u0026hellip;等等，這些有關數據內容的，都是屬於後端的範疇。 所以簡單的說的話，前端工程師就是去負責實作「這個網頁要長什麼樣子」，而後端工程師，則是負責去處理「要在這個網頁上賣什麼東西」，所以前端工程師處理的是排版設計，而後端工程師處理的則是動態的數據。\n而在理解了前端和後端的概念之後，接著就可以來理解「框架」的概念了。\n「框架」是什麼意思？ # 透過剛剛的介紹，現在我們知道，前端是負責網頁的排版設計，後端則是負責數據處理。而在前端的世界中，其實是有非常多種的程式語言，都可以去實作出網站的排版設計，所以同樣的道理，在後端的世界中，也是有非常多種的程式語言，可以去實作出數據處理的功能的。\n在後端的世界裡中，比較常被拿來使用的程式語言有 Java、Python、PHP…等等，所以「Java 後端」所表示的，就是使用 Java 來開發的後端程式。\n而在最古早的時代，工程師們就是直接拿著 Java 和 Python 這種程式語言，一筆一畫的把整個後端系統給實作出來，所以使用者就可以透過這個後端系統，在某個電商網站中執行購買商品、或是去查看商品評價……等等的操作。\n但是這些工程師們當時寫著程式就發現，每次開發一個後端系統，都要重新寫一堆相似度非常高的程式，覺得很心累也很浪費時間，因此就有團隊開始開發出了 「框架（Framework）」，試圖提升開發後端系統的效率。\n所以到這邊為止，你可以先簡單的把「框架（Framework）」想像成是一個好用的工具包，在沒有框架以前，你要花非常多時間和力氣，才能夠手動的用螺絲起子，去把整個後端的系統給蓋出來，而在有了框架之後，你就像拿到一把強力電鑽一樣，只要輕鬆的按幾下按鈕，就可以快速的把後端系統給架設出來了。\n所以「加速工程師開發的效率」，就是「框架」被發明出來的目的。\n所以，Spring Boot 到底是什麼？ # 了解了「Java 後端」和「框架」的意義之後，這時候我們回頭看最一開始說的那句話，就比較可以看的懂了。\n我們在最一開始有提到：「Spring Boot 是目前 Java 後端中最主流的開發框架」，所以 Spring Boot 的目的，就是「提供一個好用的工具，讓 Java 後端工程師可以加快開發的效率」。\n也因為 Spring Boot 非常的好用，幾行簡單的設定就可以快速架設出一個後端系統出來，所以 Spring Boot 就成為了目前 Java 業界中最主流的開發框架，甚至已經到了 「不會 Spring，不談就業」 的程度，由此也可知 Spring Boot 對 Java 業界的影響程度。\n補充：「框架」的目的，就是為了提升工程師開發的效率，而不同的程式語言，其實都會有他專屬對應的框架可以使用，譬如說以 Java 為例，他對應的主流框架就是 Spring 框架，而 PHP 的話，對應的主流框架則是 Lavarel 框架，不同程式語言之間的框架是沒辦法混用的。\nSpring Boot 的優勢在哪裡？ # 所以到這邊為止，我們已經大概了解了 Spring Boot 的用途了，基本上 Spring Boot 就是 Java 後端中的一個好用的開發框架，只要你是使用 Java 來開發後端程式，通常就是會使用 Spring Boot 這套框架，來加速你開發後端程式的效率。\n但說了這麼多，使用 Spring Boot 的好處在哪裡？他到底為我們提升了哪些開發的效率？所以以下我們就來探討一下，使用S pring Boot 開發的優勢在哪裡。\n優勢一：簡化 Spring 開發 # 使用 Spring Boot 的第一個好處，就是可以「簡化 Spring 的開發」。\n在很久很久以前，在當時傳統的 Spring 框架開發中，其實工程師是需要進行大量的 xml 設定，才能將 Spring 框架運行起來，而 Spring Boot 的推出，就是希望能夠解決 Spring 框架設定繁瑣的缺點。\n舉個例子來說的話，在傳統 Spring 框架中，你就是會有一堆車子的零件，但是你必須要自己「手動」把他們焊接起來，並且你可能還會焊錯；而新一代的 Spring Boot，則是你直接走進去汽車店裡，直接花錢下單把車開走，所以兩者相較起來，當然是 Spring Boot 更加簡單好用。\n另外大家也可以觀察一下「Spring Boot」這個單字，他其實就是由「Spring」和「Boot」兩個字所組合起來的，其中「Spring」所代表的就是 Spring 框架，而「Boot」所代表的則是開機的意思，所以組合這兩個單字的話，就可以得到「Spring Boot」。\n所以 Spring Boot 本身的目的，就是希望能提供一個按下開機鍵，就可以直接使用的後端程式給你，並且在這個後端程式的內部，就都是使用 Spring 框架的零件所組成的。\n優勢二：快速整合主流框架 # 使用 Spring Boot 開發的第二個優勢，就是可以「快速的整合主流框架」。\n因為 Spring Boot 採用了 「約定優於配置」 的設計方式，因此就可以簡化開發時繁瑣的設定檔，快速的整合其他主流框架，提升工程師開發的效率。\n這個「約定優於配置」聽起來是有點抽象，其實換句話說的話，就是 Spring Boot 會預先幫你設定好預設值的意思，所以假設你今天加了一個新功能，即使你一行設定都沒有寫，Spring Boot 也會預先套用他寫好的設定檔，快速的整合該框架進來。\n雖然「約定優於配置」是很大的優點，不過對於初學 Spring Boot 的人來說，可能反而會是一個小缺點，因為太多東西都被 Spring Boot 預先設定好了，因此初學者可能會完全搞不懂現在是發生了什麼事情。\n不過只要好好的學習過 Spring Boot 的用法、以及相關的設定之後，這個優點就會轉變成非常強大的優勢！\n其他優勢 # 當然 Spring Boot 還有其他很厲害的優勢，不過優勢都是和過往的框架比較出來的，而那些框架目前已經非常少見，因此大家有興趣的話，可以再去搜索 Spring Boot 和其他框架的對比，這邊就不多做贅述。\n系列文章規劃 # 大致了解了前端和後端的概念，以及 Spring Boot 是什麼之後，接下來是介紹一下此系列文的文章規劃安排。\n此系列文會分成 30 篇文章，透過 5 個部分來介紹 Spring Boot，預計的文章規劃如下：\n1. Day 1～4：Spring Boot 簡介、開發環境安裝 # 在最開始的幾天，我們會先簡單認識 Spring Boot，並且安裝此系列文中會使用到的所有開發工具，為將來的 Spring Boot 之旅架設好開發環境。\n2. Day 5～12：Spring 框架的特性 - IoC 和 AOP # 架設好環境之後，接著就會進到第二部分，介紹 Spring 框架中兩個非常重要的特性：IoC 和 AOP。\nIoC 和 AOP 是 Spring 框架裡的核心技術，幾乎所有 Spring 的功能，都是建立在這兩大特性之上，因此如果能夠掌握好這兩大特性，能夠為將來的 Spring Boot 之旅打下良好的基礎。\n3. Day 13～23：Spring MVC 介紹 # 介紹完 Spring 框架的核心特性之後，接著就會進到第三部分，介紹 Spring MVC 的相關知識。\nSpring MVC 的用途是和前端溝通，因此在這個章節裡，除了會介紹 Spring MVC 的基本用法之外，同時也會介紹許多通用的網路知識，像是 Http 協議、Json、RESTful.等等，讓大家了解前端和後端之間的溝通方式。\n4. Day 24～28：Spring JDBC 介紹 # 了解了 Spring MVC 的用法之後，接著會進到第四部分，介紹 Spring JDBC 的相關知識。\n不同於前面的 Spring MVC 是和前端溝通，Spring JDBC 的主要功能是和資料庫進行溝通，因此當介紹完這部分之後，大家就能夠在 Spring Boot 中去操作資料庫，進而取得到相關的數據了。\n5. Day 29：實戰演練：打造簡易的圖書館系統 # 前面的四個部分都是偏向功能的介紹，而第五部分則是會安排是一個實戰演練，實際的去整合前面四個部分所學到的知識，打造出一個簡易的圖書館系統出來。\n所以透過最後的這個實戰練習，希望能幫助大家更好的了解、活用 Spring Boot 的知識！\nFinal. Day 30：Spring Boot 零基礎入門總結 # 此系列文的最後一天會來做個大總結，詳細列出我們在這 30 天內都介紹了哪些內容，也會補充 Spring Boot 後續的學習路徑，提供給大家參考。\n總結 # 這篇文章我們先介紹了什麼是 Spring Boot，也介紹了前端和後端的區別、以及框架的概念，讓大家先對 Spring Boot 有一個簡單的認識。\n那麼下一篇文章，我們就會接著來進行環境設定，為將來的 Spring Boot 之旅架設好開發環境，那我們就下一篇文章見啦！\n補充：本文是擷取自我開設的線上課程 Java 工程師必備！Spring Boot 零基礎入門 的內容，如果你想了解更多的 Spring Boot 的用法，歡迎參考課程簡介 （輸入折扣碼「HH202601KU」即可享 85 折優惠）。\n","permalink":"https://kucw.io/blog/springboot/1/","tags":null,"title":"Spring Boot 零基礎入門 (1) - Spring Boot 簡介"},{"categories":["Other tech"],"contents":"當 Mac 升級到 Sonoma 14.0 之後，只要按下鍵盤左側的「中/英」鍵（也就是 Caps Lock 鍵），Mac 就會出現一個藍色的游標，提示你現在開啟了 Caps Lock\n要關閉這個藍色游標的話，只需要以下三個步驟\n開啟 Terminal 執行以下兩行指令（分別複製後執行） sudo mkdir -p /Library/Preferences/FeatureFlags/Domain sudo /usr/libexec/PlistBuddy -c \u0026#34;Add \u0026#39;redesigned_text_cursor:Enabled\u0026#39; bool false\u0026#34; /Library/Preferences/FeatureFlags/Domain/UIKit.plist 重新開機 這樣就可以關閉那個討厭的藍色游標了，天下太平啦！！\n","permalink":"https://kucw.io/blog/2023/10/mac-sonoma-disable-caps-lock-indicator/","tags":null,"title":"關閉 MacOS Sonoma 的 Caps Lock 游標"},{"categories":["Life"],"contents":"說到夏天，當然就是陽光、沙灘、海！但是如何在炎炎夏日做好防曬措施，絕對是大家最關心的一項議題，本文會從兩個方向來分析如何挑選防曬乳\n挑選防曬乳之前，先了解太陽中的紫外線！ # 太陽中有很多紫外線，其中對我們影響最大的就是 UVA 和 UVB，而 UVA 和 UVB 這兩個紫外線，可以簡單分成兩部分：\n但凡涉及到美醜的，不論是變黑、變老、曬斑、長皺紋，都是 UVA 造成的，也就是 UVA for Aging（老化） 但凡是涉及到生病死亡的，不論是曬傷、皮膚癌、白內障，都是 UVB 惹的禍，也就是 UVB for Burn（灼傷） 所以到這邊大家可以先有個概念，假設你今天想要防曬的是美醜的部分，你就要挑選 UVA 防護比較高的防曬乳，假設你今天想要的是別那麼早死，那你則是要挑選 UVB 防護比較高的防曬乳\n如果是想要照顧美醜的同時、又別那麼早死，那就是挑選 UVA + UVB 皆有防護的防曬乳，不過想當然就是會比較貴啦！\n我不想那麼早死！如何挑選 UVB 防曬乳？ # 美醜可能不是每個人都在意，不過大家應該都不想早死，所以在談論美醜之前，我們先討論如何挑選避免早死的防曬乳，也就是如何針對 UVB for Burn 進行防曬\n要防曬 UVB 很簡單，就是看 SPF 的指數！\nSPF 50 是最棒、SPF 30 是次棒、SPF 15 是普通，而最猛的是 SPF 50 +++++，後面的 ++ 越多表示越厲害\n當然 SPF 這個指標本身的意義不是這麼簡單暴力，他的實際意思是「能夠延長多少不被曬傷的時間」，不過我是建議一般人也不用了解的那麼詳細，就挑數字最大、++ 最多的買下去就對了\n其實大家如果只是單純想防曬 UVB 的話，防曬乳真的是便宜到有剩，因為萬一你得了皮膚癌，最終還是要花費社會的醫療資源來救你，所以各國政府為了避免醫療人口太多，都會把 UVB 防曬乳的價格定的很便宜\n因此如果你今天有出遊計畫，卻又不知道怎麼挑選防曬乳，那就先去隨便買一條 SPF 50+ 的防曬乳來用就可以了！\n除了不那麼早死之外，我還想保持的漂漂亮亮的！如何挑選 UVA 防曬乳？ # 來，只要一講到美醜，這個砸的錢就沒有上限了🥲\n如果你是想要讓自己不會變黑、變老、曬斑、長皺紋，那就是要針對 UVA for Aging 進行防曬\n你知道，因為大家美不美醜不醜，政府都不會因此而增加醫療負擔，所以各國政府其實不是很 care 這件事，因此在 UVA 的防護上，其實沒有一個各國通用的標準可以參考\n現在市面上就有好幾種國際組織，分別對 UVA 的防護進行評斷，包含：\n日本的 PA 系列 英國的 Boots Star Rating 星星系列 歐盟的 PDD 系列 \u0026hellip;..等等，族繁不及備載 也因為每一個組織都用不同的標準來衡量 UVA 的防護，所以說實話，大家就挑自己喜歡的牌子來買就好，反正也沒有一個權威的公信力可以參考，況且美醜也是比較主觀的看法，所以大家只能多買多看，比較哪一種防曬乳是最適合自己膚質、並且荷包又買得起的\n不過如果真要我推薦的話，我會建議大家參考日系的 PA 標準，PA 後面越多 ++ 越好，所以 PA++++++++ 就是 UVA 防禦力爆表的防曬乳（當然價錢可能也爆表）\n會推薦日系的 PA 標準，是因為畢竟亞洲的人種還是比較像，在意的美醜價值觀也比較相似（要白！要透！），而歐美國家畢竟都是白人居多，白人天生就曬不黑啊XDD，所以如果大家有選擇障礙的話，建議可以先從日系的 PA+++ 的防曬乳開始挑起\n不過大家在挑 UVA 防護高的防曬乳時，記得同時也要看防禦 UVB 的 SPF 係數啊！！如果因為在意漂亮而忽略了身體健康，那就得不償失了😖\n總結 # 最後我列了一張表格，整理了一下文章中提到的資訊，提供給大家參考\nUVA UVB 由來 UVA for Aging（老化） UVB for Burn（灼傷） 影響範圍 美醜 生病死亡 造成的傷害 變黑、變老、曬斑、長皺紋 曬傷、皮膚癌、白內障 防曬指標 日本 PA、歐盟 PDD\u0026hellip;.等等 SPF 簡易挑選準則 PA+++++（++ 越多越好） SPF 50+++++（數字越大越好、++ 越多越好） 價錢 貴 便宜 ","permalink":"https://kucw.io/blog/2023/5/sun-and-ultraviolet/","tags":null,"title":"夏日防曬！五分鐘了解如何正確挑選防曬乳"},{"categories":["Life"],"contents":"最近剛從宿霧玩回來，記錄一下 2023 宿霧 6 天 5 夜旅遊的行程規劃，也分享給有需要的大家\n出遊時間：2023.4.20 - 2023.4.25（6 天 5 夜） 重點行程：墨寶沙丁魚風暴、歐斯陸鯨鯊共游、薄荷島巧克力山+眼鏡猴 走法：逆時針（機場/宿霧市區 -\u0026gt; 墨寶 -\u0026gt; 歐斯陸 -\u0026gt; 薄荷島 -\u0026gt; 機場/宿霧市區） 人數：2 人 總花費：一人 28328（含機票+飯店+所有行程+按摩+各種喝爆+伴手禮） 行前準備 # 出發前 30 天內，線上申請 菲律賓電子簽證 假設 4/20 出發，就是 3/20 開始可以申請 記得印紙本出來，登機和入境要看 在台灣換好 美金現鈔 帶在身上 帶著美金去菲律賓當地再換披索，是換匯最佳解，有錢想省事的也可以在台灣直接台幣換披索 我們兩人 6 天在當地共花 800 美金（不含機票+飯店），剛剛好全花完沒有剩，供大家參考 列印 數位新冠疫苗證明 文件 登機要看 網路上買 Sim 卡，機場取貨 這個有許多選擇，也可以到當地再買，看自己需求 我們是直接買 KKday 上的 菲律賓 Globe Telecom 5G 網卡 強烈推薦帶一台 GoPro，水上活動好玩好拍很多 我們是自己有所以沒有額外租，不過如果要租的話，建議在台灣租，然後帶過去宿霧比較方便 旅平險 or 旅行不便險，依自己需求購買 Day 1 # 詳細資訊 當天重點行程 搭飛機+搭車至墨寶 當天住宿 Pig Dive Hostel（墨寶的青年旅館） 備註 我們在墨寶有許多行程和包車，都是請 Pig Dive 代訂的，老闆是台灣人會說中文，可以先訂住宿之後再跟他們聯繫幫忙代訂行程 搭乘 星宇航空 週四航班，桃園機場（早上 8:30 起飛） -\u0026gt; 宿霧（中午 11:25 降落）的班機 記得帶一支筆，在宿霧機場還需要填寫紙本入境卡，才能入境 聯絡包車司機，下午 2 點從機場出發前往墨寶 私人包車由 Pig Dive 住宿代訂 中間有請司機順路多停一站 SM Seaside City Cebu（要加一點錢），我們是在這邊換匯，1 美金 = 55 披索 大約傍晚 6 點抵達墨寶 Pig Dive Hostel，晚上自由活動 Day 2 # 詳細資訊 當天重點行程 Kawasan Falls 溯溪、墨寶沙丁魚風暴 當天住宿 續住 Pig Dive Hostel 備註 x 早上 7 點集合前往 Kawasan Falls 溯溪（私人包車，不過是搭乘嘟嘟車） 約莫中午 12 點半結束回到旅館，可休息或是附近晃晃 此行程由 Pig Dive 代訂 下午 2:30 集合前往沙丁魚風暴潛水 我們兩人皆有 OW 證照，所以是直接潛一隻水肺 約 4 點結束回到旅館 此行程也是請 Pig Dive 幫忙代訂 晚上也是在墨寶當地自由活動 Day 3 # 詳細資訊 當天重點行程 歐斯陸鯨鯊共游、搭船至薄荷島 當天住宿 Alona Austria Resort（薄荷島） 備註 x 早上 4 點集合前往 歐斯陸鯨鯊共游（私人包車） 車程大概 1 個半小時，所以約莫是快 6 點抵達歐斯陸 看完鯨鯊大概 8 點多結束 此行程也是請 Pig Dive 代訂（含包車+共游） 鯨鯊結束後請司機載我們到 Quartel Beach，此為搭船到薄荷島的港口 從歐斯陸到薄荷島，只有唯一一家船公司 APEKOPTRAVEL 可以選，船票可以事前線上訂，但是記得船票要印紙本出來，登船要看 因為抵達時間太早，所以我們有先在附近吃早餐 早上 11:30 搭船前往薄荷島 約莫下午 1 點抵達薄荷島 可以直接當地隨意攔一台車嘟嘟車前往飯店 飯店 check-in 後就自由活動，今天比較悠閒 Day 4 # 詳細資訊 當天重點行程 跳島 Island hopping（巴里卡薩島浮潛 + 處女島 or Frencesco島） 當天住宿 續住 Alona Austria Resort 備註 我們在薄荷島兩天的行程，都是找當地的導遊 Lutz Gen 幫忙安排的，他英文很好口音很不重，很推薦（可以叫他 Jay） 早上 6 點旅館接人，到 Alona beach 登船（私人包船） 補充一下 Jay 沒有買船，所以當天陪同的船夫會是其他當地人，雖然行程 Jay 會事先幫忙喬好，但介意的人可以自己斟酌 出海追海豚 Dolphin watching 巴里卡薩島浮潛 Balicasag snorkeling 可以加價租面鏡蛙鞋，我們有租 浮潛完可以在巴里卡薩島吃早餐，不吃也可以，不過我們有吃，浮潛完很餓 處女島拍照玩水 Virgin island 如果遇到漲潮，處女島會被淹沒到只剩下個牌子，這時船夫會問你要不要去隔壁另一個 Francesco 島，可自由選擇 如果兩個島都想去也可以，不過就要加錢，我們有加，想說都來了 大概下午 1 點回到 Alona beach，看你玩的速度，反正私人包船沒人趕，船夫就是捨命陪君子陪你到他下班 抵達 Alona beach 可以打電話給 Jay，他會安排人來接你回旅館 抵達旅館後，下午晚上一樣自由活動 Day 5 # 詳細資訊 當天重點行程 巧克力山 + 眼鏡猴（Chocolate hills + Tarsier） 當天住宿 Henann Resort Alona Beach 備註 這天的行程也是找 Lutz Gen 幫忙安排的 早上 8 點旅館接人（私人包車） 巧克力山 Chocolate hills 有興趣也可以加玩一項自費行程：巧克力山越野車探險 ATV，我們有玩，比起開越野車探險本身，反而是越野車導遊的拍照技術更狂一點XD 看眼鏡猴 Tarsier 人造森林拍美照 Man made forest 5 分鐘可完成的景點，還不錯 Loboc 河竹筏游船+ buffet 午餐 Loboc river cruise + buffet lunch 菲律賓式午餐不期不待不受傷害，游船倒是滿有趣，駐船歌手很會唱 因為我們早上多玩了一個越野車，所以我們大概下午 1 點才抵達游船的入口，實際吃午餐的時間為下午 1 點 ~ 下午 2 點半，建議中間可以帶一些小零食以防你餓了 聖母大教堂 Baclayon church 教堂壁畫很酷！台灣滿少看到這類的景點，推 歃血為盟紀念碑 Blood compact 5 分鐘景點，普偏廢，趕時間可跳過 大概下午 4 點回到旅館，一樣看你玩的速度，Jay 會全程開車陪同 晚上一樣是自由活動，我們盡情的享受在 Henann 中XD Day 6 # 詳細資訊 當天重點行程 買伴手禮、搭飛機回台 當天住宿 x 備註 x 早上 9:30 旅館接人，前往薄荷島港口 Tagbilaran Port 車程約 40 分鐘，約莫 10:10 抵達港口 這個車一樣是請 Jay 幫忙訂的 早上 10:40 的船回宿霧市區 約莫中午 12:40 抵達宿霧市區 船票可以事前先訂，船班公司是 OceanJet，可以直接用 Klook 代訂，但是記得船票要印紙本出來，登船要看 下船後我們直接搭計程車去 SM City Cebu 買伴手禮 裡面很大，要什麼有什麼，不用怕買不到 搭計程車記得說魔法關鍵字 \u0026ldquo;By Meter\u0026rdquo;（跳錶計價的意思），終於不用再被當盤子靴 下午 4 點抵達宿霧機場，搭乘 星宇航空 週二航班，宿霧（下午 6:55 起飛） -\u0026gt; 桃園機場（晚上 9:45 降落）的班機 總結 # 以上就是我們這一次宿霧的 6 天 5 夜行程安排，祝大家都能盡興享受海島的陽光沙灘海🏝😎\n","permalink":"https://kucw.io/blog/2023/4/cebu-plan/","tags":null,"title":"2023 宿霧 6 天 5 夜自由行分享（逆時針走法）"},{"categories":["Other tech"],"contents":"你是否曾經覺得，明明已經工作了 2、3 年，但是學的東西感覺都不是特別扎實？好像自己平常都只是東學一點、西學一點，程式出錯了就上網查解法，但出去面試被面試官問到技術問題時，你明明記得你看過的，卻不知道為什麼就是答不上來技術細節\n造就這一切的原因，其實都可以歸類成：你沒有建立過自己的知識體系\n好記性不如爛筆頭 # 俗話說「好記性不如爛筆頭」，這句話充分的強調了記筆記的重要性，更何況我們生活在這個知識爆炸的時代，你就算擁有再好的記憶能力，也沒辦法保證能將每一點的知識點都記得牢固\n而且說實在的，要能夠閉著眼睛默寫一段程式出來真的是滿難的，而且其實沒什麼意義，往後你會接觸到更多程式語言、更多框架，所以基本上是不可能把每一行程式全部背下來的\n因此平常比較用不到的知識點，其實不需要特別去記住，只要記在你的筆記裡就行，一但要用上時，只要去你的筆記中查詢，就可以快速找到你曾經學習過的知識，將它應用到你現在遇到的問題上了\n不過有的人可能會說：那這樣跟上網查解法有什麼不同？這個不同之處還是滿大的\n首先網路上的文章參差不齊，你不一定馬上就能找到你需要的解法，就算現在有 ChatGPT 可以輔助使用好了，但是要把關鍵字下的讓 ChatGPT 看得懂也是一門學問\n另外，因為這些文章中所提到的知識點，也沒有被你真正的放進你自己的知識體系，所以當你下次遇到同樣的問題時，你很有可能又忘記怎麼解了，所以你又得重新再次上網查詢解法，被同樣的問題重複絆倒許多次\n所以為什麼經常有大神會鼓勵大家要多寫技術 blog，其實也是相同的道理，你有寫 blog 就表示你有技術輸出，要寫出一篇技術文章，你就得去深入整理你對那個知識點的理解，而透過這樣的方式，無形中就是在為你自己建立知識體系\n因此當你下次又遇到同樣的問題的時候，你就會有印象「對！我曾經遇到過這個問題！」，所以你就可以回頭查看當初所寫的那篇文章，快速的回想起來要怎麼解決這個問題了\n記筆記的工具有哪些？ # 假設你看到這裡，已經認真決定要開始透過寫筆記，去建立自己的知識體系的話，那截至目前為止，記筆記的工具到底有哪些選擇？\n通常第一次筆記的工程師，我會建議選擇最容易取得的平台，也就是 Medium 寫作平台、或是 Notion 這類協作工具\n推薦這兩個平台的原因是因為想盡量降低大家寫作的門檻，因為寫筆記這件事，至少你得先寫起來，再來才是思考哪款筆記工具最好使用，所以在你真的「寫起來」之前，任何屠龍寶刀對你來說都是無用的\n而 Medium 和 Notion 這兩款工具，不僅 UI 介面舒適，並且也沒什麼惱人的廣告，作為第一個上手的記筆記工具還是很適合的\n當你寫筆記越寫越上手、以至於你已經培養了這個習慣之後，接著就可以慢慢找尋適合自己的寫筆記工具了\n工程師我會推薦可以學著使用 Markdown 的格式來記錄筆記，Markdown 是在程式領域裡面滿廣泛使用的一種文字格式，多學習是絕對沒有壞處的，而 Markdown 編輯器我個人最推薦 Typora，雖然需要付一次性買斷的費用，但是我認為非常值得，推薦使用\n總結 # 說了這麼多，最關鍵的因素還是得付出行動，其實有時候自制力差只是行動力不足，就像是想看書的人根本不用上網查：我該怎麼自律才能專注的看書，而是直接拿起書來看就可以了，所以踏出第一步真的沒有這麼複雜\n在變強的道路上總是需要付出時間和精力的，希望大家都可以找到最有效率的方法一起變得更猛💪\n","permalink":"https://kucw.io/blog/2023/4/rename-iphone-photo-by-date-copy/","tags":null,"title":"工程師如何累積程式實力？"},{"categories":["Other tech"],"contents":"iPhone airdrop 到 Macbook 上的照片檔名為 IMG_0862.JPG，不利於照片整理，改命名成右邊這種 IMG_20220726_110204.JPG 格式會好整理很多\n想要大量修改圖片檔案名稱為右邊這種格式，可以透過 ExifTool 工具解決\nExifTool 使用教學（Mac 版） # 先到 ExifTool 官網下載安裝檔，並且安裝該 dmg 程式\n打開 Terminal，執行以下指令（最後一個參數值 ~/Downloads/image 為待轉換的照片資料夾，可自行更換路徑）\nexiftool -d \u0026#39;IMG_%Y%m%d_%H%M%S\u0026#39; \u0026#39;-Filename\u0026lt;${DateTimeOriginal}.%e\u0026#39; ~/Downloads/image 執行完成後，照片就會根據創建日期重新命名了，可喜可賀XD\nPS: 注意此指令會直接覆寫檔案檔名，不會備份照片，且此操作無法透過 Ctrl+Z 復原\n","permalink":"https://kucw.io/blog/2022/8/rename-iphone-photo-by-date/","tags":null,"title":"重新命名 iPhone 照片檔名為日期時間（Mac版）"},{"categories":["Other tech"],"contents":"想要提升學習效率，不管你是使用什麼工具，只有下面這三點最重要\n系統化的學習 循序漸進 大量練習 系統化的學習，讓你可以在腦中組織這些內容的關係圖，而不是像背單字一樣背一個忘一個\n循序漸進，讓你由淺入深慢慢拓展，沒有人一開始就跳過加減乘除去學微積分的對吧\n大量練習，讓這些知識成為你的肌肉記憶，就像呼吸一樣自然，右手寫左手答\n只要能夠掌握好這三點，不管是學習哪個領域，都可以加速你的學習效率\n什麼樣的學習管道最有效率？ # 要我說，對程式語言這個領域，剛入門的人，我建議是 「直接買付費的線上課程」 來學習\n很多人在初學程式語言的時候，都是先從網路上的免費資源開始學起，因為免費嘛！誰不愛\n但是你仔細觀察過可以發現，網路上的免費資源大部分都是比較碎片化的，因為這些文章，通常只會提到幾個知識點而已，那你這樣東學一點、西學一點，其實是很難打好程式的基礎的\n而線上課程就很好的解決這個問題\n你只要跟著課程的安排好好的上，一般是從最基本的程式語言語法開始教起，然後通常也會教你怎麼使用工具、有哪些快捷鍵可以按、怎麼樣 debug 最有效率\u0026hellip;之類的，這些東西都是真的要實際有實戰經驗的人才有辦法總結的，如果你是靠自己摸索，你可能只會停留在最基本的程式語法而已\n況且能夠開設線上課程、並且累積大量好評的老師，通常都是在各自的領域積累了好幾年的經驗、總結了許多想法，才能夠取得這樣的成績，你如果能跟著這些老師按部就班的學習，一定是比你一個人自己摸索著前進還要有效的多\n還是那句話「時間是最寶貴的資源」，你得把時間拿來創造價值，而不是拿來花在摸索上，所以最好的做法，就是直接買別人整理好的內容來學就對了\n除了線上課程之外，看書這種學習方式其實也是滿好的，因為寫書的作者在寫這本書時，目錄的安排也是循序漸進的從基礎開始教你，這其實就跟線上課程有點像，都是系統性的教你如何學程式語言\n只不過看書的門檻會稍微高一點，因為程式語言這種東西有點繁瑣，書其實沒有辦法真的把每一步過程寫在書上，這樣太瑣碎了，所以書通常是講一些比較抽象的概念，然後就會貼一段程式碼，再搭配上一些註解，讓你自己去體會這一段程式碼為什麼要這樣寫\n而相對比較起來，因為線上課程是影片，所以你就可以看著老師一行一行的把程式打出來，然後在自己的電腦上練習，更容易讓自己產生大量練習的機會\n所以書和線上課程，我會偏向選線上課程，用影片的形式更能清楚的呈現程式語言的教學，至於內容上，我倒是覺得沒有太大的差異，兩個都滿棒的\n所以要來排序一下的話，作為入門程式語言的學習方法，我最推薦的學習方式是上線上課程，第二名是看書，最不推的是網路上的文章，至於資策會的程式班雖然效率高，不過你要承擔的離職風險也高，所以這個我就不多做評論\n從現在開始改變 # 最近有人問我，非本科生半路轉職學程式，會不會找不到工作？\n現實是：本科生確實就是比非本科生有優勢，但是有優勢不代表非本科生就沒有機會\n如果宏觀一點來看的話，在台灣，唸到頂的台大資工，也只是能夠在台灣軟體業/半導體業佔盡優勢而已，出了國，比起別人滿手 CMU、MIT 的學歷，台大真的相對來說是還好而已\n但是在美國的 FAANG 大廠，也還是會有台灣工程師在裡面上班\n他們在學歷上有優勢嗎？相對沒有\n但是他們為什麼能錄取？因為想進這間公司，所以就會拼了命的學習\n所以我想說的是，優勢和錄取，不是佔絕對的比重，只要展現足夠的實力，大家都還是有入場券的\n所以別想那麼多啦吼，唸就對了！！！\n履歷就給他投下去，多面試面試練練手感，會更了解自己在市場上的價值～\n","permalink":"https://kucw.io/blog/2022/4/efficient-learning/","tags":null,"title":"自學程式，如何高效率的學習？"},{"categories":["Spring Boot"],"contents":"如果在 application.properties 直接寫上中文，則 Spring Boot 在使用 @Value 讀取時會產生中文亂碼\nname=小明 解決辦法： # 在 application.properties 裡面，將「中文」轉成「Unicode」，即可解決此問題（可使用此網頁進行轉換）\nname=\\u5c0f\\u660e ","permalink":"https://kucw.io/blog/2021/7/spring-chinese-properties/","tags":null,"title":"SpringBoot - 解決 application.properties 中文亂碼"},{"categories":["Intellij"],"contents":"IntelliJ 為 JetBrains 公司旗下的一個產品，因此若要使用 IntelliJ 的折扣碼，則需要同時也創建一個 JetBrains 帳號\n1. 如何使用折扣碼，取得免費的 IntelliJ 訂閱？ # 點擊此連結，進入到 JetBrains 專屬的折扣碼兌換網頁，並填寫以下資訊\n接著會收到一封信，點擊裡面的連結驗證信箱\n接著會跳轉到 JetBrains 官網，去註冊一個 JetBrains 帳號\n填寫完成之後，就可以發現在你的 JetBrains 帳號底下，新增了一筆 IntelliJ IDEA Ultimate 的訂閱，這樣折扣碼就成功的兌換完畢了～\n2. 如何在 IntelliJ 中綁定 JetBrains 帳號？ # 若尚未開啟過 IntelliJ，則可以在第一次啟動時，在 JB Account 的地方，直接填上剛剛註冊的 JetBrains 帳號密碼\n若已使用試用版開啟過 IntelliJ，則可以點選上方的 Help，然後選擇 Register，就可以開啟 IntelliJ 的 license 管理視窗\n接著點擊 Add New license，就可以在這邊填上剛剛註冊的 JetBrains 帳號密碼了\n","permalink":"https://kucw.io/blog/2021/4/intellij-coupon/","tags":null,"title":"IntelliJ - 折扣碼使用教學"},{"categories":["Java"],"contents":"在了解 Java 8 新增的時間系列之前，我們需要先了解時間相關的知識\n1. 首先是要有時區的概念 # 在台灣的時區是 GMT+8，而在英國的時區為 GMT+0，所以在同一瞬間，在英國看見的時間是 2020/06/29 14:00:00，但在台灣看見的時間卻會是 2020/06/29 22:00:00\n2. 要有 Timestamp 時間戳的概念 # 在電腦的世界裡，有一個東西叫做 Timestamp（時間戳），這個 Timestamp 是一個整數，代表著從 UTC 1970 年 1 月 1 日 0 時 0 分 0 秒 起至現在的總秒數，UTC 代表的是英國格林威治時間，也就是 GMT+0（可以簡單的認為 UTC = GMT+0）\n所以說假設現在你人在英國格林威治，然後你現在看手錶上的時間是 2020/06/29 14:00:00，則這個當下的 Timestamp的值就為 1593439200（代表從 1970/1/1 00:00:00 到現在經過了 1593439200 秒），然後假設同一個瞬間你的朋友在台灣，因為台灣的時區為 GMT+8，所以你朋友在台灣看手錶的時間會是 2020/06/29 22:00:00，但是你朋友當下的 Timestamp 也會是 1593439200\n也就是說，雖然你和你朋友手錶上呈現的時間不一樣，但是你們兩個的 Timestamp 會是一模一樣的，因為 Timestamp 是唯一表示著 UTC 1970/1/1 00:00:00 起至現在的總秒數\n而在Java中，可以使用 System.currentTimeMillis()，取得當前的 Timestamp\n為什麼 Java 中舊版的 Date 不好 ? # 因為 Date 硬是把 時區 和 Timestamp 這兩個概念混合在一起了，這就是為什麼 Date 不好的關係\n通常我們 new 一個 Date object時，都是使用 Date date = new Date()，而這個 Constructor 其實是會去取得當前的 Timestamp，然後把 Timestamp 存放在 Date 內部的 fastTime 變量裡，所以 Date 內部存放的，實際上是 Timestamp 的值\npublic class Date { private transient long fastTime; //存放timestamp的值 public Date() { this(System.currentTimeMillis()); } public Date(long date) { fastTime = date; } } 雖然 Date 內部只存放了 Timestamp 的值，但是 Date 卻在 toString() 時，會去取得當前程式運行的時區，然後再把 Timestamp 換算成當地時區的時間印出來\npublic class MyTest { public static void main(String[] args) { // Date 內部明明是只存放 Timestamp 的值 1593439200，也就是 UTC 2020/06/29 14:00:00 // (因為 Date 的構造方法要輸入 ms 毫秒，所以要把 Timestamp 乘以 1000) Date date = new Date(1593439200L * 1000); // 但是卻會在 toString() 方法裡面再去取得當前程式運行的時區(我的時區是GMT+8) // 然後把 Timestamp 的值轉換成該時區的時間 // 所以這裡會輸出 Mon Jun 29 22:00:00 CST 2020 System.out.println(date); } } 所以 Java 為了改善 Date 混合 時區 和 Timestamp 的問題，在 Java 8 時提出了新的時間系列類，將 Timestamp 和時間分成兩組\nTimestamp組 : Instant 時間組 : LocalDate、LocalTime、LocalDateTime、ZonedDateTime Instant 用法 # 在 Java 8 新增的這一堆時間系列裡面，每個類都有工廠方法可以使用，可以直接用這些工廠方法來產生出一個新的 object\n所以我們就可以直接使用 Instant.of() 去創建一個 instant object\npublic class MyTest { public static void main(String[] args) { // 用當下的 Timestamp 來創建in1 Instant in1 = Instant.now(); // 自定義 Timestamp Instant in2 = Instant.ofEpochSecond(1593439200L); } } LocalDate、LocalTime、LocalDateTime 用法 # LocalDate : 只存日期 (2020/06/29)\n和Date不同，LocalDate內部用了三個Integer變量 year、month、day，分別存放日期的值，徹底將時間和Timestamp的概念區分開來 LocalTime : 只存時間 (14:00:00)\n也是用了三個Integer變量 hour、minutes、second來分別存放時間的值 LocalDateTime : 存了日期和時間 (2020/06/29 14:00:00)\nLocalDateTime內部其實用一個LocalDate變量存放日期，用另一個LocalTime變量存放時間，reuse的極致！ Local 這一系列的時間類型，都不帶有時區的資訊，所以說當你new一個LocalDateTime出來之後，不管你是在台灣運行程式還是在英國運行程式，輸出的值都一樣\npublic class MyTest { public static void main(String[] args) { // LocalDate LocalDate date = LocalDate.of(2020, 6, 29); // 創建一個 2020/06/29的LocalDate LocalDate date2 = LocalDate.parse(\u0026#34;2020-06-29\u0026#34;); // parse 字串成 LocalDate // LocalTime LocalTime time = LocalTime.of(14, 0, 0); // 創建一個 14:00:00 的 LocalTime LocalTime time2 = LocalTime.parse(\u0026#34;14:00:00\u0026#34;); // parse 字串成 LocalTime // LocalDateTime // 創建一個 2020/06/29 14:00:00 的 LocalDateTime LocalDateTime dateTime = LocalDateTime.of(2020, 6, 29, 14, 0, 0); // 或是也可以用 LocalDate 和 LocalTime 組合創建 LocalDateTime dateTime2 = LocalDateTime.of(date, time); // Local 系列可以和同樣也是 Java8 新增的 DateTimeFormatter 一起使用，讓時間 input/output 的更格式化 // Java8 新增的 DateTimeFormatter 和 joda-time 中的 DateTimeFormatter 名字一樣，不要 import 錯了 DateTimeFormatter DTF = DateTimeFormatter.ofPattern(\u0026#34;yyyy-MM-dd HH:mm:ss\u0026#34;); // 用DTF的格式來parse字串成LocalDateTime LocalDateTime dateTime3 = LocalDateTime.parse(\u0026#34;2020-06-29 14:00:00\u0026#34;, DTF); // 將dateTime2用DTF的形式輸出 String format = DTF.format(dateTime2); } } ZonedDateTime 用法 # ZonedDateTime 是 LocalDateTime 的進化版，增加了時區的概念，會自動幫我們計算時區之間的時差\npublic class MyTest { public static void main(String[] args) { DateTimeFormatter DTF = DateTimeFormatter.ofPattern(\u0026#34;yyyy-MM-dd HH:mm:ss\u0026#34;); LocalDateTime leaving = LocalDateTime.of(2020, 6, 29, 19, 30); // 將原本的 LocalDateTime 轉成 ZonedDateTime // 因為加上了時區的概念，所以現在就變成了 上海 的 2020/06/29 19:30:00 ZoneId leavingZone = ZoneId.of(\u0026#34;Asia/Shanghai\u0026#34;); ZonedDateTime departure = ZonedDateTime.of(leaving, leavingZone); System.out.println(\u0026#34;離開上海的時間：\u0026#34; + departure.format(DTF)); // 把時區轉成 東京 時區，並且加上飛機的飛行時間 30 分鐘 ZoneId arrivingZone = ZoneId.of(\u0026#34;Asia/Tokyo\u0026#34;); ZonedDateTime arrival = departure.withZoneSameInstant(arrivingZone).plusMinutes(30); System.out.println(\u0026#34;抵達東京的時間：\u0026#34; + arrival.format(DTF)); } } 離開上海的時間 2020-06-29 19:30:00 // 上海 的當地時間 抵達東京的時間 2020-06-29 21:00:00 // 東京 的當地時間 // 縱使飛機只飛 30 分鐘，但是因為上海和東京的時區不同(東京快一小時)，所以抵達東京的時間實際上會變成一個半小時後 // 而這中間的時差計算，就是ZonedDateTime幫我們做的 ","permalink":"https://kucw.io/blog/2020/6/java-date/","tags":null,"title":"Java - Java 8 新增的時間系列用法"},{"categories":["Spring Boot"],"contents":"ObjectMapper 是一款非常好用的 json 轉換工具，可以幫助我們完成 json 和 Java 的 Object 的互相轉換\n什麼是 Serialize 和 Deserialize？ # Serialize : 將 Java Object 轉換成 json Deserialize : 將 json 轉換成 Java Object 在 Spring Boot 裡使用 ObjectMapper # ObjectMapper 是由 Jackson library 所提供的一個功能，所以只要在 maven 中加入 spring-boot-starter-web 的 dependency 就可以了\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; Json 和 Java Object、List、Map 的互轉 # 先定義一個 User class\npublic class User { private int id; private String name; // 省略constructor, getter, setter } 使用 ObjectMapper 完成 json 和 Java Object、List、Map 之間的互轉\nimport java.util.*; import com.fasterxml.jackson.core.type.TypeReference; import com.fasterxml.jackson.databind.ObjectMapper; public class MainTest { public static void main(String[] args) throws Exception { ObjectMapper objectMapper = new ObjectMapper(); // User Object 轉 json User user1 = new User(123, \u0026#34;John\u0026#34;); String json = objectMapper.writeValueAsString(user1); // json 轉 User Object User user2 = objectMapper.readValue(json, User.class); // List\u0026lt;User\u0026gt; 轉 json List\u0026lt;User\u0026gt; ulist = new ArrayList\u0026lt;\u0026gt;(); User user4 = new User(123, \u0026#34;John\u0026#34;); ulist.add(user4); String ujson = objectMapper.writeValueAsString(ulist); // json 轉 List\u0026lt;User\u0026gt; List\u0026lt;User\u0026gt; urlist = objectMapper.readValue(ujson, new TypeReference\u0026lt;List\u0026lt;User\u0026gt;\u0026gt;() {}); // Map\u0026lt;String, User\u0026gt; 轉 json HashMap\u0026lt;String, User\u0026gt; umap = new HashMap\u0026lt;\u0026gt;(); User user3 = new User(123, \u0026#34;John\u0026#34;); umap.put(\u0026#34;John\u0026#34;, user3); String mjson2 = objectMapper.writeValueAsString(umap); // json 轉 Map\u0026lt;String, User\u0026gt; Map\u0026lt;String, User\u0026gt; urMap = objectMapper.readValue(mjson2, new TypeReference\u0026lt;HashMap\u0026lt;String, User\u0026gt;\u0026gt;() {}); } } 如果想了解更多 Spring Boot 的用法，也歡迎參考我開設的線上課程 Java 工程師必備！Spring Boot 零基礎入門 （輸入折扣碼「HH202601KU」即可享 85 折優惠）。\n","permalink":"https://kucw.io/blog/2020/6/java-jackson/","tags":null,"title":"SpringBoot - 使用 ObjectMapper 完成 json 和 Java Object 互相轉換"},{"categories":["Java"],"contents":"Lombok 是一個 Java library，可以透過簡單的寫法自動生成 Java 的 code，像是 setter、getter、logger\u0026hellip;等，目的在消除冗長的 code 和提高開發效率\n例如當你在 Class 上加上了一個 @Getter 和 @Setter 之後，Lombok 就會自動幫你產生 getter 和 setter 出來，所以你就不用再自己去寫這些煩人的程式啦！\n之所以加個 @Getter 就可以幫我們自動生成所有變數的 getter，是因為 Lombok 參與了 Java 在 compile 階段生成 .class 檔的過程，Lombok 會幫我們自動寫一堆 getter，然後塞進 .class 檔，所以真正被編譯出來的 User.class 檔案，是包含完整的 getter 的\n所以簡單的說，Lombok 可以算是一種語法糖，只是在幫我們增進開發效率而已，實際上所產生出來的.class檔仍然是完全正常的！\n安裝 Lombok # 要在 project 中使用 Lombok，除了要在 maven 中加入 Lombok dependency，還要安裝 Intellij 的 Lombok 插件\n1. 加入 maven dependency # \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.projectlombok\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;lombok\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.18.18\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 2. 在 Intellij 中安裝 Lombok 插件 # 補充：我使用的 Intellij 版本是 2019.3.3，可能會因為版本差異導致安裝方式有改變\n先點選左上角 Intellij IDEA -\u0026gt; Preferences\n然後點擊左邊的 Plugins，再點擊上面的 Marketplace tab，然後就可以在搜尋欄中輸入lombok，並且找到 Lombok 插件並安裝它\n補充：為什麼需要特地安裝 Intellij 的 Lombok 插件？ # 其實在 maven 加入 Lombok dependency 之後，使用 mvn clean package 就可以正常 build 過，在 Intellij 中點擊綠色按鈕也可以運行程式\n之所以還要特地安裝 Intellij 的 Lombok 插件，是因為如果不安裝 Lombok 插件的話，Intellij 就會沒辦法自動提示出 Lombok 產生的方法，所以就會發生你的 code 一片紅，但是運行卻可以通過的奇妙現象\n像是下面這段 code 中，因為對 Intellij 來說，code 裡並不存在 setter，所以沒辦法自動提示 setId()、setName() 等方法，但是又因為我們在 maven 中有加入 Lombok dependency，所以點擊第 13 行的綠色箭頭運行程式的話，是可以正常運行成功的\n所以 Lombok 算是侵入性很高的一個 library，只要團隊中有一個人用 Lombok 開發，那麼所有的人都必須得安裝 Lombok 插件才行，這樣才不會發生在 Intellij 中一打開 project 時，整片都是痛苦的紅字\nLombok 用法介紹 # Lombok 官網提供了許多好用的註解，但是「勁酒雖好，可不能貪杯」，你用了越多 Lombok 的進階用法，會讓整個團隊的學習曲線上升，反而會造成反效果，所以在此處只解釋最常見、並且最重要的註解使用方式，其他較少見的用法就不會涵蓋在此文章中\n此篇文章會介紹的 Lombok 方法為：\n@Getter/@Setter @ToString @EqualsAndHashCode @NoArgsConstructor、@AllArgsConstructor、@RequiredArgsConstructor @Data（最常用） @Value @Builder（常用） @Slf4j 1. @Getter/@Setter # 自動產生 getter/setter\n2. @ToString # 自動 override toString() 方法，會輸出所有變數的值\n3. @EqualsAndHashCode # 自動生成 equals(Object other) 和 hashcode() 方法，包括所有的「非靜態變數」和「非 transient 變數」\n如果某些變數不想要加進判斷，可以透過 exclude 排除（或是也可以反過來，使用 of 指定只要輸出某些字段）\n補充： 為什麼只有一個合在一起的註解 @EqualsAndHashCode，而不是兩個分開的註解 @Equals 和 @HashCode？\n因為在 Java 中有規定，當兩個 object equals 時，他們的 hashcode 一定要相同，反之，當 hashcode 相同時，object 不一定 equals。所以 equals 和 hashcode 要一起 implement，免得發生違反 Java 規定的情形發生\n4. @NoArgsConstructor、@AllArgsConstructor、@RequiredArgsConstructor # 這三個很像，都是在自動生成該 Class 的 constructor，差別只是在「生成的 constructor 的參數不一樣」而已\n@NoArgsConstructor : 生成一個沒有參數的 constructor\n@AllArgsConstructor : 生成一個包含所有參數的 constructor\n補充： 這裡要注意一個 Java 中的實作重點，當我們沒有指定 constructor 時，Java compiler 會幫我們自動生成一個沒有任何參數的 constructor 給該 Class，但是如果我們自己寫了 constructor 之後，Java 就不會自動幫我們補上那個無參數的 constructor 了！\n然而很多地方（像是 Spring Data JPA），都會要求每個 Class 一定要有一個無參數的 constructor，所以你在加上 @AllArgsConstructor 時，一定要記得補上 @NoArgsConstrcutor，不然就會出現各種意外的報錯，一定要記得！！！\n@AllArgsConstructor @NoArgsConstructor public class User { private Integer id; private String name; } @RequiredArgsConstructor : 生成一個包含「特定參數」的 constructor，特定參數指的是「那些有加上 final 修飾詞的變數們」\n補充一下，如果所有的變數都是正常的（即是都沒有用 final 修飾的話），那就會生成一個沒有任何參數的 constructor\n5. @Data # 懶人包，只要加了 @Data，等於同時加了以下註解：\n@Getter/@Setter @ToString @EqualsAndHashCode @RequiredArgsConstructor @Data 是使用頻率最高的 Lombok 用法，通常 @Data 會加在一個值可以被更新的 Object 上，像是日常使用的 DTO 們、或是 JPA 裡的 Entity 們，就很適合加上 @Data，也就是 @Data for mutable class（@Data for 可變動的 Class）\n6. @Value # 也是懶人包，但是他會把所有的變數都設成 final，其他的就跟 @Data 一樣，等於同時加了以下註解：\n@Getter（注意沒有 @Setter） @ToString @EqualsAndHashCode @RequiredArgsConstructor 上面那個 @Data 適合用在 POJO 或 DTO 上，而這個 @Value，則是適合加在「值不希望被改變的 Class 上」\n所以像是某個 Class 的值當創建後就不希望被更改，只希望我們讀它而已，這時候就適合加上 @Value，也就是 @Value for immutable class（@Value for 不可變動的 Class）\n另外在使用 @Value 時也要留意一下，此 Lombok 註解 @Value 和另一個 Spring 的註解 @Value 撞名，在 import 時要小心不要 import 錯\n7. @Builder # 自動生成流式 set 值寫法，從此之後再也不用寫一堆 setter 了！\n不過要特別注意，雖然只要在 Class 上加上 @Builder，我們就能夠用流式寫法快速設定 Object 的值，但是還是要記得實作 setter 方法，不能省略（因為 Spring 框架中有很多地方都會用到 Object 的 getter/setter，對他們取值/賦值）\n所以在使用上，通常是 @Data 和 @Builder 會一起使用，即是將他們同時加在同個 Class 上，這樣既方便我們流式寫 code，也方便框架做事\n@Data @Builder public class User { private Integer id; private String name; } 8. @Slf4j # 自動生成該 Class 的 log 變數，要打日誌就可以直接打，不用再手動 new 一個 log 變數出來了\n除了 @Slf4j 之外，Lombok 也有提供其他日誌框架的註解可以使用，像是 @Log、@Log4j\u0026hellip;等等，他們都是用來創建一個 log 變數，只是底層使用的日誌 library 不一樣而已\n@Log // 等同於下方 log 語句 private static final java.util.logging.Logger log = java.util.logging.Logger.getLogger(LogExample.class.getName()); @Log4j // 等同於下方 log 語句 private static final org.apache.log4j.Logger log = org.apache.log4j.Logger.getLogger(LogExample.class); 而因為 Spring Boot 預設使用的日誌框架為 slf4j + logback，所以最常用的註解為 @Slf4j，不需要做什麼額外的設定，直接使用就可以了\n結語 # 這篇文章介紹了 Lombok 中的好用方法，替我們節省了開發 Spring Boot 時所撰寫的冗長的程式\n如果你對後端技術有興趣的話，也歡迎免費訂閱《古古的後端筆記》電子報，每週二為你送上一篇後端技術分享\n","permalink":"https://kucw.io/blog/2020/3/java-lombok/","tags":null,"title":"Java - 五分鐘學會 Lombok 用法"},{"categories":["Spring Boot"],"contents":"Mockito就是一種 Java mock 框架，他主要是用來做 mock 測試的，他可以模擬任何 Spring 管理的 bean、模擬方法的返回值、模擬拋出異常\u0026hellip;等，在了解 Mockito 的具體用法之前，得先了解什麼是 mock 測試\n1. 什麼是 mock 測試？ # mock 測試就是在測試過程中，創建一個假的對象，避免你為了測試一個方法，卻要自行構建整個 bean 的 dependency chain\n像是以下這張圖，類 A 需要調用類 B 和類 C，而類 B 和類 C 又需要調用其他類如 D、E、F 等，假設類 D 是一個外部服務，那就會很難測，因為你的返回結果會直接的受外部服務影響，導致你的單元測試可能今天會過、但明天就過不了了\n而當我們引入 mock 測試時，就可以創建一個假的對象，替換掉真實的 bean B 和 C，這樣在調用B、C的方法時，實際上就會去調用這個假的 mock 對象的方法，而我們就可以自己設定這個 mock 對象的參數和期望結果，讓我們可以專注在測試當前的類 A，而不會受到其他的外部服務影響，這樣測試效率就能提高很多\n2. Mockito 簡介 # 說完了 mock 測試的概念，接下來我們進入到今天的主題，Mockito\nMockito 是一種 Java mock 框架，他主要就是用來做 mock 測試的，他可以模擬任何 Spring 管理的 bean、模擬方法的返回值、模擬拋出異常\u0026hellip;等，他同時也會記錄調用這些模擬方法的參數、調用順序，從而可以校驗出這個 mock 對象是否有被正確的順序調用，以及按照期望的參數被調用\n像是 Mockito 可以在單元測試中模擬一個 service 返回的數據，而不會真正去調用該 service，這就是上面提到的 mock 測試精神，也就是通過模擬一個假的 service 對象，來快速的測試當前我想要測試的類\n目前在 Java 中主流的 mock 測試工具有 Mockito、JMock、EasyMock..等，而 SpringBoot 目前內建的是 Mockito 框架\n題外話說一下，Mockito 是命名自一種調酒莫吉托（Mojito），外國人也愛玩諧音梗。。。\n3. 在 SpringBoot 單元測試中使用 Mockito # 首先在 pom.xml 下新增 spring-boot-starter-test 依賴，該依賴內就有包含了 JUnit、Mockito\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-test\u0026lt;/artifactId\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; 先寫好一個 UserService，他裡面有兩個方法 getUserById() 和 insertUser()，而他們會分別去再去調用 UserDao 這個 bean的 getUserById() 和 insertUser() 方法\n@Component public class UserService { @Autowired private UserDao userDao; public User getUserById(Integer id) { return userDao.getUserById(id); } public Integer insertUser(User user) { return userDao.insertUser(user); } } User model 的定義如下\npublic class User { private Integer id; private String name; //省略 getter/setter } 如果這時候我們先不使用 Mockito 模擬一個假的 userDao bean，而是真的去 call 一個正常的 Spring bean 的 userDao 的話，測試類寫法如下。其實就是很普通的注入 userService bean，然後去調用他的方法，而他會再去 call userDao 取得 DB 的 data，然後我們再對返回結果做 assert 檢查\n@RunWith(SpringRunner.class) @SpringBootTest public class UserServiceTest { //先普通的注入一個userService bean @Autowired private UserService userService; @Test public void getUserById() throws Exception { //普通的使用userService，他裡面會再去call userDao取得DB的data User user = userService.getUserById(1); //檢查結果 Assert.assertNotNull(user); Assert.assertEquals(user.getId(), new Integer(1)); Assert.assertEquals(user.getName(), \u0026#34;John\u0026#34;); } } 但是如果 userDao 還沒寫好，又想先測 userService 的話，就需要使用 Mockito 去模擬一個假的 userDao 出來\n使用方法是在 userDao 上加上一個 @MockBean 注解，當 userDao 被加上這個注解之後，表示 Mockito 會幫我們創建一個假的 mock 對象，替換掉 Spring 中已存在的那個真實的 userDao bean，也就是說，注入進 userService 的 userDao bean，已經被我們替換成假的 mock 對象了，所以當我們再次調用 userService 的方法時，會去調用的實際上是 mock userDao bean 的方法，而不是真實的 userDao bean\n當我們創建了一個假的 userDao 後，我們需要為這個 mock userDao 自定義方法的返回值，這裡有一個公式用法，下面這段 code 的意思為，當調用了某個 mock 對象的方法時，就回傳我們想要的自定義結果\nMockito.when( 對象.方法名() ).thenReturn( 自定義結果 ) 使用 Mockito 模擬 bean 的單元測試具體實例如下\n@RunWith(SpringRunner.class) @SpringBootTest public class UserServiceTest { @Autowired private UserService userService; @MockBean private UserDao userDao; @Test public void getUserById() throws Exception { // 定義當調用mock userDao的getUserById()方法，並且參數為3時，就返回id為200、name為I\u0026#39;m mock3的user對象 Mockito.when(userDao.getUserById(3)).thenReturn(new User(200, \u0026#34;I\u0026#39;m mock 3\u0026#34;)); // 返回的會是名字為I\u0026#39;m mock 3的user對象 User user = userService.getUserById(3); Assert.assertNotNull(user); Assert.assertEquals(user.getId(), new Integer(200)); Assert.assertEquals(user.getName(), \u0026#34;I\u0026#39;m mock 3\u0026#34;); } } Mockito 除了最基本的 Mockito.when( 對象.方法名() ).thenReturn( 自定義結果 )，還提供了其他用法讓我們使用\nthenReturn 系列方法 # 當使用任何整數值調用 userService 的 getUserById() 方法時，就回傳一個名字為 I\u0026rsquo;m mock3 的 user 對象\nMockito.when(userService.getUserById(Mockito.anyInt())).thenReturn(new User(3, \u0026#34;I\u0026#39;m mock\u0026#34;)); User user1 = userService.getUserById(3); // 回傳的user的名字為I\u0026#39;m mock User user2 = userService.getUserById(200); // 回傳的user的名字也為I\u0026#39;m mock 限制只有當參數的數字是 3 時，才會回傳名字為 I\u0026rsquo;m mock 3 的 user 對象\nMockito.when(userService.getUserById(3)).thenReturn(new User(3, \u0026#34;I\u0026#39;m mock\u0026#34;)); User user1 = userService.getUserById(3); // 回傳的user的名字為I\u0026#39;m mock User user2 = userService.getUserById(200); // 回傳的user為null 當調用 userService 的 insertUser() 方法時，不管傳進來的 user 是什麼，都回傳 100\nMockito.when(userService.insertUser(Mockito.any(User.class))).thenReturn(100); Integer i = userService.insertUser(new User()); //會返回100 thenThrow 系列方法 # 當調用 userService 的 getUserById() 時的參數是 9 時，拋出一個 RuntimeException\nMockito.when(userService.getUserById(9)).thenThrow(new RuntimeException(\u0026#34;mock throw exception\u0026#34;)); User user = userService.getUserById(9); //會拋出一個RuntimeException 如果方法沒有返回值的話（即是方法定義為public void myMethod() {...}），要改用 doThrow() 拋出 Exception\nMockito.doThrow(new RuntimeException(\u0026#34;mock throw exception\u0026#34;)).when(userService).print(); userService.print(); //會拋出一個RuntimeException verify 系列方法 # 檢查調用 userService 的 getUserById()、且參數為3的次數是否為1次\nMockito.verify(userService, Mockito.times(1)).getUserById(Mockito.eq(3)); 驗證調用順序，驗證 userService 是否先調用 getUserById() 兩次，並且第一次的參數是 3、第二次的參數是 5，然後才調用insertUser() 方法\nInOrder inOrder = Mockito.inOrder(userService); inOrder.verify(userService).getUserById(3); inOrder.verify(userService).getUserById(5); inOrder.verify(userService).insertUser(Mockito.any(User.class)); 4. Mockito 的限制 # 上述就是 Mockito 的 mock 對象使用方法，不過當使用 Mockito 在 mock 對象時，有一些限制需要遵守\n不能 mock 靜態方法 不能 mock private 方法 不能 mock final class 因此在寫 code 時，需要做良好的功能拆分，才能夠使用 Mockito 的 mock 技術，幫助我們降低測試時 bean 的 dependency\n5. 總結 # Mockito 是一個非常強大的框架，可以在執行單元測試時幫助我們模擬一個 bean，提高單元測試的穩定性，並且大家可以嘗試在寫 code 時，從 mock 測試的角度來寫，更能夠寫出功能切分良好的 code modules\n像是如果有把專門和外部 service 溝通的 code 抽出來成一個 bean，在進行單元測試時，只要透過 Mockito 更換掉那個 bean 就行了\n如果想了解更多 Spring Boot 的用法，也歡迎參考我開設的線上課程 Java 工程師必備！Spring Boot 零基礎入門 （輸入折扣碼「HH202601KU」即可享 85 折優惠）。\n","permalink":"https://kucw.io/blog/2020/2/spring-unit-test-mockito/","tags":null,"title":"SpringBoot - 單元測試工具 Mockito"},{"categories":["Intellij"],"contents":" 1. 什麼是 Debug 模式？ # 還記得以前不會使用 IntelliJ 的 debug 功能時，想要看某個 Variable 的值，都是在那行 code 的下面一行加上 System.out.println()，然後運行程式，把值 print 出來，如果要看另一個 Variable，我就再加一行 System.out.println()，所以到後來我的 code 就會長的像下圖這樣\npublic User getMaleUser() { List\u0026lt;User\u0026gt; userList = userDao.getUserList(); System.out.println(userList); // print userList，看一下userList裡面的內容長怎樣 // 從userList中取出男生，然後回傳 User resultUser; for (User user : userList) { if (user.getGender() == \u0026#34;男\u0026#34;) { resultUser = user; } } System.out.println(resultUser); // 再print resultUser，確認一下回傳的user到底是哪一個 return resultUser; } 可想而知，這樣做的開發效率是非常差的，每多看一個 variable 就要多增加一行 System.out.println()，而且每次改了之後，都要重新運行程式，讓程式再 print 出一次數據，我想想都覺得痛苦，難道 IntelliJ 就沒有一個能夠快速反應出現在這個 variable 的值是什麼的功能嗎？\n事實上，IntelliJ 是有提供的！當我們在運行程式時，改成使用 Debug 模式 運行就可以了！\n2. IntelliJ 的 Debug 模式 # 使用 IntelliJ 的 Debug 模式來運行程式的好處\n可以一行行的運行 code 可以馬上知道運行中的 variable 的值，甚至去改變它的值，從此不用再使用System.out.println()去 print variable 了 在 IntelliJ 的 Debug 模式中，有幾個比較重要的功能面板如下\n開啟 Debug 模式的開關，通常在寫 code 時都會改用 Debug 模式來跑程式，已經很少使用旁邊的 Run 模式了 設置 break point，在左邊行號欄單擊左鍵就可以設置 break point，再點一下則可以取消此 break point，能夠設置 break point 是 Debug 模式和 Run 模式最大的區別，而設置 break point 可以幫助我們一行行的運行 code，這也是為什麼推薦使用 Debug 模式而不是使用 Run 模式 Debug 按鈕，debug 的主要功能就對應著這幾個按鈕 Service 按紐，和 break point 有關係，主要搭配著 3. Debug 按鈕 一起使用 Variables，可以查看當前 break point 之前的 variable 的值 3. Debug 基本用法 # IntelliJ 的 Debug 模式基本用法主要對應著上述 3 和 4 的兩組按鈕\nDebug 按鈕，從左到右共 8 個按鈕 # Show Execution Point : 如果你在看其它行或其它頁面，點擊這個按鈕可跳轉到當前代碼執行的地方 Step Over : 一行一行的往下執行 code，如果這一行裡面有 call 其他方法的話，不會進入那些方法 Step Into : 如果當前行有 call 其他方法，可以進入該方法內部，一般用於進入自定義方法內，不會進入 library 的方法 Force Step Into : 強制進入方法內部，能進入任何方法，查看底層 source code 的時候可以用這個進入 library 的方法 Step Out : 退出方法，從進入的方法內退出到方法調用處，此時方法已執行完畢，只是還沒有完成賦值 Drop Frame : 回退 break point，很少用到 Run to Cursor : 運行到目前滑鼠點擊的位置，你可以將滑鼠點擊到你需要查看的那一行，然後使用這個功能，code 就會運行至那一行，而不需要在那一行上打 break point（前提是已經進入了 Debug 模式，就是已經停在某個 break point 上了） Evaluate Expression : 計算表達式，後面第五部分詳細說明 Service 按鈕，從上到下共 7 個按鈕 # Rerun : 重新運行程式，他會關閉程式後再重新啓動一次，不過很少用到，通常都會直接關掉，再手動開啟一次 Update \u0026rsquo;tech\u0026rsquo; application : 更新程式，就是執行當初定義的 update 選項，當 Debug 模式啟動後，再次點擊 debug 按鈕也會跳出此選項 Resume Program : 繼續執行程序，例如在第 20 行和 25 行有兩個 break point，而當前運行至第 20 行，按一下，則運行到下一個 break point（即第 25 行），再按一下，則運行完整個流程，因爲後面已經沒有 break point 了 Pause Program : 暫停程式，很少用，不是很重要 Stop : 連續按兩下關閉程式，有時候你會發現關閉程式再啓動時，說 port 被佔用，這是因爲沒完全關閉程式的原因 View Breakpoints : 查看所有 break point，後面第七部分詳細說明 Mute Breakpoints : 將所有 break point 變爲灰色並使它們失效，按 Resume Program 那個鍵（也就是第三個按鍵）可以直接運行完程式（因為所有打的 break point 都被設置為無效了），再次點擊這個 Mute Breakpoints 按鍵可以使所有無效 break point 變爲紅色有效 4. Debug 模式下的 variable 查看 # 在 Debug 過程中，跟蹤查看 variable 的值是非常必要的，有幾個方式可以查看當前 variable 的值\n參數所在行後面會顯示當前 variable 的值 滑鼠停到參數上，會顯示當前 variable 的資訊，點擊打開可以看到該 variable 的詳情 在下方的 Variables 窗口查看，這裡會顯示當前方法的所有 variable 的詳情 5. 計算表達式 Evaluate Expression # 在前面第三部分有提到一個計算表達式 Evaluation Expression 按鈕，可以使用這個按鈕在 debug 過程中計算某個表達式的值，或是直接改變某個 variable 的值，而不用再去重新改 code 然後再重啟程式\n假設在 Debug 模式下，想要快速比較當前 list.get(0).equals(\u0026quot;first\u0026quot;) 的結果，可以不用改 code，直接在計算表達式裡面運算，讓 IntelliJ 快速幫助我們計算出這個函式會回傳的值，非常方便，像是下面的 3. Result 部分，得到的就是使用計算表達式運行 list.get(0).equals(\u0026quot;first\u0026quot;) 的結果\n或是說想要更改 variable 的值的話，也可以透過計算表達式來改變，像是下面這個例子，對 code 來說，list 裡只會有 first、second 兩個字串，但是因為我們在計算表達式裡使用了 list.add(\u0026quot;third\u0026quot;) 向 list 插入一個新的 Object third，所以下方 Variables 變量區才會顯示 list 裡面有三個字串 first、second、third\n題外話說一下，如果只是單純想要改變 variable 的值的話，還有另一種方法，不用透過計算表達式那麼麻煩。只要在 Variables 在直接對想要改的 variable 上點右鍵，使用 setValue 也能重新改變此 variable 的值的\n6. Break point 條件設置 # 有的時候在 for loop 一個集合或是數組的時候，可能只想要看 for loop 裡面的某個 i 值超過多少以上的 variable 情況，這時候就可以透過設置 break point 條件來達成，也就是說，只有在滿足了 break point 的條件時，才會停在該 break point 上，不然就會直接忽略此 break point\n對 break point 點擊右鍵可以設置 break point 條件，像是下圖是設置成在 i=3 時才停下（如果沒有設置 break point 條件的話，則每進一次for loop，每個 i 都會停一次 break point）\n7. 查看所有的 break point # 在左下方點擊 View Breakpoints 可以查看目前已經設置的所有 break point，有時候自己 break point 打多了很容易忘記打在哪，可以透過這個功能知道自己都在哪些地方打了 break point，取消勾選可以使此 break point 失效\n8. 設置異常 break point # 當設置異常 break point時，在程式中出現需要攔截的異常時，會自動定位到 throw exception 的那行\n設置方式一樣是先點擊 view breakpoints，之後點擊 + 號添加異常 break point，這邊添加了一個 NullPointerException\n當程式噴出 NullPointerException 時，IntelliJ 就會自動跳到拋出 NullPointerException 的那一行，省的我們再去定位問題點在哪，非常方便\n9. 總結 # 本文列出了 IntelliJ 中 Debug 模式的實用用法，讓你在開發路上更順暢\n不過要注意一點，因為 Debug 時會讓整個程式停在你打的 break point 上，所以千萬不能夠在 production 下 debug，只能夠在測試環境中進行 debug\n有關 IntelliJ 中如何設置 remote debug，請參考我之前寫的這篇文章：IntelliJ - Remote Debug\n","permalink":"https://kucw.io/blog/2020/2/intellij-how-to-debug/","tags":null,"title":"IntelliJ - Debug 的使用方法"},{"categories":["Intellij"],"contents":"如果你想要 debug 某個 run 在 server 上的 SpringBoot 或是 Spring project 時，必須先配置好 remote debug，才能夠在本地打 break point，然後透過 remote debug 傳到 server 上，去對遠端 server 上的 project debug\n首先先運行起來在 server 上的 project # 如果是 SpringBoot project，需要在執行 build 出來的 jar 檔時，帶上 jvm 啟動參數\njava -agentlib:jdwp=transport=dt_socket,address=18090,server=y,suspend=n -jar myservice-0.0.1-SNAPSHOT.jar 如果是傳統的 Spring + tomcat war 檔 project，則是在 tomcat/bin/catalina.sh裡，加入 JAVA_OPTS 設定 jvm 啟動參數\n#!/bin/sh JAVA_OPTS=\u0026#34;-agentlib:jdwp=transport=dt_socket,address=18090,server=y,suspend=n\u0026#34; 接著在自己的電腦上開啟 tunnel # 如果自己的電腦是 Windows # 先下載 putty，下載完成之後打開他，然後點選 Tunnels\n在 Source port 填上本機的 port，這裡填 1993，但你可以挑一個自己喜歡的 port\n在 Destination上 填上 server ip 和 18090，其中 18090 要跟你剛剛在 server 上運行的參數 address 的值一樣\n填完之後按 Add，上面 Forwarded ports 就會出現你的設定值\n接著按左邊的 session 回到主頁面，在 Host Name 填上 server 的 ip\n最後再按右下角 Open 連線，就可以在 Windows 上開啟 tunnel 了\n如果自己的電腦是 Mac/Linux # Mac/Linux 開啟 tunnel 的方式比較簡單，只要運行以下指令就可以了\nssh -X -N -L 1993:your-server-ip:18090 your-server-ip 其中 18090 要跟你剛剛在 server 上運行的參數 address 的值一樣，而那個 1993 則是本機的 port，你挑一個自己喜歡的就可以了\n設定 IntelliJ # 首先先在 IntelliJ 上新增一個 Remote configuration\n在 host 的地方填入 localhost，而 port 的地方填入你剛剛開的那個本機 port，我剛剛在本機開的是 1993 port，所以我這裡就填 1993，填好按 OK 保存\n接著就可以運行剛剛設置好的 remote configuration 來進行 remote debug 了！\n如果連線有成功，IntelliJ 下方會顯示 Connected to the target VM...，這時候就可以打 break point 來對 server 上的 project debug 了\n","permalink":"https://kucw.io/blog/2020/1/intellij-remote-debug/","tags":null,"title":"IntelliJ - Remote Debug"},{"categories":["Spring Boot"],"contents":" 本文只講解 OAuth 2.0 的實作，有關 OAuth 1.0a 實作，可參考我的另一篇文章 使用 SpringBoot 實作 OAuth 1.0a 綁定 Twitter\n如果你想要在你的網站上取得某位 user 在 Github 上的資料，那麼就要使用 OAuth 2.0 將你的網站和 Github 做綁定，本文介紹如何使用 Spring Boot 來實現 Github OAuth 2.0 綁定\n首先，先進到 Github 的個人設定的 settings 頁面，點擊 Developer settings\n點擊 OAuth Apps，創建一個 OAuth App，這一步就是你的網站和 Github 的協商\n填入相關資料\n當 user 在 Github 按下授權按鈕之後，Github 會將 user 302 導到你指定的 Authorization callback URL，在此處就是 http://localhost:8080/callback，然後順便把 code 也傳給你 點擊創建之後，就會看到 Github 發給你的 OAuth 2.0 用的 Client Id 和 Client Secret 了\n接下來就是實現和 Github 綁定的 SpringBoot code，demo code 放在這裡\nGithub OAuth2 官方文件 : https://developer.github.com/apps/building-oauth-apps/authorizing-oauth-apps/\n假設你已經在 Github 上按下授權按鈕，然後你想要解綁的話，進到 Github 的 setting 頁面，點擊 Application，就可以看到剛剛綁的 oauth-test，在此處就可以刪掉你剛剛綁定的 token 了\n","permalink":"https://kucw.io/blog/2019/12/spring-oauth2-bind-github/","tags":null,"title":"使用 SpringBoot 實作 OAuth 2.0 綁定 Github"},{"categories":["Spring Boot"],"contents":" 本文只講解 OAuth 1.0a 的實作，有關 OAuth 2.0 實作，可參考我的另一篇文章 使用 SpringBoot 實作 OAuth 2.0 綁定 Github\n如果你想要在你的網站上取得某位 user 在 Twitter 上的資料，那麼就要使用 OAuth 1.0a 將你的網站和 Twitter 做綁定，本文將介紹如何使用 Spring Boot 來實現 Twitter OAuth 1.0a 綁定\n首先先進到 Twitter developer 網站，將你的 Twitter 帳號申請為 developer 帳號，申請通過之後會收到 Twitter 寄來的 email，點擊 confirm 按鈕會進入到 Twitter developer dashboard get-started\n點擊 Create an app 創建一個 oauth app，這一步是你的網站和 Twitter 的協商\n填入相關資料，需要填寫 app name、Application description、website url、callback Url\n注意此處的 callback Url 要和到時後申請 request token 帶的 callback Url 一致，不然會被 Twitter 擋下來 另外也要注意他的 website url 強制需要 https 和 有域名 兩個條件，所以這時候就要使用 ngrok 來幫我們轉發 在這裡吐嘈 Twitter 一下，為什麼不管是申請個 Twitter 開發者帳號還是申請 Oauth app，都要寫一堆理由..\n填完相關資料點擊 create 後，就成功在 Twiiter 創建 Oauth app了\n點擊 Keys and tokens tab，就可以看到 Twitter 發給我們的 consumer key 和 secret 了\nTwitter 還算貼心，可以直接在開發者頁面一鍵新增 access token，幫你省去綁定的功夫，讓你可以快速使用這個 access token 去 call 他的 api 當然這個 access token 只會提供你自己的 Twitter 帳號的 access token，如果要實現所有人都可以綁定的話，還是需要自己寫 oauth 1.0a 綁定 code，這個 access token 只是讓你能夠快速測試而已 接下來就是實現和 Twitter 綁定的 SpringBoot code，demo code 放在這裡\nTwitter OAuth1.0a 官方文件 : https://developer.twitter.com/en/docs/basics/authentication/oauth-1-0a/obtaining-user-access-tokens\n","permalink":"https://kucw.io/blog/2019/12/spring-oauth1a-bind-twitter/","tags":null,"title":"使用 SpringBoot 實作 OAuth 1.0a 綁定 Twitter"},{"categories":["Other tech"],"contents":"安裝環境 : CentOS Linux release 7.7.1908 (Core)\nsudo yum install python36-pip python3-devel gcc-c++ sudo pip3 install apache-superset superset db upgrade flask fab create-admin superset load_examples superset run -p 8088 ","permalink":"https://kucw.io/blog/2019/12/superset-install/","tags":null,"title":"Superset 安裝教學"},{"categories":["Elastic Search"],"contents":"在 ElasticSearch 中，提供了兩種用來表示地理位置的方式，分別是 geo_point 和 geo_shape\n用緯度、經度表示的座標點使用 geo_point 字段類型(較常用)，geo_point 允許你找到距離另一個座標點一定範圍內的座標點、計算出兩點之間的距離來排序或進行相關性打分、或者聚合到顯示在地圖上的一個網格 另一種是使用 GeoJSON 格式定義的複雜地理形狀，使用geo_shape字段類型 geo_point 經緯度座標格式 # 在 mapping 定義時將字段類型定義為 geo_point\nPUT mytest { \u0026#34;mappings\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;name\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34; }, \u0026#34;my_location\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;geo_point\u0026#34; } } } } 目前有6種經緯度座標格式可以插入一個座標點到 Elasticsearch中，此處只介紹幾種常用的，全部支持的格式請參考 官方文檔\n使用對象\nPOST mytest/_doc { \u0026#34;name\u0026#34;: \u0026#34;Pala Pizza as an object\u0026#34;, \u0026#34;my_location\u0026#34;: { \u0026#34;lat\u0026#34;: 40.722, \u0026#34;lon\u0026#34;: -73.989 } } 使用數組 location : [ lon, lat ]\nPOST mytest/_doc { \u0026#34;name\u0026#34;: \u0026#34;Pala Pizza as an array\u0026#34;, \u0026#34;my_location\u0026#34;: [-73.989, 40.722] } 使用字符串 location : \u0026ldquo;lat, lon\u0026rdquo;\nPOST mytest/_doc { \u0026#34;name\u0026#34;: \u0026#34;Pala Pizza as a string\u0026#34;, \u0026#34;my_location\u0026#34;: \u0026#34;40.722, -73.989\u0026#34; } 使用Geohash\nPOST mytest/_doc { \u0026#34;name\u0026#34;: \u0026#34;Pala Pizza as a geohash\u0026#34;, \u0026#34;my_location\u0026#34;: \u0026#34;drm3btev3e86\u0026#34; } 通過地理座標點進行過濾 # 目前針對 geo_point 的查詢，ElasticSearch 提供 3 種地理座標點相關的過濾器，可以用來選中或者排除文檔\ngeo_bounding_box (矩形過濾) : 找出落在指定矩形框中的點，效率最高 geo_distance (圓形過濾) : 找出與指定位置在給定距離內的點 geo_polygon (自定義多邊型過濾) : 找出落在指定多邊形中的點 (注意這個過濾器使用代價很大) geo_bounding_box 矩形過濾 # 指定一個矩形的頂部、底部、左邊界、右邊界，然後過濾器只需判斷座標的經度是否在左右邊界之間，緯度是否在上下邊界之間就可以判斷這個座標點是否在矩形範圍內\n可以選擇使用 top_left + bottom_right 或是 top_right + bottom_left 或是 top + bottom + left + right\n具體實例 : 找出那些位在 lat 40.7~40.8，且lon -73 ~ -74的座標點 # GET mytest/_search { \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34;: { \u0026#34;filter\u0026#34;: { \u0026#34;geo_bounding_box\u0026#34;: { \u0026#34;my_location\u0026#34;: { \u0026#34;top_left\u0026#34;: { \u0026#34;lat\u0026#34;: 40.8, \u0026#34;lon\u0026#34;: -74.0 }, \u0026#34;bottom_right\u0026#34;: { \u0026#34;lat\u0026#34;: 40.7, \u0026#34;lon\u0026#34;: -73.0 } } } } } } } geo_distance 圓形過濾 # 從給定的位置爲圓心畫一個圓，找出那些地理座標落在其中的文檔，distance支持的單位 : km、m、cm、mm\u0026hellip;\n圓形過濾計算代價比矩形過濾貴，爲了優化性能，ES 會先畫一個矩形框來圍住整個圓形，這樣就可以用矩形過濾先排除掉一些完全不可能的文檔，然後再對落在矩形內的座標點用地理距離計算方式處理\n在使用圓形過濾時，需要思考是否真的要這麼精確的距離過濾？通常使用矩形模型 bounding box是更更高效的方式，並且往往也能滿足應用需求，假設user想找1km內的餐廳，是否不行找了一個1.2km的餐廳給他？這200m真的差距有這麼大嗎？需要根據實際使用情況做選擇\n為了提高圓形過濾的性能，在計算兩點間的距離時，有多種犧牲性能換取精度的算法\narc : 最慢但最精確的計算方式 (默認的計算方式)，這種方式把世界當作球體來處理，不過這種方式的精度還是有極限，因爲這個世界並不是完全的球體 plane : plane的計算方式把地球當成是平坦的，這種方式快一些但是精度略遜，在赤道附近的位置精度最好，而靠近兩極則變差 具體實例 : 給定一個位置 (40.715, -73.988)，找出距離他1km以內的所有點 # GET mytest/_search { \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34;: { \u0026#34;filter\u0026#34;: { \u0026#34;geo_distance\u0026#34;: { \u0026#34;distance\u0026#34;: \u0026#34;1km\u0026#34;, \u0026#34;distance_type\u0026#34;: \u0026#34;arc\u0026#34;, \u0026#34;my_location\u0026#34;: { \u0026#34;lat\u0026#34;: 40.715, \u0026#34;lon\u0026#34;: -73.988 } } } } } } geo_polygon 自定義多邊型過濾 # geo_polygon 可以自定義一個多邊形，然後判斷這個座標點是否在該多邊形內\n在使用 geo_polygon 時，需要使用 points 數組自定義多邊形，需要把該多邊形的所有點列出來在此數組裡，順序不影響\n具體實例 : 找出那些位在指定多邊形內的座標點 # GET mytest/_search { \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34; : { \u0026#34;filter\u0026#34; : { \u0026#34;geo_polygon\u0026#34; : { \u0026#34;my_location\u0026#34; : { \u0026#34;points\u0026#34; : [ {\u0026#34;lat\u0026#34; : 40, \u0026#34;lon\u0026#34; : -70}, {\u0026#34;lat\u0026#34; : 40, \u0026#34;lon\u0026#34; : -80}, {\u0026#34;lat\u0026#34; : 50, \u0026#34;lon\u0026#34; : -70}, {\u0026#34;lat\u0026#34; : 50, \u0026#34;lon\u0026#34; : -80} ] } } } } } } 按照距離大小進行排序 # 請求 # 注意，會需要在請求時決定距離的單位的原因是因為，這些用於排序的距離的值，會設置在每個返回的結果的sort元素中，方便我們取得他們實際上距離那個點多少距離，而此時就必須知道距離的單位\nGET mytest/_search { \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34;: { \u0026#34;filter\u0026#34;: { \u0026#34;geo_bounding_box\u0026#34;: { \u0026#34;my_location\u0026#34;: { \u0026#34;top_left\u0026#34;: { \u0026#34;lat\u0026#34;: 40.8, \u0026#34;lon\u0026#34;: -74.0 }, \u0026#34;bottom_right\u0026#34;: { \u0026#34;lat\u0026#34;: 40.4, \u0026#34;lon\u0026#34;: -73.0 } } } } } }, \u0026#34;sort\u0026#34;: [ { //計算每個文檔中 my_location 字段與指定的 lat/lon 點間的距離 //my_location要先在索引中建為geo_point類型的字段 \u0026#34;_geo_distance\u0026#34;: { \u0026#34;my_location\u0026#34;: { \u0026#34;lat\u0026#34;: 40.715, \u0026#34;lon\u0026#34;: -73.998 }, //將距離以 km 爲單位寫入到每個返回結果的sort中 \u0026#34;unit\u0026#34;: \u0026#34;km\u0026#34;, \u0026#34;distance_type\u0026#34;: \u0026#34;arc\u0026#34;, \u0026#34;order\u0026#34;: \u0026#34;asc\u0026#34; } } ] } 返回結果 # 在sort存放的數字，告訴我們此餐廳到指定的位置的距離是0.0842km\n\u0026#34;hits\u0026#34;: [ { \u0026#34;_index\u0026#34;: \u0026#34;attractions\u0026#34;, \u0026#34;_type\u0026#34;: \u0026#34;restaurant\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;2\u0026#34;, \u0026#34;_score\u0026#34;: null, \u0026#34;_source\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;New Malaysia\u0026#34;, \u0026#34;location\u0026#34;: { \u0026#34;lat\u0026#34;: 40.715, \u0026#34;lon\u0026#34;: -73.997 } }, \u0026#34;sort\u0026#34;: [ 0.08425653647614346 ] }, ... ] 按照距離大小打分 # 有可能距離是決定返回結果排序的唯一重要因素，不過更常見的情況是距離會和其它因素，比如全文檢索匹配度、流行程度或者價格一起決定排序結果\n如果需要綜合多個維度一起進行排序，就需要使用 function_score 中指定方式讓我們把這些因子處理後得到一個綜合分，詳情此參考 ElasticSearch - function_score 簡介\n","permalink":"https://kucw.io/blog/2019/12/elasticsearch-geo-point/","tags":null,"title":"ElasticSearch - 地理座標點 geo_point"},{"categories":["Life"],"contents":"最近突如其來的想說來減過肥吧，然後突然想到許多健身的人為了讓肌肉更突出，通常在一定時間的重訓後，就會開始為期三個月的減脂肪餐（就是很常見的雞肉餐）\n所以我突發奇想，要是減肥和減脂，他們的原理都是要減去人體內多餘的脂肪的話，那我走減脂那一套吃法，是不是會減的比較輕鬆又快樂？可以一直吃肉，然後又可以瘦下來，怎麼想都比蔬菜水果好減吧！\n詢問了我一個重訓多年的朋友之後，他給我的建議如下\n第一步：決定目標和手段 # 首先，你想減肥，具體有想要搭配重訓長肌肉嗎？還是只是想要減掉肥肉？\n要知道，減脂和減重是不同概念\n如果只是想要減掉肥肉，多做有氧（跑步游泳騎車之類的），就可以有能量消耗。然後不用特別吃肉，只要控制整體熱量 \u0026lt; 支出，兩個月就可以瘦個三五公斤\n減脂要吃肉是為了要維持肌肉量（搭配大量重量訓練），因為減重（包含減掉脂肪＋肌肉）的時候肌肉量一定會掉，但是減脂我們盡量只減脂肪，和少量肌肉（減脂還是會掉肌肉）\n所以如果你沒有想要搭配重量訓練（維持肌肉量），那你直接有熱量赤字就好了，不管是減脂還是減重，熱量赤字都是需要的\n第二步：如何達到熱量赤字？ # 什麼是熱量赤字？\n只要 每天的熱量消耗量 \u0026gt; 每天的熱量攝取量，就是熱量赤字 # 假設你每天消耗（運動＋能量消耗＋基礎代謝）2000大卡，那你就只能吃 1500 ~ 1700 大卡，才能達到熱量赤字\n通常每 7700 大卡熱量赤字會少一公斤，所以假如你一天少吃 400 大卡，你 7700 / 400 = 19.25 天，你就可以少一公斤。所以看看你要想少幾公斤，想要多少時間內減重，再去分配\n這也是為什麼要做有氧運動，就是為了要增加自己的 \u0026ldquo;每日消耗\u0026rdquo;\n前面說到 每日消耗 = 運動消耗＋消化食物消耗的熱量＋基礎代謝（呼吸之類的），所以如果你運動一天多500大卡消耗，你就一天多減500大卡\n可是運動會餓，所以可能又會想吃東西，不過減肥、減脂的人就是要控制自己不能吃太多\n然後要怎麼算自己一天吃 1500 大卡呢？就是要自己煮，或是找有營養標示的早、午、晚餐。所以有在重訓要減脂的人才會都自己煮，這樣才抓的到每日的吸收量是多少\n減脂的話要調配三大基礎營養素的比例：碳水化合物、脂肪、蛋白質。這三種的攝取量會依照你重訓的天數、強度、組數、每天或每月做不同變化\n結論 # 如果你只是想減肥，那就 \u0026ldquo;多做有氧＋每天熱量赤字\u0026rdquo; 就 ok 了\n如果你要減脂\u0026hellip;再跟我說\n","permalink":"https://kucw.io/blog/2019/12/how-to-lose-weight/","tags":null,"title":"減肥和減脂有區別嗎？"},{"categories":["Java"],"contents":"Stopwatch 是 Guava 提供，可以用來測量程式運行時間的工具（Guava 是 Google 開發的 Java library，是一個非常好用的工具包）\n常用方法 # Stopwatch.creatStarted() : 創建一個碼表，並且開始計時 stop() : 碼表停止計時 elapsed(TimeUnit unit) : 取得從開始到結束的時間 具體實例 # public class Main { public static void main(String[] args) { Stopwatch stopwatch = Stopwatch.createStarted(); doSomething(); stopwatch.stop(); long millis = stopwatch.elapsed(TimeUnit.MILLISECONDS); System.out.println(\u0026#34;time: \u0026#34; + millis + \u0026#34; ms\u0026#34;); } } ","permalink":"https://kucw.io/blog/2019/11/java-time-measurment/","tags":null,"title":"Java - 測量程式執行時間"},{"categories":["Java"],"contents":"GraalVM 是 Oracle 發佈的下世代 jvm，2019.05 才發佈了第一個 release 版本，分別有 Community 版和 Enterprise 版\nGraalVM 三大特點 # High-performance modern Java : 使用 GraalVM 執行 Java 程式可以變得更快 Polyglot : 可以在 Java 裡面同時使用多種語言，像是 JavaScript、R\u0026hellip; Instant startup, low footprint : 直接把 Java program compile 成 machine code，執行起來體積更小、啟動更快 High-performance modern Java # High-performance modern Java 使用到了 Graal compiler 技術，Graal compiler 是一個 JIT compiler，並且是使用 Java 撰寫的，目的是拿來替換掉原本 HotSpot VM 的C2 compiler\n為了讓 Graal compiler 可以更彈性的被更新（總不能每發布一次 Graal compiler 更新就要重新 compile 整個 java），Oracle 加上了一層JVM Compiler Interface，簡稱 JVMCI，把原本那些應該由 C2 執行的請求抽象化成 interface，解耦 C1 compiler 和 Graal compiler 的連結，讓 Graal 可以更輕易的被更新\n雖然 Graal 是使用 java 寫的，難免會讓人聯想到性能會比不上 C2 compiler，但是在各種實驗之後，得到的數據顯示對於 Java program，Graal 和 C2 compiler 的能力幾乎不相上下（在已經預熱完畢的前提下），而對於 Scala program，Graal 更是達到 10% 以上的優化，這也是為什麼 Twitter 大規模的使用 GraalVM 替換掉原本的 HotspotVM\n不過在啟動時，GraalVM 會比 HotspotVM 還慢，原因是必須先將 Graal 編譯成 machine code，這個是無可避免的，只是當預熱完畢時，Graal 和 C2 compiler 的性能不相上下，並且根據 Graal 的版本不斷更新，這個數據只可能會更好\nPolyglot # GraalVM 最一開始被發明出來，就是為了讓 Java 可以在一次 runtime 中同時使用多種語言，從官網稱呼 GraalVM 為 High-performance polyglot VM，也可以發現 Oracle 對 GraalVM 定位是一個多語言 jvm\n為了實現 Polyglot，GraalVM 引入了一層 Truffle framework，只要實現了該語言的 interpreter，就可以在 Java program 中使用該語言\n目前官方支援的語言僅有 Python、R、JavaScript，後續會陸續增加\n具體實例\npublic class Main { public static void main(String[] args) { System.out.println(\u0026#34;Hello World from Java!\u0026#34;); Context context = Context.newBuilder().allowAllAccess(true).build(); context.eval(\u0026#34;js\u0026#34;, \u0026#34;print(\u0026#39;Hello World from JavaScript!\u0026#39;);\u0026#34;); context.eval(\u0026#34;python\u0026#34;, \u0026#34;print(\u0026#39;Hello World from Python!\u0026#39;)\u0026#34;); context.eval(\u0026#34;ruby\u0026#34;, \u0026#34;puts \u0026#39;Hello World from Ruby!\u0026#39;\u0026#34;); } } Hello World from Java! Hello World from JavaScript! Hello World from Python! Hello World from Ruby! Instant startup, low footprint # GraalVM 還有最後一項技術，就是 native image，他是在 compile time時，就將 Java program 直接 compiler 成 binary 的 machine code，讓這個程式可以像一般二進制的檔案被運行\nNative images compiled with GraalVM ahead-of-time improve the startup time and reduce the memory footprint of JVM-based applications.\nNative-image 帶來的好處是可以更快速的啟動一個 java program，以往如果要啟動 java 程式，需要先啟動 jvm 再載入 java code，然後再即時的 compile bytecode to machine code，非常耗時和耗 memory，而如果使用 native-image，可以取得一個更小更快速的鏡像，適合用在 cloud deploy\nnative image 之所以可以快速啟動，是因為他做了 Ahead-of-time compile，在 compile time 時，會把所有相關的東西，包含一個 Substrate VM，一起 compile 成 machine code，這個 SubstrateVM 是 GraalVM 才有的東西，他只包含最基本的 thread scheduling、垃圾回收，盡可能的縮小必要的 jvm 體積\n雖然 native image 感覺很猛，但是他也有不可抹滅的缺點，就是使用 native image 的程式，throughput 會下降，原因是因為 java 程式很大一部分的優化都在 JIT compiler 中\n還有另一個缺點是，native image 並沒有辦法動態的加載類（因為所有東西必須要在 compile time 就決定好），所以也沒辦法使用反射等相關機制，不過對於這個問題，GraalVM 也有提出相對應的解法，就是在 compile 時，把所有可能的類全部 compile 進來，所以反射機制還是可以支持的，不然的話，整個 Spring framework 就不能使用 native image 了\n目前 Spring 5 也打算開始支持 GraalVM native-image 的開箱即用設定，可以看到 serverless 的 java program 可能是之後的趨勢\n補充一下，serverless 就是指 Fuction as a Service，他的目的是希望 program 不用一直 run 著，當有請求來的時候，我快速啟動這個 program，然後請求走我就 shutdown 這個 program，不讓 program 一直啟動著，而是有需要的時候才開啟他，也就是說，FaaS 就是讓這個 program 像是 function 一樣，用完即走，因此 native-image 的快速啟動非常符合FaaS的需求\n安裝 GraalVM # 上官網下載 GraalVM community，如果電腦是 mac，選擇 graalvm-ce-darwin-amd64-19.2.0.1.tar.gz 下載，如果是 Linux/Windows，則選擇相對應版本下載\n下載完後解壓縮，放到 /Library/Java/JavaVirtualMachines 下，然後在 .bashrc 或 .zshrc 中加上以下設定\nexport PATH=\u0026#34;/Library/Java/JavaVirtualMachines/graalvm-ce-19.2.0.1/Contents/Home/bin:$PATH\u0026#34; export JAVA_HOME=\u0026#34;/Library/Java/JavaVirtualMachines/graalvm-ce-19.2.0.1/Contents/Home\u0026#34; 做完之後就可以使用 GraalVM Component Updater 的 gu 指令了，預設的 GraalVM 中只幫我們預載好了 Java 和 Javascript 而已，如果想要其他東西，需要再用 gu 額外下載\ngu install native-image ruby python R 設好路徑後，也會發現 java 默認的 vm 改成了使用 GraalVM\n原本的樣子\n改好路徑後的樣子\n接著新增一個檔案，檔名叫做 Main.java，並在裡面寫入以下內容，測試我們是否有成功切換至 GraalVM\nimport org.graalvm.polyglot.*; public class Main { public static void main(String[] args) { System.out.println(\u0026#34;Hello World from Java!\u0026#34;); Context context = Context.newBuilder().allowAllAccess(true).build(); context.eval(\u0026#34;js\u0026#34;, \u0026#34;print(\u0026#39;Hello World from JavaScript!\u0026#39;);\u0026#34;); context.eval(\u0026#34;python\u0026#34;, \u0026#34;print(\u0026#39;Hello World from Python!\u0026#39;)\u0026#34;); context.eval(\u0026#34;ruby\u0026#34;, \u0026#34;puts \u0026#39;Hello World from Ruby!\u0026#39;\u0026#34;); } } 執行以下指令\njavac Main.java java Main 如果有成功輸出以下訊息，表示成功使用 GraalVM 來 run java bytecode\nHello World from Java! Hello World from JavaScript! Hello World from Python! Hello World from Ruby! 在 Intellij 中使用 GraalVM # 點擊 Project Structure 之後，選擇 SDKs，然後選擇加號新增一個 jdk\n選擇存放 GraalVM 的位置，如果有照剛剛的步驟安裝 GraalVM 的話，就選擇 /Library/Java/JavaVirtualMachines/graalvm-ce-19.2.0.1/Contents/Home\n接著點擊下方加號，加入 graal-sdk.jar，路徑在 /Library/Java/JavaVirtualMachines/adoptopenjdk-8.jdk/Contents/Home/jre/lib/boot/graal-sdk.jar\n最後再將該 module 使用 sdk 換成 GraalVM，這樣就可以在 Intellij 中直接使用 GraalVM 來 run code了\n","permalink":"https://kucw.io/blog/2019/10/java-graalvm/","tags":null,"title":"GraalVM 介紹 + 安裝教學"},{"categories":["Java"],"contents":" Iterator 是所有 Collection 類（List、Set\u0026hellip;.）們都可以使用的迭代器，而 ListIterator 則是專門為 List 類所設計的迭代器\nIterator 只支持 hasNext()、next()、remove() 三種操作，而 ListIterator 除了原本的 3 種之外，還支持了更多操作\n//Iterator接口 public interface Iterator\u0026lt;E\u0026gt; { boolean hasNext(); E next(); void remove(); } //ListIterator接口 public interface ListIterator\u0026lt;E\u0026gt; extends Iterator\u0026lt;E\u0026gt; { //繼承自Iterator的接口 boolean hasNext(); //後面是否有元素 E next(); //游標向後移動，取得後面的元素 void remove(); //刪除最後一個返回的元素 //ListIterator新增的接口 boolean hasPrevious(); //前面是否有元素 E previous(); //游標往前移動，取得前面的元素 int previousIndex(); //取得游標前的index int nextIndex(); //取得游標後的index void set(E e); //將當前元素改設成e void add(E e); //增加一個元素 } Iterator 和 ListIterator 的差別\niterator() 方法在所有集合類中都能使用，但是 listIterator() 只有 List 類能用 Iterator 只能 remove() 元素，而 ListIterator 可以 add()、set()、remove() Iterator 只能使用 next() 順序的向後遍歷，ListIterator 則向前 previous() 和向後 next() 遍歷都可以 還有一個額外的功能，ListIterator 可以使用 nextIndex() 和 previousIndex() 取得當前游標位置的前後 index 位置，Iterator 沒有此功能 如果想在遍歷 List 時邊做刪除，用 Iterator 和 ListIterator 都能辦到，但如果是想在遍歷 List 時 add 元素，則只能使用 ListIterator 去做，因為 Iterator 是不提供此接口的\n要注意的是，邊遍歷 List 邊使用 Iterator 和 ListIterator 的 add()、remove() 時，並不會影響當前 List 輸出結果，雖然他們修改的是同一個 List，但是迭代器故意將 add 和 remove 設計成就算執行了，也不影響當前迭代器的輸出結果\npublic class Main { public static void main(String[] args) { List\u0026lt;Integer\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); list.add(1); list.add(2); list.add(3); ListIterator\u0026lt;Integer\u0026gt; it = list.listIterator(); while (it.hasNext()) { Integer x = it.next(); System.out.println(x); //雖然使用it.add(100)去新增一個元素，使得list實際儲存的是 [1,2,100,3] //但是此處的遍歷仍然只顯示[1,2,3]，這是迭代器故意這樣設計的 if (x == 2) { it.add(100); } } System.out.println(\u0026#34;list: \u0026#34; + list); } } 1 2 3 list: [1, 2, 100, 3] 另外，雖然 ArrayList 和 LinkedList 都支持 ListIterator，但通常只有在使用 LinkedList 時才會搭配 ListIterator\n因為 LinkedList 幾乎所有的時間消耗都是在去找到這個元素在哪，而找到此元素之後，對他進行修改是非常容易的事情（只要改指針就可以了），所以使用 ListIterator 的話，就可以節省下這個查找時間 而對 ArrayList來說，因為他查找的速度很快（底層是數組），因此使用 ListIterator 省下的查找時間非常少，所以對他來說，並沒有迫切的需要使用 ListIterator，使用 add(index, E) 也能達到同樣的效率 因此可以說 ListIterator 根本是為 LinkedList 發明的，ArrayList 只是順道實現而已，ArrayList 去實現只是為了設計成讓 List 接口的類們都能使用 ListIterator 而已 ","permalink":"https://kucw.io/blog/2018/12/java-iterator-and-listiterator/","tags":null,"title":"Java - Iterator 和 ListIterator"},{"categories":["Java"],"contents":" 為什麼 Iterator 接口，只有 hasNext()、next()、remove() 方法，而沒有 add(E) 方法 ? 邏輯上來說，迭代器是一個一個去遍歷集合中的元素，而當前 iterator 停下的地方，就是迭代到一半的地方 如果當迭代到一半時調用 iterator.add() 方法，理論上來說，應該是要在當前這個元素 E1 後面新增一個元素 E2，使得下次遍歷此集合時，E2 一定會出現在 E1 後面，也就是 [\u0026hellip;.E1, E2, \u0026hellip;.] 假設 add() 方法是以這個語意為前提的話，那麼迭代器不提供此方法是很合理的，對於有序的集合（像是ArrayList）來說，在此元素後面新增一個元素是一個很簡單的事情，但是對於無序的集合（像是HashSet）來說，不能保證新插入的這個元素 E2 一定會在 E1 後面（因為還得計算 HashCode），如此就違反了 add() 的語意了，這也就是為什麼 Iterator 接口不提供 add() 方法 另一個說法是，在使用迭代器時，通常就是 \u0026ldquo;遍歷\u0026rdquo; 的場景，這種場景下很少會去使用 add() 方法，因此 Iterator 接口沒必要提供這個方法 ","permalink":"https://kucw.io/blog/2018/12/java-iterator-without-add/","tags":null,"title":"Java - 為什麼 Iterator 不提供 add（E）方法 ？"},{"categories":["Java"],"contents":" 所有的集合類（List、Set\u0026hellip;）都實現自 Collection 接口，而 Collection 接口又繼承於 Iterable 接口，因此可以說所有的集合類（List、Set\u0026hellip;）都實現了 Iterable 接口\n當某個類實現 Iterable 接口時，我們就能稱這個類是一個 \u0026ldquo;可數\u0026rdquo; 的類，也就是可以使用 iterator() 獲取一個迭代器 Iterator，然後使用這個 Iterator 實例去遍歷這個類，因此所有的 Collection 類都能夠使用迭代器 Iterator 來遍歷\nIterable 接口\npublic interface Iterable\u0026lt;T\u0026gt; { //當某個類實現Iterable接口的話，就能獲取到迭代器iterator，然後就能使用這個iterator去遍歷此類 Iterator\u0026lt;T\u0026gt; iterator(); } Iterator 接口\n如果某個類實現了 Iterable 接口，那麼他也需要創建一個內部類去實現一個 Iterator 類，讓調用 Iterable 接口中的 iterator() 時，能夠獲取到一個 iterator 實例\npublic interface Iterator\u0026lt;E\u0026gt; { //是否有下一個元素 boolean hasNext(); //取得下一個元素 E next(); //刪除最後一個獲取的元素，因此調用remove()前一定得先調用一次next() void remove(); } 至於此 Iterator 接口怎麼實現，就看各個集合實現類如何定義 \u0026ldquo;下一個元素\u0026rdquo;，像是 ArrayList 的下一個元素就是 element[index+1]，而 HashMap 的下一個元素則是 hash table 數組中儲存的下一個 entry\n另外可以想像 Iterator 像是一個游標一樣，一開始停在最前面，然後不停的往後走（只能向後移動），且此游標每次都是停在元素和元素的中間，當調用 next 時，迭代器就越過下一個元素，並返回剛剛越過的那個元素的引用\n使用迭代器 Iterator 遍歷 ArrayList\npublic class Main { public static void main(String[] args) { //ArrayList實現了Collection接口，因此他也實現了Iterable接口，所以他可以使用iterator迭代器來遍歷 List\u0026lt;String\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); list.add(\u0026#34;hello\u0026#34;); list.add(\u0026#34;world\u0026#34;); //調用Iterable接口中的iterator()取得此ArrayList的迭代器實例 Iterator\u0026lt;String\u0026gt; its = list.iterator(); //使用Iterator接口的hasNext()、next()來遍歷此ArrayList集合實現類 while (true) { if (its.hasNext()) { String s = its.next(); System.out.println(s); } else { break; } } } } 而再進一步說，當某個類能使用迭代器 Iterator 來遍歷時，就能使用 java 提供的 foreach 語法糖來遍歷此類（foreach語法糖其實就是簡化的 iterator()）\nforeach 實際上會被編譯器編譯成使用迭代器 iterator() 去遍歷集合，因此能使用 foreach 的，都是得實現 Iterable 接口的集合類 Collection 們，像是 List、Set\n所以 Map 就沒有辦法直接使用 foreach（因為 Map 沒有實現 Iterable 接口），只有他的 map.entrySet()、map.keySet()、map.values() 這種返回一個集合類的方法，才能使用 foreach\npublic class Main { public static void main(String[] args) { List\u0026lt;String\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); list.add(\u0026#34;hello\u0026#34;); list.add(\u0026#34;world\u0026#34;); //原代碼，使用語法糖的foreach for (String s : list) { System.out.println(s); } //實際上會被編譯成使用iterator去遍歷 for (Iterator\u0026lt;String\u0026gt; its = list.iterator(); its.hasNext(); ) { String s = its.next(); System.out.println(s); } } } 為什麼 Iterator 要額外使用內部類去實現，而不是 ArrayList 直接實現此接口 ?\n如果看過 Collection 類的源碼（以ArrayList為例），可以發現 ArrayList 類並不是由 ArrayList 去實現 Iterator 接口，而是 ArrayList 有一個內部類 Itr，專門去實現 Iterator 接口，而 ArrayList 的 iterator() 方法，只是去創建一個內部類 ArrayList.Itr 的實例而已\n//ArrayList不實現Iterator接口，反而是由他的內部類進行實現 public class ArrayList\u0026lt;E\u0026gt; extends AbstractList\u0026lt;E\u0026gt; { //調用list.iterator()可以取得此list的迭代器 public Iterator\u0026lt;E\u0026gt; iterator() { return new Itr(); //實際上就是去創建一個內部類的實例 } //ArrayList中的內部類Itr，專門實現Iterator接口 private class Itr implements Iterator\u0026lt;E\u0026gt; { int cursor; //記錄當前迭代到哪裡 public boolean hasNext() { ... } public E next() { ... } public void remove() { ... } } } 要這樣設計是因為一個集合類可能同時有多個迭代器去遍歷他，而每個迭代器遍歷到集合的哪裡，是每個迭代器自己的事情，彼此不互相干涉，因此才需要額外使用一個內部類去實現迭代器的 Iterator 接口\n如此當需要用到 Iterator 來遍歷集合時，只需要調用 list.iterator()，就能取得一個全新的、不受別人影響的迭代器供自己使用，而迭代器彼此之間也不會互相干涉 至於為什麼要特別使用內部類來實現 Iterator 接口，而不是創建一個 Iterator 公共類來供所有集合一起使用，是因為迭代器需要知道集合的內部結構，他才能知道要怎麼去實現 hasNext()、next()、remove() 方法，而使用內部類才能無條件的取用外部類的所有信息（包含 private 的變量和方法），因此才需要將 Iterator 提取成接口，讓每個集合自己使用內部類去實現 Iterator 接口 為什麼 Iterator 接口，只有 hasNext()、next()、remove() 方法，而沒有 add(E) 方法 ?\n邏輯上來說，迭代器是一個一個去遍歷集合中的元素，而當前 iterator 停下的地方，就是迭代到一半的地方 如果當迭代到一半時調用 iterator.add() 方法，理論上來說，應該是要在當前這個元素 E1 後面新增一個元素 E2，使得下次遍歷此集合時，E2 一定會出現在 E1 後面，也就是 [\u0026hellip;.E1, E2, \u0026hellip;.] 假設 add() 方法是以這個語意為前提的話，那麼迭代器不提供此方法是很合理的，對於有序的集合（像是ArrayList）來說，在此元素後面新增一個元素是一個很簡單的事情，但是對於無序的集合（像是HashSet）來說，不能保證新插入的這個元素 E2 一定會在 E1 後面（因為還得計算 HashCode），如此就違反了 add() 的語意了，這也就是為什麼 Iterator 接口不提供 add() 方法 另一個說法是，在使用迭代器時，通常就是 \u0026ldquo;遍歷\u0026rdquo; 的場景，這種場景下很少會去使用 add() 方法，因此 Iterator 接口沒必要提供這個方法 ","permalink":"https://kucw.io/blog/2018/12/java-iterator/","tags":null,"title":"Java - Iterable 接口、迭代器 Iterator"},{"categories":["Java"],"contents":" 在探討 Java 傳遞參數是 pass by value 還是 pass by reference 之前，需要先了解 Java 中 = 的具體細節\n賦值 = 的用法\n= 的意義是賦值，但是這個賦值用在 基本類型 和 對象類型 上會有非常大的差別\n如果 = 用在基本類型上，因為基本類型儲存了實際的數值，所以在為其賦值時，是直接將值複製一份新的過去 因此假設 a、b 都是基本類型，如果執行了 a=b，那麼就是將 b 的內容直接複製一份新的給 a，之後如果改變了 a 的值，也不會影響到 b 此處的基本類型，泛指 int、long、boolean\u0026hellip;.和其包裝型態 Integer、Long、Boolean\u0026hellip;.，只要是這些類型的變量，都適用基本類型的 = 規則 但如果 = 用在對象類型上，因為在使用對象操作時，實際儲存的其實是對象的引用，所以在為其賦值時，實際上只是把 \u0026ldquo;引用\u0026rdquo; 從一個地方複製到另一個地方 因此假設 c、d 都是對象類型，如果執行了 c=d，那麼 c 和 d 都會指向原本只有 d 指向的那個對象，而原本 c 的那個對象因為沒人引用了，所以會被垃圾回收清理掉 另外，只要是數組，不管你是基本類型 int[] 還是對象類型 Tank[]，一律存的都是引用，所以只要賦值了，也會互相影響 具體實例\nt1、t2是基本類型的 = 效果（不會互相影響）\nt3、t4是對象類型的 = 效果（因為存的是引用，所以會互相影響）\ni5、i6是基本類型的數組的 = 效果（因為存的也是引用，所以也會互相影響）\nclass Tank { int level; } public class Main { public static void main(String[] args) { Tank t1 = new Tank(); Tank t2 = new Tank(); t1.level = 1; t2.level = 2; System.out.println(\u0026#34;t1: \u0026#34; + t1.level + \u0026#34;, t2: \u0026#34; + t2.level); //此處只是基本類型的賦值，所以t1、t2仍舊指到兩個不同對象 t1.level = t2.level; System.out.println(\u0026#34;t1: \u0026#34; + t1.level + \u0026#34;, t2: \u0026#34; + t2.level); t1.level = 100; System.out.println(\u0026#34;t1: \u0026#34; + t1.level + \u0026#34;, t2: \u0026#34; + t2.level); System.out.println(\u0026#34;----\u0026#34;); Tank t3 = new Tank(); Tank t4 = new Tank(); t3.level = 3; t4.level = 4; System.out.println(\u0026#34;t3: \u0026#34; + t3.level + \u0026#34;, t4: \u0026#34; + t4.level); //此處是對象類型的賦值，所以是t3和t4都指到了同一個對象上 //而原本t3那個對象因為沒人引用了，所以會被垃圾回收清理掉 t3 = t4; System.out.println(\u0026#34;t3: \u0026#34; + t3.level + \u0026#34;, t4: \u0026#34; + t4.level); t3.level = 100; System.out.println(\u0026#34;t3: \u0026#34; + t3.level + \u0026#34;, t4: \u0026#34; + t4.level); System.out.println(\u0026#34;----\u0026#34;); int[] i5 = {5}; int[] i6 = {6}; System.out.println(\u0026#34;i5[0]: \u0026#34; + i5[0] + \u0026#34;, i6[0]: \u0026#34; + i6[0]); //因為數组存的是引用，所以i5和i6會指到同一個地方上 i5 = i6; System.out.println(\u0026#34;i5[0]: \u0026#34; + i5[0] + \u0026#34;, i6[0]: \u0026#34; + i6[0]); i5[0] = 200; System.out.println(\u0026#34;i5[0]: \u0026#34; + i5[0] + \u0026#34;, i6[0]: \u0026#34; + i6[0]); } } t1: 1, t2: 2 t1: 2, t2: 2 t1: 100, t2: 2 ---- t3: 3, t4: 4 t3: 4, t4: 4 t3: 100, t4: 100 ---- i5[0]: 5, i6[0]: 6 i5[0]: 6, i6[0]: 6 i5[0]: 200, i6[0]: 200 Pass by value or Pass by reference\n和 = 一樣，只要掌握好基本類型實際儲存的是 \u0026ldquo;值\u0026rdquo;、對象類型儲存的是 \u0026ldquo;引用\u0026rdquo;、數組不論什類型存的都是 \u0026ldquo;引用\u0026rdquo;，就能了解 Java 到底什麼時候是 pass by value，什麼時候是 pass by reference\n基本類型 pass by value，對象類型 pass by reference，而數組因為存的都是引用，所以也是 pass by reference\nclass Tank { int level; } public class Main { public static void main(String[] args) { Tank t1 = new Tank(); Tank t2 = new Tank(); t1.level = 1; System.out.println(\u0026#34;t1.level: \u0026#34; + t1.level); fooInt(t1.level); //基本類型pass by value System.out.println(\u0026#34;t1.level: \u0026#34; + t1.level); t2.level = 2; System.out.println(\u0026#34;t2.level: \u0026#34; + t2.level); fooTank(t2); //對象類型pass by reference System.out.println(\u0026#34;t2.level: \u0026#34; + t2.level); } public static void fooTank(Tank tank){ tank.level = 1000; } public static void fooInt(int level){ level = 5; } } t1.level: 1 t1.level: 1 t2.level: 2 t2.level: 1000 基本類型的List、Set、Map 也是 pass by value，對象類型的 List、Set、Map 是 pass by reference\nclass Tank { int level; } public class Main { public static void main(String[] args) { List\u0026lt;Tank\u0026gt; tankList = new ArrayList\u0026lt;\u0026gt;(); List\u0026lt;Integer\u0026gt; intList = new ArrayList\u0026lt;\u0026gt;(); for (int i = 1; i \u0026lt;= 2; i++) { Tank tank = new Tank(); tank.level = i; tankList.add(tank); intList.add(i * 100); } System.out.println(\u0026#34;intList: \u0026#34; + intList.get(0) + \u0026#34;, \u0026#34; + intList.get(1)); fooIntList(intList); System.out.println(\u0026#34;intList: \u0026#34; + intList.get(0) + \u0026#34;, \u0026#34; + intList.get(1)); System.out.println(\u0026#34;tankList: \u0026#34; + tankList.get(0).level + \u0026#34;, \u0026#34; + tankList.get(1).level); fooTankList(tankList); System.out.println(\u0026#34;tankList: \u0026#34; + tankList.get(0).level + \u0026#34;, \u0026#34; + tankList.get(1).level); } public static void fooTankList(List\u0026lt;Tank\u0026gt; tankList) { for (Tank tank : tankList) { tank.level = 500; } } public static void fooIntList(List\u0026lt;Integer\u0026gt; intList) { for (Integer i : intList) { i = 2000; } } } intList: 100, 200 intList: 100, 200 tankList: 1, 2 tankList: 500, 500 ","permalink":"https://kucw.io/blog/2018/9/java-pass-param/","tags":null,"title":"Java - Pass by value or Pass by reference？"},{"categories":["Elastic Search"],"contents":" 閱讀本文需要先了解 Elastic Search 的 index 和 analyzer 的相關知識\nElasticSearch - index mapping（5.x以上）\nElasticSearch - 自定義 analysis\n在此之前，ES 所有的查詢都是針對整個詞進行操作，也就是說倒排索引存了 hello 這個詞，一定得輸入 hello 才能找到這個詞，輸入 h 或是 he 都找不到倒排索引中的 hello\n然而在現實情況下，用戶已經漸漸習慣在輸入完查詢內容之前，就能為他們展現搜索結果，這就是所謂的即時搜索（instant search），或是可以稱為 輸入即搜索（search-as-you-type） 雖然 ES 提供了一系列的前綴搜索 match_phrase、prefix、wildcard、regexp，然而這樣的查詢的性能非常差，要知道用戶每多輸入一個新的字母，就意味著要重新進行一次搜索，在實時的 web 系統中，100 ms 可能就會是一個難以忍受的延遲 因此為了加快 輸入即搜索 的查詢效率，可以改使用 edge n-gram 建立索引，如此可以避免使用前綴查詢，在建立索引時就進行優化，使用空間換取時間，讓查詢的速率增快 使用 edge n-gram 建立索引\n假設有一個詞 hello，普通建索引時，就是把這個詞 hello 放入倒排索引\n用戶輸入 h、he時會找不到索引（倒排索引中只有 hello），因此匹配失敗 而對於輸入即搜索這種應用場景，可以使用一種特殊的 n-gram，稱爲 edge n-grams\n所謂的 edge n-gram，就是指它會固定詞語開始的一邊滑動窗口，他的結果取決於 n 的選擇長度\n以單詞 hello 爲例，它的 edge n-gram 的結果如下\nh he hel hell hello 因此可以發現到，在使用 edge n-gram 建索引時，一個單詞會生成好幾個索引，而這些索引一定是重頭開始\n這符合了輸入即搜索的特性，即是用戶打 h、he 能找到倒排中的索引 h、he，而這些索引對應著的數據就是 hello\n具體實例\n建立索引時使用 edge n-gram 的 token 過濾器，為每個經過這個 token 過濾器的詞條們，都生成從頭開始的字符組合\n假設有一個輸入 QUICK! RUN!，分詞器會先將它分詞成兩個詞 quick 和 run，此時這些詞再一一的通過 edge n-gram token 過濾器，產生了 8 個索引 q、qu、qui、quic、quick、r、ru、run，接著存入倒排索引中 如此，任何詞條像是 quick、run，都能生成他們自己的 n-gram 另外要注意，要額外定義一個 search_analyzer 分析器，供查詢使用\n原因是因為我們為了要保證倒排索引中包含各種組合的詞，所以在建索引時才加入了 edge n-gram 過濾器，然而在查詢時，我們只想匹配用戶輸入的完整詞組，像是用戶的輸入 run 或 qu\n因此需要定義兩套分析器，一套是建索引的分析器（包含edge n-gram 過濾器），另一套是查詢使用的正常的分析器\nPUT my_index { \u0026#34;settings\u0026#34;: { \u0026#34;number_of_shards\u0026#34;: 1, \u0026#34;analysis\u0026#34;: { \u0026#34;filter\u0026#34;: { //定義一個edge n-gram的token過濾器 //並設置任何通過這個過濾器的詞條，都會生成一個最小固定值為1，最大固定值為20的n-gram \u0026#34;my_autocomplete_filter\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;edge_ngram\u0026#34;, \u0026#34;min_gram\u0026#34;: 1, \u0026#34;max_gram\u0026#34;: 20 } }, \u0026#34;analyzer\u0026#34;: { //自定義一個分析器，並使用自定義的edge n-gram過濾器 \u0026#34;my_autocomplete_analyzer\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;custom\u0026#34;, \u0026#34;tokenizer\u0026#34;: \u0026#34;standard\u0026#34;, \u0026#34;filter\u0026#34;: [ \u0026#34;lowercase\u0026#34;, \u0026#34;my_autocomplete_filter\u0026#34; ] } } } }, \u0026#34;mapping\u0026#34;: { \u0026#34;my_type\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;name\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;analyzer\u0026#34;: \u0026#34;my_autocomplete_analyzer\u0026#34;, //在索引時用，生成edge n-gram的每個詞 \u0026#34;search_analyzer\u0026#34;: \u0026#34;standard\u0026#34; //查詢用，只搜索用戶輸入的詞 } } } } } 讓非 text 字段也能使用 edge n-gram\n由於 edge n-gram 是一個 token 過濾器，他包含在 analyzer 分析器裡面，因此只有 text 類型的字段才能使用（其他類型的字段不會被分詞，所以不會使用到 analyzer，因此不能用 edge n-gram）\n但是可能會有一種情況是，有些精確值也希望能通過 edge n-gram 生成組合，這時就要搭配使用一個叫做 keyword 的分詞器\n注意，此 keyword 分詞器和 keyword 字段類型是不同的東西 keyword 分詞器主要的功用是，將輸入的詞條，原封不動的 output 出來，不對其內容做任何改變 因此可以利用這個特性，將精確值的字段類型改成 text，但是分詞器使用 keyword，如此就可以避免分詞的效果，又能使用 edge n-gram 具體實例\n將 postcode 這個本來是 keyword 類型的精確值，改成使用 text 類型並搭配 keyword 分詞器\n因此假設有一個輸入 ABC EF，先經過 keyword 分詞器分詞成 ABC EF（和輸入一模一樣），接著再經過 edge n-gram 生成 A、AB、ABC、ABC （有一個空格） 、ABC E、ABC EF\n如果是使用正常的分詞器，生成的 edge n-gram 會是 A、AB、ABC、E、EF，他們是有差別的\nPUT my_index { \u0026#34;settings\u0026#34;: { \u0026#34;analysis\u0026#34;: { \u0026#34;filter\u0026#34;: { \u0026#34;postcode_filter\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;edge_ngram\u0026#34;, \u0026#34;min_gram\u0026#34;: 1, \u0026#34;max_gram\u0026#34;: 8 } }, \u0026#34;analyzer\u0026#34;: { \u0026#34;postcode_index\u0026#34;: { \u0026#34;tokenizer\u0026#34;: \u0026#34;keyword\u0026#34;, \u0026#34;filter\u0026#34;: [ \u0026#34;postcode_filter\u0026#34; ] }, \u0026#34;postcode_search\u0026#34;: { \u0026#34;tokenizer\u0026#34;: \u0026#34;keyword\u0026#34; } } } }, \u0026#34;mapping\u0026#34;: { \u0026#34;my_type\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;postcode\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;analyzer\u0026#34;: \u0026#34;postcode_index\u0026#34;, \u0026#34;search_analyzer\u0026#34;: \u0026#34;postcode_search\u0026#34; } } } } } ","permalink":"https://kucw.io/blog/2018/8/elasticsearch-instant-search/","tags":null,"title":"ElasticSearch - 輸入即搜索 edge n-gram"},{"categories":["Elastic Search"],"contents":" ES 的 bulk 語法允許在一個請求中進行多個操作（create、index、update、delete），也就是可以在一次請求裡做很多事情\n也由於這個關係，因此 bulk 的請求體和其他請求的格式會有點不同 bulk 的請求模板\n分成 action 和 metadata 兩部份 action : 必須是以下 4 種選項之一 index(最常用） : 如果文檔不存在就創建他，如果文檔存在就更新他 create : 如果文檔不存在就創建他，但如果文檔存在就返回錯誤 使用時一定要在 metadata 設置 _id 值，他才能去判斷這個文檔是否存在 update : 更新一個文檔，如果文檔不存在就返回錯誤 使用時也要給 _id 值，且後面文檔的格式和其他人不一樣 delete : 刪除一個文檔，如果要刪除的文檔 id 不存在，就返回錯誤 使用時也必須在 metadata 中設置文檔 _id，且後面不能帶一個 doc，因為沒意義，他是用 _id 去刪除文檔的 metadata : 設置這個文檔的 metadata，像是 _id、_index POST mytest/_bulk { action : { metadata } } { doc } { action : { metadata } } { doc } .... 具體實例\nbulk請求\nPOST mytest/_bulk //創建一筆數據 { \u0026#34;create\u0026#34; : { \u0026#34;_id\u0026#34;: 1 } } { \u0026#34;color\u0026#34;: \u0026#34;create black\u0026#34; } //創建一筆數據，因為id=1的文檔已經存在，所以會創建失敗 { \u0026#34;create\u0026#34; : { \u0026#34;_id\u0026#34;: 1 } } { \u0026#34;color\u0026#34;: \u0026#34;create black2\u0026#34; } //索引一筆數據 { \u0026#34;index\u0026#34; : { \u0026#34;_id\u0026#34;: 2 } } { \u0026#34;color\u0026#34;: \u0026#34;index red\u0026#34; } //索引一筆數據，但是index可以創建也可以更新，所以執行成功 { \u0026#34;index\u0026#34; : { \u0026#34;_id\u0026#34;: 2 } } { \u0026#34;color\u0026#34;: \u0026#34;index red2\u0026#34; } //索引一筆數據，不一定要設置id(index又能創建又能更新又不用設id，超好用) { \u0026#34;index\u0026#34;: {} } { \u0026#34;color\u0026#34;: \u0026#34;index blue\u0026#34; } //刪除一筆文檔，注意delete後面不接一個doc { \u0026#34;delete\u0026#34; : { \u0026#34;_id\u0026#34;: \u0026#34;2\u0026#34; } } //找不到此id的文檔，刪除失敗 { \u0026#34;delete\u0026#34; : { \u0026#34;_id\u0026#34;: \u0026#34;2\u0026#34; } } //更新一筆文檔，注意doc格式不太一樣 { \u0026#34;update\u0026#34; : { \u0026#34;_id\u0026#34;: 1 } } { \u0026#34;doc\u0026#34;: { \u0026#34;color\u0026#34;: \u0026#34;update green\u0026#34;} } //更新一筆文檔，但因為此id的文檔不存在，所以更新失敗 { \u0026#34;update\u0026#34; : { \u0026#34;_id\u0026#34;: 100 } } { \u0026#34;doc\u0026#34;: { \u0026#34;color\u0026#34;: \u0026#34;update green2\u0026#34;} } bulk 的返回結果\n因為在 bulk 中，每個 action 的執行結果都是獨立的，所以有幾個 action，就會有幾個返回結果，返回結果如下\n最上面會有一個 errors，表示這一次 bulk 請求中，是否有 action 出錯了 因此寫代碼時可以先檢查 errors 這個值，如果是 false，表示這次 bulk 請求全部通過，就不用再一一去檢查是否有 action 出錯，但如果是 true，則必須去 items 一個一個檢查到底是哪個 action 出錯了 items 是一個 array，裡面則放著每個 action 對應的結果，上面的請求執行了 9 個 action，所以返回結果的 items 就會有 9 個\n返回結果會依照 action 的順序排好，因此 items 的第一個結果就是請求時第一個 action 的執行結果 { \u0026#34;took\u0026#34;: 145, \u0026#34;errors\u0026#34;: true, \u0026#34;items\u0026#34;: [ { \u0026#34;create\u0026#34;: { \u0026#34;_index\u0026#34;: \u0026#34;mytest\u0026#34;, \u0026#34;_type\u0026#34;: \u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;result\u0026#34;: \u0026#34;created\u0026#34;, \u0026#34;status\u0026#34;: 201 } }, { \u0026#34;create\u0026#34;: { \u0026#34;_index\u0026#34;: \u0026#34;mytest\u0026#34;, \u0026#34;_type\u0026#34;: \u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;status\u0026#34;: 409, \u0026#34;error\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;version_conflict_engine_exception\u0026#34;, \u0026#34;reason\u0026#34;: \u0026#34;[1]: version conflict, document already exists (current version [1])\u0026#34;, \u0026#34;index_uuid\u0026#34;: \u0026#34;PfdgdTyiRgaCIM6uKRQAPQ\u0026#34;, \u0026#34;shard\u0026#34;: \u0026#34;0\u0026#34;, \u0026#34;index\u0026#34;: \u0026#34;mytest\u0026#34; } } }, { \u0026#34;index\u0026#34;: { \u0026#34;_index\u0026#34;: \u0026#34;mytest\u0026#34;, \u0026#34;_type\u0026#34;: \u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;2\u0026#34;, \u0026#34;result\u0026#34;: \u0026#34;created\u0026#34;, \u0026#34;status\u0026#34;: 201 } }, { \u0026#34;index\u0026#34;: { \u0026#34;_index\u0026#34;: \u0026#34;mytest\u0026#34;, \u0026#34;_type\u0026#34;: \u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;2\u0026#34;, \u0026#34;result\u0026#34;: \u0026#34;updated\u0026#34;, \u0026#34;status\u0026#34;: 200 } } ... 5 RESULTS REMOVED ... ] } 使用 bulk 要注意的地方\n如果使用 127.0.0.1/_bulk，那麼就是在整個 ES 的範圍中插入數據，因此在 metadata 中要指定插入的 index，優點是可以一次插入多筆數據到不同的索引 而如果使用 127.0.0.1/mytest/_bulk，就不用在 metadata 再次指定要插入的 index，可以想像成是 _bulk API幫我們自動填好了 metadata 的 _index，很方便 還有因為 bulk 和其他請求的格式不同，或是說基本上他已經不是正常的 json 格式了，所以在使用 bulk 時，HTTP header 要使用 application/x-ndjson 而且每一行的結尾，都要使用 \\n，如果是一般在 postman 寫請求不會有問題，但是如果是使用 curl 來發送請求，就要使用 --data-binary，才會使每一句的結尾都是 \\n 多大是太大了？\n由於整個 bulk 批量請求都需要由接收到請求的節點加載到內存中，因此該請求越大，其他請求所能獲得的內存就越少 批量請求的大小有一個最佳值，大於這個值，性能將不再提升，甚至會下降，但是最佳值不是一個固定的值，它完全取決於硬件、文檔的大小和複雜度、索引和搜索的負載的整體情況 幸運的是，很容易找到這個最佳點 ：可以通過批量索引文檔，並不斷增加批量大小進行嘗試，當性能開始下降時，那就表示你的批量大小太大了 一個好的辦法是開始時將 1000 到 5000 個文檔作爲一個批次慢慢增長，試圖找到最佳點 但是如果你的文檔非常大，那麼就必須減少批量的文檔個數，密切關注你的批量請求的物理大小往往非常有用，一千個 1KB 的文檔是完全不同於一千個 1MB 文檔所佔的物理大小，一個好的批量大小在開始處理後所佔用的物理大小約爲 5-15 MB ","permalink":"https://kucw.io/blog/2018/7/elasticsearch-bulk/","tags":null,"title":"ElasticSearch - 批量操作 bulk"},{"categories":["Intellij"],"contents":" 有时候在升级 IntelliJ 時會遇到 Error: java: invalid flag: -version 解決辦法 打開 File -\u0026gt; settings，搜索 Java compiler 此時會發現右下角的每一個 module 裡的 Compilation options 中，都多加了一個 -version 把每個 module 的 -version 都刪除掉，就可以正常運行了 ","permalink":"https://kucw.io/blog/2018/7/intellij-update-error/","tags":null,"title":"IntelliJ - 升級遇到的問題 Error: java: invalid flag: -version"},{"categories":["Linux"],"contents":" tail -f catalina.log : 實時看log，會自動把新增的log直接顯示出來\n在實時日誌上打印顏色，給每個狀態給上不同的顏色，INFO 綠色、WARN 黃色、ERROR 紅色\ntail -f catalina.out | perl -pe \u0026#39;s/(INFO)/\\e[0;32m$1\\e[0m/g,s/(WARN)/\\e[0;33m$1\\e[0m/g,s/(ERROR)/\\e[1;31m$1\\e[0m/g\u0026#39; 只看 ERROR\ntail -f catalina.out | grep \u0026#34;ERROR\u0026#34; --line-buffered | perl -pe \u0026#39;s/(ERROR)/\\e[1;31m$1\\e[0m/g\u0026#39; 在 .bashrc 下加入這一段，可以讓 tail 輸出 log 時有顏色\nalias tail=\u0026#34;_tail_log\u0026#34; _tail_log() { \u0026#34;tail\u0026#34; $@ | perl -pe \u0026#39;s/(INFO)/\\e[0;32m$1\\e[0m/g,s/(WARN)/\\e[0;33m$1\\e[0m/g,s/(ERROR)/\\e[1;31m$1\\e[0m/g\u0026#39; } less : 通常用來翻找舊的日誌\n輸入 F，也可以實時滾動日誌，就像 tail -f 的效果一樣\n在 .bashrc 下加入這一段，可以讓 less 在找 log 時輸出顏色\nhighlight 整條 log\nalias less=\u0026#34;_show_log\u0026#34; _show_log() { awk \u0026#39; /ERROR/ {printf(\u0026#34;\\033[1;31m%s\\033[0m\\n\u0026#34;, $0)} /WARN/ {printf(\u0026#34;\\033[1;33m%s\\033[0m\\n\u0026#34;, $0)} !/(WARN|ERROR)/ {printf(\u0026#34;%s\\n\u0026#34;, $0)} \u0026#39; $1 | \u0026#34;less\u0026#34; -r } 只highlight INFO、WARN、ERROR 這種狀態\nalias less=\u0026#34;_show_log\u0026#34; _show_log() { awk \u0026#39; /ERROR/ {sub(/ERROR/, \u0026#34;\\033[1;31mERROR\\033[0m\u0026#34;)} /WARN/ {sub(/WARN/, \u0026#34;\\033[1;33mWARN\\033[0m\u0026#34;)} /INFO/ {sub(/INFO/, \u0026#34;\\033[0;32mINFO\\033[0m\u0026#34;)} {print} \u0026#39; $1 | \u0026#34;less\u0026#34; -r } multitail : 可同時開啟多視窗看 log，適合用在看部署在很多機器上的項目的 log\n-cS [color_scheme] : 可以選擇輸出的 log 的顏色，推薦使用 goldengate，也可自定義（修改/etc/multitail.conf）\n-s [column number] : 設定看 log 時會分成幾個縱列\nmultitail -s 2 -cS goldengate -l \u0026#39;ssh [ip] \u0026#34;tail -100f /example/logs/catalina.out\u0026#34;\u0026#39; -cS goldengate -l \u0026#39;ssh [ip] \u0026#34;tail -100f /example/logs/catalina.out\u0026#34;\u0026#39; multitail 開始運作後，點擊 b，可以選擇要 scroll 的檔案，點擊 q 退出\n","permalink":"https://kucw.io/blog/2018/7/linux-log-command/","tags":null,"title":"Linux - 查看 Log 的指令 tail、multitail、less"},{"categories":["Elastic Search"],"contents":" 聚合概念 aggs # ElasticSearch 除了致力於搜索之外，也提供了聚合實時分析數據的功能 如果把搜索比喻為大海撈針（從海量的文檔中找出符合條件的那一個），那麼聚合就是去分析大海中的針們的特性，像是 在大海里有多少針？ 針的平均長度是多少？ 按照針的製造商來劃分，針的長度中位值是多少？ 每月加入到海中的針有多少？ 這裏面有異常的針麼？ 因此透過聚合，我們可以得到一個數據的概覽，聚合能做的是分析和總結全套的數據，而不是查找單個文檔（這是搜索做的事） 聚合允許我們向數據提出一些複雜的問題，雖然他的功能完全不同於搜索，但他們其實使用了相同的數據結構，這表示聚合的執行速度很快，並且就像搜索一樣幾乎是實時的 並且由於聚合和搜索是使用同樣的數據結構，因此聚合和搜索可以是一起執行的 這表示我們可以在一次 json 請求裡，同時對相同的數據進行 搜索/過濾 + 分析，兩個願望一次滿足 聚合的兩個主要的概念，分別是 桶 和 指標 桶（Buckets）: 滿足特定條件的文檔的集合 當聚合開始被執行，每個文檔會決定符合哪個桶的條件，如果匹配到，文檔將放入相應的桶並接着進行聚合操作 像是一個員工屬於男性桶或者女性桶，日期 2014-10-28 屬於十月桶，也屬於 2014 年桶 桶可以被嵌套在其他桶裏面 像是北京能放在中國桶裡，而中國桶能放在亞洲桶裡 Elasticsearch 提供了很多種類型的桶，像是時間、最受歡迎的詞、年齡區間、地理位置桶等等，不過他們在根本上都是通過同樣的原理進行操作，也就是基於條件來劃分文檔，一個文檔只要符合條件，就可以加入那個桶，因此一個文檔可以同時加入很多桶 指標（Metrics） : 對桶內的文檔進行統計計算 桶能讓我們劃分文檔到有意義的集合， 但是最終我們需要的是對這些桶內的文檔進行一些指標的計算 指標通常是簡單的數學運算（像是min、max、avg、sum），而這些是通過當前桶中的文檔的值來計算的，利用指標能讓你計算像平均薪資、最高出售價格、95 % 的查詢延遲這樣的數據 aggs 聚合的模板 當 query 和 aggs 一起存在時，會先執行 query 的主查詢，主查詢 query 執行完後會搜出一批結果，而這些結果才會被拿去 aggs 拿去做聚合 另外要注意 aggs 後面會先接一層自定義的這個聚合的名字，然後才是接上要使用的聚合桶 如果有些情況不在意查詢結果是什麼，而只在意 aggs 的結果，可以把 size 設為 0，如此可以讓返回的 hits 結果集是 0，加快返回的速度 一個 aggs 裡可以有很多個聚合，每個聚合彼此間都是獨立的，因此可以一個聚合拿來統計數量、一個聚合拿來分析數據、一個聚合拿來計算標準差\u0026hellip;，讓一次搜索就可以把想要做的事情一次做完 像是此例就定義了 3 個聚合，分別是 custom_name1、custom_name2、custom_name3 aggs 可以嵌套在其他的 aggs裡面，而嵌套的桶能作用的文檔集範圍，是外層的桶所輸出的結果集 GET mytest/doc/_search { \u0026#34;query\u0026#34;: { ... }, \u0026#34;size\u0026#34;: 0, \u0026#34;aggs\u0026#34;: { \u0026#34;custom_name1\u0026#34;: { //aggs後面接著的是一個自定義的name \u0026#34;桶\u0026#34;: { ... } //再來才是接桶 }, \u0026#34;custom_name2\u0026#34;: { //一個aggs裡可以有很多聚合 \u0026#34;桶\u0026#34;: { ... } }, \u0026#34;custom_name3\u0026#34;: { \u0026#34;桶\u0026#34;: { ..... }, \u0026#34;aggs\u0026#34;: { //aggs可以嵌套在別的aggs裡面 \u0026#34;in_name\u0026#34;: { //記得使用aggs需要先自定義一個name \u0026#34;桶\u0026#34;: { ... } //in_name的桶作用的文檔是custom_name3的桶的結果 } } } } } 結果 { \u0026#34;hits\u0026#34;: { \u0026#34;total\u0026#34;: 8, \u0026#34;max_score\u0026#34;: 0, \u0026#34;hits\u0026#34;: [] //因為size設為0，所以沒有查詢結果返回 }, \u0026#34;aggregations\u0026#34;: { \u0026#34;custom_name1\u0026#34;: { ... }, \u0026#34;custom_name2\u0026#34;: { ... }, \u0026#34;custom_name3\u0026#34;: { ... , \u0026#34;in_name\u0026#34;: { .... } } } } terms桶 # 功能 : 針對某個 field 的值進行分組，field 有幾種值就分成幾組 terms 桶在進行分組時，會爲此 field 中的每種值創建一個新的桶 要注意此 \u0026ldquo;terms桶\u0026rdquo; 和平常用在主查詢 query 中的 \u0026ldquo;查找terms\u0026rdquo; 是不同的東西 具體實例 首先插入幾筆數據，其中 color 是一個 keyword 類型 { \u0026#34;color\u0026#34;: \u0026#34;red\u0026#34; } { \u0026#34;color\u0026#34;: \u0026#34;green\u0026#34; } { \u0026#34;color\u0026#34;: [\u0026#34;red\u0026#34;, \u0026#34;blue\u0026#34;] } 執行 terms 桶聚合 GET mytest/doc/_search { \u0026#34;query\u0026#34;: { \u0026#34;match_all\u0026#34;: {} }, \u0026#34;size\u0026#34;: 0, \u0026#34;aggs\u0026#34;: { \u0026#34;my_name\u0026#34;: { \u0026#34;terms\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;color\u0026#34;, //使用color來進行分組 } } } } 結果 因為 color 總共有 3 種值，red、blue、green，所以 terms 桶為他們產生了 3 個 bucket，並計算了每個 bucket 中符合的文檔有哪些 bucket 和 bucket 間是獨立的，也就是說一個文檔可以同時符合好幾個 bucket，像是 {\u0026quot;color\u0026quot;: [\u0026quot;red\u0026quot;, \u0026quot;blue\u0026quot;]} 就同時符合了 red 和 blue bucket \u0026#34;aggregations\u0026#34;: { \u0026#34;my_name\u0026#34;: { \u0026#34;doc_count_error_upper_bound\u0026#34;: 0, \u0026#34;sum_other_doc_count\u0026#34;: 0, \u0026#34;buckets\u0026#34;: [ //terms桶產生的buckets數組，裡面每個json對象都是一個bucket { \u0026#34;key\u0026#34;: \u0026#34;blue\u0026#34;, \u0026#34;doc_count\u0026#34;: 1 }, { \u0026#34;key\u0026#34;: \u0026#34;red\u0026#34;, //表示color為red的文檔有2個，此例中就是 {\u0026#34;color\u0026#34;: \u0026#34;red\u0026#34;} 和 {\u0026#34;color\u0026#34;: [\u0026#34;red\u0026#34;, \u0026#34;blue\u0026#34;]}這兩個文檔 \u0026#34;doc_count\u0026#34;: 2 }, { \u0026#34;key\u0026#34;: \u0026#34;green\u0026#34;, \u0026#34;doc_count\u0026#34;: 1 } ] } } 可以在參數帶上 min_doc_count 限制當 doc 數大於等於 n 筆時才會被搜出來，也可以帶上 size 參數，指名要顯示 bucket 中多少筆數據，默認是 10 GET mytest/doc/_search { \u0026#34;query\u0026#34;: { \u0026#34;match_all\u0026#34;: {} }, \u0026#34;size\u0026#34;: 0, \u0026#34;aggs\u0026#34;: { \u0026#34;my_name\u0026#34;: { \u0026#34;terms\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;color\u0026#34;, \u0026#34;size\u0026#34;: 100, //可以設置size，指定返回的桶數量，預設是10，如果總共桶數不超過100，那就會全部返回 \u0026#34;min_doc_count\u0026#34;: 2 //bucket中只有當doc_count \u0026gt;= 2的人，才會被搜出來 } } } } 結果 \u0026#34;aggregations\u0026#34;: { \u0026#34;my_name\u0026#34;: { \u0026#34;doc_count_error_upper_bound\u0026#34;: 0, \u0026#34;sum_other_doc_count\u0026#34;: 0, \u0026#34;buckets\u0026#34;: [ //因為設置了min_doc_count:2，所有只有red桶被搜出來 { \u0026#34;key\u0026#34;: \u0026#34;red\u0026#34;, \u0026#34;doc_count\u0026#34;: 2 } ] } } 具體實例二 將 terms 桶搭配度量指標（avg、min、max、sum\u0026hellip;）一起使用 其實度量指標也可以看成一種\u0026quot;桶\u0026quot;，他可以和其他正常的桶們進行嵌套作用，差別只在指標關注的是這些文檔中的某個數值的統計，而桶關注的是文檔 首先準備數據，color 一樣為 keyword 類型，而 price 為 integer 類型 { \u0026#34;color\u0026#34;: \u0026#34;red\u0026#34;, \u0026#34;price\u0026#34;: 100 } { \u0026#34;color\u0026#34;: \u0026#34;green\u0026#34;, \u0026#34;price\u0026#34;: 500 } { \u0026#34;color\u0026#34;: [\u0026#34;red\u0026#34;, \u0026#34;blue\u0026#34;], \u0026#34;price\u0026#34;: 1000 } 將 avg 指標嵌套在 terms 桶裡一起使用 GET mytest/doc/_search { \u0026#34;query\u0026#34;: { \u0026#34;match_all\u0026#34;: {} }, \u0026#34;size\u0026#34;: 0, \u0026#34;aggs\u0026#34;: { \u0026#34;my_name\u0026#34;: { \u0026#34;terms\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;color\u0026#34; }, \u0026#34;aggs\u0026#34;: { //嵌套兩個指標avg、min在terms桶中 \u0026#34;my_avg_price\u0026#34;: { //my_avg_price計算每個bucket的平均price \u0026#34;avg\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;price\u0026#34; } }, \u0026#34;my_min_price\u0026#34;: { //my_min_price計算每個bucket中的最小price \u0026#34;min\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;price\u0026#34; } } } } } } 結果 \u0026#34;aggregations\u0026#34;: { \u0026#34;my_name\u0026#34;: { \u0026#34;doc_count_error_upper_bound\u0026#34;: 0, \u0026#34;sum_other_doc_count\u0026#34;: 0, \u0026#34;buckets\u0026#34;: [ //terms桶中的每個bucket都會計算avg和min兩個指標 { \u0026#34;key\u0026#34;: \u0026#34;blue\u0026#34;, \u0026#34;doc_count\u0026#34;: 1, \u0026#34;my_avg_price\u0026#34;: { //avg指標 \u0026#34;value\u0026#34;: 1000 }, \u0026#34;my_min_price\u0026#34;: { //min指標 \u0026#34;value\u0026#34;: 100 } }, { \u0026#34;key\u0026#34;: \u0026#34;red\u0026#34;, \u0026#34;doc_count\u0026#34;: 2, //avg指標計算的值，因為符合color為red的文檔有兩筆，所以平均price為100+1000/2 = 550 \u0026#34;my_avg_price\u0026#34;: { \u0026#34;value\u0026#34;: 550 }, \u0026#34;my_min_price\u0026#34;: { \u0026#34;value\u0026#34;: 100 } }, { \u0026#34;key\u0026#34;: \u0026#34;green\u0026#34;, \u0026#34;doc_count\u0026#34;: 1, \u0026#34;my_avg_price\u0026#34;: { \u0026#34;value\u0026#34;: 500 }, \u0026#34;my_min_price\u0026#34;: { \u0026#34;value\u0026#34;: 500 } } ] } } 具體實例三 使用 terms 桶時，只聚合感興趣的 bucket，其他 bucket 都不聚合 使用 terms 桶支持的 include 和 exclude 參數來設定哪些 bucket 的值要聚合，哪些 bucket 的值不聚合 當 include 和 exclude 的規則有重疊的部份時，優先使用 exclude 的 include 和 exclude 都支持設置特定值、數組、以及正則 準備數據 { \u0026#34;color\u0026#34;: [\u0026#34;red\u0026#34;, \u0026#34;green\u0026#34;] } { \u0026#34;color\u0026#34;: [\u0026#34;red\u0026#34;, \u0026#34;blue\u0026#34;] } 聚合時只聚合我們感興趣的 bucket，也就是 color 為 red 的文檔有多少，其他的 bucket 不聚合 GET mytest/doc/_search { \u0026#34;query\u0026#34;: { \u0026#34;match_all\u0026#34;: {} }, \u0026#34;size\u0026#34;: 0, \u0026#34;aggs\u0026#34;: { \u0026#34;my_name\u0026#34;: { \u0026#34;terms\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;color\u0026#34;, \u0026#34;include\u0026#34;: \u0026#34;red\u0026#34; //include也支持數組和正則 } } } } 結果 \u0026#34;aggregations\u0026#34;: { \u0026#34;my_name\u0026#34;: { \u0026#34;doc_count_error_upper_bound\u0026#34;: 0, \u0026#34;sum_other_doc_count\u0026#34;: 0, //本來是有三個bucket的，但是因為設置了include，所以只聚合計算了一個bucket red \u0026#34;buckets\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;red\u0026#34;, \u0026#34;doc_count\u0026#34;: 2 } ] } } filter桶 # 功能 : 一個用來過濾的桶 此處的 \u0026ldquo;filter 桶\u0026rdquo; 和用在主查詢 query 的 \u0026ldquo;過濾 filter\u0026rdquo; 的用法是一模一樣的，都是過濾 不過差別是 \u0026ldquo;filter 桶\u0026rdquo; 會自己給創建一個新的桶，而不會像 \u0026ldquo;過濾 filter\u0026rdquo; 一樣依附在 query 下 因為 filter 桶畢竟還是一個聚合桶，因此他可以和別的桶進行嵌套，但他不是依附在別的桶上 具體實例 取得 color 為 red 或是 blue 的文檔 GET mytest/doc/_search { \u0026#34;query\u0026#34;: { \u0026#34;match_all\u0026#34;: {} }, \u0026#34;size\u0026#34;: 0, \u0026#34;aggs\u0026#34;: { \u0026#34;my_name\u0026#34;: { \u0026#34;filter\u0026#34;: { //此處是一個filter桶，因為他用法跟一般的過濾filter一樣，所以也能使用bool嵌套 \u0026#34;bool\u0026#34;: { \u0026#34;must\u0026#34;: { \u0026#34;terms\u0026#34;: { //注意此terms是查找terms，不是terms桶 \u0026#34;color\u0026#34;: [ \u0026#34;red\u0026#34;, \u0026#34;blue\u0026#34; ] } } } } } } } 結果 \u0026#34;aggregations\u0026#34;: { \u0026#34;my_name\u0026#34;: { \u0026#34;doc_count\u0026#34;: 2 //filter桶計算出來的文檔數量 } } 具體實例二 filter 桶和 terms 桶嵌套使用，先過濾出 color 為 red 或 blue 的文檔，再對這些文檔進行 color 分組 GET mytest/doc/_search { \u0026#34;query\u0026#34;: { \u0026#34;match_all\u0026#34;: {} }, \u0026#34;size\u0026#34;: 0, \u0026#34;aggs\u0026#34;: { \u0026#34;my_name\u0026#34;: { //my_name聚合 \u0026#34;filter\u0026#34;: { //filter桶 \u0026#34;bool\u0026#34;: { \u0026#34;must\u0026#34;: { \u0026#34;terms\u0026#34;: { \u0026#34;color\u0026#34;: [ \u0026#34;red\u0026#34;, \u0026#34;blue\u0026#34; ] } } } }, \u0026#34;aggs\u0026#34;: { \u0026#34;my_name2\u0026#34;: { //my_name2聚合，嵌套在my_name聚合裡 \u0026#34;terms\u0026#34;: { //terms桶 \u0026#34;field\u0026#34;: \u0026#34;color\u0026#34; } } } } } } 結果 因為 terms 桶嵌套在 filter 桶內，所以 query 查詢出來的文檔們會先經過 filter 桶，如果符合 filter 桶，才會進入到 terms 桶內 此處通過 filter 桶的文檔只有兩筆，分別是 {\u0026quot;color\u0026quot;: \u0026quot;red\u0026quot;}以及{\u0026quot;color\u0026quot;: [\u0026quot;red\u0026quot;, \u0026quot;blue\u0026quot;]}，所以 terms 桶只會對這兩筆文檔做分組 這也是為什麼 terms 桶裡沒有出現 color 為 green 的分組，因為這個文檔在 filter 桶就被擋下來了 \u0026#34;aggregations\u0026#34;: { \u0026#34;my_name\u0026#34;: { \u0026#34;doc_count\u0026#34;: 2, //filter桶計算的數量，通過此處的文檔只有2筆 \u0026#34;my_name2\u0026#34;: { \u0026#34;doc_count_error_upper_bound\u0026#34;: 0, \u0026#34;sum_other_doc_count\u0026#34;: 0, \u0026#34;buckets\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;red\u0026#34;, \u0026#34;doc_count\u0026#34;: 2 //terms桶計算的數量 }, { \u0026#34;key\u0026#34;: \u0026#34;blue\u0026#34;, \u0026#34;doc_count\u0026#34;: 1 //terms桶計算的數量 } ] } } } 多桶排序 # terms 桶、histogram 桶、data_histogram 桶這些桶屬於多值桶，也就是說他們會動態生成很多桶，對於這些生成出來的桶們，ES 默認會使用 doc_value 進行降序排序，也就是說哪個生成桶的 doc_value 文檔數較多，哪個生成桶就排在前面 如果想要改變這個生成桶與生成桶之間的排序，可以在使用 terms 桶、histogram 桶、data_histogram 桶時，使用 order 進行排序 order 支持的參數 _count : 按照文檔數排序 _term : 按照每個桶的字符串值的字母順序排序 具體實例 準備數據，color 是 keyword 類型 { \u0026#34;color\u0026#34;: \u0026#34;red\u0026#34;, \u0026#34;price\u0026#34;: 100 } { \u0026#34;color\u0026#34;: [\u0026#34;red\u0026#34;, \u0026#34;blue\u0026#34;], \u0026#34;price\u0026#34;: 1000 } 使用 terms 桶進行分組，並且規定按照桶的字母順序升序，因此 a 生成桶會排在最前面而 z 生成桶會排在最後面 GET mytest/doc/_search { \u0026#34;query\u0026#34;: { \u0026#34;match_all\u0026#34;: {} }, \u0026#34;size\u0026#34;: 0, \u0026#34;aggs\u0026#34;: { \u0026#34;my_name\u0026#34;: { \u0026#34;terms\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;color\u0026#34;, \u0026#34;order\u0026#34;: { \u0026#34;_term\u0026#34;: \u0026#34;asc\u0026#34; } } } } } 結果 \u0026#34;aggregations\u0026#34;: { \u0026#34;my_name\u0026#34;: { \u0026#34;doc_count_error_upper_bound\u0026#34;: 0, \u0026#34;sum_other_doc_count\u0026#34;: 0, \u0026#34;buckets\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;blue\u0026#34;, \u0026#34;doc_count\u0026#34;: 1 }, { \u0026#34;key\u0026#34;: \u0026#34;red\u0026#34;, \u0026#34;doc_count\u0026#34;: 2 } ] } } ","permalink":"https://kucw.io/blog/2018/7/elasticsearch-aggs/","tags":null,"title":"ElasticSearch - 聚合 aggs"},{"categories":["Java"],"contents":" ThreadLocal 是線程的局部變量， 是每一個線程所單獨持有的，其他線程不能對其進行訪問\nThreadLocal 支持泛型，也就是支持 value 是可以設置類型的，像是 ThreadLocal\u0026lt;Date\u0026gt; 就是設置 value 為 Date 類型 每個線程會有自己的一份 ThreadLocalMap 變量，去儲存這個線程自己想存放的 ThreadLocal 變量們，他內部儲存的是一個鍵值對 Map，其中 key 是某個 ThreadLocal，value 就是這個線程自己 set 的值，所以對於一個線程來說，一個 ThreadLocal 只能存一個值，而一個線程可以存放好多個 ThreadLocal 因此當調用 ThreadLocal tl 的 tl.get() 方法時，其實就是先去取得此線程的 ThreadLocalMap，然後再去查找這個 Map 中的 key 為 tl 的那個 Entry 的 value 值 ThreadLocal 常用的方法\nset(x) : 設置此線程的想要放的值是多少 get() : 取得此線程當初存放的值，如果沒有存放過則返回 null remove() : 刪除此線程的鍵值對，也就是如果先執行 remove 再執行 get，會返回 null ThreadLocal 通常用在 SimpleDateFormat，或是 SpringMVC 上\n因為 SimpleDateFormat 不是線程安全的，因此雖然可以每次要使用的時候重新 new 一個，但是這樣做會很浪費資源，所以如果使用 ThreadLocal 在每個線程裡都存放一個此線程專用的 SimpleDateFormat，就可以避免一直 new 的資源浪費，又確保線程安全 因為 SpringMVC 會對每個請求分配一個線程，可以在攔截器將此線程的用戶信息（ip、名字\u0026hellip;）使用 ThreadLocal 儲存，這樣在後續要用到用戶信息的地方時，就可以去 ThreadLocal 中取得，而且因為 ThreadLocal 可以隔離線程，因此每條請求對應的線程的用戶信息不會互相干擾 ThreadLocal 可能造成的內存洩漏\n在Java裡，每個線程都有自己的 ThreadLocalMap，裡面存著這個線程自己私有的 ThreadLocal 們，而 ThreadLocalMap 的 key 為 ThreadLocal 實例，value 為私有對象 T，即是透過 set() 設置的值\npublic class Thread implements Runnable { //Thread類裡的threadlocals存放此線程的專有的ThreadLocalMap ThreadLocal.ThreadLocalMap threadLocals = null; } public class ThreadLocal\u0026lt;T\u0026gt; { //根據線程，取得那個線程自己的ThreadLocalMap ThreadLocalMap getMap(Thread t) { return t.threadLocals; } static class ThreadLocalMap { //ThreadLocalMap的key是使用 \u0026#34;弱引用\u0026#34; 的ThreadLocal static class Entry extends WeakReference\u0026lt;ThreadLocal\u0026gt; { Object value; //ThreadLocalMap中的key就是ThreadLocal，value就是設置的值 Entry(ThreadLocal k, Object v) { super(k); value = v; } } } } 可以創建許多個 ThreadLocal 對象，對每個 ThreadLocal 都設置不同的值\n像是以下的例子，在 main 線程中的 ThreadLocalMap，就有兩個 key-value 的映射，分別是 userIdThreadLocal -\u0026gt; 100、userNameThreadLocal -\u0026gt; hello\npublic class Main { public static void main(String[] args){ ThreadLocal\u0026lt;Integer\u0026gt; userIdThreadLocal = new ThreadLocal\u0026lt;\u0026gt;(); ThreadLocal\u0026lt;String\u0026gt; userNameThreacLocal = new ThreadLocal\u0026lt;\u0026gt;(); userId.set(100); userName.set(\u0026#34;hello\u0026#34;); } } 之所以 ThreadLocal 會發生內存洩漏，原因是因為只要線程活著，這個線程的 ThreadLocalMap 就會一直活著，而當初透過 ThreadLocal set() 的值，也就會在 ThreadLocalMap 中一直存在這個鍵值對不消失，所以該 ThreadLocal 和該 value 的內存地址始終都有這個 ThreadLocalMap 在引用著，導致 GC 無法回收他，所以才會發生內存洩漏\n為了解決這個問題，java 做了一個小優化，也就是存放在 ThreadLocalMap 中的 ThreadLocal，會使用 弱引用 來儲存，也就是說，如果一個 ThreadLocal 內存地址沒有外部強引用來引用他，只有這條 ThreadLocalMap 的弱引用來引用他時，那麼當系統 GC 時，這些 ThreadLocal 就會被回收（因為是弱引用），如此一來，ThreadLocalMap 中就會出現 key 為 null 的 Entry 們\n下圖中，實線表示強引用，虛線表示弱引用 這個弱引用優化只能使得 ThreadLocal 被正確回收，但是這些 key 為 null 的 Entry 們仍然會存在在 ThreadLocalMap 裡，因此 value 仍然無法被回收\n所以 java 又做了一個優化，就是在 ThreadLocal 執行 get()、set()、remove() 方法時，都會將該線程 ThreadLocalMap 裡所有 key = null 的 value 也設置為 null，手動幫助 GC\nThreadLocal k = e.get(); if (k == null) { e.value = null; // Help the GC } 但是根本上的解決辦法，還是在當前線程使用完這個 ThreadLocal 時，就即時的 remove() 掉該 value，也就是使得 ThreadLocalMap 中不要存在這個鍵值對，這樣才能確保 GC 能正確回收\n具體實例\n每個線程都可以在 ThreadLocal 中放自己的值，且不會干擾到其他線程的值\nclass Tools { public static ThreadLocal threadLocal = new ThreadLocal(); } class MyThread extends Thread { @Override public void run() { if (Tools.threadLocal.get() == null) { Tools.threadLocal.set(Thread.currentThread().getName() + \u0026#34;, \u0026#34; + Math.random()); } System.out.println(Tools.threadLocal.get()); } } public class Main { public static void main(String[] args) { for (int i = 0; i \u0026lt; 5; i++) { MyThread thread = new MyThread(); thread.setName(\u0026#34;thread \u0026#34; + i); thread.start(); } } } thread 1, 0.86 thread 0, 0.42 thread 2, 0.35 thread 3, 0.41 thread 4, 0.45 使用 ThreadLocal 在 SimpleDateFormat 上，並且給 ThreadLocal 加上泛型，指定 value 的類型是 SimpleDateFormat\n因為使用了 ThreadLocal 確保每個線程有自己一份 SimpleDateFormat，所以線程安全，不會報錯\nclass Tools { public static ThreadLocal\u0026lt;SimpleDateFormat\u0026gt; threadLocal = new ThreadLocal\u0026lt;SimpleDateFormat\u0026gt;(); } class MyThread extends Thread { @Override public void run() { SimpleDateFormat sdf = Tools.threadLocal.get(); if (sdf == null) { sdf = new SimpleDateFormat(\u0026#34;yyyy-MM-dd\u0026#34;); Tools.threadLocal.set(sdf); } try { System.out.println(sdf.parse(\u0026#34;2018-07-15\u0026#34;)); } catch (ParseException e) { System.out.println(\u0026#34;報錯了\u0026#34;); } } } public class Main { public static void main(String[] args) { for (int i = 0; i \u0026lt; 5; i++) { MyThread thread = new MyThread(); thread.setName(\u0026#34;thread \u0026#34; + i); thread.start(); } } } Sun Jul 15 00:00:00 CST 2018 Sun Jul 15 00:00:00 CST 2018 Sun Jul 15 00:00:00 CST 2018 Sun Jul 15 00:00:00 CST 2018 Sun Jul 15 00:00:00 CST 2018 使用 ThreadLocal 在 SpringMVC上\n攔截器 MyInterceptor 先去從 cookie 中取得當前用戶信息，透過 UserUtils 放到 ThreadLocal\u0026lt;User\u0026gt; 裡\n然後當 MyController 要去取得這個請求（也就是這條線程）的用戶信息時，就去調用 UserUtils 取得放在 ThreadLocal\u0026lt;User\u0026gt; 裡面的 User 信息\n最後當請求結束時，刪除此條線程的 ThreadLocal\u0026lt;User\u0026gt; 信息，避免內存洩漏\n//UserUtils專門存取User信息 public class UserUtils { public static ThreadLocal\u0026lt;User\u0026gt; userThreadLocal = new ThreadLocal\u0026lt;\u0026gt;(); public static void setUser(User user) { userThreadLocal.set(user); } public static User getUser() { return userThreadLocal.get(); } public static void removeUser() { if (userThreadLocal.get() != null) { userThreadLocal.remove(); } } } //攔截器取得cookie中的User信息，並調用UserUtils放到ThreadLocal裡 //請求結束時要記得把ThreadLocal中的User刪除，因為這條線程之後還要去服務其他請求 public class MyInterceptor extends HandlerInterceptorAdapter { @Override public boolean preHandle() throws Exception { User user = getUserFromCookie(); UserUtils.setUser(user); return true; } @Override public void postHandle() throws Exception { UserUtils.removeUser(); } } //MyContoller調用UserUtils取得ThreadLocal\u0026lt;User\u0026gt;中的User @Controller @RequestMapping(\u0026#34;/\u0026#34;) public class MyController { @RequestMapping(\u0026#34;/\u0026#34;) public void test() { User user = UserUtils.getUser(); System.out.println(\u0026#34;User id: \u0026#34; + user.id); } } ","permalink":"https://kucw.io/blog/2018/7/java-thread-local/","tags":null,"title":"Java - ThreadLocal 類的使用"},{"categories":["Spring Boot"],"contents":" Spring 中，使用注解 @Autowired 進行注入好，還是使用 xml 配置進行注入好？ 先講結論，使用注解 @Autowired 注入比較好 當時 Spring 開發的初衷是為了解決類與類之間的強耦合 new，所以當時提出了 xml 配置注入bean的方法，就是讓代碼只關注我需要什麼 service，但此 service 是由哪個實現類提供的我並不關心 使用 xml 的好處就是，實現類更換的時候並不需要去改動代碼，只要去改動 xml 配置，將注入的 bean 改成另一個實現類就可以了，如此可以達到類與類之間的松耦合 但是到了 Spring3.0 之後，他們開始提出了使用 @Autowired 注解來進行 bean 的注入 有的人可能會覺得，如果使用 @Autowired、@Qualifier 來注入，那麼假設我要改注入實現類的話，得去改 java 代碼中的 @Qualifier，那這樣還是得改代碼，那這樣使用 Spring 注入和使用 new，又有什麼差別？是不是還是使用 xml 比較好？ 事實上，使用注解確實會有這個問題沒錯，不過經過長時間的項目經驗下來，你會發現，我們其實很少會去改注入的實現類的（天天改服務還要不要命?） 而注解提供的好處卻是不少，像是簡化 xml 配置的冗長、使用注解比較直觀且容易、並且是類型安全的（compiler 可以掃描注解，判斷注入的類型是否正確，但他掃描不了 xml 文件) 因此就算使用注解 @Autowired 去改變注入的實現類比 xml 更困難，但他其他大量的優點足以掩蓋過這個缺點，這也是為什麼 Spring 覺得使用注解配置比使用 xml 配置更好的理由 所以到目前為止（Spring4.0），雖然 Spring 官方本身沒有明說拋棄 xml 配置，不過事實上 Spring 已經轉往注解配置方向前進了，SpringBoot 就是最好的例子 SpringBoot 中只有一個 properties 文件負責配置一些不可避免的設定，像是數據庫連接、mvc 模板配置\u0026hellip;.，除此之外沒有任何一個 xml 文件來定義 bean，全部都是使用注解來配置 注解 vs xml 優缺點比較 注解 優點 : 簡化配置、使用起來直觀且容易，提升開發效率、類型安全 缺點 : 改變實現類比 xml 困難 xml 優點 : 類與類間的松耦合，容易擴展、更換、對象間的關係一目了然 缺點 : 配置冗長，且還要額外多維護一份配置，類型不安全，compiler 無法幫忙校驗，運行期才會發現錯誤 ","permalink":"https://kucw.io/blog/2018/7/spring-annotation-vs-xml/","tags":null,"title":"Spring Boot - 注解 vs XML 哪個好？"},{"categories":["Elastic Search"],"contents":" 閱讀本文需要先了解 function_score 的相關知識，請看 ElasticSearch - function_score 簡介\n很多變量都可以影響用戶對於酒店的選擇，像是用戶可能希望酒店離市中心近一點，但是如果價格足夠便宜，也願意為了省錢，妥協選擇一個更遠的住處\n如果我們只是使用一個 filter 排除所有市中心方圓 100 米以外的酒店，再用一個 filter 排除每晚價格超過 100 元的酒店，這種作法太過強硬，可能有一間房在 500 米，但是超級便宜一晚只要 10 元，用戶可能會因此願意妥協住這間房 為了解決這個問題，因此 function_score 查詢提供了一組 衰減函數（decay functions）， 讓我們有能力在兩個滑動標準（如地點和價格）之間權衡 function_score 支持的衰減函數有三種，分別是 linear、exp 和 gauss\nlinear、exp、gauss 三種衰減函數的差別只在於衰減曲線的形狀，在 DSL 的語法上的用法完全一樣 linear : 線性函數是條直線，一旦直線與橫軸 0 相交，所有其他值的評分都是 0 exp : 指數函數是先劇烈衰減然後變緩 guass（最常用） : 高斯函數則是鐘形的，他的衰減速率是先緩慢，然後變快，最後又放緩 衰減函數們（linear、exp、gauss）支持的參數 origin : 中心點，或是字段可能的最佳值，落在原點（origin）上的文檔評分 _score 為滿分 1.0，支持數值、時間 以及 \u0026ldquo;經緯度地理座標點\u0026rdquo;（最常用）的字段 offset : 從 origin 為中心，為他設置一個偏移量 offset 覆蓋一個範圍，在此範圍內所有的評分 _score 也都是和 origin 一樣滿分 1.0 scale : 衰減率，即是一個文檔從 origin 下落時，_score 改變的速度 decay : 從 origin 衰減到 scale 所得的評分_score，默認為 0.5（一般不需要改變，這個參數使用默認的就好了） 以上面的圖為例 所有曲線（linear、exp、gauss）的 origin 都是 40，offset 是 5，因此範圍在 40-5 \u0026lt;= value \u0026lt;= 40+5 的文檔的評分 _score 都是滿分 1.0 而在此範圍之外，評分會開始衰減，衰減率由 scale 值（此處是5）和 decay 值（此處是默認值0.5）決定，在 origin +/- (offset + scale) 處的評分是 decay 值，也就是在 30、50 的評分處是 0.5 分 也就是說，在 origin + offset + scale 或是 origin - offset - scale 的點上，得到的分數僅有 decay 分 具體實例一\n先準備數據和索引，在 ES 插入三筆數據，其中 language 是 keyword 類型，like 是 integer 類型（代表點贊量）\n{ \u0026#34;language\u0026#34;: \u0026#34;java\u0026#34;, \u0026#34;like\u0026#34;: 5 } { \u0026#34;language\u0026#34;: \u0026#34;python\u0026#34;, \u0026#34;like\u0026#34;: 10 } { \u0026#34;language\u0026#34;: \u0026#34;go\u0026#34;, \u0026#34;like\u0026#34;: 15 } 以 like = 15 為中心，使用 gauss 函數\nGET mytest/doc/_search { \u0026#34;query\u0026#34;: { \u0026#34;function_score\u0026#34;: { \u0026#34;query\u0026#34;: { \u0026#34;match_all\u0026#34;: {} }, \u0026#34;functions\u0026#34;: [ { \u0026#34;gauss\u0026#34;: { \u0026#34;like\u0026#34;: { \u0026#34;origin\u0026#34;: \u0026#34;15\u0026#34;, //如果不設置offset，offset默認為0 \u0026#34;scale\u0026#34;: \u0026#34;5\u0026#34;, \u0026#34;decay\u0026#34;: \u0026#34;0.2\u0026#34; } } } ] } } } \u0026#34;hits\u0026#34;: [ { \u0026#34;_score\u0026#34;: 1, \u0026#34;_source\u0026#34;: { \u0026#34;language\u0026#34;: \u0026#34;go\u0026#34;, \u0026#34;like\u0026#34;: 15 } }, { //因為改變了decay=0.2，所以當位於 origin-offset-scale=10 的位置時，分數為decay，就是0.2 \u0026#34;_score\u0026#34;: 0.2, \u0026#34;_source\u0026#34;: { \u0026#34;language\u0026#34;: \u0026#34;python\u0026#34;, \u0026#34;like\u0026#34;: 10 } }, { \u0026#34;_score\u0026#34;: 0.0016, \u0026#34;_source\u0026#34;: { \u0026#34;language\u0026#34;: \u0026#34;java\u0026#34;, \u0026#34;like\u0026#34;: 5 } } ] 具體實例二\n假設有一個用戶希望租一個離市中心近一點的酒店，且每晚不超過 100 元的酒店，而且與距離相比，我們的用戶對價格更敏感，那麼使用衰減函數 gauss 查詢如下 其中把 price 語句的 origin 點設為 50 是有原因的，由於價格的特性一定是越低越好，所以 0 ~ 100 元的所有價格的酒店都應該認為是比較好的，而 100 元以上的酒店就慢慢衰減 如果我們將 price 的 origin 點設置成100，那麼價格低於 100 元的酒店的評分反而會變低，這不是我們期望的結果，與其這樣不如將 origin 和 offset 同時設成 50，只讓 price 大於 100 元時評分才會變低 雖然這樣設置也會使得 price 小於 0 元的酒店評分降低沒錯，不過現實生活中價格不會有負數，因此就算 price \u0026lt; 0 的評分會下降，也不會對我們的搜索結果造成影響（酒店的價格一定都是正的） 換句話說，其實只要把 origin + offset 的值設為 100，origin 或 offset 是什麼樣的值都無所謂，只要能確保酒店價格在 100 元以上的酒店會衰減就好了 GET mytest/doc/_search { \u0026#34;query\u0026#34;: { \u0026#34;function_score\u0026#34;: { \u0026#34;query\u0026#34;: { \u0026#34;match_all\u0026#34;: {} } \u0026#34;functions\u0026#34;: [ //第一個gauss加強函數，決定距離的衰減率 { \u0026#34;gauss\u0026#34;: { \u0026#34;location\u0026#34;: { \u0026#34;origin\u0026#34;: { //origin點設成市中心的經緯度座標 \u0026#34;lat\u0026#34;: 51.5, \u0026#34;lon\u0026#34;: 0.12 }, \u0026#34;offset\u0026#34;: \u0026#34;2km\u0026#34;, //距離中心點2km以內都是滿分1.0，2km外開始衰減 \u0026#34;scale\u0026#34;: \u0026#34;3km\u0026#34; //衰減率 } } }, //第二個gauss加強函數，決定價格的衰減率 //因為用戶對價格更敏感，所以給了這個gauss加強函數2倍的權重 { \u0026#34;gauss\u0026#34;: { \u0026#34;price\u0026#34;: { \u0026#34;origin\u0026#34;: \u0026#34;50\u0026#34;, \u0026#34;offset\u0026#34;: \u0026#34;50\u0026#34;, \u0026#34;scale\u0026#34;: \u0026#34;20\u0026#34; } }, \u0026#34;weight\u0026#34;: 2 } ] } } } ","permalink":"https://kucw.io/blog/2018/7/elasticsearch-function_score-gauss/","tags":null,"title":"ElasticSearch - function_score（衰減函數 linear、exp、gauss 具體實例）"},{"categories":["Elastic Search"],"contents":" 閱讀本文需要先了解 function_score 的相關知識，請看 ElasticSearch - function_score 簡介\n在正常的查詢下，有相同評分的 score 的文檔會每次都會以相同次序出現，但是爲了提高展現率，在此引入一些隨機性可能會是個好主意，這能保證有相同評分的文檔都能有均等相似的展現機率\n但是，在隨機的同時，除了想讓不同的用戶看到不同的隨機次序之外，但也希望如果是同一用戶翻頁瀏覽時，結果的相對次序能始終保持一致，這種行爲被稱爲 一致隨機（consistently random） 因此 random_score 加強函數除了能隨機得到一個 0 ~ 1 的分數，也會使用一個 seed 值，來保障生成隨機的順序，當 seed 值相同時，生成的隨機結果是一致的 先準備數據和索引，在 ES 插入三筆數據，其中 language 是 keyword 類型，like 是 integer 類型（代表點贊量）\n{ \u0026#34;language\u0026#34;: \u0026#34;java\u0026#34;, \u0026#34;like\u0026#34;: 5 } { \u0026#34;language\u0026#34;: \u0026#34;python\u0026#34;, \u0026#34;like\u0026#34;: 5 } { \u0026#34;language\u0026#34;: \u0026#34;go\u0026#34;, \u0026#34;like\u0026#34;: 10 } 使用 random_score 生成隨機排序\n注意在 functions 裡，只有 weight 加強函數加了 filter，也就是說只有 like 數小於等於 5 的文檔，才會被 weight 加強函數加強\n而 random_score 加強函數沒有加 filter，表示所有的文檔都會被 random_score 隨機排序一遍\nGET mytest/doc/_search { \u0026#34;query\u0026#34;: { \u0026#34;function_score\u0026#34;: { \u0026#34;query\u0026#34;: { \u0026#34;match_all\u0026#34;: {} }, \u0026#34;functions\u0026#34;: [ { \u0026#34;filter\u0026#34;: { \u0026#34;range\u0026#34;: { \u0026#34;like\u0026#34;: { \u0026#34;lte\u0026#34;: 5 } } }, \u0026#34;weight\u0026#34;: 2 }, { \u0026#34;random_score\u0026#34;: { \u0026#34;seed\u0026#34;: 100 } } ] } } } 當 random_score 的 seed 設為 100，其結果為\n\u0026#34;hits\u0026#34;: [ { \u0026#34;_score\u0026#34;: 1.2912227, \u0026#34;_source\u0026#34;: { \u0026#34;language\u0026#34;: \u0026#34;python\u0026#34;, \u0026#34;like\u0026#34;: 5 } }, { \u0026#34;_score\u0026#34;: 1.1301208, \u0026#34;_source\u0026#34;: { \u0026#34;language\u0026#34;: \u0026#34;java\u0026#34;, \u0026#34;like\u0026#34;: 5 } }, { \u0026#34;_score\u0026#34;: 0.9083528, \u0026#34;_source\u0026#34;: { \u0026#34;language\u0026#34;: \u0026#34;go\u0026#34;, \u0026#34;like\u0026#34;: 10 } } ] 當 random_score 的 seed 設為 200，其結果為\n\u0026#34;hits\u0026#34;: [ { \u0026#34;_score\u0026#34;: 1.2040303, \u0026#34;_source\u0026#34;: { \u0026#34;language\u0026#34;: \u0026#34;java\u0026#34;, \u0026#34;like\u0026#34;: 5 } }, { \u0026#34;_score\u0026#34;: 0.5595852, \u0026#34;_source\u0026#34;: { \u0026#34;language\u0026#34;: \u0026#34;go\u0026#34;, \u0026#34;like\u0026#34;: 10 } }, { \u0026#34;_score\u0026#34;: 0.10916698, \u0026#34;_source\u0026#34;: { \u0026#34;language\u0026#34;: \u0026#34;python\u0026#34;, \u0026#34;like\u0026#34;: 5 } } ] ","permalink":"https://kucw.io/blog/2018/7/elasticsearch-function_score-random_score/","tags":null,"title":"ElasticSearch - function_score（random_score 具體實例）"},{"categories":["Elastic Search"],"contents":" 閱讀本文需要先了解 function_score 的相關知識，請看 ElasticSearch - function_score 簡介\n一樣先準備數據和索引，在 ES 插入三筆數據，其中 language 是 keyword 類型，like 是 integer 類型（代表點贊量）\n{ \u0026#34;language\u0026#34;: \u0026#34;java\u0026#34;, \u0026#34;like\u0026#34;: 5 } { \u0026#34;language\u0026#34;: \u0026#34;python\u0026#34;, \u0026#34;like\u0026#34;: 5 } { \u0026#34;language\u0026#34;: \u0026#34;go\u0026#34;, \u0026#34;like\u0026#34;: 10 } functions 是一個數組，裡面放著的是將要被使用的加強函數列表，我們在裡面使用了 3 個 filter 去過濾數據，並且每個 filter 都設置了一個加強函數，並且還使用了一個會應用到所有文檔的 field_value_factor 加強函數\n可以為列表裡的每個加強函數都指定一個 filter，這樣做的話，只有在文檔滿足此 filter 的要求，此 filter 的加強函數才會應用到文擋上，也可以不指定 filter，這樣的話此加強函數就會應用到全部的文擋上\n一個文檔可以一次滿足多條加強函數和多個 filter，如果一次滿足多個，那麼就會產生多個加強 score\n因此 ES 會先使用 score_mode 定義的方式來合併這些加強 score 們，得到一個總加強 score，得到總加強 score之後，才會再使用 boost_mode 定義的方式去和 old_score 做合併\nGET mytest/doc/_search { \u0026#34;query\u0026#34;: { \u0026#34;function_score\u0026#34;: { \u0026#34;query\u0026#34;: { \u0026#34;match_all\u0026#34;: {} //match_all查出來的所有文檔的_score都是1 }, \u0026#34;functions\u0026#34;: [ //第一個filter(使用weight加強函數)，如果language是java，加強score就是2 { \u0026#34;filter\u0026#34;: { \u0026#34;term\u0026#34;: { \u0026#34;language\u0026#34;: \u0026#34;java\u0026#34; } }, \u0026#34;weight\u0026#34;: 2 }, //第二個filter(使用weight加強函數)，如果language是go，加強score就是3 { \u0026#34;filter\u0026#34;: { \u0026#34;term\u0026#34;: { \u0026#34;language\u0026#34;: \u0026#34;go\u0026#34; } }, \u0026#34;weight\u0026#34;: 3 }, //第三個filter(使用weight加強函數)，如果like數大於等於10，加強score就是5 { \u0026#34;filter\u0026#34;: { \u0026#34;range\u0026#34;: { \u0026#34;like\u0026#34;: { \u0026#34;gte\u0026#34;: 10 } } }, \u0026#34;weight\u0026#34;: 5 }, //field_value_factor加強函數，會應用到所有文檔上，加強score就是like值 { \u0026#34;field_value_factor\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;like\u0026#34; } } ], \u0026#34;score_mode\u0026#34;: \u0026#34;multiply\u0026#34;, //設置functions裡面的加強score們怎麼合併成一個總加強score \u0026#34;boost_mode\u0026#34;: \u0026#34;multiply\u0026#34; //設置old_score怎麼和總加強score合併 } } } \u0026#34;hits\u0026#34;: [ { //go同時滿足filter2、filter3 //且還有一個加強函數field_value_factor產生的加強 //因此加強score為3, 5, 10，總加強score為3*5*10=150 \u0026#34;_score\u0026#34;: 150, \u0026#34;_source\u0026#34;: { \u0026#34;language\u0026#34;: \u0026#34;go\u0026#34;, \u0026#34;like\u0026#34;: 10 } }, { //java只滿足filter1 //但是因為還有field_value_facotr產生的加強score //因此加強score為2, 5，總加強score為2*5=10 \u0026#34;_score\u0026#34;: 10, \u0026#34;_source\u0026#34;: { \u0026#34;language\u0026#34;: \u0026#34;java\u0026#34;, \u0026#34;like\u0026#34;: 5 } }, { //python不滿足任何filter //因此加強score只有field_value_factor的like值 //就是5 \u0026#34;_score\u0026#34;: 5, \u0026#34;_source\u0026#34;: { \u0026#34;language\u0026#34;: \u0026#34;python\u0026#34;, \u0026#34;like\u0026#34;: 5 } } ] 其實 weight 加強函數也是可以不和 filter 搭配，自己單獨使用的，只是這樣做沒啥意義，因為只是會給全部的文檔都增加一個固定值而已\n不過就 DSL 語法上來說，他也像其他加強函數一樣，是可以直接使用而不用加 filter 的\nGET mytest/doc/_search { \u0026#34;query\u0026#34;: { \u0026#34;function_score\u0026#34;: { \u0026#34;query\u0026#34;: { \u0026#34;match_all\u0026#34;: {} } }, functions: [ { \u0026#34;weight\u0026#34;: 3 } ] } } \u0026#34;hits\u0026#34;: [ { \u0026#34;_score\u0026#34;: 3, \u0026#34;_source\u0026#34;: { \u0026#34;language\u0026#34;: \u0026#34;go\u0026#34;, \u0026#34;like\u0026#34;: 10 } }, { \u0026#34;_score\u0026#34;: 3, \u0026#34;_source\u0026#34;: { \u0026#34;language\u0026#34;: \u0026#34;python\u0026#34;, \u0026#34;like\u0026#34;: 5 } }, { \u0026#34;_score\u0026#34;: 3, \u0026#34;_source\u0026#34;: { \u0026#34;language\u0026#34;: \u0026#34;java\u0026#34;, \u0026#34;like\u0026#34;: 5 } } ] weight 加強函數也可以用來調整每個語句的貢獻度，權重 weight 的默認值是 1.0，當設置了 weight，這個 weight 值會先和自己那個 {} 裡的每個句子的評分相乘，之後再通過 score_mode 和其他加強函數合併\n下面的查詢，公式為 new_score = old_score * [ (like值 * weight1) + weight2 ] 公式解析 : weight1 先加強 like 值（只能使用乘法），接著再透過 score_mode 定義的方法（sum）和另一個加強函數 weight2 合併，得到一個總加強 score，最後再使用 boost_mode 定義的方法（默認是 multiply）和 old_score 做合併，得到 new_score\nGET mytest/doc/_search { \u0026#34;query\u0026#34;: { \u0026#34;function_score\u0026#34;: { \u0026#34;query\u0026#34;: { \u0026#34;match_all\u0026#34;: {} } }, functions: [ { \u0026#34;field_value_factor\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;like\u0026#34; }, \u0026#34;weight\u0026#34;: 3 //weight1, 加強field_value_factor，只能使用乘法，無法改變 }, { \u0026#34;weight\u0026#34;: 20 //weight2 } ], \u0026#34;score_mode\u0026#34;: \u0026#34;sum\u0026#34; } } \u0026#34;hits\u0026#34;: [ { \u0026#34;_score\u0026#34;: 50, \u0026#34;_source\u0026#34;: { \u0026#34;language\u0026#34;: \u0026#34;go\u0026#34;, \u0026#34;like\u0026#34;: 10 } }, { \u0026#34;_score\u0026#34;: 35, \u0026#34;_source\u0026#34;: { \u0026#34;language\u0026#34;: \u0026#34;python\u0026#34;, \u0026#34;like\u0026#34;: 5 } }, { \u0026#34;_score\u0026#34;: 35, \u0026#34;_source\u0026#34;: { \u0026#34;language\u0026#34;: \u0026#34;java\u0026#34;, \u0026#34;like\u0026#34;: 5 } } ] ","permalink":"https://kucw.io/blog/2018/7/elasticsearch-function_score-weight/","tags":null,"title":"ElasticSearch - function_score（weight 具體實例）"},{"categories":["Elastic Search"],"contents":" 閱讀本文需要先了解 function_score 的相關知識，請看 ElasticSearch - function_score 簡介\n首先準備數據和索引，在ES插入三筆數據，其中 title 是 text 類型，like 是 integer 類型（代表點贊量）\n{ \u0026#34;title\u0026#34;: \u0026#34;ES 入門\u0026#34;, \u0026#34;like\u0026#34;: 2 } { \u0026#34;title\u0026#34;: \u0026#34;ES 進階\u0026#34;, \u0026#34;like\u0026#34;: 5 } { \u0026#34;title\u0026#34;: \u0026#34;ES 最高難度\u0026#34;, \u0026#34;like\u0026#34;: 10 } 先使用一般的 query，查看普通的查詢的評分會是如何\nGET mytest/doc/_search { \u0026#34;query\u0026#34;: { \u0026#34;match\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;ES\u0026#34; } } } \u0026#34;hits\u0026#34;: [ { \u0026#34;_score\u0026#34;: 0.2876821, \u0026#34;_source\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;ES 入門\u0026#34;, \u0026#34;like\u0026#34;: 2 } }, { \u0026#34;_score\u0026#34;: 0.20309238, \u0026#34;_source\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;ES 進階\u0026#34;, \u0026#34;like\u0026#34;: 5 } }, { \u0026#34;_score\u0026#34;: 0.16540512, \u0026#34;_source\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;ES 最高難度\u0026#34;, \u0026#34;like\u0026#34;: 10 } } ] 使用 function_score 的 field_value_factor 改變 _score，將 old_score 乘上 like 的值\n本來 \u0026ldquo;ES 最高難度\u0026rdquo; 的 score 是0.16540512，經過 field_value_factor 的改變，乘上了那個文檔中的like值（10）之後，新的 score 變為 1.6540513\nGET mytest/doc/_search { \u0026#34;query\u0026#34;: { \u0026#34;function_score\u0026#34;: { \u0026#34;query\u0026#34;: { \u0026#34;match\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;ES\u0026#34; } }, \u0026#34;field_value_factor\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;like\u0026#34; } } } } \u0026#34;hits\u0026#34;: [ { \u0026#34;_score\u0026#34;: 1.6540513, //原本是0.16540512 \u0026#34;_source\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;ES 最高難度\u0026#34;, \u0026#34;like\u0026#34;: 10 } }, { \u0026#34;_score\u0026#34;: 1.0154619, //原本是0.20309238 \u0026#34;_source\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;ES 進階\u0026#34;, \u0026#34;like\u0026#34;: 5 } }, { \u0026#34;_score\u0026#34;: 0.5753642, //原本是0.2876821 \u0026#34;_source\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;ES 入門\u0026#34;, \u0026#34;like\u0026#34;: 2 } } ] 加上 max_boost，限制 field_value_factor 的最大加強 score\n可以看到 ES 入門的加強 score 是2，在 max_boost 限制裡，所以不受影響\n而 ES 進階和 ES 最高難度的 field_value_factor 函數產生的加強 score 因為超過 max_boost 的限制，所以被設為 3\nGET mytest/doc/_search { \u0026#34;query\u0026#34;: { \u0026#34;function_score\u0026#34;: { \u0026#34;query\u0026#34;: { \u0026#34;match\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;ES\u0026#34; } }, \u0026#34;field_value_factor\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;like\u0026#34; }, \u0026#34;max_boost\u0026#34;: 3 } } } \u0026#34;hits\u0026#34;: [ { \u0026#34;_score\u0026#34;: 0.6092771, //原本是0.20309238 \u0026#34;_source\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;ES 進階\u0026#34;, \u0026#34;like\u0026#34;: 5 } }, { \u0026#34;_score\u0026#34;: 0.5753642, //原本是0.2876821 \u0026#34;_source\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;ES 入門\u0026#34;, \u0026#34;like\u0026#34;: 2 } }, { \u0026#34;_score\u0026#34;: 0.49621537, //原本是0.16540512 \u0026#34;_source\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;ES 最高難度\u0026#34;, \u0026#34;like\u0026#34;: 10 } } ] 有時候線性的計算 new_score = old_score * like值 的效果並不是那麼好，field_value_factor 中還支持 modifier、factor 參數，可以改變 like 值對 old_score 的影響\nmodifier 參數支持的值\nnone : new_score = old_score * like值 默認狀態就是 none，線性 log1p : new_score = old_score * log(1 + like值) 最常用，可以讓 like 值字段的評分曲線更平滑 log2p : new_score = old_score * log(2 + like值) ln : new_score = old_score * ln(like值) ln1p : new_score = old_score * ln(1 + like值) ln2p : new_score = old_score * ln(2 + like值) square : 計算平方 sqrt : 計算平方根 reciprocal : 計算倒數 factor 參數\nfactor 作為一個調節用的參數，沒有 modifier 那麼強大會改變整個曲線，他僅改變一些常量值，設置 factor \u0026gt; 1 會提昇效果，factor \u0026lt; 1 會降低效果 假設 modifier 是 log1p，那麼加入了 factor 的公式就是 new_score = old_score * log(1 + factor * like值) 對剛剛的例子加上 modifier、factor\nGET mytest/doc/_search { \u0026#34;query\u0026#34;: { \u0026#34;function_score\u0026#34;: { \u0026#34;query\u0026#34;: { \u0026#34;match\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;ES\u0026#34; } }, \u0026#34;field_value_factor\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;like\u0026#34;, \u0026#34;modifier\u0026#34;: \u0026#34;log1p\u0026#34;, \u0026#34;factor\u0026#34;: 2 } } } } 就算加上了 modifier，但是 \u0026ldquo;全文評分 與 field_value_factor 函數值乘積\u0026rdquo; 的效果可能還是太大，我們可以通過參數 boost_mode 來決定 old_score 和 加強 score 合併的方法\n如果將 boost_mode 改成 sum，可以大幅弱化最終效果，特別是使用一個較小的 factor 時\n加入了 boost_mode = sum、且 factor = 0.1 的公式變為 new_score = old_score + log(1 + 0.1 * like值)\nGET mytest/doc/_search { \u0026#34;query\u0026#34;: { \u0026#34;function_score\u0026#34;: { \u0026#34;query\u0026#34;: { \u0026#34;match\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;ES\u0026#34; } }, \u0026#34;field_value_factor\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;like\u0026#34;, \u0026#34;modifier\u0026#34;: \u0026#34;log1p\u0026#34;, \u0026#34;factor\u0026#34;: 0.1 }, \u0026#34;boost_mode\u0026#34;: \u0026#34;sum\u0026#34; } } } 另外使用 field_value_factor 時要注意，有的文檔可能會缺少這個字段的值，因此這時就要加上 missing 來給這些缺失字段值的文檔一個 default 的值\nGET mytest/doc/_search { \u0026#34;query\u0026#34;: { \u0026#34;function_score\u0026#34;: { \u0026#34;query\u0026#34;: { \u0026#34;match\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;ES\u0026#34; } }, \u0026#34;field_value_factor\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;like\u0026#34;, \u0026#34;modifier\u0026#34;: \u0026#34;log1p\u0026#34;, \u0026#34;factor\u0026#34;: 0.1, \u0026#34;missing\u0026#34;: 1 //如果文檔沒有like值，就給他1的值讓他去做log1p的運算 }, \u0026#34;boost_mode\u0026#34;: \u0026#34;sum\u0026#34; } } } ","permalink":"https://kucw.io/blog/2018/7/elasticsearch-function_score-field_value_factor/","tags":null,"title":"ElasticSearch - function_score（field_value_factor 具體實例）"},{"categories":["Elastic Search"],"contents":" function_score 內容較多，此篇主要是介紹 function_score 的基本概念\n具體實例請參考以下連接\nElasticSearch - function_score（field_value_factor 具體實例）\nElasticSearch - function_score（weight 具體實例）\nElasticSearch - function_score（random_score 具體實例）\nElasticSearch - function_score（衰減函數 linear、exp、gauss 具體實例）\n在使用 ES 進行全文搜索時，搜索結果默認會以文檔的相關度進行排序，而這個 \u0026ldquo;文檔的相關度\u0026rdquo;，是可以透過 function_score 自己定義的，也就是說我們可以透過使用 function_score，來控制 \u0026ldquo;怎麼樣的文檔相關度更高\u0026rdquo; 這件事\nfunction_score 是專門用於處理文檔 _score 的 DSL，它允許爲每個主查詢 query 匹配的文檔應用加強函數， 以達到改變原始查詢評分 score 的目的 function_score 會在主查詢 query 結束後對每一個匹配的文檔進行一系列的重打分操作，能夠對多個字段一起進行綜合評估，且能夠使用 filter 將結果劃分爲多個子集（每個特性一個filter），並爲每個子集使用不同的加強函數 function_score 提供了幾種加強 _score 計算的函數\nweight : 設置一個簡單而不被規範化的權重提升值 weight 加強函數 和 boost 參數 類似，可以用於任何查詢，不過有一點差別是 weight 不會被 Lucene normalize 成難以理解的浮點數，而是直接被應用（boost 會被 normalize） 例如當 weight 爲 2 時，最終結果爲 new_score = old_score * 2 field_value_factor : 將某個字段的值乘上 old_score 像是將 字段 shareCount 或是 字段 likeCount 作爲考慮因素，new_score = old_score * 那個文檔的 likeCount 的值 random_score : 爲每個用戶都使用一個不同的隨機評分對結果排序，但對某一具體用戶來說，看到的順序始終是一致的 衰減函數 (linear、exp、guass) : 以某個字段的值為基準，距離某個值越近得分越高 script_score : 當需求超出以上範圍時，可以用自定義腳本完全控制評分計算，不過因為還要額外維護腳本不好維護，因此盡量使用 ES 提供的評分函數，需求真的無法滿足再使用 script_score function_scroe其他輔助的參數\nboost_mode : 決定 old_score 和 加強score 如何合併 multiply（默認） : new_score = old_score * 加強score sum : new_score = old_score + 加強score min : old_score 和 加強 score 取較小值，new_score = min(old_score, 加強score) max : old_score 和 加強 score 取較大值，new_score = max(old_score, 加強score) replace : 加強 score 直接替換掉 old_score，new_score = 加強score score_mode : 決定 functions 裡面的加強 score 們怎麼合併，會先合併加強 score 們成一個總加強 score，再使用總加強 score 去和 old_score 做合併，換言之就是會先執行 score_mode，再執行 boost_mode multiply（默認） sum avg first : 使用首個函數（可以有filter，也可以沒有）的結果作為最終結果 max min max_boost : 限制加強函數的最大效果，就是限制加強 score 最大能多少，但要注意不會限制 old_score 如果加強 score 超過了 max_boost 限制的值，會把加強 score 的值設成 max_boost 的值 假設加強 score 是5，而 max_boost 是2，因為加強 score 超出了 max_boost 的限制，所以 max_boost 就會把加強 score 改為2 簡單的說，就是 加強score = min(加強score, max_boost) function_score 查詢模板\n如果要使用 function_score 改變分數，要使用 function_score 查詢\n簡單的說，就是在一個 function_score 內部的 query 的全文搜索得到的 _score 基礎上，給他加上其他字段的評分標準，就能夠得到把 \u0026ldquo;全文搜索 + 其他字段\u0026rdquo; 綜合起來評分的效果\n單個加強函數的查詢模板\nGET mytest/doc/_search { \u0026#34;query\u0026#34;: { \u0026#34;function_score\u0026#34;: { //主查詢，查詢完後這裡自己會有一個評分，就是 old_score \u0026#34;query\u0026#34;: {.....}, //在 old_score 的基礎上，給他加強其他字段的評分 //這裡會產生一個加強 score，如果只有一個加強 function 時，直接將加強函數名寫在 query 下面就可以了 \u0026#34;field_value_factor\u0026#34;: {...}, //指定用哪種方式結合 old_score 和加強 score 成為 new_score \u0026#34;boost_mode\u0026#34;: \u0026#34;multiply\u0026#34;, //限制加強 score 的最高分，但是不會限制 old_score \u0026#34;max_boost\u0026#34;: 1.5 } } } 多個加強函數的查詢模板\n如果有多個加強函數，那就要使用functions來包含這些加強函數們，functions是一個數組，裡面放著的是將要被使用的加強函數列表\n可以為functions裡的加強函數指定一個filter，這樣做的話，只有在文檔滿足此filter的要求，此filter的加強函數才會應用到文擋上，也可以不指定filter，這樣的話此加強函數就會應用到全部的文擋上\n一個文檔可以一次滿足多條加強函數和多個filter，如果一次滿足多個，那麼就會產生多個加強score，因此ES會使用score_mode定義的方式來合併這些加強score們，得到一個總加強score，得到總加強score之後，才會再使用boost_mode定義的方式去和old_score做合併\n像是下面的例子，field_value_factor和gauss這兩個加強函數會應用到所有文檔上，而weight只會應用到滿足filter的文檔上，假設有個文檔滿足了filter的條件，那他就會得到3個加強score，這3個加強score會使用sum的方式合併成一個總加強score，然後才和old_score使用multiply的方式合併\nGET mytest/doc/_search { \u0026#34;query\u0026#34;: { \u0026#34;function_score\u0026#34;: { //主查詢，查詢完後這裡自己會有一個評分，就是 old_score \u0026#34;query\u0026#34;: {.....}, //可以有多個加強函數（或是 filter + 加強函數） //每一個加強函數會產生一個加強 score，因此 functions 會有多個加強 score \u0026#34;functions\u0026#34;: [ { \u0026#34;field_value_factor\u0026#34;: ... }, { \u0026#34;gauss\u0026#34;: ... }, { \u0026#34;filter\u0026#34;: {...}, \u0026#34;weight\u0026#34;: ... } ], //決定加強 score 們怎麼合併成一個總加強 score \u0026#34;score_mode\u0026#34;: \u0026#34;sum\u0026#34;, //決定總加強 score 怎麼和 old_score 合併 \u0026#34;boost_mode\u0026#34;: \u0026#34;multiply\u0026#34; } } } 不要執著在調整 function_score 上\n文檔相關度的調整非常玄，\u0026ldquo;最相關的文檔\u0026rdquo; 是一個難以觸及的模糊概念，每個人對文檔排序有著不同的想法，這很容易使人陷入持續反覆調整，但是確沒有明顯的進展 為了避免跳入這種死循環，在調整 function_score 時，一定要搭配監控用戶操作，才有意義 像是如果返回的文檔是用戶想要的高相關的文檔，那麼用戶就會選擇前 10 個中的一個文檔，得到想要的結果，反之，用戶可能會來回點擊，或是嘗試新的搜索條件 一旦有了這些監控手段，想要調適完美的 function_score 就不是問題 因此調整 function_score 的重點在於，要透過監控用戶、和用戶互動，慢慢去調整我們的搜索條件，而不要妄想一步登天，第一次就把文檔的相關度調整到最好，這幾乎是不可能的，因為，連用戶自己也不知道他自己想要什麼 ","permalink":"https://kucw.io/blog/2018/7/elasticsearch-function_score/","tags":null,"title":"ElasticSearch - function_score 簡介"},{"categories":["Elastic Search"],"contents":" ES 為了避免深分頁，不允許使用分頁（from \u0026amp; size）查詢 10000 條以後的數據，因此如果要查詢第 10000 條以後的數據，要使用 ES 提供的 scroll 游標 來查詢\n原因是因為假設取的頁數較大時（深分頁），如請求第 20 頁，ES 不得不取出所有分片上的第 1 頁到第 20 頁的所有文檔，並做排序，最終再取出 from 後的 size 條結果作爲最終的返回值 假設你有 16 個分片，則需要在 coordinate node 彙總到 shards * (from + size) 條記錄，即需要 16 * (20 + 10) 記錄後做一次全局排序 所以，當索引非常非常大(千萬或億)，是無法使用 from + size 做深分頁的，分頁越深則越容易 Out Of Memory，即使你運氣很好沒有發生 Out Of Memory，也會非常消耗 CPU 和內存資源 因此 ES 使用 index.max_result_window:10000 作爲保護措施 ，即默認 from + size 不能超過 10000，雖然這個參數可以動態修改，也可以在配置文件配置，但是最好不要這麼做，應該改用 ES 提供的 scroll 方法來取得數據 scroll 游標原理\n可以把 scroll 理解爲關係型數據庫裏的 cursor，因此，scroll 並不適合用來做實時搜索，而更適用於後台批處理任務，比如群發 scroll 具體分爲初始化和遍歷兩步 初始化時將所有符合搜索條件的搜索結果緩存起來，可以想象成快照 在遍歷時，從這個快照裏取數據 也就是說，在初始化後對索引插入、刪除、更新數據都不會影響遍歷結果 游標可以增加性能的原因，是因為如果做深分頁，每次搜索都必須重新排序，非常浪費，使用 scroll 就是一次把要用的數據都排完了，分批取出，因此比使用 from + size 還好 具體實例\n初始化\n請求\n注意要在URL中的search後加上 scroll=1m，不能寫在 request body 中，其中 1m 表示這個游標要保持開啟 1 分鐘\n可以指定 size 大小，就是每次回傳幾筆數據，當回傳到沒有數據時，仍會返回 200 成功，只是 hits 裡的 hits 會是空 list\n在初始化時除了回傳 _scroll_id，也會回傳前 100 筆（假設 size = 100）的數據\nrequest body 和一般搜索一樣，因此可以說在初始化的過程中，除了加上 scroll 設置游標開啟時間之外，其他的都跟一般的搜尋沒有兩樣（要設置查詢條件，也會回傳前 size 筆的數據）\nGET my_index/_search?scroll=1m { \u0026#34;query\u0026#34;:{ \u0026#34;range\u0026#34;:{ \u0026#34;createTime\u0026#34;: { \u0026#34;gte\u0026#34;: 1522229999999 } } }, \u0026#34;size\u0026#34;: 1000 } 返回結果\n{ \u0026#34;_scroll_id\u0026#34;: \u0026#34;DnF1ZXJ5VGhlbkZldGNoBQAAAAAAfv5-FjNOamF0Mk1aUUhpUnU5ZWNMaHJocWcAAAAAAH7-gBYzTmphdDJNWlFIaVJ1OWVjTGhyaHFnAAAAAAB-_n8WM05qYXQyTVpRSGlSdTllY0xocmhxZwAAAAAAdsJxFmVkZTBJalJWUmp5UmI3V0FYc2lQbVEAAAAAAHbCcBZlZGUwSWpSVlJqeVJiN1dBWHNpUG1R\u0026#34;, \u0026#34;took\u0026#34;: 2, \u0026#34;timed_out\u0026#34;: false, \u0026#34;_shards\u0026#34;: { \u0026#34;total\u0026#34;: 5, \u0026#34;successful\u0026#34;: 5, \u0026#34;skipped\u0026#34;: 0, \u0026#34;failed\u0026#34;: 0 }, \u0026#34;hits\u0026#34;: { \u0026#34;total\u0026#34;: 84, \u0026#34;max_score\u0026#34;: 1, \u0026#34;hits\u0026#34;: [ { \u0026#34;_index\u0026#34;: \u0026#34;video1522821719\u0026#34;, \u0026#34;_type\u0026#34;: \u0026#34;doc\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;84056\u0026#34;, \u0026#34;_score\u0026#34;: 1, \u0026#34;_source\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;三个院子\u0026#34;, \u0026#34;createTime\u0026#34;: 1522239744000 } } ....99 data ] } } 遍歷數據\n請求\n使用初始化返回的 _scroll_id 來進行請求，每一次請求都會繼續返回初始化中未讀完數據，並且會返回一個 _scroll_id，這個 _scroll_id 可能會改變，因此每一次請求應該帶上上一次請求返回的 _scroll_id\n要注意返回的是 _scroll_id，但是放在請求裡的是 scroll_id，兩者拼寫上有不同\n且每次發送 scroll 請求時，都要再重新刷新這個 scroll 的開啟時間，以防不小心超時導致數據取得不完整\nGET _search/scroll?scroll=1m { \u0026#34;scroll_id\u0026#34;: \u0026#34;DnF1ZXJ5VGhlbkZldGNoBQAAAAAAdsMqFmVkZTBJalJWUmp5UmI3V0FYc2lQbVEAAAAAAHbDKRZlZGUwSWpSVlJqeVJiN1dBWHNpUG1RAAAAAABpX2sWclBEekhiRVpSRktHWXFudnVaQ3dIQQAAAAAAaV9qFnJQRHpIYkVaUkZLR1lxbnZ1WkN3SEEAAAAAAGlfaRZyUER6SGJFWlJGS0dZcW52dVpDd0hB\u0026#34; } 返回結果\n如果沒有數據了，就會回傳空的 hits，可以用這個判斷是否遍歷完成了數據\n{ \u0026#34;_scroll_id\u0026#34;: \u0026#34;DnF1ZXJ5VGhlbkZldGNoBQAAAAAAdsMqFmVkZTBJalJWUmp5UmI3V0FYc2lQbVEAAAAAAHbDKRZlZGUwSWpSVlJqeVJiN1dBWHNpUG1RAAAAAABpX2sWclBEekhiRVpSRktHWXFudnVaQ3dIQQAAAAAAaV9qFnJQRHpIYkVaUkZLR1lxbnZ1WkN3SEEAAAAAAGlfaRZyUER6SGJFWlJGS0dZcW52dVpDd0hB\u0026#34;, \u0026#34;took\u0026#34;: 2, \u0026#34;timed_out\u0026#34;: false, \u0026#34;_shards\u0026#34;: { \u0026#34;total\u0026#34;: 5, \u0026#34;successful\u0026#34;: 5, \u0026#34;skipped\u0026#34;: 0, \u0026#34;failed\u0026#34;: 0 }, \u0026#34;hits\u0026#34;: { \u0026#34;total\u0026#34;: 84, \u0026#34;max_score\u0026#34;: null, \u0026#34;hits\u0026#34;: [] } } 優化scroll查詢\n在一般場景下，scroll 通常用來取得需要排序過後的大筆數據，但是有時候數據之間的排序性對我們而言是沒有關係的，只要所有數據都能取出來就好，這時能夠對 scroll 進行優化\n初始化\n使用 _doc 去 sort 得出來的結果，這個執行的效率最快，但是數據就不會有排序，適合用在只想取得所有數據的場景\nGET my_index/_search?scroll=1m { \u0026#34;query\u0026#34;: { \u0026#34;match_all\u0026#34; : {} }, \u0026#34;sort\u0026#34;: [\u0026#34;_doc\u0026#34;] } 清除 scroll\n雖然我們在設置開啟 scroll 時，設置了一個 scroll 的存活時間，但是如果能夠在使用完順手關閉，可以提早釋放資源，降低 ES 的負擔\nDELETE _search/scroll { \u0026#34;scroll_id\u0026#34;: \u0026#34;DnF1ZXJ5VGhlbkZldGNoBQAAAAAAdsMqFmVkZTBJalJWUmp5UmI3V0FYc2lQbVEAAAAAAHbDKRZlZGUwSWpSVlJqeVJiN1dBWHNpUG1RAAAAAABpX2sWclBEekhiRVpSRktHWXFudnVaQ3dIQQAAAAAAaV9qFnJQRHpIYkVaUkZLR1lxbnZ1WkN3SEEAAAAAAGlfaRZyUER6SGJFWlJGS0dZcW52dVpDd0hB\u0026#34; } ","permalink":"https://kucw.io/blog/2018/6/elasticsearch-scroll/","tags":null,"title":"ElasticSearch - 解決 ES 的深分頁問題（游標 scroll）"},{"categories":["Elastic Search"],"contents":" 由於在 ES 中，所有單個文檔的增刪改都是原子性的操作，因此將相關的實體數據都儲存在同一個文檔是很好的，且由於所有信息都在一個文檔中，因此當我們查詢時就沒有必要像 mysql 一樣去關聯很多張表，只要搜一遍文檔就可以查出所有需要的數據，查詢效率非常高\n因此除了基本數據類型之外，ES 也支持使用複雜的數據類型，像是數組、內部對象，而要使用內部對象的話，需要使用 nested 來定義索引，使文檔內可以包含一個內部對象\n為什麼不用 object 而要使用 nested 來定義索引的原因是，object 類型會使得內部對象的關聯性丟失\n這是因為 Lucene 底層其實沒有內部對象的概念，所以 ES 會利用簡單的列表儲存字段名和值，將 object 類型的對象層次攤平，再傳給 Lucene\n假設 user 類型是 object，當插入一筆新的數據時，ES 會將他轉換為下面的內部文檔，其中可以看見 alice 和 white 的關聯性丟失了\nPUT mytest/doc/1 { \u0026#34;group\u0026#34;: \u0026#34;fans\u0026#34;, \u0026#34;user\u0026#34;: [ { \u0026#34;first\u0026#34;: \u0026#34;John\u0026#34;, \u0026#34;last\u0026#34;: \u0026#34;Smith\u0026#34; }, { \u0026#34;first\u0026#34;: \u0026#34;Alice\u0026#34;, \u0026#34;last\u0026#34;: \u0026#34;White\u0026#34; } ] } 轉換後的內部文檔 { \u0026#34;group\u0026#34;: \u0026#34;fans\u0026#34;, \u0026#34;user.first\u0026#34;: [ \u0026#34;alice\u0026#34;, \u0026#34;john\u0026#34; ], \u0026#34;user.last\u0026#34;: [ \u0026#34;smith\u0026#34;, \u0026#34;white\u0026#34; ] } 理論上從插入的數據來看，應該搜索 \u0026ldquo;first 為 Alice 且 last 為 White\u0026rdquo; 時，這個文檔才算符合條件被搜出來，其他的條件都不算符合，但是因為 ES 把 object 類型的對象攤平了，所以實際上如果搜索 \u0026ldquo;first 為 Alice 且 last 為 Smith\u0026rdquo;，這個文檔也會當作符合的文檔被搜出來，但這樣就違反我們的意願了，我們希望內部對象自己的關聯性還是存在的\n因此在使用內部對象時，要改使用 nested 類型來取代 object 類型 (因為 nested 類型不會被攤平，下面說明)\nnested 類型就是為了解決 object 類型在對象數組上丟失關聯性的問題的，如果將字段設置為 nested 類型，那個每一個嵌套對象都會被索引為一個 \u0026ldquo;隱藏的獨立文檔\u0026rdquo;\n其本質上就是將數組中的每個對象作為分離出來的隱藏文檔進行索引，因此這也意味著每個嵌套對象可以獨立於其他對象被查詢\n假設將上面的例子的 user 改為 nested 類型，經過 ES 轉換後的文檔如下\n//嵌套文檔1 { \u0026#34;user.first\u0026#34;: [ \u0026#34;alice\u0026#34; ], \u0026#34;user.last\u0026#34;: [ \u0026#34;white\u0026#34; ] } //嵌套文檔2 { \u0026#34;user.first\u0026#34;: [ \u0026#34;john\u0026#34; ], \u0026#34;user.last\u0026#34;: [ \u0026#34;smith\u0026#34; ] } //根文檔，或者也可以稱為父文檔 { \u0026#34;group\u0026#34;: \u0026#34;fans\u0026#34; } 在獨立索引每一個嵌套對象後，對象中每個字段的相關性得以保留，因此我們查詢時，也僅返回那些真正符合條件的文檔\n不僅如此，由於嵌套文檔直接儲存在文檔內部，因此查詢時嵌套文檔和根文檔的聯合成本很低，速度和單獨儲存幾乎一樣\n但是要注意，查詢的時候返回的是整個文檔，而不是嵌套文檔本身，並且如果要增刪改一個嵌套對象，必須把整個文檔重新索引才可以\n具體實例\n索引準備\n定義一個 nested 類型的 mapping，user 是一個內部對象，裡面包含了 first、last 和 age，因為 user 設置了 nested 類型，因此 user 對象會被索引在獨立的嵌套文檔中\nPUT mytest { \u0026#34;mappings\u0026#34;: { \u0026#34;doc\u0026#34;: { \u0026#34;properties\u0026#34;: { //group是正常的keyword字段 \u0026#34;group\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34; }, //user是一個nested類型，表示他底下還會包含子對象 \u0026#34;user\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;nested\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;first\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34; }, \u0026#34;last\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34; }, \u0026#34;age\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;integer\u0026#34; } } } } } } } 插入兩筆數據\nPOST mytest/doc { \u0026#34;group\u0026#34;: \u0026#34;fans\u0026#34;, \u0026#34;user\u0026#34;: { \u0026#34;first\u0026#34;: \u0026#34;Taylor\u0026#34;, \u0026#34;last\u0026#34;: \u0026#34;Swift\u0026#34;, \u0026#34;age\u0026#34;: 30 } } POST mytest/doc { \u0026#34;group\u0026#34;: \u0026#34;fans\u0026#34;, \u0026#34;user\u0026#34;: [ { \u0026#34;first\u0026#34;: \u0026#34;Amy\u0026#34;, \u0026#34;last\u0026#34;: \u0026#34;White\u0026#34;, \u0026#34;age\u0026#34;: 18 }, { \u0026#34;first\u0026#34;: \u0026#34;John\u0026#34;, \u0026#34;last\u0026#34;: \u0026#34;Smith\u0026#34;, \u0026#34;age\u0026#34;: 22 } ] } 因此在ES中存在的文檔如下\n\u0026#34;hits\u0026#34;: [ { \u0026#34;_source\u0026#34;: { \u0026#34;group\u0026#34;: \u0026#34;fans\u0026#34;, \u0026#34;user\u0026#34;: { \u0026#34;first\u0026#34;: \u0026#34;Taylor\u0026#34;, \u0026#34;last\u0026#34;: \u0026#34;Swift\u0026#34;, \u0026#34;age\u0026#34;: 30 } } }, { \u0026#34;_source\u0026#34;: { \u0026#34;group\u0026#34;: \u0026#34;fans\u0026#34;, \u0026#34;user\u0026#34;: [ { \u0026#34;first\u0026#34;: \u0026#34;Amy\u0026#34;, \u0026#34;last\u0026#34;: \u0026#34;White\u0026#34;, \u0026#34;age\u0026#34;: 18 }, { \u0026#34;first\u0026#34;: \u0026#34;John\u0026#34;, \u0026#34;last\u0026#34;: \u0026#34;Smith\u0026#34;, \u0026#34;age\u0026#34;: 22 } ] } } ] 嵌套對象查詢 nested\n由於嵌套對象被索引在獨立的隱藏文檔中，因此我們無法直接使用一般的 query 去查詢他，我們必須改使用 \u0026ldquo;nested查詢\u0026rdquo; 去查詢他們\nnested 查詢是一個葉子子句，因此外層需要使用 query 或是 bool 來包含他，且因為 nested 查詢是一個葉子子句，所以他也可以像一般的葉子子句一樣被 bool 層層嵌套 nested 查詢的內部必須要包含一個 path 參數，負責指定要用的是哪個 nested 類型的字段，且要包含一個 query，負責進行此嵌套對象內的查詢 如果是將 bool 子句寫在 nested 裡面，表示要查詢某個子對象中，必須同時包含這兩個條件\n也就是說，下面的查詢實際上是查找必須存在一個子對象，然後此對象必須同時滿足 user.first 為 Taylor，且 user.last 為 Swift，所以能夠找到一個存在的文檔\nGET mytest/doc/_search { \u0026#34;query\u0026#34;: { \u0026#34;nested\u0026#34;: { \u0026#34;path\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34;: { \u0026#34;must\u0026#34;: [ { \u0026#34;term\u0026#34;: { \u0026#34;user.first\u0026#34;: \u0026#34;Taylor\u0026#34; } }, { \u0026#34;term\u0026#34;: { \u0026#34;user.last\u0026#34;: \u0026#34;Swift\u0026#34; } } ] } } } } } \u0026#34;hits\u0026#34;: [ { \u0026#34;_source\u0026#34;: { \u0026#34;group\u0026#34;: \u0026#34;fans\u0026#34;, \u0026#34;user\u0026#34;: { \u0026#34;first\u0026#34;: \u0026#34;Taylor\u0026#34;, \u0026#34;last\u0026#34;: \u0026#34;Swift\u0026#34;, \u0026#34;age\u0026#34;: 30 } } } ] 但將查詢改寫成下面這樣的話，則搜索不到任何結果，因為沒有一個子對象同時滿足 user.first 為 Taylor 且 user.last 為xxx\nGET mytest/doc/_search { \u0026#34;query\u0026#34;: { \u0026#34;nested\u0026#34;: { \u0026#34;path\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34;: { \u0026#34;must\u0026#34;: [ { \u0026#34;term\u0026#34;: { \u0026#34;user.first\u0026#34;: \u0026#34;Taylor\u0026#34; } }, { \u0026#34;term\u0026#34;: { \u0026#34;user.last\u0026#34;: \u0026#34;xxx\u0026#34; } } ] } } } } } 而如果是將 bool 子句寫在 nested 的外面，表示要查詢此 nested 對象兩次，而這兩次是分別使用不同的條件，因此不需要一定要同一個子對象中同時滿足這兩個條件\n下面的查詢表示只要 user 中包含 user.first 為 Amy，且也包含 user.last 為 Smith 就行了，但不是要求一定要有一個子對象是 user.first 為 Amy 且他的 user.last 剛好也是 Smith，所以結果才能搜出一個文檔\n如果這裡將 bool 改寫在 nested 裡面，那就搜不出任何文檔了\nGET mytest/doc/_search { \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34;: { \u0026#34;filter\u0026#34;: [ { \u0026#34;nested\u0026#34;: { \u0026#34;path\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;query\u0026#34;: { \u0026#34;term\u0026#34;: { \u0026#34;user.first\u0026#34;: \u0026#34;Amy\u0026#34; } } } }, { \u0026#34;nested\u0026#34;: { \u0026#34;path\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;query\u0026#34;: { \u0026#34;term\u0026#34;: { \u0026#34;user.last\u0026#34;: \u0026#34;Smith\u0026#34; } } } } ] } } } \u0026#34;hits\u0026#34;: [ { \u0026#34;_source\u0026#34;: { \u0026#34;group\u0026#34;: \u0026#34;fans\u0026#34;, \u0026#34;user\u0026#34;: [ { \u0026#34;first\u0026#34;: \u0026#34;Amy\u0026#34;, \u0026#34;last\u0026#34;: \u0026#34;White\u0026#34;, \u0026#34;age\u0026#34;: 18 }, { \u0026#34;first\u0026#34;: \u0026#34;John\u0026#34;, \u0026#34;last\u0026#34;: \u0026#34;Smith\u0026#34;, \u0026#34;age\u0026#34;: 22 } ] } } ] 和 bool 的其他葉子子句（term、range\u0026hellip;）一起搭配使用的 nested 查詢\nGET mytest/doc/_search { \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34;: { \u0026#34;filter\u0026#34;: [ { \u0026#34;term\u0026#34;: { \u0026#34;group\u0026#34;: \u0026#34;fans\u0026#34; } }, { \u0026#34;nested\u0026#34;: { \u0026#34;path\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;query\u0026#34;: { \u0026#34;term\u0026#34;: { \u0026#34;user.first\u0026#34;: \u0026#34;Amy\u0026#34; } } } } ] } } } 嵌套對象的評分 score_mode\n假設 nested 類型的 user，儲存的是一個數組，那麼在進行嵌套查詢時，可能會匹配到多個嵌套的文檔，而每一個匹配的嵌套文檔都有自己的相關度得分\n假設有一個文檔如下，一個根文檔內，包含了3個嵌套文檔\n當查詢 \u0026ldquo;user.first = July 或 user.last = Month\u0026rdquo; 時，第一個嵌套文檔的分數最高，第二個嵌套文檔次之，第三個嵌套文檔的分數最低\n\u0026#34;hits\u0026#34;: [ { \u0026#34;_source\u0026#34;: { \u0026#34;group\u0026#34;: \u0026#34;fans\u0026#34;, \u0026#34;user\u0026#34;: [ { \u0026#34;first\u0026#34;: \u0026#34;July\u0026#34;, \u0026#34;last\u0026#34;: \u0026#34;Month\u0026#34;, \u0026#34;age\u0026#34;: 18 }, { \u0026#34;first\u0026#34;: \u0026#34;Aug\u0026#34;, \u0026#34;last\u0026#34;: \u0026#34;Month\u0026#34;, \u0026#34;age\u0026#34;: 22 }, { \u0026#34;first\u0026#34;: \u0026#34;Monday\u0026#34;, \u0026#34;last\u0026#34;: \u0026#34;Day\u0026#34;, \u0026#34;age\u0026#34;: 25 } ] } } ] 為了匯集這眾多的嵌套文檔分數到根文檔，就需要設置 score_mode 來指定怎樣去計算這些嵌套文檔的總分\n默認情況下，根文檔的分數是這些嵌套文檔分數的平均值，就是默認 score_mode = avg\n可以透過設置 score_mode 為 avg、max、sum、none (直接返回1.0常數值分數)，來控制根文檔的得分策略\n不過要注意，如果 nested 查詢放在一個 filter 子句中，就算定義了 score_mode 也不會生效，因為 filter 不打分，所以 score_mode 就沒有任何意義\nGET mytest/doc/_search { \u0026#34;query\u0026#34;: { \u0026#34;nested\u0026#34;: { \u0026#34;path\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;score_mode\u0026#34;: \u0026#34;max\u0026#34;, //返回最佳匹配嵌套文檔的_score給根文檔使用 \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34;: { \u0026#34;should\u0026#34;: [ { \u0026#34;term\u0026#34;: { \u0026#34;user.first\u0026#34;: \u0026#34;July\u0026#34; } }, { \u0026#34;term\u0026#34;: { \u0026#34;user.last\u0026#34;: \u0026#34;Month\u0026#34; } } ] } } } } } 使用嵌套對象的字段來排序\n儘管嵌套對象儲存於獨立的隱藏文檔中，但依然有方法按照嵌套字段的值排序 假設我們想要查出 user.first 為 Amy，且依照 user.age 這個內部對象的字段，由小到大進行排序，查詢語句如下 GET mytest/doc/_search { \u0026#34;query\u0026#34;: { \u0026#34;nested\u0026#34;: { \u0026#34;path\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;query\u0026#34;: { \u0026#34;term\u0026#34;: { \u0026#34;user.first\u0026#34;: \u0026#34;Amy\u0026#34; } } } }, \u0026#34;sort\u0026#34;: { \u0026#34;user.age\u0026#34;: { \u0026#34;nested\u0026#34;: { \u0026#34;path\u0026#34;: \u0026#34;user\u0026#34; }, \u0026#34;order\u0026#34;: \u0026#34;asc\u0026#34; } } } ","permalink":"https://kucw.io/blog/2018/6/elasticsearch-nested/","tags":null,"title":"ElasticSearch - 嵌套對象 nested"},{"categories":["Elastic Search"],"contents":" ES 中的 term 和 match 牽扯到了分詞器、mapping、倒排索引等，如果不熟悉相關知識，請先看 ElasticSearch - index mapping（5.x以上） 這篇文章 term 是直接把 field 拿去查詢倒排索引中確切的 term match 會先對 field 進行分詞操作，然後再去倒排索引中查詢 具體實例 假設有一個字段 nickname，存放的類型是 text，因此當新增一筆文檔時，內容會被分詞器分詞，然後才儲存進倒排索引 假設插入了一筆文檔，其中 \u0026quot;nickname\u0026quot;: \u0026quot;1 hello\u0026quot;，分詞過後變為 1、hello，因此倒排索引中儲存的是兩筆索引 1 和 hello，而不是一筆索引 1 hello 使用 match 做查詢 \u0026quot;match\u0026quot;: \u0026quot;1-hello\u0026quot; : 成功，因為 match 把 1-hello 分詞成 1、hello，而 1 和 hello 都存在在倒排索引中，所以不只能夠查到，_score 還很高 \u0026quot;match\u0026quot;: \u0026quot;1\u0026quot; : 成功，1 被分詞過後還是 1，而 1 存在在倒排索引中 \u0026quot;match\u0026quot;: \u0026quot;hello how r u\u0026quot; : 成功，match 把 hello how r u 分詞成 hello、how、r、u，而 hello 存在在倒排索引中 使用 term 做查詢 \u0026quot;term\u0026quot;: \u0026quot;2222-hello : 失敗，倒排索引只有 1、hello，並沒有 2222-hello \u0026quot;term\u0026quot;: \u0026quot;hello\u0026quot; : 成功，因為倒排索引中有 hello \u0026quot;term\u0026quot;: \u0026quot;1 hello\u0026quot; : 失敗，雖然 1 hello 和我們當時插入的數據一模一樣，但是因為倒排索引在建立索引時把原始的數據分詞了才儲存進索引，裡面存的是 1 和 hello，並沒有存放 1 hello，因此查詢失敗 ","permalink":"https://kucw.io/blog/2018/6/elasticsearch-term-match/","tags":null,"title":"ElasticSearch - term 和 match 的差別"},{"categories":["Java"],"contents":" Java 基本內置 annotation\n@Override\n@Override用在方法上，表示這個方法重寫了父方法，如toString() 如果父方法沒有這個方法，那麼就無法編譯過 如果實現接口，需要在每個實現方法都加上@Override，說明這是要實現那個接口的方法，而不是自己新創的方法 @Deprecated\n@Deprecated 表示這個方法已經過期，不建議開發者使用 暗示在將來某個不確定的版本，就有可能會被取消掉 @SuppressWarnings\n@SuppressWarnings是抑制警告的意思，這個注解主要的用處就是忽略警告信息\n常見的警告值\ndeprecation : 使用了不贊成使用的類或方法時的警告 unused : 某個變量被定義，但是沒有被使用 path : 在類路徑、源文件路徑等中有不存在的路徑時的警告 具體實例\npublic class Test { //定義了一個不建議使用了方法 @Deprecated public void sayHello() { System.out.println(\u0026#34;Hello\u0026#34;); } //聲明以下的方法，自動忽略deprecation和unused的警告，不要在console上報出warn //以下的方法使用了被Deprecated的方法sayHello //也沒有使用到一個被定義的變量 i //但是因為設置了警告忽略所以不會有warning @SuppressWarnings({\u0026#34;deprecation\u0026#34;, \u0026#34;unused\u0026#34;}) public static void main(String[] args) { int i; Test test = new Test(); test.sayHello(); } } @FunctionallInterface\nJava 1.8新增的注解，用於約定函數式接口\n函數式接口存在的意義，主要是配合Lambda表達式來使用\n如果接口中只允許有一個public的抽象方法，該接口就稱為函數式接口 (不過此接口可以包含多個default方法或是多個static方法) 能夠包含多個default和static方法的原因是因為在使用函數式編程時，為了能夠使用lambda表達式，所以每個接口的實現類只允許實現一個方法 而default方法和static方法不允許實現類實現，所以就不會影響lambda表達式，因此就可以存在在函數式接口裡 //匿名實現類 new Function\u0026lt;Integer, String\u0026gt; 實現了Function接口 List\u0026lt;Integer\u0026gt; intList = Lists.newArrayList(1, 2, 3); List\u0026lt;String\u0026gt; stringList = Lists.transform(intList, new com.google.common.base.Function\u0026lt;Integer, String\u0026gt;() { @Override public String apply(Integer input) { return input + \u0026#34;aa\u0026#34;; } }); //可以轉換成下面的lambda表達式 List\u0026lt;Integer\u0026gt; intList = Lists.newArrayList(1, 2, 3); List\u0026lt;String\u0026gt; stringList = Lists.transform(intList, input -\u0026gt; input + \u0026#34;aa\u0026#34;); 使用 @FunctionallInterface 自定義函數式接口\n//自定義一個函數式接口，並且只有一個public的抽象方法 @FunctionalInterface public interface MyFunction { public String myApply(); } //定義一個類，讓這個類去使用 MyFunction public class Hello { void say(MyFunction myFunction) { System.out.println(myFunction.myApply()); } } public class MainTest { public static void main(String[] args) { Hello hello = new Hello(); //輸出 Hello World hello.say(new MyFunction() { @Override public String myApply() { return \u0026#34;Hello World\u0026#34;; } }); //可以轉換為以下的lambda表達式，同樣輸出 Hello World hello.say(() -\u0026gt; \u0026#34;Hello World\u0026#34;); } } 自定義新的 annotation\n使用元注解(meta annotation)來設定一個注解的作用，可以說他是 \u0026ldquo;自定義注解\u0026rdquo; 的注解\n元注解的種類\n@Target : 表示這個注解可以放在什麼位置上，也就是可以修飾 ElementType.TYPE : 能修飾類、接口、枚舉、注解 ElementType.FIELD : 能修飾字段、枚舉的常量 ElementType.METHOD : 能修飾方法 ElementType.PARAMETER : 能修飾方法參數 ElementType.CONSTRUCTOR : 能修飾構造函數 ElementType.LOCAL_VARIABLE : 能修飾局部變量 ElementType.ANNOTATION_TYPE : 能修飾注解 (元注解就是此種) ElementType.PACKAGE : 能修飾包 @Retention : 表示這個注解的生命週期 可選的值有三種 RetentionPolicy.SOURCE 表示此注解只在源代碼中有效果，不會編譯進class文件 @Override就是這種注解 RetentionPolicy.CLASS 表示此注解除了在源代碼有效果，也會編譯進class文件，但是在運行期是無效果的 @Retention的默認值，即是當沒有指定@Retention的時候，就會是這種類型 RetentionPolicy.RUNTIME 表示此注解從源代碼到運行期一直存在 程序可以透過反射獲取這個注解的信息 @Inherited : 表示該注解有繼承性，即是子類可以拿到繼承父類上的注解信息 @Documetned : 在用javadoc命令生成API文檔後，文檔裡會出現該注解說明 @Repeatable (java1.8新增) 當沒有使用@Repeatable修飾的時候，注解在同一個位置只能出現一次，如果寫重複的兩次就會報錯 但是使用@Repeatable之後，就能夠在同一個地方使用多次 使用@Repeatable的時機通常在想要取得一組資訊時 像是一個User裡面可能有id、name屬性，我們想要以User為單位來取 但是因為注解裡面無法使用自定義對象 所以只能透過@Repeatable這種方法來達成目標 注解參數的數據類型\n支持的類型 所有基本數據類型 (int, float, boolean, byte, double, char, long, short) String類型 Class類型 enum類型 Annotation類型 以上所有類型的數組 不支持的類型 自定義對象 注解參數\n可以使用default來自定義某個參數的默認值 如果注解裡面只有一個參數value(名字很重要，只能用這個名字)，或是其他參數值都有default設定，這時使用此注解時可以不用打參數值，例如 @GetMapping(\u0026quot;/\u0026quot;) 具體實例\n如何使用一個自定義的注解\n//自定義注解 MyAnnotaion，使用 @interface 定義他是一個注解 @Target({ElementType.METHOD, ElementType.TYPE}) @Retention(RetentionPolicy.RUNTIME) @Documented @interface MyAnnotation { String[] value(); String comment() default \u0026#34;hello\u0026#34;; } //使用自定義的注解 MyAnnotation，並給value值\u0026#34;John\u0026#34; @MyAnnotation(\u0026#34;John\u0026#34;) class MyTest { public static void test(){ //透過反射取得某個類上的某個注解 MyAnnotation config = MyTest.class.getAnnotation(MyAnnotation.class); System.out.println(\u0026#34;value: \u0026#34; + config.value() + \u0026#34;, comment: \u0026#34; + config.comment()); } } public class Main{ public static void main(String[] args) { MyTest.test(); //輸出 value: John, comment: hello } } 使用 @Repeatable 元注解\npublic class FindFiles{ //此注解接住 FileType 注解，並把它存起來 @Target(ElementType.METHOD) @Retention(RetentionPolicy.RUNTIME) public @interface FileTypes { FileType[] value(); } //自定義的注解，可以想像成是一個自定義的對象，裡面有很多成員變量 //使用 @Repeatable 讓這個注解可以被重複使用 //並且 @Repeatable 還指定這個 FileType 注解要放到 FileTypes 注解裡 @Target(ElementType.METHOD) @Retention(RetentionPolicy.RUNTIME) @Repeatable(FileTypes.class) public @interface FileType { String value(); String comment(); } @FileType(value=\u0026#34;.java\u0026#34;, comment=\u0026#34;java\u0026#34;) @FileType(value=\u0026#34;.html\u0026#34;, comment=\u0026#34;html\u0026#34;) @FileType(value=\u0026#34;.css\u0026#34;, comment=\u0026#34;css\u0026#34;) public void work() throws Exception { //透過反射取得類，並取得work方法，然後再work方法上的FileType注解們 FileType[] fileTypes = this.getClass().getMethod(\u0026#34;work\u0026#34;).getAnnotationsByType(FileType.class); for (FileType fileType : fileTypes) { System.out.println(\u0026#34;value: \u0026#34; + fileType.value() + \u0026#34;, comment: \u0026#34; + fileType.comment()); } } public static void main(String[] args) throws Exception { new FindFiles().work(); } } //輸出 value: .java, comment: java value: .html, comment: html value: .css, comment: css ","permalink":"https://kucw.io/blog/2018/6/java-annotation/","tags":null,"title":"Java - annotation 的使用"},{"categories":["Elastic Search"],"contents":" ElasticSearch 的 analysis 實際上是將三個功能封裝在一起，這三個功能按照順序執行，而這三個功能都是能自定義的 字符過濾器 (char_filter) 首先，字符串按順序通過每個字符過濾器，他們的任務是在分詞前整理字符串 一個字符過濾器可以用來去掉HTML，或者將\u0026amp;轉化成and 分詞器 (tokenizer) 其次，字符串被分詞器分爲單個的詞條，一個簡單的分詞器遇到空格和標點的時候，可能會將文本拆分成詞條 Hello how are you?會被ES預設的分詞器standard分成hello、how、are、you Token 過濾器 (filter) 最後，詞條按順序通過每個 token 過濾器，這個過程可能會改變詞條(Quick -\u0026gt; quick)、刪除詞條(a、an、and、the\u0026hellip;)、增加詞條(jump和leap這種同義詞) 自定義 analysis 格式 PUT mytest { \u0026#34;setting\u0026#34;: { \u0026#34;analysis\u0026#34;: { \u0026#34;char_filter\u0026#34;: { 自定義的字符過濾器 }, \u0026#34;tokenizer\u0026#34;: { 自定義的分詞器 }, \u0026#34;filter\u0026#34;: { 自定義的token過濾器 }, \u0026#34;analyzer\u0026#34;: { 自定義的分析器，可以將上面的char_filter、tokenizer、filter用不同的組合拼起來，形成不同的分析器 } } } } 具體實例 PUT mytest { \u0026#34;settings\u0026#34;: { \u0026#34;analysis\u0026#34;: { \u0026#34;char_filter\u0026#34;: { \u0026#34;\u0026amp;_to_and\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;mapping\u0026#34;, \u0026#34;mappings\u0026#34;: [\u0026#34;\u0026amp;=\u0026gt; and \u0026#34;] }, \u0026#34;xxx\u0026#34;: {....}, \u0026#34;yyy\u0026#34;: {....} }, \u0026#34;filter\u0026#34;: { \u0026#34;my_stopwords\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;stop\u0026#34;, \u0026#34;stopwords\u0026#34;: [\u0026#34;the\u0026#34;, \u0026#34;a\u0026#34;] } }, \u0026#34;analyzer\u0026#34;: { //自定義分析器，將想要的char_filter、tokenizer、filter給加載進來 //數組順序很重要，因為是照順序執行，先執行htmp_strip，再執行\u0026amp;_to_and，然後才去執行tokenizer \u0026#34;my_analyzer\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;custom\u0026#34;, \u0026#34;char_filter\u0026#34;: [\u0026#34;htmp_strip\u0026#34;, \u0026#34;\u0026amp;_to_and\u0026#34;], \u0026#34;tokenizer\u0026#34;: \u0026#34;standard\u0026#34;, \u0026#34;filter\u0026#34;: [\u0026#34;lowercase\u0026#34;, \u0026#34;my_stopwords\u0026#34;] } } } }, \u0026#34;mappings\u0026#34;: { \u0026#34;doc\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;nickname\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;analyzer\u0026#34;: \u0026#34;my_analyzer\u0026#34; //使用自定義的分析器 } } } } } 控制分析器 search_analyzer、analyzer 分析器主要有兩種情況會被使用，一種是插入文檔時，將text類型的字段做分詞然後插入倒排索引，第二種就是在查詢時，先對要查詢的text類型的輸入做分詞，再去倒排索引搜索\n如果想要讓 索引 和 查詢 時使用不同的分詞器，ElasticSearch也是能支持的，只需要在字段上加上search_analyzer參數\n在索引時，只會去看字段有沒有定義analyzer，有定義的話就用定義的，沒定義就用ES預設的 在查詢時，會先去看字段有沒有定義search_analyzer，如果沒有定義，就去看有沒有analyzer，再沒有定義，才會去使用ES預設的 具體實例\nPUT mytest { \u0026#34;mappings\u0026#34;: { \u0026#34;doc\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;nickname\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;analyzer\u0026#34;: \u0026#34;standard\u0026#34;, //索引時使用standard分詞器 \u0026#34;search_analyzer\u0026#34;: \u0026#34;simple\u0026#34; //查詢時使用simple分詞器 }, \u0026#34;name\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;analyzer\u0026#34;: \u0026#34;standard\u0026#34; //索引和查詢都使用standard分詞器 } } } } } ","permalink":"https://kucw.io/blog/2018/6/elasticsearch-analysis/","tags":null,"title":"ElasticSearch - 自定義 analysis"},{"categories":["Elastic Search"],"contents":" Elasticsearch支持的基本類型\n字符串 : text, keyword text : 存儲數據的時候，會自動分詞，並生成索引 keyword : 存儲數據的時候，不會分詞，而是直接整個詞拿去建索引 整數 : byte, short, integer, long 浮點數 : float, double 布爾型 : boolean 日期 : date 自定義 mapping\nindex : 設置此字段能不能被查詢，就是決定要不要將這個字段放進倒排索引裡\n若 index 設置為 true（默認是 true），則表示這個這個字段會被放進倒排索引裡，如果是 text 就是分詞過後放進索引，如果是 keyword、integer\u0026hellip;就直接整段放進索引裡 若 index 設置為 false，則表示這個字段不放進倒排索引裡，因此不能查詢這個字段（因為他不存在於倒排索引裡） 通常這種被設成 false 的字段，可以想像成是屬於一種附屬的字段，就是不能被 match、term 查詢，但是當該文檔被其他搜索條件搜出來時，他可以附帶的一起被找出來，因為他們同屬於同一個文檔 analyzer : 主要用在 text 類型的字段上，就是設定要使用哪種分詞器來建立索引\n可以使用內建的分詞器，或是使用自定義的分詞器 可以使用 /_analyze 測試分析器具體會將句子分詞成什麼樣子，它能幫助我們理解 Elasticsearch 索引內部發生了什麼\nGET _analyze { \u0026#34;analyzer\u0026#34;: \u0026#34;standard\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;Text to analyze\u0026#34; } 具體實例\nmapping\nPUT mytest { \u0026#34;mappings\u0026#34;: { \u0026#34;doc\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;name\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34;, \u0026#34;index\u0026#34;: false }, \u0026#34;uid\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;integer\u0026#34; }, \u0026#34;nickname\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;analyzer\u0026#34;: \u0026#34;standard\u0026#34; } } } } } 搜索 uid 時，name 會一起被找出來\nGET mytest/_search { \u0026#34;query\u0026#34;: { \u0026#34;term\u0026#34;: { \u0026#34;uid\u0026#34;: 1 } } } { \u0026#34;uid\u0026#34;: 1, \u0026#34;name\u0026#34;: \u0026#34;1-hello\u0026#34;, \u0026#34;nickname\u0026#34;: \u0026#34;1-nickname\u0026#34; } 搜索 name，會報 error\nGET mytest/_search { \u0026#34;query\u0026#34;: { \u0026#34;term\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;1-hello\u0026#34; } } } \u0026#34;error\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;illegal_argument_exception\u0026#34;, \u0026#34;reason\u0026#34;: \u0026#34;Cannot search on field [name] since it is not indexed.\u0026#34; } 更新 mapping\n當首次創建一個 index 的時候，可以指定類型的 mapping，但假設後來想要增加一個新的映射字段，可以使用 /_mapping 把新的字段加進 mapping 映射裡\n可以增加一個新的映射，但是不能修改存在的映射，原因是因為這個映射可能有文檔去用，如果改了映射的類型，可能會導致 index 的數據出錯，因此只能新加字段進去，不能修改 具體實例\n在 mytest 映射中的 doc 類型增加一個新的名爲 tag 的 keyword\nPUT mytest/_mapping/doc { \u0026#34;properties\u0026#34;: { \u0026#34;tag\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34; } } } 在 ES 中更新 mapping（新增一個字段）會產生的問題\n雖然 ES 支持更新映射在 mapping 中新增字段，但是這樣會造成一個問題，就是舊的文檔並不會自動更新產生新的字段\n假設舊文檔有 name、nickname 這兩個字段，並且已經插入了兩筆數據\n{ \u0026#34;name\u0026#34;: \u0026#34;Jackson\u0026#34;, \u0026#34;nickname\u0026#34;: \u0026#34;jack\u0026#34; } { \u0026#34;name\u0026#34;: \u0026#34;Amy\u0026#34;, \u0026#34;nickname\u0026#34;: \u0026#34;a\u0026#34; } 此時插入一個新的字段 sex，並且插入一筆新的數據\n{ \u0026#34;name\u0026#34;: \u0026#34;NewYork\u0026#34;, \u0026#34;nickname\u0026#34;: \u0026#34;new\u0026#34;, \u0026#34;sex\u0026#34;: 1 } 執行 \u0026quot;match_all\u0026quot;: {} 查詢時，結果如下\n由於 Jackson 和 Amy 並沒有 sex 這個字段，所以雖然執行 match_all 搜索時能被搜出來，但是搜索 \u0026quot;term\u0026quot;: { \u0026quot;sex\u0026quot;: 1 } 的話，就搜索不出來\n{ \u0026#34;name\u0026#34;: \u0026#34;Jackson\u0026#34;, \u0026#34;nickname\u0026#34;: \u0026#34;jack\u0026#34; } { \u0026#34;name\u0026#34;: \u0026#34;Amy\u0026#34;, \u0026#34;nickname\u0026#34;: \u0026#34;a\u0026#34; } { \u0026#34;name\u0026#34;: \u0026#34;NewYork\u0026#34;, \u0026#34;nickname\u0026#34;: \u0026#34;new\u0026#34;, \u0026#34;sex\u0026#34;: 1 } 我們希望的狀況是，增加一個新字段，舊文檔應該也要設置一個預設值，像是 sex=0，而不是整個字段消失，如此在查詢時邏輯才不會有問題\n解決舊文檔沒有新字段這個問題主要有3種方法\n新建一個 index，使用 scroll + bulk insert 將數據從舊的索引批量插入到新索引中\n可以在 java 裡自定義舊文檔預設值的邏輯 新建一個 index，使用 ES 提供的 reindex API 將數據從舊的索引 reindex 到新索引\n需要使用 ES 的腳本 script，在 reindex 的請求裡定義舊文檔預設值的邏輯\nPOST _reindex { \u0026#34;source\u0026#34;: { \u0026#34;index\u0026#34;: \u0026#34;mytest\u0026#34; }, \u0026#34;dest\u0026#34;: { \u0026#34;index\u0026#34;: \u0026#34;mytest2\u0026#34; }, \u0026#34;script\u0026#34;: { \u0026#34;source\u0026#34;: \u0026#34;if (ctx._source.new == null) {ctx._source.new = params.new}\u0026#34;, \u0026#34;params\u0026#34;: { \u0026#34;new\u0026#34;: \u0026#34;good\u0026#34; }, \u0026#34;lang\u0026#34;: \u0026#34;painless\u0026#34; } } 使用 update_by_query 更新所有舊文檔，給他們加上新的字段\n","permalink":"https://kucw.io/blog/2018/6/elasticsearch-index-mapping/","tags":null,"title":"ElasticSearch - index mapping（5.x以上）"}]